,abstract,abstract-zh,authors,date,title,title-de,title-zh,url
0,"Software Bill of Materials (SBOMs) are increasingly regarded as essential tools for securing software supply chains (SSCs), yet their real-world use and adoption barriers remain poorly understood. This systematic literature review synthesizes evidence from 40 peer-reviewed studies to evaluate how SBOMs are currently used to bolster SSC security. We identify five primary application areas: vulnerability management, transparency, component assessment, risk assessment, and SSC integrity. Despite clear promise, adoption is hindered by significant barriers: generation tooling, data privacy, format/standardization, sharing/distribution, cost/overhead, vulnerability exploitability, maintenance, analysis tooling, false positives, hidden packages, and tampering. To structure our analysis, we map these barriers to the ISO/IEC 25019:2023 Quality-in-Use model, revealing critical deficiencies in SBOM trustworthiness, usability, and suitability for security tasks. We also highlight key gaps in the literature. These include the absence of applying machine learning techniques to assess SBOMs and limited evaluation of SBOMs and SSCs using software quality assurance techniques. Our findings provide actionable insights for researchers, tool developers, and practitioners seeking to advance SBOM-driven SSC security and lay a foundation for future work at the intersection of SSC assurance, automation, and empirical software engineering.","材料软件法案(SBOMs)日益被视为保障软件供应链的基本工具,然而,其实际使用和采用障碍仍然不为人所知。这一系统文献审查综合了40项经同行审查的研究中的证据,以评价目前如何利用SBOMs加强SSC安全。我们确定了五个主要应用领域:脆弱性管理、透明度、组成部分评估、风险评估和SSC完整性。尽管有明确的承诺,但采用却受到重大障碍的阻碍:生成工具、数据隐私、格式/标准化、共享/分发、成本/管理、脆弱性利用、维护、分析工具、假阳性、隐藏的软件包和篡改。我们的分析结构为ISO/IEC 25019:2023质量使用模型绘制了这些障碍,揭示了SBOM的可靠性、可用性和安全任务的适宜性。我们还强调了文献中的关键差距。其中包括:没有应用机器学习技术来评估SBOMs、共享/分发、成本/管理、对SBOMMs和SSCSSC的有限评价。我们的调查结果为研究人员、工具开发商和SBSAS-SAS-SUSB的交叉化工作提供了可操作基础以及SISISSBSB。我们的调查结果为SAS-SAS-SB的高级安全基础和操作基础和操作者提供了可操作基础。","Eric O'Donoghue, Yvette Hastings, Ernesto Ortiz, A. Redempta Manzi Muneza",2025-06-05T16:49:12Z,Software Bill of Materials in Software Supply Chain Security A   Systematic Literature Review,Software Bill of Materials in Software Supply Chain Sicherheit Ein systematischer Literaturbericht,软件供应链安全材料法案系统化文献审查,http://arxiv.org/abs/2506.03507v2
1,"The Model Context Protocol (MCP) is an emerging standard designed to enable seamless interaction between Large Language Model (LLM) applications and external tools or resources. Within a short period, thousands of MCP services have already been developed and deployed. However, the client-server integration architecture inherent in MCP may expand the attack surface against LLM Agent systems, introducing new vulnerabilities that allow attackers to exploit by designing malicious MCP servers. In this paper, we present the first systematic study of attack vectors targeting the MCP ecosystem. Our analysis identifies four categories of attacks, i.e., Tool Poisoning Attacks, Puppet Attacks, Rug Pull Attacks, and Exploitation via Malicious External Resources. To evaluate the feasibility of these attacks, we conduct experiments following the typical steps of launching an attack through malicious MCP servers: upload-download-attack. Specifically, we first construct malicious MCP servers and successfully upload them to three widely used MCP aggregation platforms. The results indicate that current audit mechanisms are insufficient to identify and prevent the proposed attack methods. Next, through a user study and interview with 20 participants, we demonstrate that users struggle to identify malicious MCP servers and often unknowingly install them from aggregator platforms. Finally, we demonstrate that these attacks can trigger harmful behaviors within the user's local environment-such as accessing private files or controlling devices to transfer digital assets-by deploying a proof-of-concept (PoC) framework against five leading LLMs. Additionally, based on interview results, we discuss four key challenges faced by the current security ecosystem surrounding MCP servers. These findings underscore the urgent need for robust security mechanisms to defend against malicious MCP servers.","示范背景协议(MCP)是一个新兴标准,旨在让大语言模型(LLM)应用程序和外部工具或资源之间实现无缝互动。在短时期内,已经开发并部署了数千项MCP服务。然而,MCP所固有的客户服务器整合架构可能会扩大对LLM代理系统的攻击面面面,引入新的弱点,使攻击者能够通过设计恶意MCP服务器加以利用。在本文中,我们介绍了针对MCP生态系统的攻击矢量的首次系统研究。我们的分析确定了四类攻击,即工具中毒袭击、布偶袭击、鲁格拉袭击和通过恶意外部资源进行剥削。在短短时期内,已经开发并部署了数千项MCP服务。为了评估这些攻击的可行性,我们在通过恶意 MCP服务器发动攻击的典型步骤之后进行了实验。具体地说,我们首先建造恶意的MCP服务器,并成功地将它们上传到三个广泛使用的MCP聚合平台。结果表明,目前的审计机制不足以识别和防止拟议的攻击方法。接下来,通过对20名参与者的用户进行一项保护,我们证明用户努力辨别了恶意的MCP服务器,我们无法识别当前四类关键的磁盘服务器,然后才能将这五种主要的磁盘服务器,然后我们才能在进入这些平台上显示这些有害的磁盘服务器上,我们进入了这些机器。","Hao Song, Yiming Shen, Wenxuan Luo, Leixin Guo, Ting Chen, Jiashui Wang, Beibei Li, Xiaosong Zhang, Jiachi Chen",2025-06-05T16:22:09Z,Beyond the Protocol: Unveiling Attack Vectors in the Model Context   Protocol Ecosystem,Jenseits des Protokolls: Enthüllen von Angriffsvektoren im Modell Kontext Protokoll Ökosystem,"《议定书》之后的《议定书》:《示范背景议定书》中的 "" 固定攻击矢量 "" 生态系统",http://arxiv.org/abs/2506.02040v2
2,"The assurance of mobile app GUI is more and more significant. Automated GUI testing approaches of different strategies have been developed, while there are still huge gaps between the approaches and the app business logic, not taking the completion of specific testing scenarios as the exploration target, leading to the exploration missing of critical app functionalities. Learning from the manual testing, which takes testing scenarios with app business logic as the basic granularity, in this paper, we utilize the LLMs to understand the semantics presented in app GUI and how they are mapped in the testing context based on specific testing scenarios. Then, scenario-based GUI tests are generated with the guidance of multi-agent collaboration. Specifically, we propose ScenGen, a novel LLM-guided scenario-based GUI testing approach involving five agents to respectively take responsibilities of different phases of the manual testing process. The Observer perceives the app GUI state by extracting GUI widgets and forming GUI layouts, understanding the expressed semantics. Then the app GUI info is sent to the Decider to make decisions on target widgets based on the target testing scenarios. The decision-making process takes the completion of specific testing scenarios as the exploration target. The Executor then executes the demanding operations on the apps. The execution results are checked by the Supervisor on whether the generated tests are consistent with the completion target of the testing scenarios, ensuring the traceability of the test generation and execution. Furthermore, the corresponding GUI test operations are recorded to the context memory by Recorder as an important basis for further decision-making, meanwhile monitoring the runtime bug occurrences. ScenGen is evaluated and the results show that ScenGen can effectively generate scenario-based GUI tests guided by LLMs.","移动应用程序 GUI 的保证越来越重要。 不同战略的自动图形用户界面测试方法已经开发出来, 虽然在方法与应用程序业务逻辑之间仍然存在着巨大的差距, 但没有将完成具体测试情景作为勘探目标, 导致关键应用程序功能的探索缺失。 从手工测试中学习, 将应用商业逻辑测试情景作为基本颗粒, 我们使用 LLMS 来理解 App GUI 中显示的语义, 以及如何根据具体测试情景在测试背景下进行绘图。 然后, 在多试剂合作的指导下, 生成基于情景的图形测试。 具体而言, 我们提议ScenGen, 新的LLM- 指导情景基于情景的图形测试方法, 由5个代理商分别承担人工测试过程不同阶段的责任。 观察员通过提取 GUB 部件和设置图形布局来理解应用图形界面状态。 然后, 应用程序GUIFinf 被发送给决策者, 以便根据目标测试情景做出进一步的决定。 决策过程将相应的测试情景进行完成, 进行相应的测试过程, 要求执行重要操作, 运行GLBIL 进行持续的测试, 运行将运行测试, 运行将运行运行测试结果与持续运行运行进行。 运行运行运行运行 运行 运行 运行测试 运行 运行 运行测试 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 测试 运行 运行 测试 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行 运行","Shengcheng Yu, Yuchen Ling, Chunrong Fang, Quan Zhou, Chunyang Chen, Shaomin Zhu, Zhenyu Chen",2025-06-05T14:27:40Z,LLM-Guided Scenario-based GUI Testing,LLM-geführte Szenario-basierte GUI-Tests,LLM-LLM 指导设想情况用户界面测试,http://arxiv.org/abs/2506.05079v1
3,"Address Sanitizer (ASan) is a sharp weapon for detecting memory safety violations, including temporal and spatial errors hidden in C/C++ programs during execution. However, ASan incurs significant runtime overhead, which limits its efficiency in testing large software. The overhead mainly comes from sanitizer checks due to the frequent and expensive shadow memory access. Over the past decade, many methods have been developed to speed up ASan by eliminating and accelerating sanitizer checks, however, they either fail to adequately eliminate redundant checks or compromise detection capabilities. To address this issue, this paper presents Tech-ASan, a two-stage check based technique to accelerate ASan with safety assurance. First, we propose a novel two-stage check algorithm for ASan, which leverages magic value comparison to reduce most of the costly shadow memory accesses. Second, we design an efficient optimizer to eliminate redundant checks, which integrates a novel algorithm for removing checks in loops. Third, we implement Tech-ASan as a memory safety tool based on the LLVM compiler infrastructure. Our evaluation using the SPEC CPU2006 benchmark shows that Tech-ASan outperforms the state-of-the-art methods with 33.70% and 17.89% less runtime overhead than ASan and ASan--, respectively. Moreover, Tech-ASan detects 56 fewer false negative cases than ASan and ASan-- when testing on the Juliet Test Suite under the same redzone setting.","桑尼泽(ASan)是发现记忆安全违规现象(包括C/C++方案在执行期间隐藏的时间和空间错误)的尖锐武器。然而,阿桑拥有大量运行时间的间接费用,这限制了测试大型软件的效率。管理费用主要来自清洁剂检查,因为经常和昂贵的影子内存访问。在过去十年里,通过消除和加速防疫检查,开发了许多方法来加速桑尼安,但是,它们要么未能充分消除多余的检查或妥协检测能力。为解决这一问题,本文展示了基于C/C++方案在执行期间加速桑尼的两阶段检查技术ASan。首先,我们提出了一个新的两阶段检查算法,它利用神奇价值的比较来减少大部分昂贵的影子内存访问。第二,我们设计了一个高效的优化器来消除重复性检查,它结合了用于消除循环检查的新算法。第三,我们用LLVM编译系统基础设施将Tech-A桑尼作为记忆红红工具。我们使用SPU2006基准来加速桑桑的测试方法,显示桑桑比亚测试案例少一次。","Yixuan Cao, Yuhong Feng, Huafeng Li, Chongyi Huang, Fangcao Jian, Haoran Li, Xu Wang",2025-06-05T13:32:48Z,Tech-ASan: Two-stage check for Address Sanitizer,Tech-ASan: Zweistufiger Check für Address Sanitizer,Tech-Asan:地址防疫剂两阶段检查,http://arxiv.org/abs/2506.05022v1
4,"Accessing quality preparation and feedback for the Romanian Bacalaureat exam is challenging, particularly for students in remote or underserved areas. This paper introduces BacPrep, an experimental online platform exploring Large Language Model (LLM) potential for automated assessment, aiming to offer a free, accessible resource. Using official exam questions from the last 5 years, BacPrep employs one of Google's newest models, Gemini 2.0 Flash (released Feb 2025), guided by official grading schemes, to provide experimental feedback. Currently operational, its primary research function is collecting student solutions and LLM outputs. This focused dataset is vital for planned expert validation to rigorously evaluate the feasibility and accuracy of this cutting-edge LLM in the specific Bacalaureat context before reliable deployment. We detail the design, data strategy, status, validation plan, and ethics.","罗马尼亚巴卡拉乌雷亚考试的质量准备和反馈是困难的,特别是对偏远地区或服务不足地区的学生而言。本文介绍BacPrep,这是一个实验性在线平台,探讨大语言模型的自动评估潜力,目的是提供一个免费、无障碍的资源。利用过去五年的官方考试问题,BacPrep在官方评分计划的指导下,利用谷歌的最新模型之一Gemini 2.0 Flash(2025年2月发布)提供实验反馈。目前,其主要研究功能是收集学生解决方案和LLLM产出。这一重点数据集对于计划的专家验证至关重要,以便在可靠部署之前严格评估具体巴卡拉乌雷亚特背景下这一尖端LLM的可行性和准确性。我们详细介绍了设计、数据战略、状况、验证计划和道德规范。","Dumitran Adrian Marius, Dita Radu",2025-06-05T13:02:06Z,BacPrep: An Experimental Platform for Evaluating LLM-Based Bacalaureat   Assessment,BacPrep: Eine experimentelle Plattform zur Bewertung von LLM-basiertem Bacalaureat Assessment,BacPrep:评估以LLM为基础的Bakaraureat评估的实验平台,http://arxiv.org/abs/2506.04989v1
5,"Software vulnerabilities pose significant security threats, requiring effective mitigation. While Automated Program Repair (APR) has advanced in fixing general bugs, vulnerability patching, a security-critical aspect of APR remains underexplored. This study investigates pre-trained language models, CodeBERT and CodeT5, for automated vulnerability patching across six datasets and four languages. We evaluate their accuracy and generalization to unknown vulnerabilities. Results show that while both models face challenges with fragmented or sparse context, CodeBERT performs comparatively better in such scenarios, whereas CodeT5 excels in capturing complex vulnerability patterns. CodeT5 also demonstrates superior scalability. Furthermore, we test fine-tuned models on both in-distribution (trained) and out-of-distribution (unseen) datasets. While fine-tuning improves in-distribution performance, models struggle to generalize to unseen data, highlighting challenges in robust vulnerability detection. This study benchmarks model performance, identifies limitations in generalization, and provides actionable insights to advance automated vulnerability patching for real-world security applications.","软件的弱点构成严重的安全威胁,需要有效缓解。虽然自动程序修复(APR)在解决一般故障、脆弱性补补补方面有所进展,但非洲同行审议机构的安全关键方面仍未得到充分探讨。本研究调查了经过预先培训的语言模式、代码BERT和代码T5, 用于在6个数据集和4种语文之间进行自动补补补的自动脆弱性。我们评估了这两个模式的准确性和对未知脆弱性的概括性。结果显示,虽然这两个模式在零散或稀少的情况下面临挑战,但代码BERT在这类情况下的表现相对好,而代码T5在捕捉复杂的脆弱性模式方面表现也比较好。代码T5也显示了更高的可扩展性。此外,我们测试了在分配(经过培训的)和分配(不见的)数据集方面经过精细调整的模型。同时微调了分配性业绩,模型努力推广到看不见的数据,突出了可靠脆弱性探测方面的挑战。本研究模型的性能基准、查明了普遍性的局限性,并提供可操作的洞察力,以推进现实世界安全应用的自动弥补脆弱性。","Zanis Ali Khan, Aayush Garg, Qiang Tang",2025-06-05T13:00:19Z,A Multi-Dataset Evaluation of Models for Automated Vulnerability Repair,Eine Multi-Dataset-Bewertung von Modellen für die Automatisierte Sicherheitsreparatur,对自动脆弱性修复模型的多数据集评价,http://arxiv.org/abs/2506.04987v1
6,"Security vulnerabilities in software packages are a significant concern for developers and users alike. Patching these vulnerabilities in a timely manner is crucial to restoring the integrity and security of software systems. However, previous work has shown that vulnerability reports often lack proof-of-concept (PoC) exploits, which are essential for fixing the vulnerability, testing patches, and avoiding regressions. Creating a PoC exploit is challenging because vulnerability reports are informal and often incomplete, and because it requires a detailed understanding of how inputs passed to potentially vulnerable APIs may reach security-relevant sinks. In this paper, we present PoCGen, a novel approach to autonomously generate and validate PoC exploits for vulnerabilities in npm packages. This is the first fully autonomous approach to use large language models (LLMs) in tandem with static and dynamic analysis techniques for PoC exploit generation. PoCGen leverages an LLM for understanding vulnerability reports, for generating candidate PoC exploits, and for validating and refining them. Our approach successfully generates exploits for 77% of the vulnerabilities in the SecBench.js dataset and 39% in a new, more challenging dataset of 794 recent vulnerabilities. This success rate significantly outperforms a recent baseline (by 45 absolute percentage points), while imposing an average cost of $0.02 per generated exploit.","软件包的安全脆弱性是开发者和用户都十分关切的软件包中的安全脆弱性问题。及时弥补这些脆弱性对于恢复软件系统的完整和安全至关重要。然而,先前的工作表明,脆弱性报告往往缺乏概念验证(POC)的利用,而这种利用对于确定脆弱性、测试补丁和避免倒退至关重要。 创建一个PoC的利用具有挑战性,因为脆弱性报告是非正式的,而且往往不完全的,并且因为它要求详细了解如何向潜在脆弱的API提供投入可能达到与安全有关的汇水层。在本文中,我们介绍了PoCGen,这是自主生成和验证PoC在npm软件包中利用脆弱性的新颖方法。这是使用大型语言模型(LLMS)的完全自主的方法,与PoC开发一代的静态和动态分析技术一道,是不可或缺的。 PoCGen利用一个LM来理解脆弱性报告,以产生候选的PoC的利用,以及验证和完善。我们的方法成功地利用了SecBench的77%的脆弱性。js数据集和39 %,这是新的、更具有挑战性的45美元比率的新数据,这是最近创下的标准率。","Deniz Simsek, Aryaz Eghbali, Michael Pradel",2025-06-05T12:37:33Z,PoCGen: Generating Proof-of-Concept Exploits for Vulnerabilities in Npm   Packages,PoCGen: Proof-of-Concept Exploits für Schwachstellen in Npm-Paketen generieren,PoCGen:为Npm包件的脆弱度生成概念探索校验,http://arxiv.org/abs/2506.04962v1
7,"Code comprehension is often supported by source code analysis tools which provide more abstract views over software systems, such as those detecting design patterns. These tools encompass analysis of source code and ensuing extraction of relevant information. However, the analysis of the source code is often specific to the target programming language. We propose DP-LARA, a multi-language pattern detection tool that uses the multi-language capability of the LARA framework to support finding pattern instances in a code base. LARA provides a virtual AST, which is common to multiple OOP programming languages, and DP-LARA then performs code analysis of detecting pattern instances on this abstract representation. We evaluate the detection performance and consistency of DP-LARA with a few software projects. Results show that a multi-language approach does not compromise detection performance, and DP-LARA is consistent across the languages we tested it for (i.e., Java and C/C++). Moreover, by providing a virtual AST as the abstract representation, we believe to have decreased the effort of extending the tool to new programming languages and maintaining existing ones.","代码理解往往得到源代码分析工具的支持,这些工具对软件系统(例如探测设计模式)提供更抽象的观点,这些工具包括对源代码的分析以及随后对相关信息的提取。然而,对源代码的分析往往是针对目标编程语言的。我们建议DP-LARA,这是一个多语言模式检测工具,使用LARA框架的多语言能力,支持在代码库中查找模式实例。LARA提供虚拟AST,这是多种OOP编程语言的通用语言,而DP-LARA则随后对这种抽象表述模式进行代码分析。我们用几个软件项目评估DP-LARA的检测性能和一致性。结果显示,多语言方法不会影响检测性能,DP-LARA在我们测试的语言(即爪哇和C/C++)之间是一致的。此外,通过提供虚拟AST作为抽象的表述,我们认为,将该工具推广到新的编程语言并保持现有语言的努力已经减少。","Hugo Andrade, João Bispo, Filipe F. Correia",2025-06-05T12:05:59Z,Multi-Language Detection of Design Pattern Instances,Mehrsprachige Erkennung von Designmuster-Instanzen,多语言设计模式多语言探测,http://arxiv.org/abs/2506.03903v2
8,"Large language models (LLMs) have shown promise in software engineering, yet their effectiveness for binary analysis remains unexplored. We present the first comprehensive evaluation of commercial LLMs for assembly code deobfuscation. Testing seven state-of-the-art models against four obfuscation scenarios (bogus control flow, instruction substitution, control flow flattening, and their combination), we found striking performance variations--from autonomous deobfuscation to complete failure. We propose a theoretical framework based on four dimensions: Reasoning Depth, Pattern Recognition, Noise Filtering, and Context Integration, explaining these variations. Our analysis identifies five error patterns: predicate misinterpretation, structural mapping errors, control flow misinterpretation, arithmetic transformation errors, and constant propagation errors, revealing fundamental limitations in LLM code processing.We establish a three-tier resistance model: bogus control flow (low resistance), control flow flattening (moderate resistance), and instruction substitution/combined techniques (high resistance). Universal failure against combined techniques demonstrates that sophisticated obfuscation remains effective against advanced LLMs. Our findings suggest a human-AI collaboration paradigm where LLMs reduce expertise barriers for certain reverse engineering tasks while requiring human guidance for complex deobfuscation. This work provides a foundation for evaluating emerging capabilities and developing resistant obfuscation techniques.x deobfuscation. This work provides a foundation for evaluating emerging capabilities and developing resistant obfuscation techniques.","大型语言模型(LLMS)在软件工程方面表现出了希望,然而其二进制分析的有效性仍未得到探讨。我们首次对商用LLMS进行了全面的评估,以用于组装代码的分解。我们根据四种模糊假设(博格控制流程、教学替代、控制流程平流及其组合)测试了七种最先进的模型,我们发现从自主脱钩到完全失败的惊人的性能差异。我们提出了一个基于四个层面的理论框架:解释深度、模式识别、噪音过滤和背景整合,解释这些差异。我们的分析确定了五种错误模式:上游误差、结构绘图错误、控制流程错误、算术转换错误和持续的传播错误,揭示了LLMM代码处理中的基本限制。我们建立了三层阻力模型:博格控制流程(低抗力)、控制流程稳定(模范抗力)和教学替代/组合技术(高抗力)。我们提出的理论表明,复杂的粘合法仍然对先进的LMS有效。我们的研究发现,一种人类-AI合作模式,即LOBMS提供新的抗力基础,同时要求降低某些反向工程的复杂工作能力。","Anton Tkachenko, Dmitrij Suskevic, Benjamin Adolphi",2025-06-05T10:02:39Z,Deconstructing Obfuscation: A four-dimensional framework for evaluating   Large Language Models assembly code deobfuscation capabilities,Dekonstruieren von Obfuscation: Ein vierdimensionaler Rahmen für die Auswertung von Großsprachenmodellen Assembly Code Deobfuscation Fähigkeiten,"解构腐蚀:四维框架,用于评价大语言模型组装编码脱腐能力",http://arxiv.org/abs/2505.19887v2
9,"In this note, we evaluate the performances, the features and the user-experience of some methods (and their implementations) designed for tensor- (or data-) based multivariate function construction and approximation. To this aim, a collection of multivariate functions extracted from contributive works coming from different communities, is suggested. First, these functions with varying complexity (e.g. number and degree of the variables) and nature (e.g. rational, irrational, differentiable or not, symmetric, etc.) are used to construct tensors, each of different dimension and size on the disk. Second, grounded on this tensor, we inspect performances of each considered method (e.g. the accuracy, the computational time, the parameters tuning impact, etc.). Finally, considering the ""best"" parameter tuning set, we compare each method using multiple evaluation criteria. The purpose of this note is not to rank the methods but rather to evaluate as fairly as possible the different available strategies, with the idea in mind to guide users to understand the process, the possibilities, the advantages and the limits brought by each tools. The contribution claimed is to suggest a complete benchmark collection of some available tools for tensor approximation by surrogate models (e.g. rational functions, networks, etc.). In addition, as contributors of the multivariate Loewner Framework (mLF) approach (and its side implementation in MDSPACK), attention and details of the latter are more explicitly given, in order to provide readers a digest of this contributive work and some details with simple examples.","在本说明中,我们评估了某些方法(及其实施)的性能、特点和用户经验,这些方法(及其执行经验)是为高频(或数据)的多变量函数构建和近似而设计的。为此,我们建议收集从不同社区集成作品中提取的多变量功能。首先,这些功能复杂程度(例如变量的数量和程度)和性质(例如合理、不合理、可区别或不同、对称等)不尽相同,用来构建磁盘上不同维度和大小的反射器。第二,基于这种高频,我们检查每种考虑方法(例如准确性、计算时间、调控影响参数等)的性能。最后,考虑到“最佳”参数调制,我们用多种评价标准对每种方法进行比较。本说明的目的不是对方法进行分级,而是尽可能公平地评估现有不同关注度战略,目的是指导用户理解过程、可能性、优势和极限。在每种工具中,我们检查每个工具的侧值的精确度和分数级的精确度,目的是用各种工具的精确度来衡量一个完整的指标,用来衡量这些工具的完整收集。","Athanasios C. Antoulas, Ion Victor Gosea, Charles Poussot-Vassal, Pierre Vuillemin",2025-06-05T09:17:55Z,Tensor-based multivariate function approximation: methods benchmarking   and comparison,Tensor-basierte multivariate Funktionsannäherung: Methoden Benchmarking und Vergleich,以电锯为基础的多变量函数近似值:方法基准和比较,http://arxiv.org/abs/2506.04791v1
10,"Knowledge transfer is fundamental to human collaboration and is therefore common in software engineering. Pair programming is a prominent instance. With the rise of AI coding assistants, developers now not only work with human partners but also, as some claim, with AI pair programmers. Although studies confirm knowledge transfer during human pair programming, its effectiveness with AI coding assistants remains uncertain. To analyze knowledge transfer in both human-human and human-AI settings, we conducted an empirical study where developer pairs solved a programming task without AI support, while a separate group of individual developers completed the same task using the AI coding assistant GitHub Copilot. We extended an existing knowledge transfer framework and employed a semi-automated evaluation pipeline to assess differences in knowledge transfer episodes across both settings. We found a similar frequency of successful knowledge transfer episodes and overlapping topical categories across both settings. Two of our key findings are that developers tend to accept GitHub Copilot's suggestions with less scrutiny than those from human pair programming partners, but also that GitHub Copilot can subtly remind developers of important code details they might otherwise overlook.","知识转让是人类合作的基础,因此在软件工程中很常见。 平方编程是一个突出的例子。 随着AI编码助理的崛起, 开发者现在不仅与人类伙伴合作, 也像某些人声称的那样与AI对配程序员合作。 虽然研究证实了在人与人之间编程过程中的知识转让,但与AI编码助理之间的效力仍然不确定。 为了分析人与人之间和人类-AI环境中的知识转让,我们进行了一项经验性研究,开发者在没有AI支持的情况下解决了编程任务,而另外一组个体开发者则利用AI编码助理GitHub Copilot完成了同样的任务。 我们扩展了现有的知识转让框架,并使用了半自动评价管道来评估两个环境中知识转让过程的差异。 我们发现两个环境中知识转让过程的成功频率相似,主题类别重叠。 我们的两个主要结论是,开发者倾向于接受GitHub Copil的建议,但不像人类对口编程伙伴的建议那么仔细,但是GitHub Copil可以向开发者解释他们可能忽略的重要代码细节。","Alisa Welter, Niklas Schneider, Tobias Dick, Kallistos Weis, Christof Tinnes, Marvin Wyrich, Sven Apel",2025-06-05T09:13:30Z,From Developer Pairs to AI Copilots: A Comparative Study on Knowledge   Transfer,Von Entwicklerpaaren zu KI-Copiloten: Eine vergleichende Studie zum Wissenstransfer,从开发者对等到AI 副驾驶员:知识转让比较研究,http://arxiv.org/abs/2506.04785v1
11,"This paper introduces QuanUML, an extension of the Unified Modeling Language (UML) tailored for quantum software systems. QuanUML integrates quantum-specific constructs, such as qubits and quantum gates, into the UML framework, enabling the modeling of both quantum and hybrid quantum-classical systems. We apply QuanUML to Efficient Long-Range Entanglement using Dynamic Circuits and Shor's Algorithm, demonstrating its utility in designing and visualizing quantum algorithms. Our approach supports model-driven development of quantum software and offers a structured framework for quantum software design. We also highlight its advantages over existing methods and discuss future improvements.","本文件介绍量子软件系统专用的统一模型语言(UML)的扩展 QuanUML。 QuanUML将量子和量子门等量子特定构件纳入UML框架,使量子和混合量子古典系统建模。 我们运用 QuanUML 来利用动态电路和Shor's Algorithm 进行高效长距离缠绕,以展示其在量子算法的设计和可视化方面的实用性。 我们的方法支持量子软件的模型驱动开发,并为量子软件的设计提供一个结构化的框架。 我们还强调其相对于现有方法的优势,并讨论今后的改进。","Xiaoyu Guo, Shinobu Saito, Jianjun Zhao",2025-06-05T05:19:22Z,QuanUML: Towards A Modeling Language for Model-Driven Quantum Software   Development,QuanUML: Auf dem Weg zu einer Modellierungssprache für modellgetriebene Quantensoftware-Entwicklung,QuuUML:争取为开发模型驱动量子软件开发建立示范语言,http://arxiv.org/abs/2506.04639v1
12,"Code data in large language model (LLM) pretraining is recognized crucial not only for code-related tasks but also for enhancing general intelligence of LLMs. Current open-source LLMs often heavily rely on human effort to produce their code pretraining data, such as employing hand-crafted filtering rules tailored to individual programming languages, or using human-annotated data to train quality filters. However, these approaches are inherently limited in scalability, prone to subjective biases, and costly to extend and maintain across diverse programming languages. To address these challenges, we introduce Seed-Coder, a series of open-source LLMs comprising base, instruct and reasoning models of 8B size, minimizing human involvement in data construction. Our code pretraining data is produced by a model-centric data pipeline, which predominantly leverages LLMs for scoring and filtering code data. The instruct model is further trained via supervised fine-tuning and preference optimization, and the reasoning model leverages Long-Chain-of-Thought (LongCoT) reinforcement learning to improve multi-step code reasoning. Seed-Coder achieves state-of-the-art results among open-source models of similar size and even surpasses some much larger models, demonstrating superior performance in code generation, code completion, code editing, code reasoning, and software engineering tasks.","在大型语言模式(LLM)培训前,人们公认,守则数据不仅对与代码有关的任务至关重要,而且对加强LLM公司的一般情报也至关重要。目前的开放源代码LLM公司常常严重依赖人的努力来编制其代码培训前数据,例如采用适合个人编程语言的手工制作过滤规则,或使用附加说明的数据来培训质量过滤器。然而,这些方法在可扩展性方面本质上是有限的,容易主观偏见,而且推广和维持不同编程语言的费用也很高。为了应对这些挑战,我们引入了种子-Coder公司(Seed-Coder),这是由8B大小的基地、指示和推理模型组成的一系列开放源代码LMSLM公司。我们的代码培训前数据是通过一个以模式为中心的数据管道制作的,主要用于评分和筛选代码数据。指导模型通过监督下的微调和优化以及推理模型(Long-Chain-fought)(Long-Cott公司)来强化学习,以改进多步骤代码推理。甚至Sead-Coder公司在开源代码的模型中实现了一些先进的状态,在更高级的编程、更高级的编程、更高级的编程、更高级的编程、更高级的编程任务中展示。","ByteDance Seed, Yuyu Zhang, Jing Su, Yifan Sun, Chenguang Xi, Xia Xiao, Shen Zheng, Anxiang Zhang, Kaibo Liu, Daoguang Zan, Tao Sun, Jinhua Zhu, Shulin Xin, Dong Huang, Yetao Bai, Lixin Dong, Chao Li, Jianchong Chen, Hanzhi Zhou, Yifan Huang, Guanghan Ning, Xierui Song, Jiaze Chen, Siyao Liu, Kai Shen, Liang Xiang, Yonghui Wu",2025-06-05T03:26:05Z,Seed-Coder: Let the Code Model Curate Data for Itself,Saatgut-Coder: Lassen Sie das Code-Modell Daten für sich selbst kuratieren,种子编码器:让代码模型为它自己计算曲线数据,http://arxiv.org/abs/2506.03524v2
13,"To ensure the reliability of cloud systems, their performance is monitored using KPIs (key performance indicators). When issues arise, root cause localization identifies KPIs responsible for service degradation, aiding in quick diagnosis and resolution. Traditional methods rely on similarity calculations, which can be ineffective in complex, interdependent cloud environments. While deep learning-based approaches model these dependencies better, they often face challenges such as high computational demands and lack of interpretability.   To address these issues, KPIRoot is proposed as an efficient method combining similarity and causality analysis. It uses symbolic aggregate approximation for compact KPI representation, improving analysis efficiency. However, deployment in Cloud H revealed two drawbacks: 1) threshold-based anomaly detection misses some performance anomalies, and 2) SAX representation fails to capture intricate variation trends. KPIRoot+ addresses these limitations, outperforming eight state-of-the-art baselines by 2.9% to 35.7%, while reducing time cost by 34.7%. We also share our experience deploying KPIRoot in a large-scale cloud provider's production environment.","为确保云系统的可靠性,使用基本业绩指标(关键业绩指标)对云系统的业绩进行监测。一旦出现问题,根本原因就确定KPI对服务退化负有责任,协助快速诊断和解决。传统方法依靠相似性计算,在复杂、相互依存的云环境中,这种计算可能无效。虽然深层次的学习基础方法可以更好地模拟这些依赖性,但它们往往面临高计算要求和缺乏解释性等挑战。为解决这些问题,KPIRooot被提议为一种将相似性和因果关系分析相结合的有效方法。它使用紧凑的KPI代表制的象征性总近似,提高了分析效率。然而,在云 H 中的部署揭示了两个缺陷:(1) 基于临界异常的检测没有出现某些性能异常;(2) SAX 代表未能捕捉到复杂的变化趋势。 KPIRoot+ 解决了这些局限性,将8个最先进的基线比2.9%到35.7%的基线要高,同时将时间成本降低34.7%。我们还分享了我们在大型云源生产环境中部署KPIRooot的经验。","Wenwei Gu, Renyi Zhong, Guangba Yu, Xinying Sun, Jinyang Liu, Yintong Huo, Zhuangbin Chen, Jianping Zhang, Jiazhen Gu, Yongqiang Yang, Michael R. Lyu",2025-06-05T02:42:07Z,KPIRoot+: An Efficient Integrated Framework for Anomaly Detection and   Root Cause Analysis in Large-Scale Cloud Systems,KPIRoot+: Ein effizientes integriertes Framework für Anomalieerkennung und Ursachenanalyse in großräumigen Cloud-Systemen,KPIROot+:大型云系统异常探测和根本原因分析有效综合框架,http://arxiv.org/abs/2506.04569v1
14,"Traditional multi-objective optimization in software engineering (SE) can be slow and complex. This paper introduces the BINGO effect: a novel phenomenon where SE data surprisingly collapses into a tiny fraction of possible solution ""buckets"" (e.g., only 100 used from 4,096 expected).   We show the BINGO effect's prevalence across 39 optimization in SE problems. Exploiting this, we optimize 10,000 times faster than state-of-the-art methods, with comparable effectiveness. Our new algorithms (LITE and LINE), demonstrate that simple stochastic selection can match complex optimizers like DEHB. This work explains why simple methods succeed in SE-real data occupies a small corner of possibilities-and guides when to apply them, challenging the need for CPU-heavy optimization.   Our data and code are public at GitHub (see anon-artifacts/bingo).","软件工程( SE) 的传统多目标优化可能是缓慢和复杂的。 本文介绍了 BINGO 效果: 一种新现象, SE 数据出乎意料地崩溃成微小部分可能的解决方案“ 桶”( 例如, 从4,096个预期中只使用了100个 ) 。 我们展示了 BINGO 效应在SE 问题的39个优化中的流行程度。 利用这个效果, 我们优化速度比最先进的方法快10 000倍, 效果也相当。 我们的新算法( LITE 和 LINE ) 显示, 简单的随机选择可以匹配像 DEHB 这样的复杂优化器 。 这项工作解释了为什么在 SE- real 数据成功时, 占用了很小的可能性和指南的角落, 从而挑战了 CUP- Heavy 优化的需要。 我们的数据和代码在 GitHub 公开( 见 an- artifacts/ binggo) 。","Kishan Kumar Ganguly, Tim Menzies",2025-06-04T23:13:58Z,BINGO! Simple Optimizers Win Big if Problems Collapse to a Few Buckets,"BINGO! Einfache Optimierer gewinnen groß, wenn Probleme zusammenbrechen zu ein paar Eimern","BINNGO ! 如果问题折叠成几个巴克塔, 简单优化者会大获成功 。",http://arxiv.org/abs/2506.04509v1
15,"Software signing is the most robust method for ensuring the integrity and authenticity of components in a software supply chain. However, traditional signing tools place key management and signer identification burdens on practitioners, leading to both security vulnerabilities and usability challenges. Next-generation signing tools such as Sigstore have automated some of these concerns, but little is known about their usability and adoption dynamics. This knowledge gap hampers the integration of signing into the software engineering process.   To fill this gap, we conducted a usability study of Sigstore, a pioneering and widely adopted exemplar in this space. Through 18 interviews, we explored (1) the factors practitioners consider when selecting a signing tool, (2) the problems and advantages associated with the tooling choices of practitioners, and (3) practitioners' signing-tool usage has evolved over time. Our findings illuminate the usability factors of next-generation signing tools and yield recommendations for toolmakers, including: (1) enhance integration flexibility through officially supported plugins and APIs, and (2) balance transparency with privacy by offering configurable logging options for enterprise use.","软件的签名是确保软件供应链各组成部分的完整性和真实性的最可靠方法。然而,传统的签名工具将关键管理和签名识别责任置于从业人员身上,导致安全脆弱性和使用性挑战。下一代的签名工具,如Sigstore, 将其中一些关切自动化,但对其可用性和采用动态知之甚少。这一知识差距妨碍了将签名纳入软件工程流程。为填补这一空白,我们进行了Sigstore的可用性研究,Sigstore是这一空间的先驱和广泛采用的实例。通过18次访谈,我们探讨了:(1) 从业人员在选择签名工具时考虑的因素,(2) 与从业人员工具选择有关的问题和优势,(3) 从业人员的签名工具使用情况随着时间的演变。我们的调查结果揭示了下一代签名工具的可用性要素,并为工具制造者提出了建议,包括:(1) 通过官方支持的插件和API加强整合的灵活性,以及(2) 通过提供企业使用的可配置的伐木选项,使透明度与隐私平衡。","Kelechi G. Kalu, Sofia Okorafor, Tanmay Singla, Santiago Torres-Arias, James C. Davis",2025-06-04T22:10:22Z,Why Johnny Signs with Next-Generation Tools: A Usability Case Study of   Sigstore,Warum Johnny mit Next-Generation Tools unterzeichnet: Eine Usability-Fallstudie von Sigstore,为何约翰尼使用下一轮发牌工具签名:斯格斯托尔的可用性案例研究,http://arxiv.org/abs/2503.00271v4
16,"Code review is a crucial component of modern software development, involving the evaluation of code quality, providing feedback on potential issues, and refining the code to address identified problems. Despite these benefits, code review can be rather time consuming, and influenced by subjectivity and human factors. For these reasons, techniques to (partially) automate the code review process have been proposed in the literature. Among those, the ones exploiting deep learning (DL) are able to tackle the generative aspect of code review, by commenting on a given code as a human reviewer would do (i.e., comment generation task) or by automatically implementing code changes required to address a reviewer's comment (i.e., code refinement task). In this paper, we introduce CoRAL, a deep learning framework automating review comment generation by exploiting reinforcement learning with a reward mechanism considering both the semantics of the generated comments as well as their usefulness as input for other models automating the code refinement task. The core idea is that if the DL model generates comments that are semantically similar to the expected ones or can be successfully implemented by a second model specialized in code refinement, these comments are likely to be meaningful and useful, thus deserving a high reward in the reinforcement learning framework. We present both quantitative and qualitative comparisons between the comments generated by CoRAL and those produced by the latest baseline techniques, highlighting the effectiveness and superiority of our approach.","守则审查是现代软件开发的关键组成部分,涉及对守则质量的评价,提供潜在问题的反馈,并改进守则,以解决已查明的问题。尽管有这些好处,守则审查可能耗费大量时间,并受主观因素和人的因素影响。出于这些原因,文献中提出了使守则审查过程(部分)自动化的技术。在其中,利用深层次学习(DL)的技巧能够解决守则审查的基因化方面问题,办法是作为人类审查员对某一守则进行评论(即评论生成任务),或通过自动执行处理审查者评论(即改进守则任务)所需的守则修改。在本文件中,我们引入了CorAL这一深层次的学习框架,通过利用强化学习机制使守则审查过程自动化,既考虑到所产生评论的语义性,又考虑到它们作为使守则改进任务自动化的其他模型的用处。核心思想是,如果DL模型能够产生与预期相似的评论,或者可以通过在改进守则方面进行第二次示范性专门性评论(即改进守则)来成功执行。这些评论很可能通过提高质量框架的精准性、提高质量方法产生。","Oussama Ben Sghaier, Rosalia Tufano, Gabriele Bavota, Houari Sahraoui",2025-06-04T21:31:38Z,Leveraging Reward Models for Guiding Code Review Comment Generation,Leveraging Reward Modelle für Guiding Code Review Comment Generierung,利用奖励模式促进《指导原则》审查,http://arxiv.org/abs/2506.04464v1
17,"Recent advances in large language models (LLMs) have improved their performance on coding benchmarks. However, improvement is plateauing due to the exhaustion of readily available high-quality data. Prior work has shown the potential of synthetic self-instruct data, but naively training on a model's own outputs can cause error accumulation, especially in coding tasks, where generalization may collapse due to overly simple or erroneous training data, highlighting the need for rigorous quality checks on synthetic data. In this work, we explore an effective approach whereby the model itself verifies the correctness of its own data. We thus propose Sol-Ver, a self-play solver-verifier framework that jointly improves a single model's code and test generation capacity. By iteratively refining code (LLM-as-a-solver) and tests (LLM-as-a-verifier) together, we boost both capabilities without relying on human annotations or larger teacher models. Experiments with the Llama 3.1 8B model demonstrate substantial performance enhancements, achieving average relative improvements of 19.63% in code generation and 17.49% in test generation on MBPP and LiveCodeBench.","大型语言模型(LLMS)最近的进展改善了其在编码基准方面的绩效。然而,由于已经耗尽了现成的高质量数据,改进工作正在趋于平稳。先前的工作已经表明合成自学数据的潜力,但就模型本身的产出进行天真的培训,可能会造成错误积累,特别是在编码任务方面,由于过于简单或错误的培训数据,一般化可能会崩溃,突出表明需要对合成数据进行严格的质量检查。在这项工作中,我们探索一种有效的方法,使模型本身核查其数据是否正确。因此,我们提议Sol-Ver,即一个自编解算器-验证器框架,共同改进单一模型的代码和测试生成能力。通过迭接地改进代码(LLM-as-as-solver)和测试(LLM-as-as-vererger)和测试(LLLM-as-a-vererger),我们无需依靠人类说明或更大的教师模型而提高这两种能力。与Llama 3.1 8B模型的实验表明业绩得到大幅度提高,从而实现了19.63%的代码生成和17.49%在MTP和LiveCodeBench的测试生成中平均相对改进了17.49%。","Zi Lin, Sheng Shen, Jingbo Shang, Jason Weston, Yixin Nie",2025-06-04T20:52:16Z,Learning to Solve and Verify: A Self-Play Framework for Code and Test   Generation,Lernen zu lösen und zu überprüfen: Ein Selbstspiel-Framework für Code- und Testgenerierung,学会解决和核查:守则和试验生成的自玩框架,http://arxiv.org/abs/2502.14948v3
18,"Autonomous systems have gained an important role in many industry domains and are beginning to change everyday life. However, due to dynamically emerging applications and often proprietary constraints, there is a lack of information about the practice of developing autonomous systems. This paper presents the first part of the longitudinal study focused on establishing state-of-the-practice, identifying and quantifying the challenges and benefits, identifying the processes and standards used, and exploring verification and validation (V&V) practices used for the development of autonomous systems. The results presented in this paper are based on data about software systems that have autonomous functionality and may employ model-based software engineering (MBSwE) and reuse. These data were collected using an anonymous online survey that was administered in 2019 and were provided by experts with experience in development of autonomous systems and /or the use of MBSwE. Our current work is focused on repeating the survey to collect more recent data and discover how the development of autonomous systems has evolved over time.","自主系统在许多行业领域已发挥重要作用,并开始改变日常生活,然而,由于动态的应用程序和往往独有的限制,缺乏关于发展自主系统做法的信息,本文件介绍了纵向研究的第一部分,其重点是建立最新做法,查明和量化挑战和效益,确定所采用的程序和标准,探讨用于开发自主系统的核查和验证(V&V)做法,本文件介绍的结果以具有自主功能并可能采用基于模型的软件工程和再利用的软件系统的数据为基础,这些数据是利用2019年进行的匿名在线调查收集的,这些调查是由具有开发自主系统和/或使用MBSwE经验的专家提供的。我们目前的工作重点是重复调查,以收集最新数据,并了解自主系统的发展如何随着时间推移而演变。","Katerina Goseva-Popstojanova, Denny Hood, Johann Schumann, Noble Nkwocha",2025-06-04T20:44:12Z,On the Practices of Autonomous Systems Development: Survey-based   Empirical Findings,Über die Praxis der Entwicklung autonomer Systeme: Empirische Erkenntnisse auf Basis von Umfragen,《关于发展自治系统的做法:基于调查的经验性调查结果》,http://arxiv.org/abs/2506.04438v1
19,"Multi-hunk bugs, where fixes span disjoint regions of code, are common in practice, yet remain underrepresented in automated repair. Existing techniques and benchmarks pre-dominantly target single-hunk scenarios, overlooking the added complexity of coordinating semantically related changes across the codebase. In this work, we characterize HUNK4J, a dataset of multi-hunk patches derived from 372 real-world defects. We propose hunk divergence, a metric that quantifies the variation among edits in a patch by capturing lexical, structural, and file-level differences, while incorporating the number of hunks involved. We further define spatial proximity, a classification that models how hunks are spatially distributed across the program hierarchy. Our empirical study spanning six LLMs reveals that model success rates decline with increased divergence and spatial dispersion. Notably, when using the LLM alone, no model succeeds in the most dispersed Fragment class. These findings highlight a critical gap in LLM capabilities and motivate divergence-aware repair strategies.","多洪虫在代码区域脱节,在实践上很常见,但在自动修理中仍然代表性不足。现有的技术和基准在自动修理中仍然不足。现有的技术和基准在目标前是目标单月情景,忽略了在整个代码库中协调与自然相关的变化的复杂性。在这项工作中,我们把HUNK4J这个由372个现实世界缺陷产生的多洪虫补丁数据集定性为HUNK4J。我们提议了洪块差异,该指标通过捕捉词汇、结构和文件层面的差异来量化编辑在一个补丁中的差异,同时纳入所涉的括号数量。我们进一步界定了空间接近性,这是一种模型,该模型如何在空间上分布在程序的各个层次上。我们的经验研究覆盖了六个LLMM,表明模型的成功率随着差异和空间分布的扩大而下降。值得注意的是,单使用LLM,在最分散的碎裂类中没有成功模型。这些结论突出了LLM能力的重大差距,并激发了差异-认知的修复策略。","Noor Nashid, Daniel Ding, Keheliya Gallaba, Ahmed E. Hassan, Ali Mesbah",2025-06-04T19:58:44Z,"Characterizing Multi-Hunk Patches: Divergence, Proximity, and LLM Repair   Challenges","Charakterisieren von Multi-Hunk Patches: Divergenz, Nähe und LLM-Reparatur-Herausforderungen",多湖补丁:差异、近似和LLM修理挑战,http://arxiv.org/abs/2506.04418v1
20,"Providing optimal contextual input presents a significant challenge for automated end-to-end (E2E) test generation using large language models (LLMs), a limitation that current approaches inadequately address. This paper introduces Visual-Semantic Component Abstractor (VISCA), a novel method that transforms webpages into a hierarchical, semantically rich component abstraction. VISCA starts by partitioning webpages into candidate segments utilizing a novel heuristic-based segmentation method. These candidate segments subsequently undergo classification and contextual information extraction via multimodal LLM-driven analysis, facilitating their abstraction into a predefined vocabulary of user interface (UI) components. This component-centric abstraction offers a more effective contextual basis than prior approaches, enabling more accurate feature inference and robust E2E test case generation. Our evaluations demonstrate that the test cases generated by VISCA achieve an average feature coverage of 92%, exceeding the performance of the state-of-the-art LLM-based E2E test generation method by 16%.","提供最佳背景投入对使用大型语言模型(LLMs)进行自动端到端测试(E2E)的生成提出了重大挑战,这是目前方法不恰当的限制。本文介绍了视觉-Semantic 元素摘要(VISCA),这是将网页转换成等级分级、精密内容丰富的部分抽象的新方法。VISCA开始使用新颖的超光速分解法将网页分割成候选部分。这些候选部分随后通过多式LMM驱动分析进行分类和背景信息提取,便利将其抽象成预先定义的用户界面(UI)组件的词汇。这种以组件为中心的抽象比以前的方法提供了更有效的背景基础,使得能够更精确地推断和稳健的E2E测试案例生成。我们的评估表明,VISCA产生的测试案例的平均特征覆盖率达到92%,超过以LME2E为主的测试方法的16 %。","Parsa Alian, Martin Tang, Ali Mesbah",2025-06-04T17:00:38Z,VISCA: Inferring Component Abstractions for Automated End-to-End Testing,VISCA: Rückschlüsse auf Komponentenabstractions für automatisierte End-to-End-Tests,VISCA: 自动端对端测试的推断要素摘要,http://arxiv.org/abs/2506.04161v1
21,"The rapid advancement of Information and Communication Technologies is transforming Cultural Heritage access, experience, and preservation. However, many digital heritage applications lack interactivity, personalization, and adaptability, limiting user engagement and educational impact. This short paper presents a reference architecture for gamified cultural heritage applications leveraging generative AI and augmented reality. Gamification enhances motivation, artificial intelligence enables adaptive storytelling and personalized content, and augmented reality fosters immersive, location-aware experiences. Integrating AI with gamification supports dynamic mechanics, personalized feedback, and user behavior prediction, improving engagement. The modular design supports scalability, interoperability, and adaptability across heritage contexts. This research provides a framework for designing interactive and intelligent cultural heritage applications, promoting accessibility and deeper appreciation among users and stakeholders.","信息和通信技术的快速进步正在改变文化遗产的获取、经验和保存,然而,许多数字遗产应用缺乏互动性、个性化和适应性,限制了用户的参与和教育影响。这份简短的文件为利用基因改变的人工智能和增强现实,综合了文化遗产应用的参考结构。 游戏增强了动力,人工智能使适应性故事和个性化内容,扩大了现实,促进了隐性、地点认知的经验。将大赦国际与拼写结合起来,支持动态机械、个性化反馈和用户行为预测,改善了参与。模块设计支持了跨遗产背景的可扩展性、互操作性和适应性。这一研究为设计互动和智能文化遗产应用提供了一个框架,促进了用户和利益攸关方之间的无障碍和深入理解。","Federico Martusciello, Henry Muccini, Antonio Bucchiarone",2025-06-04T15:49:05Z,A Reference Architecture for Gamified Cultural Heritage Applications   Leveraging Generative AI and Augmented Reality,Eine Referenzarchitektur für Gamified Cultural Heritage Applications Leveraging Generative KI und Augmented Reality,彩色文化遗产应用的参考架构,http://arxiv.org/abs/2506.04090v1
22,"Developing safety-critical automotive software presents significant challenges due to increasing system complexity and strict regulatory demands. This paper proposes a novel framework integrating Generative Artificial Intelligence (GenAI) into the Software Development Lifecycle (SDLC). The framework uses Large Language Models (LLMs) to automate code generation in languages such as C++, incorporating safety-focused practices such as static verification, test-driven development and iterative refinement. A feedback-driven pipeline ensures the integration of test, simulation and verification for compliance with safety standards. The framework is validated through the development of an Adaptive Cruise Control (ACC) system. Comparative benchmarking of LLMs ensures optimal model selection for accuracy and reliability. Results demonstrate that the framework enables automatic code generation while ensuring compliance with safety-critical requirements, systematically integrating GenAI into automotive software engineering. This work advances the use of AI in safety-critical domains, bridging the gap between state-of-the-art generative models and real-world safety requirements.","由于系统复杂性的提高和严格的监管要求,开发安全临界汽车软件面临重大挑战,因为系统复杂性的提高和严格的监管要求,本文件提议了一个新颖的框架,将创造人工智能(GenAI)纳入软件开发生命周期(SDLC)。框架使用大语言模型(LLMs)将C++等语言的代码生成自动化,将静态核查、测试驱动开发和迭接改进等以安全为重点的做法纳入其中。反馈驱动管道确保测试、模拟和核查的一体化,以遵守安全标准。框架通过开发适应性巡航控制(ACC)系统得到验证。LLMS比较基准确保最佳模式的选择准确性和可靠性。结果显示,该框架既能自动生成代码,又能确保遵守安全关键要求,系统地将GenAI纳入汽车软件工程。这项工作促进了在安全关键领域使用AI,缩小了最新基因化模型与现实世界安全要求之间的差距。","Sven Kirchner, Alois C. Knoll",2025-06-04T15:01:59Z,Generating Automotive Code: Large Language Models for Software   Development and Verification in Safety-Critical Systems,Generieren von Automotive Code: Große Sprachmodelle für Softwareentwicklung und Verifikation in sicherheitskritischen Systemen,生成汽车编码:安全临界系统软件开发和核查大语言模式,http://arxiv.org/abs/2506.04038v1
23,"LLMs have been extensively used for the task of automated code generation. In this work, we examine the applicability of LLMs for the related but relatively unexplored task of code-equivalence checking, i.e., given two programs, whether they are functionally equivalent or not. This is an important problem since benchmarking code equivalence can play a critical role in evaluating LLM capabilities for tasks such as code re-writing and code translation. Towards this end, we present CETBench - Code Equivalence with Transformations Benchmark, constructed via a repository of programs, where two programs in the repository may be solving the same or different tasks. Each instance in our dataset is obtained by taking a pair of programs in the repository and applying a random series of pre-defined code transformations, resulting in (non-)equivalent pairs. Our analysis on this dataset reveals a surprising finding that very simple code transformations in the underlying pair of programs can result in a significant drop in performance of SOTA LLMs for the task of code-equivalence checking. To remedy this, we present a simple fine-tuning-based approach to boost LLM performance on the transformed pairs of programs. Our approach for dataset generation is generic, and can be used with repositories with varying program difficulty levels and allows for applying varying numbers as well as kinds of transformations. In our experiments, we perform ablations over the difficulty level of original programs, as well as the kind of transformations used in generating pairs for equivalence checking. Our analysis presents deep insights into the working of LLMs for the task of code-equivalence, and points to the fact that they may still be far from what could be termed as a semantic understanding of the underlying code.","在这项工作中,我们检查了LLMS对相关但相对未探索的代码等效检查任务的适用性,即,给两个程序,不管它们是否在功能上等同。这是一个重要的问题,因为基准代码等同在评估代码重写和代码翻译等任务LLM能力方面可以发挥关键作用。为此,我们展示了CETBench - Coc Equvalence with Transformations Birectors Birectors,它通过程序库的两个程序库可以解决相同或不同的任务。我们的数据集中的每个实例都是通过在存储库中采取一对程序来获取的,并应用一系列预定义的代码转换,从而导致(非)等同对等。我们对这个数据集的分析显示了一个非常简单的发现,基本程序中的代码转换可以导致SOTA LLMS的运行率大幅下降,用于代码等同检查任务。为了补救这一点,我们用一个简单的基于精细度的方法来提升LM的直径直径直径直到数据转换过程的操作水平,而我们用一个用于生成程序的运行过程的精度分析过程的精度水平。","Neeva Oza, Ishaan Govil, Parul Gupta, Dinesh Khandelwal, Dinesh Garg, Parag Singla",2025-06-04T14:47:14Z,CETBench: A Novel Dataset constructed via Transformations over Programs   for Benchmarking LLMs for Code-Equivalence Checking,"CETBench: Ein neuartiger Datensatz, der über Transformationen über Programme zum Benchmarking von LLMs für Code-Equivalenz-Checking erstellt wurde",CETBennch:通过对代码等效检查LMLM基准测试方案进行转换而构建的新数据集,http://arxiv.org/abs/2506.04019v1
24,"Unit testing plays a critical role in ensuring software correctness. However, writing unit tests manually is laborious, especially for strong typed languages like Java, motivating the need for automated approaches. Traditional methods primarily rely on search-based or randomized algorithms to generate tests that achieve high code coverage and produce regression oracles, which are derived from the program's current behavior rather than its intended functionality. Recent advances in large language models (LLMs) have enabled oracle generation from natural language descriptions. However, existing LLM-based methods often require LLM fine-tuning or rely on external tools such as EvoSuite for test prefix generation.   In this work, we propose CANDOR, a novel end-to-end, prompt-based LLM framework for automated JUnit test generation. CANDOR orchestrates multiple specialized LLM agents to generate JUnit tests, including both high-quality test prefixes and accurate oracles. To mitigate the notorious hallucinations in LLMs, we introduce a novel strategy that engages multiple reasoning LLMs in a panel discussion and generate accurate oracles based on consensus. Additionally, to reduce the verbosity of reasoning LLMs' outputs, we propose a novel dual-LLM pipeline to produce concise and structured oracle evaluations.   Our experiments on the HumanEvalJava and LeetCodeJava datasets show that CANDOR can generate accurate oracles and is slightly better than EvoSuite in generating tests with high line coverage and clearly superior in terms of mutation score. Moreover, CANDOR significantly outperforms the state-of-the-art, prompt-based test generator LLM-Empirical, achieving improvements of 15.8 to 25.1 percentage points in oracle correctness on both correct and faulty source code. Ablation studies confirm the critical contributions of key agents in improving test prefix quality and oracle accuracy.","单位测试在确保软件正确性方面起着关键作用。 然而, 以LLM为基础的写字单位测试手工操作是困难的, 特别是像爪哇这样的强型语言, 需要自动化方法。 传统方法主要依靠基于搜索或随机的算法来生成测试, 达到高代码覆盖率并产生回归或触角, 这些测试来自程序当前的行为, 而不是其预期的功能。 大型语言模型( LLLMs) 的最近进步使得奥氏生成能够从自然语言描述中解析。 然而, 现有的LLM 方法往往需要LLM 的精细调或依赖外部工具, 如 EvoSeter 等用于测试前置生成。 在此工作中, 我们建议 CANDOR, 一个全新的端到端的LMM框架。 CANDOR 的精度测试中, CANDOR 的精度、 CRLM 的精度分析中, 更清晰的精度中, CAVALM 的精度和精度的精度分析中, CRLM 的精度分析中, 更精确的精度的精度。","Qinghua Xu, Guancheng Wang, Lionel Briand, Kui Liu",2025-06-04T14:43:39Z,A Multi-agent LLM-based JUnit Test Generation with Strong Oracles,Eine Multi-Agent LLM-basierte JUnit Test Generation mit starken Oracles,多试剂LLM 以JUUU单位为基础的具有强大甲骨文的多剂LLM,http://arxiv.org/abs/2506.02943v2
25,"Swarm behaviour engineering is an area of research that seeks to investigate methods and techniques for coordinating computation and action within groups of simple agents to achieve complex global goals like pattern formation, collective movement, clustering, and distributed sensing. Despite recent progress in the analysis and engineering of swarms (of drones, robots, vehicles), there is still a need for general design and implementation methods and tools that can be used to define complex swarm behaviour in a principled way. To contribute to this quest, this article proposes a new field-based coordination approach, called MacroSwarm, to design and program swarm behaviour in terms of reusable and fully composable functional blocks embedding collective computation and coordination. Based on the macroprogramming paradigm of aggregate computing, MacroSwarm builds on the idea of expressing each swarm behaviour block as a pure function, mapping sensing fields into actuation goal fields, e.g., including movement vectors. In order to demonstrate the expressiveness, compositionality, and practicality of MacroSwarm as a framework for swarm programming, we perform a variety of simulations covering common patterns of flocking, pattern formation, and collective decision-making. The implications of the inherent self-stabilisation properties of field-based computations in MacroSwarm are discussed, which formally guarantee some resilience properties and guided the design of the library.","尽管最近在分析和工程群群(无人机、机器人、车辆)方面有所进展,但仍需要一般性的设计和实施方法和工具,以便以原则方式界定复杂的群温行为,为这一探索作出贡献,本篇文章提议了一种新的实地协调办法,称为宏观群温,以设计和规划在可再利用和完全可折合的功能组群嵌入集体计算和协调方面的群态行为。根据总体计算宏观方案模式,宏观群集基于将每个群集行为组(无人机、机器人、车辆)表述为纯功能的构想,将感测场绘制成活动目标领域,包括移动矢量。为了表明宏观群集体作为群集规划框架的表达性、构成性和实用性,我们开展了各种模拟活动,包括了集体计算和可完全可折合的功能组群集的功能组群体。在总体计算和协调中,根据总体计算宏观组群集的宏观组群集的宏观组群集的模型模型模型的模型模型模型化和模型化的模型化,并讨论了内部系统模型化的自身设计、模型化的系统化。","Gianluca Aguzzi, Roberto Casadei, Mirko Viroli",2025-06-04T14:39:12Z,MacroSwarm: A Field-based Compositional Framework for Swarm Programming,MacroSwarm: Ein feldbasierter Kompositionsrahmen für die Schwarmprogrammierung,宏观群群:基于实地的蜂群方案规划组成框架,http://arxiv.org/abs/2401.10969v3
26,"With the rapid growth of open-source ecosystems (e.g., Linux) and domain-specific software projects (e.g., aerospace), efficient management of reusable artifacts is becoming increasingly crucial for software reuse. The multi-level feature tree enables semantic management based on functionality and supports requirements-driven artifact selection. However, constructing such a tree heavily relies on domain expertise, which is time-consuming and labor-intensive. To address this issue, this paper proposes an automatic multi-level feature tree construction framework named FTBUILDER, which consists of three stages. It automatically crawls domain-specific software repositories and merges their metadata to construct a structured artifact library. It employs clustering algorithms to identify a set of artifacts with common features. It constructs a prompt and uses LLMs to summarize their common features. FTBUILDER recursively applies the identification and summarization stages to construct a multi-level feature tree from the bottom up. To validate FTBUILDER, we conduct experiments from multiple aspects (e.g., tree quality and time cost) using the Linux distribution ecosystem. Specifically, we first simultaneously develop and evaluate 24 alternative solutions in the FTBUILDER. We then construct a three-level feature tree using the best solution among them. Compared to the official feature tree, our tree exhibits higher quality, with a 9% improvement in the silhouette coefficient and an 11% increase in GValue. Furthermore, it can save developers more time in selecting artifacts by 26% and improve the accuracy of artifact recommendations with GPT-4 by 235%. FTBUILDER can be extended to other open-source software communities and domain-specific industrial enterprises.","随着开放源码生态系统(如Linux)和特定域的软件项目(如航空航天)的快速增长,对可再利用的文物的有效管理对软件再利用越来越至关重要。多层地貌树能够根据功能进行语义管理,支持需求驱动的文物选择。然而,建造这样的树在很大程度上依赖于域域专长,这需要时间和劳力密集型。为了解决这个问题,本文件建议建立一个名为FTBUILDER的多层次功能树建设框架,由三个阶段组成。它自动爬行特定域软件库,并合并其元数据,以建立一个结构化的文物库。它使用群集算算法来确定一套具有共同特性的艺术品。它建立快速并使用LLLMS来总结其共同特性。FBUILDER反复应用识别和合成阶段,从下到下到上,为了验证FBUDERDER,我们从多个方面(例如PT)的域域域域域域域域数据库和时间成本,我们可以从多个方面(例如树质量和时间成本)进行实验,利用Linux 分配生态系统。具体地,我们同时开发并评估GDRILEDER的24个域域域域域域域域域域域域域域域域域域域域域域域域域域图,在S-S-S-realdealdealalalalalalalalalalalalde 上的一个域域域域域域域域BBBBBBB的一个特性特性,在11级GBBBILBILILB。","Dongming Jin, Zhi Jin, Nianyu Li, Kai Yang, Linyu Li, Suijing Guan",2025-06-04T13:33:53Z,Automatic Multi-level Feature Tree Construction for Domain-Specific   Reusable Artifacts Management,Automatische Mehrebenen-Feature-Bauweise für Domain-Spezifische wiederverwendbare Artefakte Management,用于域域特定可使用性能管理的多级自动多级特性树建设,http://arxiv.org/abs/2506.03946v1
27,"Large language models (LLMs) often struggle with visualization tasks like plotting diagrams, charts, where success depends on both code correctness and visual semantics. Existing instruction-tuning datasets lack execution-grounded supervision and offer limited support for iterative code correction, resulting in fragile and unreliable plot generation. We present VisCode-200K, a large-scale instruction tuning dataset for Python-based visualization and self-correction. It contains over 200K examples from two sources: (1) validated plotting code from open-source repositories, paired with natural language instructions and rendered plots; and (2) 45K multi-turn correction dialogues from Code-Feedback, enabling models to revise faulty code using runtime feedback. We fine-tune Qwen2.5-Coder-Instruct on VisCode-200K to create VisCoder, and evaluate it on PandasPlotBench. VisCoder significantly outperforms strong open-source baselines and approaches the performance of proprietary models like GPT-4o-mini. We further adopt a self-debug evaluation protocol to assess iterative repair, demonstrating the benefits of feedback-driven learning for executable, visually accurate code generation.","大型语言模型(LLMS)经常与图示图、图表等可视化任务挣扎,成功与否取决于代码正确性和视觉语义。现有的指令调数据集缺乏执行现场的监督,对迭代代码校正的支持有限,导致生成脆弱和不可靠的地块。我们在VisCode-200K上展示了用于 Python 可视化和自我校正的大型指令调制数据集VisCode-200K。它包含来自两个来源的200K以上实例:(1) 验证过的开放源库的绘图代码,配以自然语言指令和设定图;(2) 45K 多方向校正对话,使代码后退的模型能够利用运行时间反馈修改错误代码。我们在VisCode-200K上展示了Viscoder-200K的微调调调调调调调调调调数据,并在PandasPlotBench. VisCoder 上评价了强的开放源基线,并接近了GPT-4-O-Mini等专有模型的性模型的性能。我们进一步采用了自调调式评价程序来调式评价程序,用于评估生成的模拟校正变码的模拟的模拟。我们进一步采用自调制评估程序,以评价程序,以评估生成的模拟的模拟的模拟的模拟的生成的模拟的模拟的模拟。","Yuansheng Ni, Ping Nie, Kai Zou, Xiang Yue, Wenhu Chen",2025-06-04T13:24:44Z,VisCoder: Fine-Tuning LLMs for Executable Python Visualization Code   Generation,VisCoder: Feinjustierende LLMs für die Generierung von ausführbaren Python-Visualisierungscodes,VisCoder: 用于可执行的 Python 可视化代码生成的精准导出LMsLMs,http://arxiv.org/abs/2506.03930v1
28,"Several closed-source LLMs have consistently outperformed open-source alternatives in program repair tasks, primarily due to their superior reasoning capabilities and extensive pre-training. This paper introduces Repairity, a novel three-stage methodology that significantly narrows this performance gap through reasoning extraction and reinforcement learning. Our approach: (1) systematically filters high-quality reasoning traces from closed-source models using correctness verification, (2) transfers this reasoning knowledge to open-source models via supervised fine-tuning, and (3) develops reinforcement learning with LLM-based feedback to further optimize performance. Empirical evaluation across multiple program repair benchmarks demonstrates that Repairity improves the performance of Qwen2.5-Coder-32B-Instruct, a base open source LLM, by 8.68\% on average, reducing the capability gap with Claude-Sonnet3.7, a state-of-the-art closed-source model, from 10.05% to 1.35%. Ablation studies confirm that both reasoning extraction and LLM-guided reinforcement learning contribute significantly to these improvements. Our methodology generalizes effectively to additional code-related tasks, enabling organizations to leverage high-quality program repair capabilities while maintaining the customizability, transparency, and deployment flexibility inherent to open-source models.","几个封闭源LLM公司在方案维修任务中一直表现优于开放源的替代方法,这主要是因为它们的推理能力和广泛的培训前阶段。本文件介绍了修复,这是一个新颖的三阶段方法,通过推理提取和强化学习大大缩小了绩效差距。我们的方法:(1) 系统地过滤来自封闭源模式的高质量推理痕迹,使用正确性核查,(2) 通过监管的微调将这种推理知识转移到开放源模式,(3) 通过基于LLM公司的反馈发展强化学习,以进一步优化绩效。多个方案修理基准的实证评估表明,修复可提高Quen2.5-Coder-32B-Instruct的绩效,这是基础开放源LM公司的业绩,平均提高8.68,从而缩小了与Claude-Sonnet3.7公司的能力差距,这是一种先进的封闭源模式,从0.05%到1.35%。 吸收研究证实,推理提取和LM公司指导的强化学习为这些改进作出了重大贡献。我们的方法对与代码相关的额外任务作了有效的普及,使各组织能够利用高品质的软件配置灵活性,同时保持客户可操作性、透明性、透明性和固有的软件部署。","Xunzhu Tang, Jacques Klein, Tegawendé F. Bissyandé",2025-06-04T13:13:58Z,Boosting Open-Source LLMs for Program Repair via Reasoning Transfer and   LLM-Guided Reinforcement Learning,Steigerung von Open-Source-LLMs zur Programmreparatur durch vernünftigen Transfer und LLM-geführtes Verstärkungslernen,"推动开放源开放LLM项目,通过合理调剂和LLM-指导强化学习进行方案维修",http://arxiv.org/abs/2506.03921v1
29,"Smart contracts are computer programs that run on blockchain platforms, with Solidity being the most widely used language for their development. As blockchain technology advances, smart contracts have become increasingly important across various fields. In order for smart contracts to operate correctly, the correctness of the compiler is particularly crucial. Although some research efforts have been devoted to testing Solidity compilers, they primarily focus on testing methods and do not address the core issue of generating test programs. To fill this gap, this paper designs and implements Solsmith, a test program generator specifically aimed at uncovering defects in Solidity compilers. It tests the compiler correctness by generating valid and diverse Solidity programs. We have designed a series of unique program generation strategies tailored to Solidity, including enabling optimizations more frequently, avoiding undefined behaviour, and mitigating behavioural differences caused by intermediate representations. To validate the effectiveness of Solsmith, we assess the effectiveness of the test programs generated by Solsmith using the approach of differential testing. The preliminary results show that Solsmith can generate the expected test programs and uncover four confirmed defects in Solidity compilers, demonstrating the effectiveness and potential of Solsmith.","智能合同是计算机程序,它们运行在链链平台上,而“团结”是其发展最广泛使用的语言。作为链链式技术的进步,智能合同在各个领域变得越来越重要。为了使智能合同能够正确运行,编译员的正确性尤为重要。虽然一些研究工作致力于测试“团结”编译员,但它们主要侧重于测试方法,而没有解决产生测试程序的核心问题。为了填补这一空白,纸面设计和软件Solmith是专门为发现“团结”编译员的缺陷而设计的测试程序生成者。它通过生成有效和多样化的“团结”程序测试了“汇编员的正确性。我们设计了一系列适合“团结”的独特程序生成战略,包括更频繁地进行优化,避免未定义的行为,以及减少由中间表述造成的行为差异。为了验证“Solsmith”的有效性,我们利用差别测试方法评估了“Solsmith”产生的测试程序的有效性。初步结果表明,“Solmith”能够生成预期的测试程序,并发现“团结”编译员的4个经证实的缺陷,展示了“ Solsmith”的有效性和潜力。","Lantian Li, Zhihao Liu, Zhongxing Yu",2025-06-04T13:04:17Z,Solsmith: Solidity Random Program Generator for Compiler Testing,Solsmith: Solidity Random Programm Generator für Compiler Tests,Solsmith: 用于汇编者测试的固态随机程序生成器,http://arxiv.org/abs/2506.03909v1
30,"With the rise of AI-based code generation, customizing existing code out of natural language instructions to modify visual results -such as figures or images -has become possible, promising to reduce the need for deep programming expertise. However, even experienced developers can struggle with this task, as it requires identifying relevant code regions (feature location), generating valid code variants, and ensuring the modifications reliably align with user intent. In this paper, we introduce vTikZ, the first benchmark designed to evaluate the ability of Large Language Models (LLMs) to customize code while preserving coherent visual outcomes. Our benchmark consists of carefully curated vTikZ editing scenarios, parameterized ground truths, and a reviewing tool that leverages visual feedback to assess correctness. Empirical evaluation with stateof-the-art LLMs shows that existing solutions struggle to reliably modify code in alignment with visual intent, highlighting a gap in current AI-assisted code editing approaches. We argue that vTikZ opens new research directions for integrating LLMs with visual feedback mechanisms to improve code customization tasks in various domains beyond TikZ, including image processing, art creation, Web design, and 3D modeling.","随着AI型代码生成的兴起,从自然语言指令中定制现有代码以修改视觉结果(如数字或图像)已成为可能,有望减少对深层编程专门知识的需求。然而,即使有经验的开发者也可以为此而挣扎,因为需要确定相关的代码区域(地物位置),生成有效的代码变量,并确保与用户意图可靠地保持一致。在本文件中,我们引入了 vTikZ,这是旨在评价大语言模型(LLMS)在保存一致的视觉结果的同时自定义代码能力的第一个基准。我们的基准包括精心整理的 vTikZ编辑情景、参数化地面真相以及一个审查工具,利用视觉反馈评估正确性。与最新LLMS的实证评估表明,现有解决方案在可靠地修改代码与视觉意图保持一致方面挣扎,突出当前AI型代码编辑方法的差距。我们说, vTikZ为将LMS与视觉反馈机制相结合,以改进TikZ以外各个领域的代码定制任务开辟了新的研究方向,包括图像处理、艺术创作、网络设计和3D建模。","Charly Reux, Mathieu Acher, Djamel Eddine Khelladi, Olivier Barais, Clément Quinton",2025-06-04T12:57:19Z,LLM Code Customization with Visual Results: A Benchmark on TikZ,LLM-Code-Anpassung mit visuellen Ergebnissen: Ein Benchmark auf TikZ,具有视觉效果的LLM 码定制:TikZ基准,http://arxiv.org/abs/2505.04670v2
31,"In our previous research, we addressed the problem of automated transformation of models, represented using the business process model and notation (BPMN) standard, into the methods of a smart contract. The transformation supports BPMN models that contain complex multi-step activities that are supported using our concept of multi-step nested trade transactions, wherein the transactional properties are enforced by a mechanism generated automatically by the transformation process from a BPMN model to a smart contract. In this paper, we present a methodology for repairing a smart contract that cannot be completed due to events that were not anticipated by the developer and thus prevent the completion of the smart contract. The repair process starts with the original BPMN model fragment causing the issue, providing the modeler with the innermost transaction fragment containing the failed activity. The modeler amends the BPMN pattern on the basis of successful completion of previous activities. If repairs exceed the inner transaction's scope, they are addressed using the parent transaction's BPMN model. The amended BPMN model is then transformed into a new smart contract, ensuring consistent data and logic transitions. We previously developed a tool, called TABS+, as a proof of concept (PoC) to transform BPMN models into smart contracts for nested transactions. This paper describes the tool TABS+R, developed by extending the TABS+ tool, to allow the repair of smart contracts.","在先前的研究中,我们处理了将模型自动转换成智能合同的方法的问题,这些模型使用业务流程模型和标记标准(BPMN)代表的模型自动转换成智能合同的方法。这种转换支持了BPMN模型,这些模型包含复杂的多步活动,这些模型利用我们的多步嵌套贸易交易概念得到支持,其中交易性质由从BPMN模型转换成智能合同而自动产生的机制加以执行。在本文中,我们提出了一个修复智能合同的方法,由于开发商没有预见到的事件而无法完成,因此无法完成智能合同的智能合同。修复过程始于原始的BPMN模型碎片引发问题的,为建模者提供了包含失败活动的最深层交易碎片。模型在成功完成以前的活动的基础上对BPMN模型模式进行了修正。如果修理超出内部交易的范围,则使用母交易的BPMN模型加以处理。随后将修改后的BMN模型转换成一个新的智能合同,确保数据和逻辑转换。我们以前开发了一个工具,称为TABS+智能BS模型,将智能交易转化为工具工具工具工具。","Christian Gang Liu, Peter Bodorik, Dawn Jutla",2025-06-04T12:13:07Z,Automated Mechanism to Support Trade Transactions in Smart Contracts   with Upgrade and Repair,Automatisierter Mechanismus zur Unterstützung von Handelstransaktionen in Smart Contracts mit Upgrade und Reparatur,支持升级和修理智能合同贸易交易的自动化机制,http://arxiv.org/abs/2506.03877v1
32,"Neurodiversity describes variation in brain function among people, including common conditions such as Autism spectrum disorder (ASD), Attention deficit hyperactivity disorder (ADHD), and dyslexia. While Software Engineering (SE) literature has started to explore the experiences of neurodivergent software engineers, there is a lack of research that compares their challenges to those of neurotypical software engineers. To address this gap, we analyze existing data from the 2022 Stack Overflow Developer survey that collected data on neurodiversity. We quantitatively compare the answers of professional engineers with ASD (n=374), ADHD (n=1305), and dyslexia (n=363) with neurotypical engineers. Our findings indicate that neurodivergent engineers face more difficulties than neurotypical engineers. Specifically, engineers with ADHD report that they face more interruptions caused by waiting for answers, and that they less frequently interact with individuals outside their team. This study provides a baseline for future research comparing neurodivergent engineers with neurotypical ones. Several factors in the Stack Overflow survey and in our analysis are likely to lead to conservative estimates of the actual effects between neurodivergent and neurotypical engineers, e.g., the effects of the COVID-19 pandemic and our focus on employed professionals.","软件工程(SE)文献开始探索神经分解软件工程师的经验,但缺乏将其挑战与神经异常软件工程师的挑战进行比较的研究。为了弥补这一差距,我们分析了收集神经多样性数据的2022年Stack超流开发者调查的现有数据。我们量化地比较了专业工程师的答案,如自闭症谱谱系障碍(ASD)、自闭症多动障碍(ADHD)(n=1305)和自闭症(n=363)与神经异常工程师的答案。虽然软件工程(SE)文献已开始探索神经分解工程师的经验,但缺乏将其挑战与神经异常软件工程师的挑战进行比较的研究。为了解决这一差距,我们分析了2022年Stack超流出开发者调查收集神经多样性数据的现有数据。我们量化地比较了专业工程师的答案(n=374),ADHDHD(n=1305)和自闭症(n=363)与神经超常动工程师的答案。我们的研究结果表明,神经分辨工程师比神经分辨工程师面临更多的困难。具体地说,他们因等待答案而面临更多的干扰干扰,他们与其团队外的个人互动接触。本研究为未来的研究提供了比较神经分解工程师和神经分流和神经分流研究的基准。在神经分流调查和神经分流和神经分流研究的影响。","Pragya Verma, Marcos Vinicius Cruz, Grischa Liebel",2025-06-04T11:17:03Z,Differences between Neurodivergent and Neurotypical Software Engineers:   Analyzing the 2022 Stack Overflow Survey,Unterschiede zwischen Neurodivergenten und neurotypischen Software-Ingenieuren: Analyse der Stack Overflow Survey 2022,Neucrodistrent 和 Neurodrom软件工程师之间的差异:分析2022年Stack 溢流调查,http://arxiv.org/abs/2506.03840v1
33,"Traditional Business Process Management (BPM) struggles with rigidity, opacity, and scalability in dynamic environments while emerging Large Language Models (LLMs) present transformative opportunities alongside risks. This paper explores four real-world use cases that demonstrate how LLMs, augmented with trustworthy process intelligence, redefine process modeling, prediction, and automation. Grounded in early-stage research projects with industrial partners, the work spans manufacturing, modeling, life-science, and design processes, addressing domain-specific challenges through human-AI collaboration. In manufacturing, an LLM-driven framework integrates uncertainty-aware explainable Machine Learning (ML) with interactive dialogues, transforming opaque predictions into auditable workflows. For process modeling, conversational interfaces democratize BPMN design. Pharmacovigilance agents automate drug safety monitoring via knowledge-graph-augmented LLMs. Finally, sustainable textile design employs multi-agent systems to navigate regulatory and environmental trade-offs. We intend to examine tensions between transparency and efficiency, generalization and specialization, and human agency versus automation. By mapping these trade-offs, we advocate for context-sensitive integration prioritizing domain needs, stakeholder values, and iterative human-in-the-loop workflows over universal solutions. This work provides actionable insights for researchers and practitioners aiming to operationalize LLMs in critical BPM environments.","本文探讨四个现实世界使用的案例,这些案例展示了LLMM如何以值得信赖的过程情报、重新定义过程模型、预测和自动化加以增强; 以工业伙伴的早期研究项目为基础,工作范围包括制造、建模、生命科学和设计过程,通过人类-AI合作解决特定领域的挑战; 在制造业,由LLM驱动的框架将具有可解释性的不确定性的机器学习(ML)与互动对话相结合,将不透明的预测转化为可审计工作流程; 在程序建模方面,对话界面使BPMN设计民主化; 药效调和代理自动化药物安全监测,通过知识-绘图推荐LMMMs进行; 最后,可持续纺织设计采用多试系统,以管理监管和环境交易; 我们打算研究透明度和效率、一般化和专业化以及人力资源与自动化之间的紧张关系; 通过绘制这些取舍的图解,我们倡导将这种对背景敏感的一体化,使BPM工作流程成为对领域需要的民主化。","Peter Pfeiffer, Alexander Rombach, Maxim Majlatow, Nijat Mehdiyev",2025-06-04T10:12:09Z,"From Theory to Practice: Real-World Use Cases on Trustworthy LLM-Driven   Process Modeling, Prediction and Automation","Von der Theorie zur Praxis: Real-World Use Cases on Trustworthy LLM-Driven Process Modeling, Prediction and Automation",从理论到实践:关于可信赖的LLM-驱动过程建模、预测和自动化的真实世界使用案例,http://arxiv.org/abs/2506.03801v1
34,"Continuous Integration and Continuous Deployment (CI/CD) pipelines are pivotal to modern software engineering, yet diagnosing and resolving their failures remains a complex and labor-intensive challenge. In this paper, we present LogSage, the first end-to-end LLM-powered framework that performs root cause analysis and solution generation from failed CI/CD pipeline logs. During the root cause analysis stage, LogSage employs a specialized log preprocessing pipeline tailored for LLMs, which extracts critical error logs and eliminates noise to enhance the precision of LLM-driven root cause analysis. In the solution generation stage, LogSage leverages RAG to integrate historical resolution strategies and utilizes tool-calling to deliver actionable, automated fixes. We evaluated the root cause analysis stage using a newly curated open-source dataset, achieving 98\% in precision and 12\% improvement over naively designed LLM-based log analysis baselines, while attaining near-perfect recall. The end-to-end system was rigorously validated in a large-scale industrial CI/CD environment of production quality, processing more than 3,000 executions daily and accumulating more than 1.07 million executions in its first year of deployment, with end-to-end precision exceeding 88\%. These two forms of evaluation confirm that LogSage providing a scalable and practical solution to manage CI/CD pipeline failures in real-world DevOps workflows.","连续整合和连续部署(CI/CD)管道是现代软件工程的关键,但诊断和解决其失败仍然是一个复杂和劳动密集型的挑战。本文介绍LogSage,这是第一个端到端LLM驱动框架,从失败的CI/CD管道记录中进行根本原因分析并产生解决办法。在根源分析阶段,LogSage专门为LLMS专门设计了一个记录前处理管道,提取关键错误日志,消除噪音,以提高LLMM驱动的根源分析的精确性。在解决方案生成阶段,LogSage利用RAG将历史解决方案战略整合起来,并利用工具呼叫交付可操作的自动修正。我们利用新整理的开源数据集评估了根源分析阶段,实现了98精确度和12改进了天真设计的LLMM逻辑分析基线,同时实现了近乎效果的回顾。终端到终端系统系统在大型工业性CI/CD环境中得到严格验证,每天处理3 000多起处决,并且正在将超过1.07万次的RAG-D在第一年的精确度上进行精确的运行。","Weiyuan Xu, Juntao Luo, Tao Huang, Kaixin Sui, Jie Geng, Qijun Ma, Isami Akasaka, Xiaoxue Shi, Jing Tang, Peng Cai",2025-06-04T08:22:56Z,A Two-Staged LLM-Based Framework for CI/CD Failure Detection and   Remediation with Industrial Validation,Ein zweistufiges LLM-basiertes Framework für CI/CD-Fehlererkennung und -Reparatur mit industrieller Validierung,以双级LLM为基础的CI/CD故障检测和用工业验证进行补救的CI/CD故障检测和补救框架,http://arxiv.org/abs/2506.03691v1
35,"Auto-vectorization is a fundamental optimization for modern compilers to exploit SIMD parallelism. However, state-of-the-art approaches still struggle to handle intricate code patterns, often requiring manual hints or domain-specific expertise. Large language models (LLMs), with their ability to capture intricate patterns, provide a promising solution, yet their effective application in compiler optimizations remains an open challenge due to issues such as hallucinations and a lack of domain-specific reasoning. In this paper, we present VecTrans, a novel framework that leverages LLMs to enhance compiler-based code vectorization. VecTrans first employs compiler analysis to identify potentially vectorizable code regions. It then utilizes an LLM to refactor these regions into patterns that are more amenable to the compilers auto-vectorization. To ensure semantic correctness, VecTrans further integrates a hybrid validation mechanism at the intermediate representation (IR) level. With the above efforts, VecTrans combines the adaptability of LLMs with the precision of compiler vectorization, thereby effectively opening up the vectorization opportunities. experimental results show that among all TSVC functions unvectorizable by GCC, ICC, Clang, and BiSheng Compiler, VecTrans achieves an geomean speedup of 1.77x and successfully vectorizes 24 of 51 test cases. This marks a significant advancement over state-of-the-art approaches while maintaining a cost efficiency of $0.012 per function optimization for LLM API usage.","对现代编译者来说,自动消化是利用SIMD平行法的一种基本优化。然而,最先进的方法仍然难以处理复杂的代码模式,往往需要人工提示或特定领域的专门知识。大型语言模型(LLMS)具有捕捉复杂模式的能力,提供了有希望的解决办法,但它们在编译器优化方面的有效应用仍然是一个公开的挑战,因为存在幻觉和缺乏特定域的推理等问题。在本文件中,我们介绍了VecTrans,这是一个利用LLMS来利用LLMS来增强基于编译器的编码矢量的精确度的新框架。VecTrans首先使用编译器分析,以确定潜在的可传译代码区域。然后,它利用LLM将这些区域重新编成更适合编译者自动演算的模式。为了确保语义正确性,VecTranser进一步整合了中间代言层(IR)一级的混合验证机制。通过上述努力,VecTransmal将LMS的适应性与基于编译器矢量的精确度的精确度结合起来,从而有效地打开传介机会。在TSVSLMSLM中,所有TSLMLM 24级(Cx) 级的快速测试性、Cx) 上,并成功进行一个测试。","Zhongchun Zheng, Kan Wu, Long Cheng, Lu Li, Rodrigo C. O. Rocha, Tianyi Liu, Wei Wei, Jianjiang Zeng, Xianwei Zhang, Yaoqing Gao",2025-06-04T07:49:21Z,VecTrans: Enhancing Compiler Auto-Vectorization through LLM-Assisted   Code Transformations,VecTrans: Verbesserung der automatischen Vektorisierung des Compilers durch LLM-Assistente Code-Transformationen,"Vectrans:通过LLM协助的代码转换,加强编纂者自动检验",http://arxiv.org/abs/2503.19449v3
36,"The quantity and quality of vulnerability datasets are essential for developing deep learning solutions to vulnerability-related tasks. Due to the limited availability of vulnerabilities, a common approach to building such datasets is analyzing security patches in source code. However, existing security patches often suffer from inaccurate labels, insufficient contextual information, and undecidable patches that fail to clearly represent the root causes of vulnerabilities or their fixes. These issues introduce noise into the dataset, which can mislead detection models and undermine their effectiveness. To address these issues, we present mono, a novel LLM-powered framework that simulates human experts' reasoning process to construct reliable vulnerability datasets. mono introduces three key components to improve security patch datasets: (i) semantic-aware patch classification for precise vulnerability labeling, (ii) iterative contextual analysis for comprehensive code understanding, and (iii) systematic root cause analysis to identify and filter undecidable patches. Our comprehensive evaluation on the MegaVul benchmark demonstrates that mono can correct 31.0% of labeling errors, recover 89% of inter-procedural vulnerabilities, and reveals that 16.7% of CVEs contain undecidable patches. Furthermore, mono's enriched context representation improves existing models' vulnerability detection accuracy by 15%. We open source the framework mono and the dataset MonoLens in https://github.com/vul337/mono.","脆弱性数据集的数量和质量对于制定与脆弱性有关的任务的深层次学习解决方案至关重要。由于脆弱性的可用性有限,建立这类数据集的共同方法是分析源代码中的安全补丁。然而,现有的安全补丁往往受到标签不准确、背景信息不足和无法分解的补丁的困扰,无法清楚地代表脆弱性的根源或固定点。这些问题在数据集中引入噪音,这可能会误导检测模型,损害其有效性。为了解决这些问题,我们只提出一个创新的LLM驱动框架,模拟人类专家构建可靠脆弱性数据集的推理过程。一个单项引入了三个关键组成部分来改进安全补丁数据集:(一) 精确脆弱性标签的语义认知补丁分类,(二) 用于全面理解代码的迭代背景分析,以及(三) 系统化根分析,以识别和过滤不可分解的补补补补的补补补补补。我们对Megavul基准的全面评价表明,单项能够纠正31.0%的标签误差,恢复89 %的跨度脆弱性数据集。单项引入了三个关键部分的CVE的精确度分类/透明度框架,并揭示了16.7%的CVERismroup 15 的元的元的元的元的元的加密的元化数据。","Zeyu Gao, Junlin Zhou, Bolun Zhang, Yi He, Chao Zhang, Yuxin Cui, Hao Wang",2025-06-04T07:43:04Z,"Mono: Is Your ""Clean"" Vulnerability Dataset Really Solvable? Exposing   and Trapping Undecidable Patches and Beyond","Mono: Ist Ihr ""sauberer"" Sicherheitsdatensatz wirklich lösbar? Unentschlossene Patches und darüber hinaus enthüllen und verschleppen",Mono: 您的“ 干净” 脆弱数据集是否真的可以解决? 曝光和跟踪不可量化的补丁及其他,http://arxiv.org/abs/2506.03651v1
37,"Function-calling has enabled large language models (LLMs) to act as tool-using agents, but injecting thousands of tool schemas into the prompt is costly and error-prone. We introduce MCP-Zero, a proactive agent framework that lets the LLM itself decide when and which external tools to retrieve, thereby assembling a task-specific toolchain from scratch. The framework is built upon three components: (1) Proactive Tool Request, where the model emits a structured $\left<\operatorname{tool\_assistant}\right>$ block that explicitly specifies the desired server and task; (2) Hierarchical Vector Routing, a coarse-to-fine retrieval algorithm that first selects candidate servers and then ranks tools within each server based on the semantic similarity; (3) Iterative Proactive Invocation, enabling multi-round, cross-domain toolchain construction with minimal context overhead, and allowing the model to iteratively revise its request when the returned tools are insufficient. To evaluate our approach we also compile MCP-tools, a retrieval dataset comprising 308 MCP servers and 2,797 tools extracted from the official Model-Context-Protocol repository and normalized into a unified JSON schema. Experiments show that MCP-Zero (i) effectively addresses the context overhead problem of existing methods and accurately selects the correct tool from a pool of nearly 3,000 candidates (248.1k tokens); (ii) reduces token consumption by 98\% on the APIbank while maintaining high accuracy; and (iii) supports multi-turn tool invocation with consistent accuracy across rounds.","调用功能使大型语言模型(LLMS)能够作为工具使用代理商,但将数千个工具图状输入到快速点是昂贵和容易出错的。我们引入了MCP-Zero,这是一个让LLM自己决定何时和哪些外部工具的主动代理框架,让LLM自己决定何时和哪些外部工具可以检索,从而从零开始集合一个任务特定的工具链。该框架建立在三个组成部分上:(1) 主动工具请求,其中模型释放了一个结构化的$leftoperatorname{toolregnt@right>$块,明确指定了所需的服务器和任务;(2) 高级矢量矢量矢量矢量旋转,一个粗精精精精精精精确的精确度到精准的精准精准精准精确度检索算法,首先根据语义的相似性选择候选服务器,然后将工具排在每服务器内部排序;(3) 动态主动性,使多方向工具链结构能够反复修改其请求。 我们还将多CP工具汇编一个检索数据集,由308 MCP服务器和2 797 快速的检索工具库中,同时从正常地展示一个常规的模型,从目前的模型-Slimal工具库中将一个正常地复制了。","Xiang Fei, Xiawu Zheng, Hao Feng",2025-06-04T06:37:09Z,MCP-Zero: Proactive Toolchain Construction for LLM Agents from Scratch,MCP-Zero: Proaktive Werkzeugkettenkonstruktion für LLM-Agenten von Scratch,MCP-零:Scratch公司LLM代理商的前瞻性供应链建设,http://arxiv.org/abs/2506.01056v2
38,"Fault localization, the process of identifying the software components responsible for failures, is essential but often time-consuming. Recent advances in Large Language Models (LLMs) have enabled fault localization without extensive defect datasets or model fine-tuning. However, existing LLM-based methods rely only on general LLM capabilities and lack integration of project-specific knowledge, resulting in limited effectiveness, especially for complex software.   We introduce MemFL, a novel approach that enhances LLM-based fault localization by integrating project-specific knowledge via external memory. This memory includes static summaries of the project and dynamic, iterative debugging insights gathered from previous attempts. By leveraging external memory, MemFL simplifies debugging into three streamlined steps, significantly improving efficiency and accuracy. Iterative refinement through dynamic memory further enhances reasoning quality over time.   Evaluated on the Defects4J benchmark, MemFL using GPT-4o-mini localized 12.7% more bugs than current LLM-based methods, achieving this improvement with just 21% of the execution time (17.4 seconds per bug) and 33% of the API cost (0.0033 dollars per bug). On complex projects, MemFL's advantage increased to 27.6%. Additionally, MemFL with GPT-4.1-mini outperformed existing methods by 24.4%, requiring only 24.7 seconds and 0.0094 dollars per bug. MemFL thus demonstrates significant improvements by effectively incorporating project-specific knowledge into LLM-based fault localization, delivering high accuracy with reduced time and cost.","错误本地化是查明造成故障的软件元件的过程,这是必要,但往往耗费时间。大语言模型(LLMS)的最近进步使得在没有广泛的缺陷数据集或模型微调的情况下出现故障本地化,但是,现有的LLMM方法仅依靠一般LLM能力,缺乏具体项目知识的整合,结果效果有限,特别是对复杂的软件而言。我们引入MemFLL,这是一种新颖的办法,通过将基于LLM的本地化知识纳入外部记忆,从而增强基于LLM的本地化。这种记忆包括项目静态摘要和动态的、从以往尝试中收集的反复调试的洞见。通过利用外部记忆,MemFLL简化到三个简化的步骤,大大提高效率和准确性。通过动态记忆的优化,随着时间的推移进一步提高推理质量。根据Deffects4J基准评估MemFLFL,使用GP-4-min-mino-MMMLF, 比目前基于LM方法多12.7%,只用21%的执行错误时间(每个错误17.4秒)和APILF成本的33%(0.00M-M-40美元)的改进,因此将现有的M-M-FLFLFLFLM-rol项目从24美元改为25的改进。","Inseok Yeo, Duksan Ryu, Jongmoon Baik",2025-06-04T05:33:32Z,Improving LLM-Based Fault Localization with External Memory and Project   Context,Verbesserung der LLM-basierten Fehlerlokalisierung mit externem Speicher und Projektkontext,利用外部内存和项目背景改进基于LLM的LLM违约地方化,http://arxiv.org/abs/2506.03585v1
39,"Current research on large language models (LLMs) with retrieval-augmented code generation (RACG) mainly focuses on single-language settings, leaving cross-lingual effectiveness and security unexplored. Multi-lingual RACG systems are valuable for migrating code-bases across programming languages (PLs), yet face risks from error (e.g. adversarial data corruption) propagation in cross-lingual transfer. We construct a dataset spanning 13 PLs with nearly 14k instances to explore utility and robustness of multi-lingual RACG systems. Our investigation reveals four key insights: (1) Effectiveness: multi-lingual RACG significantly enhances multi-lingual code LLMs generation; (2) Inequality: Java demonstrate superior cross-lingual utility over Python in RACG; (3) Robustness: Adversarial attacks degrade performance significantly in mono-lingual RACG but show mitigated impacts in cross-lingual scenarios; Counterintuitively, perturbed code may improve RACG in cross-lingual scenarios; (4) Specialization: Domain-specific code retrievers outperform significantly general text retrievers. These findings establish foundation for developing effective and secure multi-lingual code assistants.","目前关于大语言模型(LLMs)的研究(LLMs)具有检索增强代码生成功能,主要侧重于单一语言环境,使跨语言的有效性和安全性得不到探索。多语言RACG系统对于跨程序语言迁移代码库很有价值,但面临跨语言传输错误(如对抗数据腐败)的风险。我们构建了一个涵盖13PLM的数据集,有近14k个实例,探索多语言RACG系统的实用性和稳健性。我们的调查揭示了四个关键洞察:(1) 有效性:多语言RACG显著增强多语言代码LMs的生成;(2) 不平等:Java展示了超越RACG中Python的高级跨语言功能;(3) 强势:Aversarial袭击显著地降低了单语言RACG的性能,但在跨语言情景中显示出减轻的影响; 反直觉的、渗透式代码可以改善跨语言情景中的RACG;(4) 专业化:多语言代码检索器超越了显著的一般文本检索器。这些结论为发展有效和安全的多语言助理奠定了基础。","Qiming Zhu, Jialun Cao, Xuanang Chen, Yaojie Lu, Hongyu Lin, Xianpei Han, Le Sun, Shing-Chi Cheung",2025-06-04T03:31:00Z,Across Programming Language Silos: A Study on Cross-Lingual   Retrieval-augmented Code Generation,Across Programming Language Silos: Eine Studie zur Cross-Lingual Retrieval-Augmented Code Generation,跨语言学习室:关于跨语言检索的跨语言学习,http://arxiv.org/abs/2506.03535v1
40,"Ensuring the robustness of code generated by large language models (LLMs) is crucial for real-world reliability. However, existing evaluations predominantly focus on correctness, often neglecting key robustness concerns such as missing input validation and insufficient error handling. In this paper, we present the first empirical study on the robustness of LLM-generated code. We introduce novel robustness metrics and analyze four state-of-the-art code LLMs, revealing that, on average, 43.1% of their generated code is less robust than human-written counterparts. Notably, over 90% of robustness deficiencies stem from missing conditional checks, with 70% of these omissions occurring in the first line of code. Additionally, in 69% of cases where a conditional statement is necessary but absent, the ""if"" token still ranks third or higher in the model's predicted token probabilities, indicating an implicit recognition of control structures. Building on these findings, we propose RobGen, a framework designed to enhance code robustness without requiring model retraining. RobGen leverages two model-agnostic techniques: RobGen-Adj, which dynamically adjusts token probabilities during decoding to encourage the inclusion of control structures, and RobGen-Ins, which improves generated code by inserting missing conditionals after generation. Experimental results demonstrate that RobGen reduces the proportion of less robust model-generated code by 20.0%, significantly enhancing code reliability across diverse tasks. As a lightweight and adaptable solution, RobGen effectively mitigates robustness challenges in LLM-generated code. All code and data are available at https://github.com/SYSUSELab/RobGen.","确保大型语言模型(LLMS)生成的代码的稳健性对于真实世界的可靠性至关重要。 但是,现有的评价主要侧重于正确性,常常忽视关键稳健性关切,例如缺失输入验证和错误处理不足。 在本文中,我们提出了关于LLM生成代码稳健性的第一次实证研究。 我们引入了新的稳健性指标,并分析了四个最先进的代码LLMS, 显示其生成的代码平均有43.1%比人造代码强。 值得注意的是,超过90%的稳健性缺陷来自缺失的有条件检查,其中70%的遗漏发生在代码的第一行中。 此外,在69%的案例中,如果有条件声明是缺失的,则“如果”符号在模型预测的象征概率中排名第三或更高,表明对控制结构的隐含认识。 基于这些发现,我们建议 RobGen,一个旨在增强代码稳健性的框架,而不需要模型再培训。 RobGen利用两种模型- 智能智能技术:RobGen-Adj,它能动态地稳定性地调整Obbbbbbal-Addj,在生成过程中大幅地改进了数据控制,在解化数据结构中,在生成中,在解化数据生成中可以大幅地改进数据中,在创建化数据中,在生成中,在生成中,在生成过程中,使数据控制过程中会后,使数据格式化地标法则会降低。","Zike Li, Mingwei Liu, Anji Li, Kaifeng He, Yanlin Wang, Xin Peng, Zibin Zheng",2025-06-04T03:08:57Z,Enhancing the Robustness of LLM-Generated Code: Empirical Study and   Framework,Verbesserung der Robustheit des LLM-generierten Codes: Empirische Studie und Rahmen,加强LLM-创制守则的威力:经验研究和框架,http://arxiv.org/abs/2503.20197v3
41,"This proposal discusses the growing challenges in reverse engineering modern software binaries, particularly those compiled from newer system programming languages such as Rust, Go, and Mojo. Traditional reverse engineering techniques, developed with a focus on C and C++, fall short when applied to these newer languages due to their reliance on outdated heuristics and failure to fully utilize the rich semantic information embedded in binary programs. These challenges are exacerbated by the limitations of current data-driven methods, which are susceptible to generating inaccurate results, commonly referred to as hallucinations. To overcome these limitations, we propose a novel approach that integrates probabilistic binary analysis with fine-tuned large language models (LLMs). Our method systematically models the uncertainties inherent in reverse engineering, enabling more accurate reasoning about incomplete or ambiguous information. By incorporating LLMs, we extend the analysis beyond traditional heuristics, allowing for more creative and context-aware inferences, particularly for binaries from diverse programming languages. This hybrid approach not only enhances the robustness and accuracy of reverse engineering efforts but also offers a scalable solution adaptable to the rapidly evolving landscape of software development.","本提案讨论了反向工程现代软件的二进制,特别是从鲁斯特、戈和莫霍等较新的系统编程语言中汇编出来的软件。以C和C+++为重点开发的传统反向工程技术,在应用到这些较新语言时,由于依赖过时的超自然学和未能充分利用二进制程序所包含的丰富的语义信息,因此不够完善。由于目前数据驱动方法的局限性,容易产生不准确的结果(通常称为幻觉),这些挑战更加严重。为了克服这些限制,我们提出了一种新颖的方法,将概率二进制分析与微调的大语言模型(LLMs)相结合。我们的方法系统地模拟了反向工程中固有的不确定性,使得能够更准确地解释不完整或模糊的信息。我们通过纳入LLMS,将分析扩大到传统的超自然论,允许更富有创造性和符合背景的推论,特别是针对不同编程语言的二进制。这种混合方法不仅能增强反向工程努力的稳健性和准确性,而且还提供了适应软件发展迅速变化的全局的可变化解决方案。","Zhuo Zhuo, Xiangyu Zhang",2025-06-04T02:45:27Z,Beyond C/C++: Probabilistic and LLM Methods for Next-Generation Software   Reverse Engineering,Beyond C/C++: Probabilistische und LLM-Methoden für Software-Umkehrtechnik der nächsten Generation,C/C+++后C/C++:下一代软件反转工程的概率和LLM方法,http://arxiv.org/abs/2506.03504v1
42,"While large language models (LLMs) have demonstrated remarkable reasoning capabilities, they often struggle with complex tasks that require specific thinking paradigms, such as divide-and-conquer and procedural deduction, \etc Previous researches integrate external, reliable tools to alleviate logical inconsistencies and hallucinations in LLMs' problem-solving processes. However, we argue that the root challenge is more profound: LLMs lack the complex thinking paradigms (\ie, computational thinking) during reasoning. In this paper, we propose Computational Thinking Model (CTM), a novel framework that incorporates computational thinking paradigms into LLMs. This framework enables LLMs to reformulate complex problems through decomposition, abstraction, reduction, and simulation, among other techniques. Specifically, live code execution is seamlessly integrated into the reasoning process, allowing CTM to think by computing. CTM directly instills computational thinking objectives into LLMs through tailored reinforcement learning rewards, which encourages problem simplification, modular planning, and iterative verification. We conduct extensive evaluations on multiple code generation and mathematical benchmarks. The results demonstrate that CTM outperforms conventional reasoning models and tool-augmented baselines in terms of accuracy, interpretability, and generalizability. We hope this study offers valuable insights for AI reasoning, where LLMs can transform problems into robust, verifiable, and scalable computational workflows, much like computer scientists do.","虽然大型语言模型(LLMS)表现出了非凡的推理能力,但它们往往与需要具体思维范式的复杂任务挣扎,如分解和解析及程序推算等,而以往的研究则整合了外部、可靠的工具,以缓解LLMS解决问题过程中的逻辑不一致和幻觉。然而,我们认为,根本挑战是更深刻的:LMS在推理过程中缺乏复杂的思维范式(\ie,计算思维思维),在推理过程中,我们提出“计算思维模式”(CTM),这是一个将计算思维范式纳入LLMS的新框架。这个框架使LMS能够通过分解、抽象、减少和模拟等技术重新配置复杂的问题。具体地说,现场代码执行被无缝地纳入推理过程,使CTM能够通过计算将计算中的计算目标直接将计算进LMS(计算方法),这鼓励问题简化、模块规划、迭代核查。我们对多种代码生成和数学基准进行广泛的评价。结果表明,CTMSLMS超越了常规推理模型和工具推算模型和工具推算模型,在精确性、可理解性推理学上提供了许多的精确的基线。","Kechi Zhang, Ge Li, Jia Li, Huangzhao Zhang, Jingjing Xu, Hao Zhu, Lecheng Wang, Jia Li, Yihong Dong, Jing Mai, Bin Gu, Zhi Jin",2025-06-04T02:01:09Z,Computational Thinking Reasoning in Large Language Models,Computational Thinking Reasoning in großen Sprachmodellen,大语言模式中计算思考理由,http://arxiv.org/abs/2506.02658v2
43,"The rapid evolution of code largelanguage models underscores the need for effective and transparent benchmarking of their reasoning capabilities. However, the current benchmarking approach heavily depends on publicly available, human-created datasets. The widespread use of these fixed benchmark datasets makes the benchmarking process to be static and thus particularly susceptible to data contamination, an unavoidable consequence of the extensive data collection processes used to train Code LLMs. Existing approaches that address data contamination often suffer from human effort limitations and imbalanced problem complexity. To tackle these challenges, we propose \tool, a novel benchmarking suite for evaluating Code LLMs under potential data contamination. Given a seed programming problem, \tool employs multiple agents to extract and modify the context without altering the core logic, generating semantically equivalent variations. We introduce a dynamic data generation methods and conduct empirical studies on two seed datasets across 21 Code LLMs. Results show that \tool effectively benchmarks reasoning capabilities under contamination risks while generating diverse problem sets to ensure consistent and reliable evaluations.","大语言代码模型的迅速演变突出表明,需要对其推理能力进行有效和透明的基准,然而,目前的基准方法在很大程度上依赖于公开的、人造的数据集。这些固定基准数据集的广泛使用使得基准进程是静止的,因此特别容易受到数据污染,这是用于培训代码LLMS的广泛数据收集过程的不可避免的后果。现有的处理数据污染的方法往往受到人类努力的局限和不平衡问题的复杂性的影响。为了应对这些挑战,我们建议为在潜在数据污染下评价代码LMS提供一套新的基准套件。鉴于种子编程问题,\工具使用多种代理来提取和修改环境,而不改变核心逻辑,产生等同的变体。我们采用动态数据生成方法,对21代码LLMS的两个种子数据集进行实证研究。结果显示,在污染风险下,有效的推理能力基准,同时产生不同的问题组,以确保一致性和可靠的评价。","Simin Chen, Pranav Pusarla, Baishakhi Ray",2025-06-03T22:14:34Z,Dynamic Benchmarking of Reasoning Capabilities in Code Large Language   Models Under Data Contamination,Dynamisches Benchmarking von Vernunftfähigkeiten in Code Large Language Models unter Datenkontamination,数据污染下守则大语言模式,http://arxiv.org/abs/2503.04149v2
44,"Recent studies show that 60% of LLM-based compound systems in enterprise environments leverage some form of retrieval-augmented generation (RAG), which enhances the relevance and accuracy of LLM (or other genAI) outputs by retrieving relevant information from external data sources. LLMOps involves the practices and techniques for managing the lifecycle and operations of LLM compound systems in production environments. It supports enhancing LLM systems through continuous operations and feedback evaluation. RAGOps extends LLMOps by incorporating a strong focus on data management to address the continuous changes in external data sources. This necessitates automated methods for evaluating and testing data operations, enhancing retrieval relevance and generation quality. In this paper, we (1) characterize the generic architecture of RAG applications based on the 4+1 model view for describing software architectures, (2) outline the lifecycle of RAG systems, which integrates the management lifecycles of both the LLM and the data, (3) define the key design considerations of RAGOps across different stages of the RAG lifecycle and quality trade-off analyses, (4) highlight the overarching research challenges around RAGOps, and (5) present two use cases of RAG applications and the corresponding RAGOps considerations.","最近的研究表明,企业环境中60%的以LLM为基础的复合系统利用某种形式的检索-增强生成(RAG),通过从外部数据来源检索相关信息,提高LLM(或其他genAI)产出的相关性和准确性。LLMMOps涉及管理LLM复合系统在生产环境中的生命周期和运作的做法和技术。它支持通过连续操作和反馈评价加强LLM系统。RAGOPs通过大力注重数据管理来扩展LMMOps,以应对外部数据源的不断变化。这就要求采用自动化方法来评估和测试数据操作,提高检索相关性和生成质量。在本文件中,我们(1) 描述以4+1模型观点为基础的RAG应用通用结构,(2) 概述RAG系统的生命周期,将LM和数据的管理生命周期结合起来,(3) 界定RAGOPs在RAG生命周期和质量交易分析的不同阶段的主要设计考虑,(4) 突出RAGOPs周围的总体研究挑战,以及(5) 使用RAGAG应用程序和相应的RAGps考虑因素的两个案例。","Xiwei Xu, Hans Weytjens, Dawen Zhang, Qinghua Lu, Ingo Weber, Liming Zhu",2025-06-03T21:22:23Z,RAGOps: Operating and Managing Retrieval-Augmented Generation Pipelines,RAGOps: Betrieb und Verwaltung von Retrieval-Augmented Generation Pipelines,RAGOPs: 操作和管理回收养殖管道,http://arxiv.org/abs/2506.03401v1
45,"Numerous Fault Localisation (FL) and repair techniques have been proposed to address faults in Deep Learning (DL) models. However, their effectiveness in practical applications remains uncertain due to the reliance on pre-defined rules. This paper presents a comprehensive evaluation of state-of-the-art FL and repair techniques, examining their advantages and limitations. Moreover, we introduce a novel approach that harnesses the power of Large Language Models (LLMs) in localising and repairing DL faults. Our evaluation, conducted on a carefully designed benchmark, reveals the strengths and weaknesses of current FL and repair techniques. We emphasise the importance of enhanced accuracy and the need for more rigorous assessment methods that employ multiple ground truth patches. Notably, LLMs exhibit remarkable performance in both FL and repair tasks. For instance, the GPT-4 model achieves 44% and 82% improvements in FL and repair tasks respectively, compared to the second-best tool, demonstrating the potential of LLMs in this domain. Our study sheds light on the current state of FL and repair techniques and suggests that LLMs could be a promising avenue for future advancements.","为解决深层学习(DL)模型中的缺陷,提出了多种失灵定位和修理技术(FL),但是,由于依赖预先确定的规则,这些技术在实际应用中的效力仍然不确定,本文件对最新的FL和修理技术进行了全面评估,审查了其优点和局限性;此外,我们采用了一种新颖的方法,利用大语言模型(LLMs)的力量,对DL错误进行本地化和修复;我们根据精心设计的基准进行的评估,揭示了目前的FL和修理技术的优缺点;我们强调提高准确性的重要性和采用更严格评估方法的必要性,采用多种地面真相补补补。值得注意的是,LLMS在FL和修理任务两方面都表现出了显著的成绩。例如,GPT-4模型在FL和修理任务方面分别实现了44%和82%的改进,与第二最佳工具相比,显示了LLMs在这方面的潜力。我们的研究揭示了目前FL和修理技术的优点和弱点,并表明LMs可以成为未来进步的有希望的途径。","Jinhan Kim, Nargiz Humbatova, Gunel Jahangirova, Shin Yoo, Paolo Tonella",2025-06-03T21:08:33Z,Fault Localisation and Repair for DL Systems: An Empirical Study with   LLMs,Fehler Lokalisierung und Reparatur von DL-Systemen: Eine empirische Studie mit LLMs,DL系统失事定位和修理:与LLMs进行的一项经验研究,http://arxiv.org/abs/2506.03396v1
46,"Automated Program Repair (APR) proposes bug fixes to aid developers in maintaining software. The state of the art in this domain focuses on using LLMs, leveraging their strong capabilities to comprehend specifications in natural language and to generate program code. Recent works have shown that LLMs can be used to generate repairs. However, despite the APR community's research achievements and several industry deployments in the last decade, APR still lacks the capabilities to generalize broadly. In this work, we present an intensive empirical evaluation of LLMs for generating patches. We evaluate a diverse set of 13 recent models, including open ones (e.g., Llama 3.3, Qwen 2.5 Coder, and DeepSeek R1 (dist.)) and closed ones (e.g., o3-mini, GPT-4o, Claude 3.7 Sonnet, Gemini 2.0 Flash). In particular, we explore language-agnostic repairs by utilizing benchmarks for Java (e.g., Defects4J), JavaScript (e.g., BugsJS), Python (e.g., BugsInPy), and PHP (e.g., BugsPHP). Besides the generalization between different languages and levels of patch complexity, we also investigate the effects of fault localization (FL) as a preprocessing step and compare the progress for open vs closed models. Our evaluation represents a snapshot of the current repair capabilities of the latest LLMs. Key results include: (1) Different LLMs tend to perform best for different languages, which makes it hard to develop cross-platform repair techniques with single LLMs. (2) The combinations of models add value with respect to uniquely fixed bugs, so a committee of expert models should be considered. (3) Under realistic assumptions of imperfect FL, we observe significant drops in accuracy from the usual practice of using perfect FL. Our findings and insights will help both researchers and practitioners develop reliable and generalizable APR techniques and evaluate them in realistic and fair environments.","自动程序修理( APR) 提议对开发者进行错误修正, 以帮助开发者维护软件。 该领域的先进技术重点是利用LLMM(Llama3.3, Qwen 2.5 coardr, Deep Seek R1 (dist.)) 和封闭模型( eg., o3- mini, GPT-4o, Claude 3. 7 Sonnet, Gemini 2.0 Flash ) 。 然而,尽管在过去十年中, RAPR( APR) 社区的研究成就和一些行业部署仍然缺乏广泛推广能力。 在这项工作中, 我们对LMMS( e. defects4J) 进行密集的经验评估。 我们评估了13个最新模型的多种不同的交叉模型, 包括开放模型( Bugs JS, Qwenwy 2.5 ) 和关闭系统( BARFMS( Bug InP) 的精确模型, 和快速分析( Oqualdaldal) 的精确数据, 和快速数据( Oute) Prodealdal deal deview disal disal disal deal deal deal deal) del deal deal deal deal deal deal disal deal deal deal deal deal) del) del) del deal deal deal deal deal deald del) delisal deal deal deal deal deal deal deal deal deviewts, 我们算。","Viola Campos, Ridwan Shariffdeen, Adrian Ulges, Yannic Noller",2025-06-03T18:15:14Z,Empirical Evaluation of Generalizable Automated Program Repair with   Large Language Models,Empirische Auswertung der allgemeinen Automatisierten Programmreparatur mit großen Sprachmodellen,用大语言模型对通用的自动化方案修理进行经验评价,http://arxiv.org/abs/2506.03283v1
47,"Large Language Models (LLMs) are increasingly deployed in critical domains, yet they often exhibit biases inherited from training data, leading to fairness concerns. This work focuses on the problem of effectively detecting fairness violations, especially intersectional biases that are often missed by existing template-based and grammar-based testing methods. Previous approaches, such as CheckList and ASTRAEA, provide structured or grammar-driven test generation but struggle with low test diversity and limited sensitivity to complex demographic interactions. To address these limitations, we propose GenFair, a metamorphic fairness testing framework that systematically generates source test cases using equivalence partitioning, mutation operators, and boundary value analysis. GenFair improves fairness testing by generating linguistically diverse, realistic, and intersectional test cases. It applies metamorphic relations (MR) to derive follow-up cases and detects fairness violations via tone-based comparisons between source and follow-up responses. In experiments with GPT-4.0 and LLaMA-3.0, GenFair outperformed two baseline methods. It achieved a fault detection rate (FDR) of 0.73 (GPT-4.0) and 0.69 (LLaMA-3.0), compared to 0.54/0.51 for template-based and 0.39/0.36 for ASTRAEA. GenFair also showed the highest test case diversity (syntactic:10.06, semantic: 76.68) and strong coherence (syntactic: 291.32, semantic: 0.7043), outperforming both baselines. These results demonstrate the effectiveness of GenFair in uncovering nuanced fairness violations. The proposed method offers a scalable and automated solution for fairness testing and contributes to building more equitable LLMs.","大型语言模型(LLMS)越来越多地部署在关键领域,但它们往往表现出从培训数据中继承下来的偏差,导致公平问题。这项工作侧重于有效发现违反公平情况的问题,特别是现有基于模板和语法的测试方法往往遗漏的交叉偏差问题。以前的办法,如CheckList和AstraEA, 提供结构化或语法驱动的测试生成,但在测试多样性和对复杂人口互动的敏感度较低的情况下挣扎。为了解决这些限制,我们建议GenFair, 一种超常公平测试框架,利用等值分布、突变操作和边界价值分析系统生成源测试案例。GenFair通过生成语言多样性、现实性和交叉测试方法改进公平性测试。过去的方法,如CheckListist和AstraREEA, 提供基于语法的跟踪案例,并通过对源和后续反应进行基于语法的比较,发现不公平性测试,但是在GPT-4和LAMA-3.0, 两种基线方法优于两种方法。它实现了0.74/(GPT-400) 和0.69(LAMA-30.10) 最高测试案例:显示基于S-ral-ral-ralreval) 和0.5。","Madhusudan Srinivasan, Jubril Abdel",2025-06-03T16:00:30Z,GenFair: Systematic Test Generation for Fairness Fault Detection in   Large Language Models,GenFair: Systematische Testgeneration für Fairnessfehlererkennung in großen Sprachmodellen,GenFair: 大型语言模型中公平错失探测系统测试生成,http://arxiv.org/abs/2506.03024v1
48,"In the evolving landscape of scientific and scholarly research, effective collaboration between Research Software Engineers (RSEs) and Software Engineering Researchers (SERs) is pivotal for advancing innovation and ensuring the integrity of computational methodologies. This paper presents ten strategic guidelines aimed at fostering productive partnerships between these two distinct yet complementary communities. The guidelines emphasize the importance of recognizing and respecting the cultural and operational differences between RSEs and SERs, proactively initiating and nurturing collaborations, and engaging within each other's professional environments. They advocate for identifying shared challenges, maintaining openness to emerging problems, ensuring mutual benefits, and serving as advocates for one another. Additionally, the guidelines highlight the necessity of vigilance in monitoring collaboration dynamics, securing institutional support, and defining clear, shared objectives. By adhering to these principles, RSEs and SERs can build synergistic relationships that enhance the quality and impact of research outcomes.","在不断演变的科学和学术研究领域,研究软件工程师和软件工程研究人员之间的有效合作对于推进创新和确保计算方法的完整性至关重要,本文件提出了十项战略指导方针,旨在促进这两个不同但相互补充的社区之间的生产性伙伴关系,该指导方针强调必须承认和尊重研究软件工程师和软件工程师之间的文化和业务差异,积极主动地发起和培育合作,在彼此的专业环境内参与,倡导找出共同的挑战,保持对新出现的问题的开放态度,确保互利,并相互倡导。此外,该指导方针强调在监测合作动态、确保机构支持和确定明确、共同目标方面必须保持警惕。通过遵守这些原则,研究工程师和研究人员可以建立协同关系,提高研究成果的质量和影响。","Nasir U. Eisty, Jeffrey C. Carver, Johanna Cohoon, Ian A. Cosden, Carole Goble, Samuel Grayson",2025-06-03T15:51:17Z,Ten Simple Rules for Catalyzing Collaborations and Building Bridges   between Research Software Engineers and Software Engineering Researchers,Zehn einfache Regeln für katalysierende Kooperationen und Brücken zwischen Forschungssoftware-Ingenieuren und Software-Ingenieuren,《催化合作和在研究软件工程师和软件工程研究人员之间建立桥梁的十条简单规则》,http://arxiv.org/abs/2506.03012v1
49,"Open-Source Pre-Trained Models (PTMs) provide extensive resources for various Machine Learning (ML) tasks, yet these resources lack a classification tailored to Software Engineering (SE) needs. To address this gap, we derive a taxonomy encompassing 147 SE tasks and apply an SE-oriented classification to PTMs in a popular open-source ML repository, Hugging Face (HF). Our repository mining study began with a systematically gathered database of PTMs from the HF API, considering their model card descriptions and metadata, and the abstract of the associated arXiv papers. We confirmed SE relevance through multiple filtering steps: detecting outliers, identifying near-identical PTMs, and the use of Gemini 2.0 Flash, which was validated with five pilot studies involving three human annotators. This approach uncovered 2,205 SE PTMs. We find that code generation is the most common SE task among PTMs, primarily focusing on software implementation, while requirements engineering and software design activities receive limited attention. In terms of ML tasks, text generation dominates within SE PTMs. Notably, the number of SE PTMs has increased markedly since 2023 Q2. Our classification provides a solid foundation for future automated SE scenarios, such as the sampling and selection of suitable PTMs.","开放源码预培训模型(PTMS)为各种机器学习任务提供了广泛的资源,然而,这些资源缺乏适合软件工程需要的分类。为了解决这一差距,我们从一个广受欢迎的开放源码ML存储库(Huging Face (HF))对PTM进行分类,对PTM进行SE型分类。我们的储存采矿研究从一个系统收集的来自高频API的PTM数据库开始,考虑到其示范卡说明和元数据,以及相关的ArXiv文件摘要。我们确认SE通过多个过滤步骤具有相关性:发现外端点,确定接近相同的PTM,使用Gemini 2.0 Flaster(Gemini 2.0 Flad),这通过涉及三名人类笔记号员的五项试点研究得到验证。这个方法发现了2 205 SETM(HF) 。我们发现代码生成是PTM之间最常见的SE任务,主要侧重于软件的实施,而要求的工程和软件设计活动则很少受到注意。在ML任务中,文本生成在SEPTM内部占主导地位。值得注意的是,SEM(S)的数目是,SETM)作为2023(Se-Seal)的可靠取样基础的可靠地)和SeTM(SETM)选择基础。","Alexandra González, Xavier Franch, David Lo, Silverio Martínez-Fernández",2025-06-03T15:51:17Z,How do Pre-Trained Models Support Software Engineering? An Empirical   Study in Hugging Face,Wie unterstützen vortrainierte Modelle die Software-Engineering? Eine empirische Studie in Hugging Face,培训前模型如何支持软件工程?,http://arxiv.org/abs/2506.03013v1
50,"While Large Language Models (LLMs) have demonstrated remarkable progress in generating functionally correct Solidity code, they continue to face critical challenges in producing gas-efficient and secure code, which are critical requirements for real-world smart contract deployment. Although recent advances leverage Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) for code preference alignment, existing approaches treat functional correctness, gas optimization, and security as independent objectives, resulting in contracts that may achieve operational soundness but suffer from prohibitive execution costs or dangerous vulnerabilities. To address these limitations, we propose PrefGen, a novel framework that extends standard DPO beyond human preferences to incorporate quantifiable blockchain-specific metrics, enabling holistic multi-objective optimization specifically tailored for smart contract generation. Our framework introduces a comprehensive evaluation methodology with four complementary metrics: Pass@k (functional correctness), Compile@k (syntactic correctness), Gas@k (gas efficiency), and Secure@k (security assessment), providing rigorous multi-dimensional contract evaluation. Through extensive experimentation, we demonstrate that PrefGen significantly outperforms existing approaches across all critical dimensions, achieving 66.7% Pass@5, 58.9% Gas@5, and 62.5% Secure@5, while generating production-ready smart contracts that are functionally correct, cost-efficient, and secure.","虽然大语言模型(LLMS)在生成功能正确固态代码方面取得了显著进展,但在生成功能正确固态代码方面,它们继续面临严峻的挑战,因为生产天然气效率和安全代码是现实世界智能合同部署的关键要求。虽然最近的一些进步带动了监管精通度和直接偏好优化(DPO)的代码偏好调整,但现有方法将功能正确性、气体优化和安全作为独立目标处理,从而导致合同可能实现运行稳健,但执行成本过高或存在危险弱点。为了应对这些限制,我们提议PrefGen(PrefGen),这是一个将标准DPO扩展至人类偏好以外的新框架,以纳入可量化的块链特定指标,使全方位的多目标优化能够专门针对智能合同的生成。我们的框架引入了全面的评价方法,有四个补充性指标:Pass@k(功能正确性)、Antoil@k(合成正确性)、Gas@k(气体效率)和安全性@k(安全性评估),提供严格的多维度评估。通过广泛的实验,我们证明PrefGen大大超越了所有关键层面的现有方法,66.7%Pass@pres-lax-lax-lax-58,同时实现S-h-685、Syal-58、Syal-ass-ass-ass-flipal-lax-flax-f-f-f-685、S-685、S-685、S-68-685、安全效率合同。","Zhiyuan Peng, Xin Yin, Chenhao Ying, Chao Ni, Yuan Luo",2025-06-03T15:45:31Z,A Preference-Driven Methodology for High-Quality Solidity Code   Generation,Eine präferenzorientierte Methodik für die Erzeugung von Soliditätscodes hoher Qualität,高质量固体废物代码生成的优先开发方法,http://arxiv.org/abs/2506.03006v1
51,"Efficiency is essential to support ever-growing datasets, especially for Deep Learning (DL) systems. DL frameworks have traditionally embraced deferred execution-style DL code -- supporting symbolic, graph-based Deep Neural Network (DNN) computation. While scalable, such development is error-prone, non-intuitive, and difficult to debug. Consequently, more natural, imperative DL frameworks encouraging eager execution have emerged but at the expense of run-time performance. Though hybrid approaches aim for the ""best of both worlds,"" using them effectively requires subtle considerations. Our key insight is that, while DL programs typically execute sequentially, hybridizing imperative DL code resembles parallelizing sequential code in traditional systems. Inspired by this, we present an automated refactoring approach that assists developers in determining which otherwise eagerly-executed imperative DL functions could be effectively and efficiently executed as graphs. The approach features novel static imperative tensor and side-effect analyses for Python. Due to its inherent dynamism, analyzing Python may be unsound; however, the conservative approach leverages a speculative (keyword-based) analysis for resolving difficult cases that informs developers of any assumptions made. The approach is: (i) implemented as a plug-in to the PyDev Eclipse IDE that integrates the WALA Ariadne analysis framework and (ii) evaluated on nineteen DL projects consisting of 132 KLOC. The results show that 326 of 766 candidate functions (42.56%) were refactorable, and an average relative speedup of 2.16 on performance tests was observed with negligible differences in model accuracy. The results indicate that the approach is useful in optimizing imperative DL code to its full potential.","效率对于支持不断增长的数据集至关重要, 特别是深海学习( DL) 系统。 DL 框架传统上采用推迟执行式 DL 代码, 支持符号性、 基于图形的深神经网络( DNN) 计算。 虽然可以缩放, 但这种开发是容易出错的, 非直观的, 并且难以调试。 因此, 更自然的、 必要的 DL 框架鼓励急迫执行, 但却牺牲了运行时的性能。 虽然混合方法旨在“ 最佳世界” , 有效地使用它们需要微妙的考虑。 我们的关键洞察力是, DL 程序通常按顺序执行, 混合的 DL 代码类似于传统系统中的平行代码。 受此启发, 我们提出了一个自动重构的重构方法, 帮助开发者确定哪些否则急迫地执行的 DL 功能可以有效和高效地作为图表执行。 这种方法以新颖的静态 高压和副效果分析为Python 。 由于它固有的活力, 分析Python 可能是不准确的; 但是, 保守方法将一个可调的 Ral- dal- dal- dal- disal- disal 函数法的精准的精准的精准的精准的精度函数在传统方法在传统的精准的精准的精准的精准的精准的精准的精准的精准的精度函数( , 。","Raffi Khatchadourian, Tatiana Castro Vélez, Mehdi Bagherzadeh, Nan Jia, Anita Raja",2025-06-03T15:01:43Z,Speculative Automated Refactoring of Imperative Deep Learning Programs   to Graph Execution,Spekulative Automatisierte Refaktorisierung imperativer Deep Learning-Programme zur Graphen-Execution,用于图表执行的势必深深学习方案的投机性自动重组,http://arxiv.org/abs/2504.05424v2
52,"Unit tests play a vital role in uncovering potential faults in software. While tools like EvoSuite focus on maximizing code coverage, recent advances in large language models (LLMs) have shifted attention toward LLM-based test generation. However, code coverage metrics -- such as line and branch coverage -- remain overly emphasized in reported research, despite being weak indicators of a test suite's fault-detection capability. In contrast, \textit{mutation score} offers a more reliable and stringent measure, as demonstrated in our findings where some test suites achieve 100\% coverage but only 4\% mutation score. Although a few studies consider mutation score, the effectiveness of LLMs in killing mutants remains underexplored.   In this paper, we propose MUTGEN, a mutation-guided, LLM-based test generation approach that incorporates mutation feedback directly into the prompt. Evaluated on 204 subjects from two benchmarks, MUTGEN significantly outperforms both EvoSuite and vanilla prompt-based strategies in terms of mutation score. Furthermore, MUTGEN introduces an iterative generation mechanism that pushes the limits of LLMs in killing additional mutants. Our study also provide insights into the limitations of LLM-based generation, analyzing the reasons for live and uncovered mutants, and the impact of different mutation operators on generation effectiveness.","单位测试在发现软件中的潜在缺陷方面发挥着关键作用。EvoSacterite等工具在发现软件中的潜在缺陷方面扮演了关键角色。虽然EvoSite关注最大限度地扩大代码覆盖范围,但大型语言模型(LLMs)最近的进展已经将注意力转移到了基于LLM的测试生成上。然而,尽管对测试套件的缺陷检测能力来说指标薄弱,但报告的研究仍然过分强调代码覆盖面指标(如线和分支覆盖面),尽管这是测试套件检测缺陷的薄弱指标。相比之下,\ Textit{mation 评分 提供了一种更加可靠和严格的衡量标准,正如我们的调查结果所显示的,有些测试套件达到100覆盖率,但只有4突变得分。虽然有几项研究考虑突变得分,但LLMMs在杀死变种人方面的效力仍然不足。在本论文中,我们建议采用MUTGEN, 一种以突变基因组为基础的测试生成方法,将突变异反馈直接评估204个主题,MUTGEN在突变得分方面明显超越了EVilla-GENLMs的定位,还在研究中将LMs的生成的极限推介结果和变异特性的生成的极限,也提供了。","Guancheng Wang, Qinghua Xu, Lionel C. Briand, Kui Liu",2025-06-03T14:47:22Z,Towards More Effective Fault Detection in LLM-Based Unit Test Generation,Auf dem Weg zu einer effektiveren Fehlererkennung bei der LLM-basierten Einheitentestgenerierung,争取在基于LLM的单位测试生成中更有效地发现过失,http://arxiv.org/abs/2506.02954v1
53,"Large Language Models (LLMs) have emerged as the new recommendation engines, surpassing traditional methods in both capability and scope, particularly in code generation. In this paper, we reveal a novel provider bias in LLMs: without explicit directives, these models show systematic preferences for services from specific providers in their recommendations (e.g., favoring Google Cloud over Microsoft Azure). To systematically investigate this bias, we develop an automated pipeline to construct the dataset, incorporating 6 distinct coding task categories and 30 real-world application scenarios. Leveraging this dataset, we conduct the first comprehensive empirical study of provider bias in LLM code generation across seven state-of-the-art LLMs, utilizing approximately 500 million tokens (equivalent to $5,000+ in computational costs). Our findings reveal that LLMs exhibit significant provider preferences, predominantly favoring services from Google and Amazon, and can autonomously modify input code to incorporate their preferred providers without users' requests. Such a bias holds far-reaching implications for market dynamics and societal equilibrium, potentially contributing to digital monopolies. It may also deceive users and violate their expectations, leading to various consequences. We call on the academic community to recognize this emerging issue and develop effective evaluation and mitigation methods to uphold AI security and fairness.","大型语言模型(LLMS)已成为新的建议引擎,超越了能力和范围的传统方法,特别是在代码生成方面。在本文中,我们揭示了在LLMS中存在一种新颖的提供者偏向:在没有明确指示的情况下,这些模型在其建议中显示了对具体提供者服务的系统性偏好(例如,偏爱谷歌云而不是微软Azure ) 。为了系统地调查这一偏向,我们开发了一条自动管道来构建数据集,其中包括6个不同的编码任务类别和30个现实世界应用情景。利用这一数据集,我们首次对7个最先进的LLMM代号生成中的LM代号供应商偏向进行了全面的经验性研究,利用了大约5亿个符号(相当于计算成本中的5,000美元+ ) 。我们的调查结果显示,LMS展示了供应商的偏好,主要是支持谷歌和亚马逊的服务,可以自主地修改输入代码,以纳入其首选提供者,而无需用户的请求。这种偏向市场动态和社会平衡有着深远的影响,有可能促成数字垄断。我们也可能欺骗用户,并违反他们的期望,导致各种后果。我们呼吁学术界认识到这一问题的公平性和制定有效的评估方法。","Xiaoyu Zhang, Juan Zhai, Shiqing Ma, Qingshuang Bao, Weipeng Jiang, Qian Wang, Chao Shen, Yang Liu",2025-06-03T12:58:57Z,The Invisible Hand: Unveiling Provider Bias in Large Language Models for   Code Generation,Die unsichtbare Hand: Enthüllen von Provider-Bias in großen Sprachmodellen für die Codegenerierung,"无形手:守则生成大语言模式中的 "" 无形手 "" : "" 不可忽视的提供者 "" 。",http://arxiv.org/abs/2501.07849v3
54,"In recent years, code intelligence has gained increasing importance in the field of automated software engineering. Meanwhile, the widespread adoption of Pretrained Language Models (PLMs) and Large Language Models (LLMs) has raised concerns regarding data contamination and its potential impact on model performance evaluation. This paper presents a systematic empirical study to investigate the fine-grained data contamination on code intelligence tasks. Our study involves diverse representative PLMs, namely RoBERTa and GPT-2, and LLMs, namely LLaMA and StarCoder, covering three major tasks: code translation, code generation, and code summarization. We categorize contamination scenarios into four types according to the code intelligence practice, namely input-only, output-only, unpaired, and paired contamination settings, and construct corresponding experimental and control groups for exploration.   Experimental results show that, under the pre-training, fine-tuning, and inference paradigm adopted by PLMs, even deliberately injecting paired contamination does not lead to significant performance overestimation. But direct inference or small-scale fine-tuning uncovers the contamination effects. In contrast, LLMs with pre-training and inference paradigm are significantly affected by the paired contamination. Apart from the above, other contamination scenarios have no impact on both PLMs and LLMs. Our findings challenge the conventional belief that contamination inevitably leads to performance overestimation, providing new insights into the evaluation and deployment of code intelligence models.","近年来,代码情报在自动化软件工程领域的重要性日益增强,与此同时,广泛采用预先培训语言模型和大语言模型使人们对数据污染及其对模型绩效评估的潜在影响产生关切,本文件介绍了一项系统的经验研究,以调查细化数据污染对代码情报任务的影响。我们的研究涉及不同的代表PLM,即RoBERTA和GPT-2,以及LLLMS,即LalaMA和StarCoder,涵盖三大任务:代码翻译、代码生成和代码合成。我们根据代码情报实践,将污染情景分为四种类型,即只投入、只产出、未覆盖和配对的污染环境,并构建相应的实验和控制组。实验结果显示,根据预先培训、微调和PLMS采用的推断模式,即使有意注射配对的污染也不会导致显著的过度估计。但直接推断或小规模微调揭示了污染效应。相比之下,具有前培训前和内置的污染状况的LLMS和内置的内置,对常规污染的预测性影响,因此无法对常规污染的预测和内置。","Zhen Yang, Hongyi Lin, Yifan He, Jie Xu, Zeyu Sun, Shuo Liu, Pengpeng Wang, Zhongxing Yu, Qingyuan Liang",2025-06-03T12:15:44Z,Rethinking the effects of data contamination in Code Intelligence,Überdenken der Auswirkungen der Datenkontamination in Code Intelligence,重新思考法典情报部门数据污染的影响,http://arxiv.org/abs/2506.02791v1
55,"Large Language Models (LLMs) have demonstrated remarkable capabilities in code editing, substantially enhancing software development productivity. However, the inherent complexity of code editing tasks forces existing approaches to rely on LLMs' autoregressive end-to-end generation, where decoding speed plays a critical role in efficiency. While inference acceleration techniques like speculative decoding are applied to improve the decoding efficiency, these methods fail to account for the unique characteristics of code editing tasks where changes are typically localized and existing code segments are reused. To address this limitation, we propose EfficientEdit, a novel method that improves LLM-based code editing efficiency through two key mechanisms based on speculative decoding: (1) effective reuse of original code segments while identifying potential edit locations, and (2) efficient generate edit content via high-quality drafts from edit-oriented draft models and a dynamic verification mechanism that balances quality and acceleration. Experimental results show that EfficientEdit can achieve up to 10.38$\times$ and 13.09$\times$ speedup compared to standard autoregressive decoding in CanItEdit and CodeIF-Bench, respectively, outperforming state-of-the-art inference acceleration approaches by up to 90.6%.","大型语言模型(LLMS)在代码编辑方面表现出了非凡的能力,大大提高了软件开发的生产率;然而,由于代码编辑任务的内在复杂性,迫使现有方法依赖LLMS自动递增端到端生成,解码速度在效率方面起着关键作用;虽然应用投机性解码等加速技术来提高解码效率,但这些方法没有考虑到代码编辑任务的独特性,其中的变化通常是本地化的,现有代码部分得到再利用。为了应对这一限制,我们建议高效Eddi,这是一种新颖的方法,通过基于投机性解码的两个关键机制提高LLMS基于LM的代码编辑效率:(1) 有效再利用原始代码部分,同时确定潜在的编辑地点,(2) 通过高质量草案生成高效的编辑内容,这些草案来自编辑导向型模型,以及平衡质量和加速的动态核查机制。实验结果表明,高效的Edit可以达到10.38美元的时间和13.09美元的时间。 与CanITEdit和coDIF-Bench的标准自动分解码速度相比,分别比90至90 %的州加速率。","Peiding Wang, Li Zhang, Fang Liu, Yinghao Zhu, Wang Xu, Lin Shi, Xiaoli Lian, Minxiao Li, Bo Shen, An Fu",2025-06-03T12:01:20Z,Reuse or Generate? Accelerating Code Editing via Edit-Oriented   Speculative Decoding,Wiederverwendung oder Generierung? Beschleunigen von Code-Editing über Edit-Oriented Spekulative Decodierung,重新使用或生成? 通过编辑导向的投机代号加速代码编辑,http://arxiv.org/abs/2506.02780v1
56,"Development of blockchain smart contracts is more difficult than mainstream software development because the underlying blockchain infrastructure poses additional complexity. To ease the developer's task of writing smart contract, as other research efforts, we also use Business Process Model and Notation BPMN modeling to describe application requirements for trade of goods and services and then transform automatically the BPMN model into the methods of a smart contract. In our previous research we described our approach and a tool to Transform Automatically BPMN models into Smart contracts TABS. In this paper, we describe how the TABS approach is augmented with the support for a BPMN collaborative transaction by several actors. Our approach analyzes the BPMN model to determine which patterns in the BPMN model are suitable for use as collaborative transactions. The found BPMN patterns that are suitable as transactions are shown to the developer who decides which ones should be deployed as collaborative transactions. We describe how our approach automatically transform the BPMN model into smart contract the provides a transaction mechanism to enforce the transactional properties of the nested transactions. Our approach greatly reduces the developers task as synchronization of collaborative activities is provided by our approach, so that the developer needs to code only independent tasks with well-defined inputs and outputs. We also overview the TABS+ tool we built as a proof of concept to show that our approach is feasible. Finally, we provide estimates on the cost of supporting the nested BPMN collaborative transactions.","与主流软件开发相比,发展链链智能合同比主流软件开发更为困难,因为基本的链链基础设施增加了复杂性。为了减轻开发商写智能合同的任务,作为其他研究努力,我们还利用业务流程模型和BPMN标记模型模型模型描述货物和服务贸易的应用要求,然后将BPMN模型自动转换为智能合同的方法。在先前的研究中,我们描述了我们的方法和工具,将BPMN模型自动转换为智能合同TABS。在本文中,我们描述了TABS方法如何在几个行为者对BPMN合作交易的支持下得到加强。我们的方法分析了BPMN模型模型模型,以确定BPMN模型中哪些模式适合作为合作交易使用。发现BPMN模型模式适合用于描述货物和服务贸易的应用要求,然后将BMN模型模式自动转换为智能合同。我们的方法提供了一种交易机制,用以执行嵌套交易的交易性质。我们的方法大大降低了BPN合作活动的同步性开发商任务,由我们的方法提供了合作交易的模型模型,因此,BPMA最终需要我们制定成本代码,我们只能提供我们定义的模型。","Christian Gang Liu, Peter Bodorik, Dawn Jutla",2025-06-03T10:37:41Z,Transforming Automatically BPMN Models to Smart Contracts with Nested   Collaborative Transactions (TABS+),Automatische Umwandlung von BPMN-Modellen in intelligente Verträge mit verschachtelten Kooperationstransaktionen (TABS+),将BPMN模型自动转换为与内层合作交易的智能合同(TABS+),http://arxiv.org/abs/2506.02727v1
57,"Large Language Models (LLMs) generate functionally correct solutions but often fall short in code efficiency, a critical bottleneck for real-world deployment. In this paper, we introduce a novel test-time iterative optimization framework to address this, employing a closed-loop system where LLMs iteratively refine code based on empirical performance feedback from an execution sandbox. We explore three training strategies: Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and Group Relative Policy Optimization (GRPO). Experiments on our Venus dataset and the APPS benchmark show that SFT and DPO rapidly saturate in efficiency gains. In contrast, GRPO, using reinforcement learning (RL) with execution feedback, continuously optimizes code performance, significantly boosting both pass@1 (from 47% to 62%) and the likelihood of outperforming human submissions in efficiency (from 31% to 45%). Our work demonstrates effective test-time code efficiency improvement and critically reveals the power of RL in teaching LLMs to truly self-improve code efficiency.","大语言模型(LLMS)产生功能正确的解决方案,但在代码效率方面往往不足,这是现实世界部署的关键瓶颈。在本文中,我们引入了一个创新的测试-时间迭代优化框架来解决这个问题,使用封闭环系统,由LLMS根据执行沙箱的经验性能反馈反复完善代码。我们探索了三个培训战略:监督微调(SFT)、直接偏好优化(DPO)和集体相对政策优化(GROPO)。对我们的金星数据集和APPS基准的实验显示,SFT和DPO在效率收益方面迅速饱和。相比之下,GROPO利用执行反馈强化学习(RL),不断优化代码性能,大幅提升1号(从47%到62%)和人效率上表现不佳(从31%到45%)的可能性。我们的工作表明测试-时间效率的有效提高,并批判地揭示了RLLMS在教授LMS实现真正自我保护代码效率方面的力量。","Mingzhe Du, Luu Anh Tuan, Yue Liu, Yuhao Qing, Dong Huang, Xinyi He, Qian Liu, Zejun Ma, See-kiong Ng",2025-06-03T09:55:22Z,Afterburner: Reinforcement Learning Facilitates Self-Improving Code   Efficiency Optimization,Nachbrenner: Verstärktes Lernen erleichtert selbstverbessernde Code-Effizienz-Optimierung,事后焚烧:强化学习促进自我改进法规效率优化,http://arxiv.org/abs/2505.23387v3
58,"Code generation models have shown significant potential for programming tasks. However, existing training methods like supervised fine-tuning face key limitations: they do not effectively teach models to prioritize correct over incorrect solutions in ambiguous situations, nor do they effectively optimize the runtime efficiency of the generated code. To address these challenges, we propose CodeDPO, a framework that integrates preference learning into code generation to improve two key code preference factors: code correctness and efficiency. CodeDPO employs a novel dataset construction method, utilizing a self-generation-and-validation mechanism that simultaneously generates and evaluates code and test cases. The underlying assumption is that test cases executable by multiple code snippets provide more reliable validation, and code that passes more tests is more likely to be correct. Through this self-validation process, our PageRank-inspired algorithm iteratively updates the ranking score of each code snippet, ultimately creating a code preference optimization dataset based on correctness and efficiency. CodeDPO is flexible and scalable, generating diverse preference optimization data without depending on external resources. Through comprehensive evaluations of five widely used benchmarks, CodeDPO demonstrates significant improvements in correctness and efficiency compared to existing methods. Our experiments prove that CodeDPO enhances the capabilities of LLMs in code generation and provides a robust foundation for conducting code preference optimization in more complex and challenging real-world scenarios.","然而,现有的培训方法,如监督下的微调等,面临一些关键限制:这些方法并没有有效地教给各种模型,以在模棱两可的情况下优先纠正错误,而不是不正确的解决办法,也没有有效地优化生成代码的运行效率。为了应对这些挑战,我们提议了代码DPO,这是一个将偏好学习纳入代码生成的框架,以改进两种关键的代码偏好因素:代码正确性和效率。代码DPO使用一种新型的数据集构建方法,利用一种自我生成和验证机制,同时生成和评估代码和测试案例。基本假设是,由多个代码片段执行的测试案件提供更可靠的验证,而通过更多测试的代码则更有可能得到纠正。通过这一自我验证过程,我们的PacelRank激励的算法反复更新了代码的排名,最终创建了一个基于正确性和效率的代码优化数据集。代码是灵活和可缩放的,在不依赖外部资源的情况下生成多种偏好的数据。通过对五个广泛使用的基准进行综合评估,代码DcoDO展示了更具有挑战性的能力,并且比我们更精细的模型更能化的模型,比我们更能地展示了更精确的模型。","Kechi Zhang, Ge Li, Yihong Dong, Jingjing Xu, Jun Zhang, Jing Su, Yongfei Liu, Zhi Jin",2025-06-03T09:19:46Z,CodeDPO: Aligning Code Models with Self Generated and Verified Source   Code,CodeDPO: Kodemodelle mit selbsterzeugtem und verifiziertem Quellcode ausrichten,代码DPO:与自产生和经核实的源代码统一代码模式,http://arxiv.org/abs/2410.05605v2
59,"Code generation models have shown significant potential for automating programming tasks. However, the challenge of generating accurate and reliable code persists due to the highly complex and long-reasoning nature of the task. Even state-of-the-art models often fail in code generation due to small errors, which can drastically affect the overall functionality of code. Our study identifies that current models tend to produce errors concentrated at specific error-prone points, which significantly impacts the accuracy of the generated code. To address this issue, we introduce Focused-DPO, a framework that enhances code generation by directing preference optimization towards these critical error-prone areas. This approach builds on Direct Preference Optimization, emphasizing accuracy in parts prone to errors. Additionally, we develop a method called Error-Point Identification, which constructs a dataset that targets these problematic points without requiring costly human annotations. Our experiments on benchmarks such as HumanEval(+), MBPP(+), and LiveCodeBench demonstrate that Focused-DPO significantly improves the precision and reliability of code generation, reducing common errors and enhancing overall code quality. By focusing on error-prone points, Focused-DPO advances the accuracy and functionality of model-generated code.","生成代码的模型显示出了使编程任务自动化的巨大潜力,然而,由于任务高度复杂和长时间的原因,生成准确和可靠代码的挑战依然存在。即使是最先进的模型也常常由于小错误而未能生成代码,这可能会严重影响代码的整体功能。我们的研究发现,目前的模型往往产生错误,集中在特定易出错点,严重影响生成代码的准确性。为了解决这一问题,我们引入了聚焦DPO这一框架,通过引导偏好优化到这些关键易出错地区来增强代码的生成。这一方法以直接偏差优化为基础,强调易出错部分的准确性。此外,我们开发了一种称为错误点识别的方法,用于针对这些问题点而不需要昂贵的人文说明。我们在HumanEval(+)、MBPP(+)和LiveCodeBench等基准方面的实验表明,聚焦DPO显著改进了代码生成的准确性和可靠性,减少了共同错误,并提高了总体代码质量。我们侧重于错误易出错点,聚焦点,重点-DPO提高了模型的准确性和功能。","Kechi Zhang, Ge Li, Jia Li, Yihong Dong, Jia Li, Zhi Jin",2025-06-03T09:17:05Z,Focused-DPO: Enhancing Code Generation Through Focused Preference   Optimization on Error-Prone Points,Focused-DPO: Verbesserung der Codegenerierung durch fokussierte Preference-Optimierung auf Error-Prone-Punkte,"重点突出的DPO:通过重点突出的优化差分点,通过重点突出的优化,加强代码生成",http://arxiv.org/abs/2502.11475v2
60,"Automated debugging, long pursued in a variety of fields from software engineering to cybersecurity, requires a framework that offers the building blocks for a programmable debugging workflow. However, existing debuggers are primarily tailored for human interaction, and those designed for programmatic debugging focus on kernel space, resulting in limited functionality in userland. To fill this gap, we introduce libdebug, a Python library for programmatic debugging of userland binary executables. libdebug offers a user-friendly API that enables developers to build custom debugging tools for various applications, including software engineering, reverse engineering, and software security. It is released as an open-source project, along with comprehensive documentation to encourage use and collaboration across the community. We demonstrate the versatility and performance of libdebug through case studies and benchmarks, all of which are publicly available. We find that the median latency of syscall and breakpoint handling in libdebug is 3 to 4 times lower compared to that of GDB.","在从软件工程到网络安全等各个领域长期追求的自动调试,需要一个为可编程调试工作流程提供构件的框架。然而,现有的调试器主要是为人类互动而定制的,而那些设计用于对内核空间进行程序调试的,因此在用户土地上的功能有限。为了填补这一空白,我们引入了libdebug,这是一个用于对用户用地二进制可执行软件进行程序调试的Python图书馆。libdebug提供了一个方便用户使用的API,使开发者能够为各种应用,包括软件工程、反向工程和软件安全,建立自定义调试工具。它作为开放源项目发布,同时发布综合文件,鼓励社区使用和协作。我们通过案例研究和基准展示了libdebug的多功能和性,所有这些都可以公开查阅。我们发现,libdebug的调试和断点处理的中值比GDB低3至4倍。","Gabriele Digregorio, Roberto Alessandro Bertolini, Francesco Panebianco, Mario Polino",2025-06-03T09:14:57Z,"Poster: libdebug, Build Your Own Debugger for a Better (Hello) World","Poster: libdebug, Build Your Own Debugger for a Better (Hallo) World","海报: libdebug, 构建您自己的调试器以建立一个更美好的世界 (哈罗)",http://arxiv.org/abs/2506.02667v1
61,"Software engineers typically interpret the domain description in natural language and translate it into a conceptual model. Three approaches are used in this domain modeling: textual languages, diagrammatic languages, and a mixed based of text and diagrams. According to some researchers, relying on a diagrammatic notation levies certain burdens for designing large models because visual languages are intended to depict everything diagrammatically during a development process but fail to do so for a lack of developer efficiency. It is claimed that textual formats enable easier manipulation in editors and tools and facilitate the integration of ontologies in software systems. In this paper, we explore the problem of the relationship between textual format and diagramming in conceptual modeling. The main focus is modeling based on the so-called thinging machine (TM). Several examples are developed in detail to contrast side-by-side targeted domains represented in textual description and TM modeling. A TM model is defined as a thimac (thing/machine) with a time feature that forms dynamic events over static thimacs utilizing five generic actions: create, process, release, transfer, and receive. This provides a conceptual foundation that can be simplified further by eliminating the actions of release, transfer, and receive. A multilevel reduction in the TM diagram s complexity can also be achieved by assuming diagrammatic notations represent the actions of creation and processing. We envision that special tools will help improve developer efficiency. The study s results of contrasting textual and mix-based descriptions vs. TM modeling justify our claim that TM modeling is a more appropriate methodology than other diagrammatic schemes (e.g., UML classes) examined in this paper.","软件工程师通常以自然语言解释域描述,并将它转换成概念模型。 在这个域建模中,我们使用了三种方法:文本语言、图表语言以及混合的文本和图表。一些研究人员认为,依靠图表符号,设计大型模型要承担一定的负担,因为视觉语言的目的是在开发过程中以图表形式描述所有事物,但由于缺乏开发者效率而未能这样做。据称文本格式使得编辑和工具的操作更容易,便于将本体的本体描述纳入软件系统。在本文中,我们探讨了在概念图建模中文本格式和图表图解之间的关系问题。主要重点是以所谓的装饰机器(TM)为基础建模。一些实例是详细开发的,以对比在文本描述和TM建模过程中所呈现的目标领域。TM模型被定义为一个Timac(Thing/M)模型,其时间特征是静态的本体模型,它代表了静体模型的动态事件。使用五种通用行动:创建、进程、发布、传输和接收。我们的主要重点是基于所谓的装像仪的模型,这个概念基础可以通过简化的图像处理过程,从而进一步消除解算法的变现。",Sabah Al-Fedaghi,2025-06-03T09:00:26Z,Textual-Based vs. Thinging Machines Conceptual Modeling,Textbasierte vs. Dinging Machines Konzeptuelle Modellierung,以文字为基础的概念建模,http://arxiv.org/abs/2506.02646v1
62,"The environmental impact of Artificial Intelligence (AI)-enabled systems is increasing rapidly, and software engineering plays a critical role in developing sustainable solutions. The ""Greening AI with Software Engineering"" CECAM-Lorentz workshop (no. 1358, 2025) funded by the Centre Europ\'een de Calcul Atomique et Mol\'eculaire and the Lorentz Center, provided an interdisciplinary forum for 29 participants, from practitioners to academics, to share knowledge, ideas, practices, and current results dedicated to advancing green software and AI research. The workshop was held February 3-7, 2025, in Lausanne, Switzerland. Through keynotes, flash talks, and collaborative discussions, participants identified and prioritized key challenges for the field. These included energy assessment and standardization, benchmarking practices, sustainability-aware architectures, runtime adaptation, empirical methodologies, and education. This report presents a research agenda emerging from the workshop, outlining open research directions and practical recommendations to guide the development of environmentally sustainable AI-enabled systems rooted in software engineering principles.","利用人工智能(AI)推动的系统对环境的影响正在迅速增加,软件工程在制订可持续解决办法方面发挥着关键作用。由欧洲工业和机械中心(Europ\'een de Calcul Atomique et mol\'eculaire)和Lorentz中心资助的CECAM-Lorentz研讨会(第1358号,2025年)为来自实践者到学术界的29名参与者提供了一个跨学科论坛,以分享知识、想法、做法和当前致力于推进绿色软件和AI研究的成果。该研讨会于2025年2月3日至7日在瑞士洛桑举行。通过主旨、快速会谈和合作讨论,与会者查明了该领域的主要挑战并确定了其优先次序,其中包括能源评估和标准化、基准做法、可持续性意识架构、运行时间适应、经验方法和教育。本报告介绍了讲习班产生的研究议程,概述了用于指导基于软件工程原则的环境可持续性的全能系统发展的公开研究方向和实际建议。","Luís Cruz, João Paulo Fernandes, Maja H. Kirkeby, Silverio Martínez-Fernández, June Sallou, Hina Anwar, Enrique Barba Roque, Justus Bogner, Joel Castaño, Fernando Castor, Aadil Chasmawala, Simão Cunha, Daniel Feitosa, Alexandra González, Andreas Jedlitschka, Patricia Lago, Henry Muccini, Ana Oprescu, Pooja Rani, João Saraiva, Federica Sarro, Raghavendra Selvan, Karthik Vaidhyanathan, Roberto Verdecchia, Ivan P. Yamshchikov",2025-06-03T08:44:31Z,Greening AI-enabled Systems with Software Engineering: A Research Agenda   for Environmentally Sustainable AI Practices,Ökologische KI-fähige Systeme mit Software Engineering: Eine Forschungsagenda für umweltverträgliche KI-Praktiken,具有软件工程的绿色AI-辅助系统:环境上可持续的AI做法研究议程,http://arxiv.org/abs/2506.01774v2
63,"The advent of large language models (LLMs) has significantly advanced artificial intelligence (AI) in software engineering (SE), with source code embeddings playing a crucial role in tasks such as source code clone detection and source code clustering. However, existing methods for source code embedding, including those based on LLMs, often rely on costly supervised training or fine-tuning for domain adaptation. This paper proposes a novel approach to embedding source code by combining large language and sentence embedding models. This approach attempts to eliminate the need for task-specific training or fine-tuning and to effectively address the issue of erroneous information commonly found in LLM-generated outputs. To evaluate the performance of our proposed approach, we conducted a series of experiments on three datasets with different programming languages by considering various LLMs and sentence embedding models. The experimental results have demonstrated the effectiveness and superiority of our approach over the state-of-the-art unsupervised approaches, such as SourcererCC, Code2vec, InferCode, TransformCode, and LLM2Vec. Our findings highlight the potential of our approach to advance the field of SE by providing robust and efficient solutions for source code embedding tasks.","大型语言模型(LLMS)的出现极大地推动了软件工程(SE)中的人工智能(AI),源代码嵌入在源代码克隆检测和源代码组合等任务中发挥着关键作用;然而,源代码嵌入的现有方法,包括基于LLMS的方法,往往依赖于成本高昂的监管培训或微调,以适应领域。本文件提出了一种新颖的办法,将大型语言和刑罚嵌入模型结合起来,嵌入源代码。这种方法试图消除任务特定培训或微调的必要性,并有效解决LLM产出中常见的错误信息问题。为了评估我们拟议方法的绩效,我们通过考虑各种LLMS和句嵌入模型,对三种不同程序语言的数据集进行了一系列实验。实验结果表明,我们的方法相对于最先进的非监管方法,例如SourcerrCC、DC2vec、InferCode、变换Code和LLM2Vec。我们通过提供强大和高效的源代码嵌入任务解决方案,从而推进SE领域的可能性。","Zixiang Xian, Chenhui Cui, Rubing Huang, Chunrong Fang, Zhenyu Chen",2025-06-03T08:41:08Z,An Effective Approach to Embedding Source Code by Combining Large   Language and Sentence Embedding Models,Ein effektiver Ansatz zur Einbettung von Quellcode durch die Kombination großer Sprach- und Satzeinbettungsmodelle,"结合大语言和判刑嵌入模式,以有效办法纳入《源代码》",http://arxiv.org/abs/2409.14644v3
64,"Vector database management systems (VDBMSs) play a crucial role in facilitating semantic similarity searches over high-dimensional embeddings from diverse data sources. While VDBMSs are widely used in applications such as recommendation, retrieval-augmented generation (RAG), and multimodal search, their reliability remains underexplored. Traditional database reliability models cannot be directly applied to VDBMSs because of fundamental differences in data representation, query mechanisms, and system architecture. To address this gap, we present the first large-scale empirical study of software defects in VDBMSs. We manually analyzed 1,671 bug-fix pull requests from 15 widely used open-source VDBMSs and developed a comprehensive taxonomy of bugs based on symptoms, root causes, and developer fix strategies. Our study identifies five categories of bug symptoms, with more than half manifesting as functional failures. We further reveal 31 recurring fault patterns and highlight failure modes unique to vector search systems. In addition, we summarize 12 common fix strategies, whose distribution underscores the critical importance of correct program logic. These findings provide actionable insights into VDBMS reliability challenges and offer guidance for building more robust future systems.","病媒数据库管理系统(VDBMS)在促进对来自不同数据源的高维嵌入层进行语义相似性搜索方面发挥着关键作用。虽然VDBMS广泛用于建议、检索增强的生成和多式联运搜索等应用,但其可靠性仍然未得到充分探讨。传统的数据库可靠性模型不能直接适用于VDBMS,因为数据代表、查询机制和系统结构存在根本差异。为了弥补这一差距,我们提出了对VDBMS软件缺陷的首次大规模实验性研究。我们人工分析了15个广泛使用的开源VDBMS软件的1 671个错误修正拉动请求,并根据症状、根源和开发者修正战略制定了对错误的综合分类方法。我们的研究确定了五类错误症状,其中一半以上表现为功能性失灵。我们进一步揭示了31种反复出现的故障模式,并强调了病媒搜索系统特有的故障模式。此外,我们总结了12种常见的修复战略,这些模式的分布强调了正确程序逻辑的至关重要性。这些结论为VDBMS可靠性提供了可操作的洞察力的洞察力,并为建设更稳健的未来系统提供指导。","Yinglin Xie, Xinyi Hou, Yanjie Zhao, Shenao Wang, Kai Chen, Haoyu Wang",2025-06-03T08:34:01Z,Toward Understanding Bugs in Vector Database Management Systems,Auf dem Weg zum Verständnis von Bugs in Vector Database Management Systemen,了解矢量数据库管理系统中的臭虫,http://arxiv.org/abs/2506.02617v1
65,"Web applications are critical to modern software ecosystems, yet ensuring their reliability remains challenging due to the complexity and dynamic nature of web interfaces. Recent advances in large language models (LLMs) have shown promise in automating complex tasks, but limitations persist in handling dynamic navigation flows and complex form interactions. This paper presents an automated system for generating test cases for two key aspects of web application testing: site navigation and form filling. For site navigation, the system employs screen transition graphs and LLMs to model navigation flows and generate test scenarios. For form filling, it uses state graphs to handle conditional forms and automates Selenium script generation. Key contributions include: (1) a novel integration of graph structures and LLMs for site navigation testing, (2) a state graph-based approach for automating form-filling test cases, and (3) a comprehensive dataset for evaluating form-interaction testing. Experimental results demonstrate the system's effectiveness in improving test coverage and robustness, advancing the state of web application testing.","网络应用对于现代软件生态系统至关重要,但由于网络界面的复杂性和动态性质,确保其可靠性仍然具有挑战性。大型语言模型(LLMs)最近的进展显示,在使复杂任务自动化方面很有希望,但在处理动态导航流程和复杂形式互动方面仍然存在限制。本文为网站应用测试的两个关键方面提供了一个生成测试案例的自动化系统:网站导航和填表。关于网站导航,该系统使用屏幕过渡图和LMs来模拟导航流程和生成测试假想。对于填充形式,它使用州图处理有条件的表格和自动生成Selenium脚本。关键贡献包括:(1) 将图表结构和LLMs进行现场导航测试的新整合,(2) 以州图为基础的自动填表测试案例,(3) 用于评价形式间测试的综合数据集。实验结果显示系统在改进测试覆盖面和稳健性、推进网络应用程序测试状态方面的有效性。","Nguyen-Khang Le, Quan Minh Bui, Minh Ngoc Nguyen, Hiep Nguyen, Trung Vo, Son T. Luu, Shoshin Nomura, Minh Le Nguyen",2025-06-03T07:08:21Z,Automated Web Application Testing: End-to-End Test Case Generation with   Large Language Models and Screen Transition Graphs,Automatisierte Web Application Testing: End-to-End Test Case Generation mit großen Sprachmodellen und Screen Transition Graphen,自动网络应用程序测试:以大语言模型和屏幕过渡图生成端到端测试案例,http://arxiv.org/abs/2506.02529v1
66,"Kubernetes, a notably complex and distributed system, utilizes an array of controllers to uphold cluster management logic through state reconciliation. Nevertheless, maintaining state consistency presents significant challenges due to unexpected failures, network disruptions, and asynchronous issues, especially within dynamic cloud environments. These challenges result in operational disruptions and economic losses, underscoring the necessity for robust root cause analysis (RCA) to enhance Kubernetes reliability. The development of large language models (LLMs) presents a promising direction for RCA. However, existing methodologies encounter several obstacles, including the diverse and evolving nature of Kubernetes incidents, the intricate context of incidents, and the polymorphic nature of these incidents. In this paper, we introduce SynergyRCA, an innovative tool that leverages LLMs with retrieval augmentation from graph databases and enhancement with expert prompts. SynergyRCA constructs a StateGraph to capture spatial and temporal relationships and utilizes a MetaGraph to outline entity connections. Upon the occurrence of an incident, an LLM predicts the most pertinent resource, and SynergyRCA queries the MetaGraph and StateGraph to deliver context-specific insights for RCA. We evaluate SynergyRCA using datasets from two production Kubernetes clusters, highlighting its capacity to identify numerous root causes, including novel ones, with high efficiency and precision. SynergyRCA demonstrates the ability to identify root causes in an average time of about two minutes and achieves an impressive precision of approximately 0.90.","Kubernetes是一个显著的复杂和分布式系统,它利用一系列控制器来通过国家和解来维护集束管理逻辑。然而,由于出乎意料的失败、网络中断和不同步问题,特别是在动态云层环境中,保持国家一致性提出了重大挑战。这些挑战导致业务中断和经济损失,突出表明必须进行强有力的根本原因分析(RCA)以提高Kubernetes的可靠性。开发大型语言模型(LLLMs)为RCA提供了一个充满希望的方向。然而,现有方法遇到了若干障碍,包括Kubernetes事件的多样性和演变性质、事件的复杂背景以及这些事件的多变性质。在本文件中,我们引入了SymergyRCA这一创新工具,它利用图表数据库的检索和专家提示来利用LLMSMS进行回升,以捕捉到空间和时间关系,并利用MetaGraph来概述实体关系。一旦发生事件,LLMM预测最相关的资源,SymergyRCA询问MGraph和州级事件多形态特性,从而提供具体背景的直观数据。","Yong Xiang, Charley Peter Chen, Liyi Zeng, Wei Yin, Xin Liu, Hu Li, Wei Xu",2025-06-03T06:09:13Z,Simplifying Root Cause Analysis in Kubernetes with StateGraph and LLM,Vereinfachende Ursachenanalyse in Kubernetes mit StateGraph und LLM,利用国家格普和法学硕士简化Kubernetes公司的根本原因分析,http://arxiv.org/abs/2506.02490v1
67,"We launch Parf - a toolkit for adaptively tuning abstraction strategies of static program analyzers in a fully automated manner. Parf models various types of external parameters (encoding abstraction strategies) as random variables subject to probability distributions over latticed parameter spaces. It incrementally refines the probability distributions based on accumulated intermediate results generated by repeatedly sampling and analyzing, thereby ultimately yielding a set of highly accurate abstraction strategies. Parf is implemented on top of Frama-C/Eva - an off-the-shelf open-source static analyzer for C programs. Parf provides a web-based user interface facilitating the intuitive configuration of static analyzers and visualization of dynamic distribution refinement of the abstraction strategies. It further supports the identification of dominant parameters in Frama-C/Eva analysis. Benchmark experiments and a case study demonstrate the competitive performance of Parf for analyzing complex, large-scale real-world programs.","我们推出 Parf 工具箱, 用于对静态程序分析器的抽象战略进行适应性调整; 将各种类型的外部参数( 编码抽象战略)作为随机变量,在悬浮参数空间上进行概率分布; 根据反复取样和分析所积累的中间结果,逐步完善概率分布,从而最终产生一套非常准确的抽象战略; Parf 在Frama-C/Eva(Frama-C/Eva)之上实施,这是为 C 程序提供的一个现成的公开源静态分析器; Parf 提供基于网络的用户界面,促进静态分析器的直观配置和对抽象战略动态分布的完善的可视化; 进一步支持在Frama-C/Eva 分析中确定主导参数; 基准实验和案例研究表明 Parf 在分析复杂、大规模真实世界方案方面的竞争性表现。","Zhongyi Wang, Mingshuai Chen, Tengjie Lin, Linyu Yang, Junhao Zhuo, Qiuye Wang, Shengchao Qin, Xiao Yi, Jianwei Yin",2025-06-03T05:33:47Z,PARF: An Adaptive Abstraction-Strategy Tuner for Static Analysis,PARF: Ein adaptives Abstraktions-Strategie-Tuner für statische Analyse,PARF: 用于静态分析的适应性抽象-战略图纳,http://arxiv.org/abs/2505.13229v2
68,"The Pandas API has been central to the success of pandas and its alternatives. Despite its importance, there is no benchmark for it, and we argue that we cannot repurpose existing benchmarks (from other domains) for the Pandas API.   In this paper, we introduce requirements that are necessary for a Pandas API enchmark, and present the first benchmark that fulfills them: PandasBench. We argue that it should evaluate the real-world coverage of a technique. Yet, real-world coverage is not sufficient for a useful benchmark, and so we also: cleaned it from irrelevant code, adapted it for benchmark usage, and introduced input scaling. We claim that uniform scaling used in other benchmarks (e.g., TPC-H) is too coarse-grained for PandasBench, and use a non-uniform scaling scheme. PandasBench is the largest Pandas API benchmark to date, with 102 notebooks and 3,721 cells.   We used PandasBench to evaluate Modin, Dask, Koalas, and Dias. This is the largest-scale evaluation of all these techniques to date. Prior works report significant speedups using constrained benchmarks, but we show that on a larger benchmark with real-world code, the most notebooks that got a speedup were 8/102 (~8%) for Modin, and 0 for both Koalas and Dask. Dias showed speedups in up to 55 notebooks (~54%), but it rewrites code incorrectly in certain cases, which had not been observed in prior work. Second, we identified many failures: Modin runs only 72/102 (~70%) notebooks, Dask 4 (~4%), Koalas 10 (~10%), and Dias 97 (95%).","Pandas API是熊猫及其替代品成功速度的核心。 尽管它很重要, 现实世界的覆盖面不足以成为有用的基准。 尽管它很重要, 但是它没有基准, 而且我们辩称我们不能重新使用 Pandas API 的已有基准( 其它域) 。 在本文中, 我们引入了对 Pandas API ENchmark 所必要的要求, 并展示了实现这些要求的第一个基准 : Pandas Bench 。 我们主张它应该评估一个技术的真实世界覆盖率。 然而, 现实世界的覆盖率还不足以成为有用的基准, 因此我们: 从不相关的代码中清理它, 修改它的基准使用, 并引入了投入的缩放。 我们声称, 其它基准( 例如, TPC- H) 使用的统一比例( 来自其它域) ANDA API ANPE ENK 的缩略图 97 , 并使用非统一比例缩略图计划。 Pandas Bennch是迄今为止最大的 Pandas API API 基准, 102 10 10 10 和 7211 单元格。 我们用的是 KOA BES 的缩略图来评估了 mandas 。 我们用了 mandus Best , laus laus la la lax lax lax","Alex Broihier, Stefanos Baziotis, Daniel Kang, Charith Mendis",2025-06-03T00:52:06Z,PandasBench: A Benchmark for the Pandas API,PandasBench: Ein Benchmark für die Pandas API,Pandas Bunch:Pandas API基准,http://arxiv.org/abs/2506.02345v1
69,"Foundation Models (FMs) such as Large Language Models (LLMs) are reshaping the software industry by enabling FMware, systems that integrate these FMs as core components. In this KDD 2025 tutorial, we present a comprehensive exploration of FMware that combines a curated catalogue of challenges with real-world production concerns. We first discuss the state of research and practice in building FMware. We further examine the difficulties in selecting suitable models, aligning high-quality domain-specific data, engineering robust prompts, and orchestrating autonomous agents. We then address the complex journey from impressive demos to production-ready systems by outlining issues in system testing, optimization, deployment, and integration with legacy software. Drawing on our industrial experience and recent research in the area, we provide actionable insights and a technology roadmap for overcoming these challenges. Attendees will gain practical strategies to enable the creation of trustworthy FMware in the evolving technology landscape.","大型语言模型(LLMS)等基础模型(FMs)正在通过使FMware能够改造软件产业,而FMware是这些调频作为核心组成部分的集成系统。在这个KDD 2025年的教程中,我们展示了对调频软件的全面探索,该软件将一个汇集的挑战目录与现实世界生产关切结合起来。我们首先讨论了建立调频软件的研究和实践状况。我们进一步考察了在选择合适的模型、调整高质量特定域数据、工程强力提示和调控自主代理方面的困难。我们随后通过概述系统测试、优化、部署和与遗留软件整合的问题,解决了从令人印象深刻的演示到为生产做好准备的系统的复杂旅程。我们利用我们在该领域的工业经验和近期研究,为克服这些挑战提供了可操作的洞察力和技术路线图。参与者将获得实用的战略,以便在不断发展的技术环境中创建可靠的调频软件。","Kirill Vasilevski, Benjamin Rombaut, Gopi Krishnan Rajbahadur, Gustavo A. Oliva, Keheliya Gallaba, Filipe R. Cogo, Jiahuei Lin, Dayi Lin, Haoxiang Zhang, Bouyan Chen, Kishanthan Thangarajah, Ahmed E. Hassan, Zhen Ming Jiang",2025-06-02T20:08:34Z,The Hitchhikers Guide to Production-ready Trustworthy Foundation Model   powered Software (FMware),Der Hitchhikers Guide für produktionsfähige vertrauenswürdige Foundation Model powered Software (FMware),生产准备就绪、可信赖基金会示范动力软件(FMware)的《Hitchhikers指南》,http://arxiv.org/abs/2505.10640v2
70,"This paper critically evaluates the applicability of the Project Management Body of Knowledge (PMBOK) Guide framework to Artificial Intelligence (AI) software projects, highlighting key limitations and proposing tailored adaptations. Unlike traditional projects, AI initiatives rely heavily on complex data, iterative experimentation, and specialized expertise while navigating significant ethical considerations. Our analysis identifies gaps in the PMBOK Guide, including its limited focus on data management, insufficient support for iterative development, and lack of guidance on ethical and multidisciplinary challenges. To address these deficiencies, we recommend integrating data lifecycle management, adopting iterative and AI project management frameworks, and embedding ethical considerations within project planning and execution. Additionally, we explore alternative approaches that better align with AI's dynamic and exploratory nature. We aim to enhance project management practices for AI software projects by bridging these gaps.","本文批判性地评价了《知识项目管理机构指南》框架对人工智能软件项目的适用性,强调了关键限制,并提出了有针对性的调整建议。与传统项目不同,AI倡议在探索重要的道德考量的同时,严重依赖复杂的数据、迭代实验和专业知识。我们的分析在PMBOK指南中找出了差距,包括其对数据管理的有限重视、对迭代开发的支持不足,以及缺乏对伦理和多学科挑战的指导。为了解决这些缺陷,我们建议整合数据生命周期管理,采用迭代和AI项目管理框架,并将道德考虑纳入项目规划和执行。此外,我们探索了与AI动态和探索性更好的一致的替代方法。我们的目标是通过弥合这些差距,加强AI软件项目的项目管理做法。","Alexey Burdakov, Max Jaihyun Ahn",2025-06-02T19:54:54Z,Is PMBOK Guide the Right Fit for AI? Re-evaluating Project Management in   the Face of Artificial Intelligence Projects,Ist PMBOK Leitfaden die richtige Fit für KI? Neubewertung des Projektmanagements im Angesicht von Projekten der Künstlichen Intelligenz,PMBOK指南是否适合大赦国际的权利? 面对人工情报项目重新评价项目管理,http://arxiv.org/abs/2506.02214v1
71,"Agile software development relies on self-organized teams, underlining the importance of individual responsibility. How developers take responsibility and build ownership are influenced by external factors such as architecture and development methods. This paper examines the existing literature on ownership in software engineering and in psychology, and argues that a more comprehensive view of ownership in software engineering has a great potential in improving software team's work. Initial positions on the issue are offered for discussion and to lay foundations for further research.","开发者如何承担责任和建立所有权受到建筑和开发方法等外部因素的影响,本文审查了关于软件工程和心理学所有权的现有文献,认为软件工程所有权的更全面的观点对于改进软件团队的工作有很大的潜力,提出有关该问题的初步立场供讨论并为进一步研究奠定基础。","Tomi Suomi, Petri Ihantola, Tommi Mikkonen, Niko Mäkitalo",2025-06-02T19:35:10Z,A Mosaic of Perspectives: Understanding Ownership in Software   Engineering,Ein Mosaik aus Perspektiven: Die Eigentümerschaft in der Software-Engineering verstehen,A Mosaic of Resources: 了解软件工程的所有权,http://arxiv.org/abs/2505.14220v2
72,"Dynamic software updating (DSU) is an extremely useful feature to be used during the software evolution. It can be used to reduce downtime costs, for security enhancements, profiling and testing the new functionalities. There are many researches and solutions on dynamic software updating regarding diverse problems introduced by the topic, but there is a lack of research which compare various approaches concerning supported changes and demands on re-sources. In this paper we are comparing currently available con-cepts for Java programming language that deal with dynamically applied changes and impact of those changes on computer resource demands.","动态软件更新(DSU)是软件演进期间使用的一个极为有用的特征,可用于减少故障时间费用,用于加强安保、剖析和测试新功能;关于动态软件更新,有许多研究和解决办法涉及本专题引起的各种问题,但缺乏比较支持性变化和对再资源需求的各种办法的研究;在本文件中,我们比较了Java编程语言的现有概念,这些概念涉及动态应用的变化以及这些变化对计算机资源需求的影响。","Danijel Mlinaric, Vedran Mornar",2025-06-02T17:04:49Z,Dynamic Software Updating in Java -- Comparing Concepts and Resource   Demands,Dynamische Software Aktualisierung in Java -- Vergleich von Konzepten und Ressourcenanforderungen,在爪哇更新动态软件 -- -- 比较概念和资源需求,http://arxiv.org/abs/2506.01875v1
73,"We present the CASE framework, an open-source platform for adaptive, context-aware participatory research, and pandemic preparedness. CASE implements an event-driven architecture that enables dynamic survey workflows, allowing real-time adaptation based on participant responses, external data, temporal conditions, and evolving user states. The framework supports a broad range of research needs, from simple one-time questionnaires to complex longitudinal studies with advanced conditional logic. Built on over a decade of practical experience, CASE underwent a major architectural rework in 2024, transitioning from a microservice-based design to a streamlined monolithic architecture. This evolution significantly improved maintainability, flexibility, and accessibility to deployment, particularly for institutions with limited technical capacity. CASE has been successfully deployed across diverse domains, powering national disease surveillance platforms, supporting post-COVID cohort studies, and enabling real-time sentiment analysis during political events. These applications, involving tens of thousands of participants, demonstrate the framework's scalability, versatility, and practical value. This paper describes the foundations of CASE, details its architectural evolution, and presents lessons learned from real-world deployments. We establish CASE as a mature and reusable research infrastructure that balances sophisticated functionality with practical implementation, addressing the critical global need for sustainable and institutionally controlled data collection systems.","我们提出了CASE框架,这是一个适应性、有环境意识的参与性研究和大流行病防备的开放源码平台。CASE实施一个事件驱动结构,能够动态调查工作流程,允许根据参与者的反应、外部数据、时间条件和不断演变的用户状态进行实时适应。框架支持广泛的研究需求,从简单的一次性问卷调查到具有先进的有条件逻辑的复杂纵向研究。根据十多年的实际经验,CASE在2024年进行了重大的建筑改造,从基于微观服务的设计过渡到精简的单一结构。这一演变极大地改善了CASE的可维持性、灵活性和可部署性,特别是对技术能力有限的机构而言。CASE成功地在不同领域进行了部署,赋予了国家疾病监测平台的权力,支持了COVID后的群群研究,并在政治活动期间进行了实时的情绪分析。这些应用包括数以万计的参与者,展示了框架的可扩展性、多功能性和实际价值。本文描述了CASE的基础,详细介绍了其建筑演变,并介绍了从实际部署中汲取的教训。我们成功地将CASE部署到了各种复杂的系统,我们建立了一套可操作的精确的系统。","Marco Hirsch, Peter Hevesi, Paul Lukowicz",2025-06-02T16:37:01Z,The CASE Framework -- A New Architecture for Participatory Research and   Digital Health Surveillance,Der CASE Framework - Eine neue Architektur für partizipative Forschung und digitale Gesundheitsüberwachung,CASE框架 -- -- 参与性研究和数字健康监测的新架构,http://arxiv.org/abs/2505.23516v2
74,"Code LLMs are increasingly employed in software development. However, studies have shown that they are vulnerable to backdoor attacks: when a trigger (a specific input pattern) appears in the input, the backdoor will be activated and cause the model to generate malicious outputs. Researchers have designed various triggers and demonstrated the feasibility of implanting backdoors by poisoning a fraction of the training data. Some basic conclusions have been made, such as backdoors becoming easier to implant when more training data are modified. However, existing research has not explored other factors influencing backdoor attacks on Code LLMs, such as training batch size, epoch number, and the broader design space for triggers, e.g., trigger length.   To bridge this gap, we use code summarization as an example to perform an empirical study that systematically investigates the factors affecting backdoor effectiveness and understands the extent of the threat posed. Three categories of factors are considered: data, model, and inference, revealing previously overlooked findings. We find that the prevailing consensus -- that attacks are ineffective at extremely low poisoning rates -- is incorrect. The absolute number of poisoned samples matters as well. Specifically, poisoning just 20 out of 454K samples (0.004\% poisoning rate -- far below the minimum setting of 0.1\% in prior studies) successfully implants backdoors! Moreover, the common defense is incapable of removing even a single poisoned sample from it. Additionally, small batch sizes increase the risk of backdoor attacks. We also uncover other critical factors such as trigger types, trigger length, and the rarity of tokens in the triggers, leading to valuable insights for assessing Code LLMs' vulnerability to backdoor attacks. Our study highlights the urgent need for defense mechanisms against extremely low poisoning rate settings.","软件开发中越来越多地使用代码LLMS。 但是,研究显示,它们很容易受到后门攻击:当输入中出现触发器(具体输入模式)时,后门会被激活,并导致模型产生恶意产出。研究人员设计了各种触发器,并展示了通过污染部分培训数据而植入后门的可行性。已经得出一些基本结论,例如,在修改更多的培训数据后,后门更容易植入。然而,现有研究没有探索影响对代码LMS进行后门攻击的其他因素,例如,当输入中出现一个触发器(具体输入模式)时,后门就会启动,后门就会触发器的设计空间会扩大,例如:当输入输入器出现一个触发器(特定输入模式)时,后门就会启动器会启动。为了弥补这一缺口,我们用代码进行实证研究,系统调查影响后门效率的因素,如后门安装后门安装的后门更容易植入门,揭示以前被忽视的调查结果。我们发现,目前的共识 -- 以极低的中毒率为后门攻击的后门攻击无效。 毒样本的绝对数量,比如是:紧急取样的绝对数量,比如的 RIdefrefrefreforde rial ride ride ride ride ride ride crecude ride ride rime ride lax mess mess mess mess la mess mess mess mess mess mess more dreme dreme dreme","Chenyu Wang, Zhou Yang, Yaniv Harel, David Lo",2025-06-02T16:07:34Z,Which Factors Make Code LLMs More Vulnerable to Backdoor Attacks? A   Systematic Study,Welche Faktoren machen Code LLMs anfälliger für Backdoor-Angriffe? Eine systematische Studie,哪些因素使《守则》LLLM女士更容易受到后门攻击?系统研究,http://arxiv.org/abs/2506.01825v1
75,"Large Language Models (LLMs) have achieved significant success in various tasks, yet concerns about their safety and security have emerged. In particular, they pose risks in generating harmful content and vulnerability to jailbreaking attacks. To analyze and monitor machine learning models, model-based analysis has demonstrated notable potential in stateful deep neural networks, yet suffers from scalability issues when extending to LLMs due to their vast feature spaces. In this paper, we propose ReGA, a model-based analysis framework with representation-guided abstraction, to safeguard LLMs against harmful prompts and generations. By leveraging safety-critical representations, which are low-dimensional directions emerging in hidden states that indicate safety-related concepts, ReGA effectively addresses the scalability issue when constructing the abstract model for safety modeling. Our comprehensive evaluation shows that ReGA performs sufficiently well in distinguishing between safe and harmful inputs, achieving an AUROC of 0.975 at the prompt level and 0.985 at the conversation level. Additionally, ReGA exhibits robustness to real-world attacks and generalization across different safety perspectives, outperforming existing safeguard paradigms in terms of interpretability and scalability. Overall, ReGA serves as an efficient and scalable solution to enhance LLM safety by integrating representation engineering with model-based abstraction, paving the way for new paradigms to utilize software insights for AI safety. Our code is available at https://github.com/weizeming/ReGA.","大型语言模型(LLMS)在各种任务中取得了重大成功,但人们对其安全和安保的关切已经出现,特别是在产生有害内容和易受侵入性袭击伤害方面,这些模型对产生有害内容和容易发生侵入性袭击的风险构成风险;为分析和监测机器学习模型,模型分析显示,在有声深深处的神经网络中具有显著潜力,但在扩展到LMS时,由于其巨大的地貌空间而存在可伸缩性的问题;在本文件中,我们提议ReGA(一个具有代表制制抽象的模型分析框架),即基于代表性的抽象分析框架,以保护LLMS不受有害瞬间和几代人的伤害;通过利用安全临界方位(这是在显示安全相关概念的隐蔽国家中出现的低度指示),ReGA(ReGA)在构建安全模型时,有效地解决了可伸缩性问题。我们的全面评价显示,ReGA(ReGA)在区分安全和有害的投入方面表现得足够,在迅速实现AUROC0.97,在对话层面展示现有可解释性/缩略图解。","Zeming Wei, Chengcan Wu, Meng Sun",2025-06-02T15:17:38Z,ReGA: Representation-Guided Abstraction for Model-based Safeguarding of   LLMs,ReGA: Darstellungsgeführte Abstraktion zur modellbasierten Sicherung von LLMs,ReGA: 以示范方式保障LLMM模型的代表性指导摘要,http://arxiv.org/abs/2506.01770v1
76,"Modern software systems complexity challenges efficient testing, as traditional machine learning (ML) struggles with large test suites. This research presents a hybrid framework integrating Quantum Annealing with ML to optimize test case prioritization in CI/CD pipelines. Leveraging quantum optimization, it achieves a 25 percent increase in defect detection efficiency and a 30 percent reduction in test execution time versus classical ML, validated on the Defects4J dataset. A simulated CI/CD environment demonstrates robustness across evolving codebases. Visualizations, including defect heatmaps and performance graphs, enhance interpretability. The framework addresses quantum hardware limits, CI/CD integration, and scalability for 2025s hybrid quantum-classical ecosystems, offering a transformative approach to software quality assurance.","现代软件系统的复杂性挑战了高效测试,因为传统的机器学习(ML)与大型测试套件相抗争。本研究提出了一个混合框架,将Qantum Annealing与ML相结合,以优化CI/CD管道的测试优先级。利用量子优化,它使缺陷检测效率提高了25%,测试执行时间比传统的ML减少了30%,在Deffects4J数据集上得到了验证。模拟的CI/CD环境显示了不断发展的代码库的稳健性。视觉化,包括缺陷热图和性能图,提高了可解释性。框架涉及量子硬件限值、CI/CD整合以及2025年代混合量子类生态系统的可缩放性,为软件质量保证提供了一个变革性方法。",Gopichand Bandarupalli,2025-06-02T15:04:10Z,The Impact of Software Testing with Quantum Optimization Meets Machine   Learning,Die Wirkung von Software-Tests mit Quantenoptimierung trifft auf maschinelles Lernen,利用量子优化软件测试对机器学习的影响,http://arxiv.org/abs/2506.02090v1
77,"The increasing popularity of the Rust programming language in building robotic applications using the Robot Operating System (ROS 2) raises questions about its real-time execution capabilities, particularly when employing asynchronous programming. Existing real-time scheduling and response-time analysis techniques for ROS 2 focus on applications written in C++ and do not address the unique execution models and challenges presented by Rust's asynchronous programming paradigm. In this paper, we analyze the execution model of R2R -- an asynchronous Rust ROS 2 bindings and various asynchronous Rust runtimes, comparing them with the execution model of C++ ROS 2 applications. We propose a structured approach for R2R applications aimed at deterministic real-time operation involving thread prioritization and callback-to-thread mapping schemes. Our experimental evaluation based on measuring end-to-end latencies of a synthetic application shows that the proposed approach is effective and outperforms other evaluated configurations. A more complex autonomous driving case study demonstrates its practical applicability. Overall, the experimental results indicate that our proposed structure achieves bounded response times for time-critical tasks. This paves the way for future work to adapt existing or develop new response-time analysis techniques for R2R applications using our structure.","在使用机器人操作系统(ROS 2)建立机器人应用程序的过程中,拉斯特编程语言越来越受欢迎,这使人们对其实时执行能力产生疑问,特别是在使用无同步程序时。ROS 2的现有实时时间安排和响应时间分析技术侧重于C++中写成的应用程序,而没有解决拉斯特的无同步程序拟定范式提出的独特的执行模式和挑战。在本文件中,我们分析了R2R的执行模式 -- -- 一个无同步的拉斯特 ROS 2捆绑定和各种不同步的拉斯特运行时间,将其与C+ROS 2应用程序的执行模式进行比较。我们为R2应用程序提出了一个结构结构结构结构结构结构,旨在确定实时操作的确定性操作,包括线性优先排序和回溯至全程绘图计划。我们基于测量一个合成应用程序的端到端的迟误的实验性评估表明,拟议的方法是有效的,而且比其他经过评估的配置更完善。更复杂的自动驱动案例研究表明其实际适用性。总体而言,实验结果表明我们拟议的结构在时间紧迫的任务方面实现了约束的反应时间。我们现有的工作结构,或者用新的方法来为进行新的适应。","Martin Škoudlil, Michal Sojka, Zdeněk Hanzálek",2025-06-02T13:09:50Z,A first look at ROS 2 applications written in asynchronous Rust,Ein erster Blick auf ROS 2 Anwendungen geschrieben in asynchronen Rust,"第一次查看ROS 2 申请,以非同步鲁斯特书写",http://arxiv.org/abs/2505.21323v2
78,"As Large Language Models (LLMs) become integral software components in modern applications, unauthorized model derivations through fine-tuning, merging, and redistribution have emerged as critical software engineering challenges. Unlike traditional software where clone detection and license compliance are well-established, the LLM ecosystem lacks effective mechanisms to detect model lineage and enforce licensing agreements. This gap is particularly problematic when open-source model creators, such as Meta's LLaMA, require derivative works to maintain naming conventions for attribution, yet no technical means exist to verify compliance.   To fill this gap, treating LLMs as software artifacts requiring provenance tracking, we present TensorGuard, a gradient-based fingerprinting framework for LLM similarity detection and family classification. Our approach extracts model-intrinsic behavioral signatures by analyzing gradient responses to random input perturbations across tensor layers, operating independently of training data, watermarks, or specific model formats. TensorGuard supports the widely-adopted safetensors format and constructs high-dimensional fingerprints through statistical analysis of gradient features. These fingerprints enable two complementary capabilities: direct pairwise similarity assessment between arbitrary models through distance computation, and systematic family classification of unknown models via the K-Means clustering algorithm with domain-informed centroid initialization using known base models. Experimental evaluation on 58 models comprising 8 base models and 50 derivatives across five model families (Llama, Qwen, Gemma, Phi, Mistral) demonstrates 94% classification accuracy under our centroid-initialized K-Means clustering.","随着大型语言模型(LLMS)成为现代应用中综合软件组成部分,未经授权的模型通过微调、合并和再分配得出,已成为关键的软件工程挑战。与克隆检测和许可证合规性已经确立的传统软件不同,LLM生态系统缺乏检测模型线和执行许可证协议的有效机制。当开源模型创建者(如Meta's LalaMA)需要派生工程来维持归属的命名公约,而没有技术手段来核查其遵守情况时,这一差距尤其成问题。为了填补这一空白,将LLMs作为需要源头跟踪的软件工艺品处理,我们提出了TensorGuard,这是一个基于梯度的指纹框架,用于LLM的类似性检测和家庭分类。我们的方法提取了模型的模型,即:通过分析对多层随机输入的梯度反应以及实施许可证协议协议协议协议协议协议。 独立于培训数据、水标记或具体模型,支持广泛采用的安全传感器格式,并通过对梯度特征进行统计分析来建立高维度指纹。这些指纹使两种互补能力成为:直接对准的类似性QQ,50个任意性模型之间,通过KML模型,通过基础的原始模型进行任意性模型,通过已知的模型进行基础计算。","Zehao Wu, Yanjie Zhao, Haoyu Wang",2025-06-02T13:08:01Z,Gradient-Based Model Fingerprinting for LLM Similarity Detection and   Family Classification,Gradient-Based Model Fingerprinting für LLM Ähnlichkeitserkennung und Familienklassifizierung,LLM相似性探测和家庭分类的渐进式样指纹,http://arxiv.org/abs/2506.01631v1
79,"Blockchain benefits are due to immutability, replication, and storage-and-execution of smart contracts on the blockchain. However, the benefits come at increased costs due to the blockchain size and execution. We address three fundamental issues that arise in transferring certain parts of a smart contract to be executed off-chain: (i) identifying which parts (patterns) of the smart contract should be considered for processing off-chain, (ii) under which conditions should a smart-contract pattern to be processed off-chain, and (iii) how to facilitate interaction between the computation off and on-chain. We use separation of concerns and FSM modeling to model a smart contract and generate its code. We then (i) use our algorithm to determine which parts (patterns) of the smart contract are to be processed off-chain; (ii) consider conditions under which to move the pattern off-chain; and (iii) provide model for automatically generating the interface between on and off-chain computation.","链链的好处是由于在链条上智能合同的可移动性、复制和储存及执行造成的。但是,由于链条的大小和执行,这些好处的成本会增加。我们讨论了在转让拟在链外执行的智能合同的某些部分时产生的三个基本问题:(一) 确定应考虑将智能合同的哪些部分(模式)用于离链外加工,(二) 在哪些条件下应处理离链外的智能合同模式,以及(三) 如何促进计算与链外的相互作用。我们利用将关切和密克罗尼西亚的模型化来模拟智能合同并生成其代码。我们随后(一) 使用我们的算法来确定智能合同的哪些部分(模式)将进行离链外加工;(二) 考虑将模式向链外加工的条件;(三) 为自动生成链外计算与离链外的界面提供模式。",Christian Gang Liu,2025-06-02T12:46:31Z,FSM Modeling For Off-Blockchain Computation,FSM-Modellierung für Off-Blockchain-Computation,FSM 离锁链计算模型,http://arxiv.org/abs/2506.02086v1
80,"The growing integration of AI tools in software development, particularly Large Language Models (LLMs) such as ChatGPT, has revolutionized how developers approach coding tasks. However, achieving high-quality code often requires iterative interactions, which can be time-consuming and inefficient. This paper explores the application of structured prompt patterns to minimize the number of interactions required for satisfactory AI-assisted code generation. Using the DevGPT dataset, we analyzed seven distinct prompt patterns to evaluate their effectiveness in reducing back-and-forth communication between developers and AI. Our findings highlight patterns such as ''Context and Instruction'' and ''Recipe'' as particularly effective in achieving high-quality outputs with minimal iterations. The study emphasizes the potential for prompt engineering to streamline developer-AI collaboration, providing practical insights into crafting prompts that balance precision, efficiency, and clarity.","在软件开发中,特别是大语言模型(LLMs)等大语言模型(LLMs)的日益一体化使开发商如何处理编码任务发生了革命性的变化。然而,高质量代码的实现往往需要迭代互动,这种互动可能耗时且效率低下。本文件探讨了如何应用结构化的快速模式,以最大限度地减少令人满意的AI协助代码生成所需的互动次数。我们利用DevGPT数据集分析了七个截然不同的快速模式,以评价其在减少开发商和AI之间的回溯通信方面的有效性。我们的调查结果突出表明,“Context and production”和“Recipe”等模式对于以最小的迭代实现高质量产出特别有效。研究强调迅速工程的潜力,以简化开发商与AI的合作,为精准、高效和清晰度的精确度的速率提供实用的洞察力。","Sophia DiCuffa, Amanda Zambrana, Priyanshi Yadav, Sashidhar Madiraju, Khushi Suman, Eman Abdullah AlOmar",2025-06-02T12:43:08Z,Exploring Prompt Patterns in AI-Assisted Code Generation: Towards Faster   and More Effective Developer-AI Collaboration,Erforschen von Prompt-Mustern in der KI-Assistenten Code-Generierung: Auf dem Weg zu einer schnelleren und effektiveren Entwickler-AI-Kollaboration,探索AI协助的代码生成的快速模式:实现更快和更有效的开发者-AI合作,http://arxiv.org/abs/2506.01604v1
81,"Background: Due to their diversity, complexity, and above all importance, safety-critical and dependable systems must be developed with special diligence. Criticality increases as these systems likely contain artificial intelligence (AI) components known for their uncertainty. As software and reference architectures form the backbone of any successful system, including safety-critical dependable systems with learning-enabled components, choosing the suitable architecture that guarantees safety despite uncertainties is of great eminence.   Aim: We aim to provide the missing overview of all existing architectures, their contribution to safety, and their level of maturity in AI-based safety-critical systems.   Method: To achieve this aim, we report a systematic mapping study. From a set of 1,639 primary studies, we selected 38 relevant studies dealing with safety assurance through software architecture in AI-based safety-critical systems. The selected studies were then examined using various criteria to answer the research questions and identify gaps in this area of research.   Results: Our findings showed which architectures have been proposed and to what extent they have been implemented. Furthermore, we identified gaps in different application areas of those systems and explained these gaps with various arguments.   Conclusion: As the AI trend continues to grow, the system complexity will inevitably increase, too. To ensure the lasting safety of the systems, we provide an overview of the state of the art, intending to identify best practices and research gaps and direct future research more focused.","背景:由于其多样性、复杂性,特别是其重要性,必须特别谨慎地开发安全临界和可靠的系统。关键度的增加,因为这些系统可能包含以其不确定性而闻名的人工智能(AI)组件。软件和参考结构构成任何成功系统的基石,包括具有学习辅助组件的安全临界可靠系统,选择了在不确定情况下保障安全的合适架构。目标:我们的目标是提供所有现有架构缺失的概览,这些架构对安全的贡献,以及基于AI的安全关键系统成熟程度。方法:为实现这一目标,我们报告系统绘图研究。从一组1,639项主要研究中,我们选择了38项相关研究,通过基于AI的安全关键系统中的软件结构处理安全保障问题。随后,利用各种标准对选定的研究进行了审查,以解答研究问题,找出研究领域的差距。结果:我们的调查结果显示,哪些架构已经提出,这些架构在多大程度上已经落实。此外,我们查明了这些系统不同应用领域的差距,并用各种论点解释了这些差距。结论:随着AI的趋势继续增长,我们不断发现未来系统的复杂性将增加。","Amra Ramic, Stefan Kugele",2025-06-02T12:29:54Z,A Systematic Mapping Study on Software Architecture for AI-based   Mobility Systems,Eine systematische Mapping-Studie zur Softwarearchitektur für KI-basierte Mobilitätssysteme,关于基于AI的移动系统软件结构的系统绘图研究,http://arxiv.org/abs/2506.01595v1
82,"Code embeddings are essential for semantic code search; however, current approaches often struggle to capture the precise syntactic and contextual nuances inherent in code. Open-source models such as CodeBERT and UniXcoder exhibit limitations in scalability and efficiency, while high-performing proprietary systems impose substantial computational costs. We introduce a parameter-efficient fine-tuning method based on Low-Rank Adaptation (LoRA) to construct task-specific adapters for code retrieval. Our approach reduces the number of trainable parameters to less than two percent of the base model, enabling rapid fine-tuning on extensive code corpora (2 million samples in 25 minutes on two H100 GPUs). Experiments demonstrate an increase of up to 9.1% in Mean Reciprocal Rank (MRR) for Code2Code search, and up to 86.69% for Text2Code search tasks across multiple programming languages. Distinction in task-wise and language-wise adaptation helps explore the sensitivity of code retrieval for syntactical and linguistic variations. To foster research in this area, we make our code and pre-trained models publicly available.","代码嵌入对于语义代码搜索至关重要; 然而, 目前的方法往往难以捕捉代码中固有的精确的合成和背景细微差别。 CodBERT 和 UnXcoder 等开放源码模型在可缩放性和效率方面表现出局限性,而高性能的专有系统则规定了大量的计算成本。 我们采用了基于低兰克适应(LORA)的参数高效微调方法,以构建特定任务适应器,用于代码检索。 我们的方法将可训练参数的数量减少到低于基准模型的2%,从而能够快速微调广泛的代码囊体(在2 H100 GPUs上25分钟中的200万个样本 ) 。 实验显示,在代码2Code搜索中,对等平均值增加了9.1%,在多种编程语言中,对文本2Code搜索任务增加了高达86.69%。 任务和语言适应的区分有助于探索用于合成和语言变化的代码检索的敏感度。为了促进这一领域的研究,我们把代码和预先训练模型公开提供。","Saumya Chaturvedi, Aman Chadha, Laurent Bindschaedler",2025-06-02T12:19:34Z,LoRACode: LoRA Adapters for Code Embeddings,LoRACode: LoRA Adapter für Code-Embeddings,LoRACode: 代码嵌入器的 LoRA 适应器,http://arxiv.org/abs/2503.05315v2
83,"Multiplexed immunofluorescence microscopy captures detailed measurements of spatially resolved, multiple biomarkers simultaneously, revealing tissue composition and cellular interactions in situ among single cells. The growing scale and dimensional complexity of these datasets demand reproducible, comprehensive and user-friendly computational tools. To address this need, we developed SPAC (SPAtial single-Cell analysis), a Python-based package and a corresponding shiny application within an integrated, modular SPAC ecosystem (Liu et al., 2025) designed specifically for biologists without extensive coding expertise. Following image segmentation and extraction of spatially resolved single-cell data, SPAC streamlines downstream phenotyping and spatial analysis, facilitating characterization of cellular heterogeneity and spatial organization within tissues. Through scalable performance, specialized spatial statistics, highly customizable visualizations, and seamless workflows from dataset to insights, SPAC significantly lowers barriers to sophisticated spatial analyses.","为解决这一需要,我们开发了SPAC(SPATIAL 单细胞分析)、一个基于Python的包件和在综合、模块化SPAC生态系统内相应的闪亮应用(Liu等人,2025年),专门为生物学家设计,没有广泛的编码专门知识。在图像分割和提取空间溶解单细胞数据后,SPAC简化了下游的口腔和空间分析,便利了对组织内细胞异性和空间组织特征的定性。通过可扩缩性性、专门空间统计、高度定制的可视化以及从数据集到洞察的无缝工作流程,SPAC大大降低了尖端空间分析的障碍。","Fang Liu, Rui He, Andrei Bombin, Ahmad B. Abdallah, Omar Eldaghar, Tommy R. Sheeley, Sam E. Ying, George Zaki",2025-06-02T11:36:32Z,SPAC: A Python Package for Spatial Single-Cell Analysis of Multiplex   Imaging,SPAC: Python-Paket für die räumliche Einzelzellanalyse von Multiplex-Imaging,SPAC:多式成象空间单细胞分析的Python包件,http://arxiv.org/abs/2506.01560v1
84,"Security code review is a time-consuming and labor-intensive process typically requiring integration with automated security defect detection tools. However, existing security analysis tools struggle with poor generalization, high false positive rates, and coarse detection granularity. Large Language Models (LLMs) have been considered promising candidates for addressing those challenges. In this study, we conducted an empirical study to explore the potential of LLMs in detecting security defects during code review. Specifically, we evaluated the performance of six LLMs under five different prompts and compared them with state-of-the-art static analysis tools. We also performed linguistic and regression analyses for the best-performing LLM to identify quality problems in its responses and factors influencing its performance. Our findings showthat: (1) existing pre-trained LLMs have limited capability in security code review but significantly outperformthe state-of-the-art static analysis tools. (2) GPT-4 performs best among all LLMs when provided with a CWE list for reference. (3) GPT-4 frequently generates verbose or non-compliant responses with the task requirements given in the prompts. (4) GPT-4 is more adept at identifying security defects in code files with fewer tokens, containing functional logic, or written by developers with less involvement in the project.","安全代码审查是一个耗时和劳动密集型的过程,通常需要与自动化安全缺陷检测工具相结合;然而,现有的安全分析工具与一般化不良、高假正率和粗粗检测颗粒进行斗争,认为大语言模型是应对这些挑战的有希望的人选;在这项研究中,我们进行了实证研究,以探讨LLMS在代码审查期间在发现安全缺陷方面的潜力;具体地说,我们评估了5种不同提示下的6个LLMs的性能,并将其与最先进的静态分析工具进行比较;我们还对最优秀的LMM进行了语言和回归分析,以查明其反应中的质量问题和影响其绩效的因素;我们的调查结果显示:(1) 受过培训的现有LMS在安全代码审查方面的能力有限,但大大超出最新静态分析工具。 (2) GPT-4在提供CWE清单供参考时,在所有LMsms中表现最佳。 (3) GPT-4经常生成符合提示中任务要求的verbose或不合规答复。 (4) GPT-4在确定安全缺陷方面,以较少的功能开发商的逻辑中,以较少的功能性文件为参考。","Jiaxin Yu, Peng Liang, Yujia Fu, Amjed Tahir, Mojtaba Shahin, Chong Wang, Yangxiao Cai",2025-06-02T10:06:31Z,"An Insight into Security Code Review with LLMs: Capabilities, Obstacles,   and Influential Factors","Ein Einblick in die Überprüfung von Sicherheitscodes mit LLMs: Fähigkeiten, Hindernisse und Einflussfaktoren",与LLM公司一道深入了解《安全守则》审查:能力、障碍和利害因素,http://arxiv.org/abs/2401.16310v4
85,"This study investigates the challenges in designing research infrastructure software for automated software publication in multi-stakeholder environments, focusing specifically on the HERMES system. Through two quantitative surveys of research software engineers (RSEs) and infrastructure facility staff (IFs), it examines technical, organizational, and social requirements across these stakeholder groups. The study reveals significant differences in how RSEs and IFs prioritize various system features. While RSEs highly value compatibility with existing infrastructure, IFs prioritize user-focused aspects like system usability and documentation. The research identifies two main challenges in designing research infrastructure software: (1) the existence of multiple stakeholder groups with differing requirements, and (2) the internal heterogeneity within each stakeholder group across dimensions such as technical experience. The study also highlights that only half of RSE respondents actively practice software publication, pointing to potential cultural or technical barriers. Additionally, the research reveals discrepancies in how stakeholders view organizational aspects, with IFs consistently rating factors like responsibility structures and quality assurance as more important than RSEs do. These findings contribute to a better understanding of the complexities involved in designing research infrastructure software and emphasize the need for systems that can accommodate diverse user groups while maintaining usability across different technical expertise levels.","这项研究调查了在多利益攸关方环境中设计自动化软件出版的研究基础设施软件的挑战,特别侧重于HERMES系统;通过对研究软件工程师和基础设施工作人员进行两次定量调查,研究了这些利益攸关方群体的技术、组织和社会要求;研究揭示了RSE和IF如何确定各种系统特征的优先次序方面的巨大差异;虽然RESE与现有基础设施高度相容,但IFS将系统可用性和文件等以用户为重点的方面列为优先事项;研究查明了设计研究基础设施软件方面的两个主要挑战:(1) 存在需求不同的多个利益攸关方群体,以及(2) 每个利益攸关方群体内部存在技术经验等不同层面的差异;研究还突出表明,只有半数RESE的受访者积极开展软件出版物,指出潜在的文化或技术障碍;此外,研究还揭示了利益攸关方如何看待组织方面差异,而IFs一贯将责任结构和质量保证等因素定级为比RESE更为重要。这些研究结果有助于更好地了解设计研究基础设施软件所涉及的复杂性,并强调系统需要能够容纳不同用户群体,同时保持在不同技术专长层面上的实用性。","Stephan Druskat, Sabine Theis",2025-06-02T09:50:30Z,Challenges in designing research infrastructure software in   multi-stakeholder contexts,Herausforderungen bei der Entwicklung von Forschungsinfrastruktur-Software in Multi-Stakeholder-Kontexten,在多方利益攸关方背景下设计研究基础设施软件的挑战,http://arxiv.org/abs/2506.01492v1
86,"AI workloads experience frequent incidents due to intensive hardware utilization and extended training times. The current incident management workflow is provider-centric, where customers report incidents and place the entire troubleshooting responsibility on the infrastructure provider. However, the inherent knowledge gap between customer and provider significantly impacts incident resolution efficiency. In AI infrastructure, incidents may take several days on average to mitigate, resulting in delays and productivity losses. To address these issues, we present AidAI, a customer-centric system that provides immediate incident diagnosis for customers and streamlines the creation of incident tickets for unresolved issues. The key idea of AidAI is to construct internal knowledge bases from historical on-call experiences during the offline phase and mimic the reasoning process of human experts to diagnose incidents through trial and error in the online phase. Evaluations using real-world incident records in Microsoft show that AidAI achieves an average Micro F1 score of 0.854 and Macro F1 score of 0.816 without significant overhead.","由于硬件的密集使用以及培训时间的延长,大赦国际的工作量频繁发生。目前的事件管理工作流程以供应商为中心,客户报告事件,将全部故障排除责任推给基础设施提供者。然而,客户和提供者之间的内在知识差距严重影响了事故解决效率。在AI基础设施中,事故平均需要几天时间才能缓解,造成延误和生产力损失。为解决这些问题,我们介绍AIDAI,这是一个以客户为中心的系统,为客户提供即时事件诊断,并简化为未决问题制造事故罚单的程序。AIDAI的主要想法是从离线阶段的历史对接经验中建立内部知识库,并模仿人类专家通过试验和网上错误诊断事件的推理过程。使用微软体实体世界事件记录进行的评估显示,AIDAI平均得分为0.854,而Mic F1得分为0.816,而Mac F1得分则为0.816,没有重大间接费用。","Yitao Yang, Yangtao Deng, Yifan Xiong, Baochun Li, Hong Xu, Peng Cheng",2025-06-02T09:41:25Z,AidAI: Automated Incident Diagnosis for AI Workloads in the Cloud,AidAI: Automatisierte Vorkommnisdiagnose für KI-Workloads in der Cloud,AIDAI:人工智能云中工作量自动事故诊断,http://arxiv.org/abs/2506.01481v1
87,"Translating C to Rust is a promising way to enhance the reliability of legacy system programs. Although the industry has developed an automatic C-to-Rust translator, C2Rust, its translation remains unsatisfactory. One major reason is that C2Rust retains C standard library (libc) function calls instead of replacing them with functions from the Rust standard library (Rust std). However, little work has been done on replacing library functions in C2Rust-generated code. In this work, we focus on replacing the I/O API, an important subset of library functions. This poses challenges due to the semantically different designs of I/O APIs in libc and Rust std. First, the two APIs offer different sets of types that represent the origins (e.g., standard input, files) and capabilities (e.g., read, write) of streams used for I/O. Second, they use different error-checking mechanisms: libc uses internal indicators, while Rust std uses return values. To address these challenges, we propose two static analysis techniques, origin and capability analysis and error source analysis, and use their results to replace the I/O API. Our evaluation shows that the proposed approach is (1) correct, with all 32 programs that have test suites passing the tests after transformation, (2) efficient, analyzing and transforming 422k LOC in 14 seconds, and (3) widely applicable, replacing 82% of I/O API calls.","将 C 转换为 Rust 是提高遗留系统程序可靠性的一个有希望的方法。 虽然该行业开发了自动 C- RO 翻译器 C2Rust , 但它的翻译仍然不能令人满意。 一个主要原因是 C2Rust 保留 C 标准图书馆( libc) 的功能, 而不是用 Rust 标准图书馆( Rust std) 的功能替换这些功能。 但是, 替换 C2Rust 生成的代码中的图书馆功能的工作很少。 在这项工作中, 我们侧重于替换 I/ O API, 这是图书馆功能的一个重要部分。 这带来了挑战, 因为它在 libc 和 Rust Std 中 I/ O API 的语义设计存在差异。 首先, 两个 API 提供了不同的类型, 它代表了源( 如标准输入、 文件) 和 能力( 如读、 写) 用于 I/ O 生成的 代码。 其次, 它们使用不同的错误校验机制: libc 替换内部指标, Rust std 使用回报值。 为了应对这些挑战, 我们提议两个静态分析技术, 和变压 A 测试 A 测试 A 后 测试 A 测试 A 测试程序 使用所有 。","Jaemin Hong, Sukyoung Ryu",2025-06-02T08:34:06Z,Forcrat: Automatic I/O API Translation from C to Rust via Origin and   Capability Analysis,Forcrat: Automatische I/O-API-Übersetzung von C nach Rust über Origin und Capability Analysis,Forcrat: 通过起源和能力分析将 C 自动 I/O API 从 C 翻译到 Rust,http://arxiv.org/abs/2506.01427v1
88,"Enterprise Resource Planning (ERP) systems serve as the digital backbone of modern financial institutions, yet they continue to rely on static, rule-based workflows that limit adaptability, scalability, and intelligence. As business operations grow more complex and data-rich, conventional ERP platforms struggle to integrate structured and unstructured data in real time and to accommodate dynamic, cross-functional workflows.   In this paper, we present the first AI-native, agent-based framework for ERP systems, introducing a novel architecture of Generative Business Process AI Agents (GBPAs) that bring autonomy, reasoning, and dynamic optimization to enterprise workflows. The proposed system integrates generative AI with business process modeling and multi-agent orchestration, enabling end-to-end automation of complex tasks such as budget planning, financial reporting, and wire transfer processing. Unlike traditional workflow engines, GBPAs interpret user intent, synthesize workflows in real time, and coordinate specialized sub-agents for modular task execution. We validate the framework through case studies in bank wire transfers and employee reimbursements, two representative financial workflows with distinct complexity and data modalities. Results show that GBPAs achieve up to 40% reduction in processing time, 94% drop in error rate, and improved regulatory compliance by enabling parallelism, risk control insertion, and semantic reasoning. These findings highlight the potential of GBPAs to bridge the gap between generative AI capabilities and enterprise-grade automation, laying the groundwork for the next generation of intelligent ERP systems.","机构资源规划(ERP)系统是现代金融机构的数码主干,但它们继续依赖那些限制适应性、可缩放性和情报的静态、有章可循的工作流程。随着业务活动日益复杂和数据丰富,传统的机构资源规划平台难以实时整合结构化和非结构化数据,并适应动态、跨职能工作流程。在本文件中,我们提出了第一个基于代理的企业资源规划系统AI-初始框架,引入了一个创新的 "" 创用业务流程AI代理 "" 架构,为企业工作流程带来自主权、推理和动态优化。拟议的系统将基因化的AI与业务流程建模和多代理协调相结合,使预算规划、财务报告和电汇处理等复杂任务的端到端到端自动化。与传统的工作流程引擎不同,USBA解释用户意向,实时合成工作流程,协调模块任务执行的专门分代理人。我们通过银行间电汇转移和员工补偿的案例研究、两个具有代表性的金融工作流程和数据模式来验证该框架。结果显示,未来计算机化ABRBA系统实现40%的升级,使机构机率升级,使机构机能升级。","Hongyang Yang, Likun Lin, Yang She, Xinyu Liao, Jiaoyang Wang, Runjia Zhang, Yuquan Mo, Christina Dan Wang",2025-06-02T08:22:28Z,FinRobot: Generative Business Process AI Agents for Enterprise Resource   Planning in Finance,FinRobot: Generative Business Process AI Agents für Enterprise Resource Planning in Finance,FinRobot: 产生业务流程 AI 财务机构资源规划代理,http://arxiv.org/abs/2506.01423v1
89,"While large language models (LLMs) show promise in code generation, existing benchmarks neglect the flowchart-based code generation. To promote further research on flowchart-based code generation, this work presents Flow2Code, a novel benchmark for flowchart-based code generation evaluation. The evaluation dataset spans 15 programming languages and includes 5,622 code segments paired with 16,866 flowcharts of three types: code, UML, and pseudocode. Extensive experiments with 13 multimodal LLMs reveal that current LLMs can not generate code based on flowcharts perfectly. Besides, experiment results show that the supervised fine-tuning technique contributes greatly to the models' performance. We publicly release our code and datasets at https://github.com/hml-github/Flow2Code.","虽然大型语言模型(LLMs)在代码生成方面有希望,但现有基准忽略了流程图代码生成。 为促进对流程图代码生成的进一步研究,这项工作介绍了流程图代码生成的新基准Flook2Code,这是流程图代码生成评估的新基准。 评价数据集覆盖15种编程语言,包括5,622个代码部分,配有16,866个流程图,分为三种类型:代码、UML和伪代码。 与13个多式联运模型进行的广泛实验显示,目前的本地模型无法完美生成基于流程图的代码。 此外,实验结果表明,受监督的微调技术极大地促进了模型的绩效。 我们在https://github.com/hl-github/Flow2Code公开发布我们的代码和数据集。","Mengliang He, Jiayi Zeng, Yankai Jiang, Wei Zhang, Zeming Liu, Xiaoming Shi, Aimin Zhou",2025-06-02T07:48:57Z,Flow2Code: Evaluating Large Language Models for Flowchart-based Code   Generation Capability,Flow2Code: Bewertung großer Sprachmodelle für Flowchart-basierte Codegenerierungskapazität,流程2守则:评估以流程图为基础的代码生成能力大语言模型,http://arxiv.org/abs/2506.02073v1
90,"Identifying the impact scope and scale is critical for software supply chain vulnerability assessment. However, existing studies face substantial limitations. First, prior studies either work at coarse package-level granularity, producing many false positives, or fail to accomplish whole-ecosystem vulnerability propagation analysis. Second, although vulnerability assessment indicators like CVSS characterize individual vulnerabilities, no metric exists to specifically quantify the dynamic impact of vulnerability propagation across software supply chains. To address these limitations and enable accurate and comprehensive vulnerability impact assessment, we propose a novel approach: (i) a hierarchical worklist-based algorithm for whole-ecosystem and call-graph-level vulnerability propagation analysis and (ii) the Vulnerability Propagation Scoring System (VPSS), a dynamic metric to quantify the scope and evolution of vulnerability impacts in software supply chains. We implement a prototype of our approach in the Java Maven ecosystem and evaluate it on 100 real-world vulnerabilities. Experimental results demonstrate that our approach enables effective ecosystem-wide vulnerability propagation analysis, and provides a practical, quantitative measure of vulnerability impact through VPSS.","对软件供应链脆弱性评估而言,确定影响范围和规模至关重要,但是,现有研究面临重大限制。首先,以前的研究要么是在粗糙的包包级颗粒上工作,产生许多假正数,要么没有完成整个生态系统脆弱性传播分析。第二,尽管CVSS等脆弱性评估指标是个人脆弱性的特征,但没有指标可以具体量化整个软件供应链脆弱性传播的动态影响。为了解决这些局限性,并能够进行准确和全面的脆弱性影响评估,我们提议了一种新颖的方法:(一) 整个生态系统和呼叫绘图级脆弱性传播分析基于等级工作列表的算法,以及(二) 脆弱性促进分解系统(VPSS),这是量化软件供应链脆弱性影响的范围和演变的动态衡量标准。我们在爪哇马文生态系统中采用我们的方法的原型,对100个现实世界脆弱性进行评估。实验结果表明,我们的方法能够进行有效的全生态系统脆弱性传播分析,并通过VPSS提供脆弱性影响的实际定量衡量。","Bonan Ruan, Zhiwei Lin, Jiahao Liu, Chuqi Zhang, Kaihang Ji, Zhenkai Liang",2025-06-02T05:55:45Z,An Accurate and Efficient Vulnerability Propagation Analysis Framework,Ein präziser und effizienter Rahmen für die Risikoanalyse,准确和有效的脆弱性传播分析框架,http://arxiv.org/abs/2506.01342v1
91,"Automatic software system optimization can improve software speed, reduce operating costs, and save energy. Traditional approaches to optimization rely on manual tuning and compiler heuristics, limiting their ability to generalize across diverse codebases and system contexts. Recent methods using Large Language Models (LLMs) offer automation to address these limitations, but often fail to scale to the complexity of real-world software systems and applications. We present SysLLMatic, a system that integrates LLMs with profiling-guided feedback and system performance insights to automatically optimize software code. We evaluate it on three benchmark suites: HumanEval_CPP (competitive programming in C++), SciMark2 (scientific kernels in Java), and DaCapoBench (large-scale software systems in Java). Results show that SysLLMatic can improve system performance, including latency, throughput, energy efficiency, memory usage, and CPU utilization. It consistently outperforms state-of-the-art LLM baselines on microbenchmarks. On large-scale application codes, it surpasses traditional compiler optimizations, achieving average relative improvements of 1.85x in latency and 2.24x in throughput. Our findings demonstrate that LLMs, guided by principled systems thinking and appropriate performance diagnostics, can serve as viable software system optimizers. We further identify limitations of our approach and the challenges involved in handling complex applications. This work provides a foundation for generating optimized code across various languages, benchmarks, and program sizes in a principled manner.","自动软件系统优化可以提高软件速度、降低操作成本并节省能源。 优化的传统方法依靠人工调试和编译的杂质技术,限制了其推广不同代码库和系统环境的能力。 使用大语言模型(LLMS)的最近方法提供了自动化,以应对这些限制,但往往无法达到现实世界软件系统和应用的复杂性。 我们介绍了SysLLLMIC, 该系统将LLM与剖析引导的反馈和系统性能洞察力结合起来,以自动优化软件代码。 我们评估了三个基准套: HumanEval_CPP(C++中的竞争性编程)、Scimark2(爪哇中的科学内涵)和DacapoBench(爪哇的大规模软件系统), 结果表明,SysLLMIC能够提高系统性能,包括惯用量、能源效率、记忆使用和CCPU的利用。 它持续地在微书标记上改进了最新的LM基准。 关于大规模应用代码的代码,它超越了传统的编程优化应用, 实现了传统的编程优化应用, 实现了我们1.85x 的系统 的系统 的优化的操作, 通过适当的操作, 展示了我们的系统, 提供了我们最精确的操作的系统, 提供了我们最精确的精确的操作的操作, 的操作的操作的改进了我们 的操作, 提供了我们 的系统, 的操作的操作的系统, 提供了我们 的精度的精确的精确的精确的精确的精确的精确的操作的操作。","Huiyun Peng, Arjun Gupte, Ryan Hasler, Nicholas John Eliopoulos, Chien-Chou Ho, Rishi Mantri, Leo Deng, Konstantin Läufer, George K. Thiruvathukal, James C. Davis",2025-06-02T01:57:21Z,SysLLMatic: Large Language Models are Software System Optimizers,SysLLMatic: Große Sprachmodelle sind Software System Optimierer,SysLLMATIC: 大语言模型是软件系统优化器,http://arxiv.org/abs/2506.01249v1
92,"Assessing the programming capabilities of Large Language Models (LLMs) is crucial for their effective use in software engineering. Current evaluations, however, predominantly measure the accuracy of generated code on static benchmarks, neglecting the critical aspect of model robustness during programming tasks. While adversarial attacks offer insights on model robustness, their effectiveness is limited and evaluation could be constrained. Current adversarial attack methods for robustness evaluation yield inconsistent results, struggling to provide a unified evaluation across different LLMs. We introduce EVALOOP, a novel assessment framework that evaluate the robustness from a self-consistency perspective, i.e., leveraging the natural duality inherent in popular software engineering tasks, e.g., code generation and code summarization. EVALOOP initiates a self-contained feedback loop: an LLM generates output (e.g., code) from an input (e.g., natural language specification), and then use the generated output as the input to produce a new output (e.g., summarizes that code into a new specification). EVALOOP repeats the process to assess the effectiveness of EVALOOP in each loop. This cyclical strategy intrinsically evaluates robustness without rely on any external attack setups, providing a unified metric to evaluate LLMs' robustness in programming. We evaluate 16 prominent LLMs (e.g., GPT-4.1, O4-mini) on EVALOOP and found that EVALOOP typically induces a 5.01%-19.31% absolute drop in pass@1 performance within ten loops. Intriguingly, robustness does not always align with initial performance (i.e., one-time query); for instance, GPT-3.5-Turbo, despite superior initial code generation compared to DeepSeek-V2, demonstrated lower robustness over repeated evaluation loop.","评估大语言模型(LLMS)的编程能力对于在软件工程中有效使用这些模型至关重要。 但是,目前的评价主要是测量生成的固定基准代码的准确性,忽略了模型稳健性的关键方面。 对抗性攻击提供了对模型稳健性的洞察力,但其效力有限,评价可能受到限制。 目前稳健性评价的对抗性攻击方法产生不一致的结果,难以在不同LMS之间提供统一的评价。 我们引入了EVALOOP,这是一个从绝对一致性角度评价稳健性强性的新评估框架,即利用流行软件工程任务中固有的自然双重性,例如,静态生成和代码合成。 EVALOOP 启动了一个自成一体的反馈循环:一个LM(例如,自然语言规格)生成产出,然后将产生的产出用作新的产出(例如,将该代码总结为一种稳定的初始规格) 。 EVALOOP- 19 继续评估过程评估 EVALOO-40 在每个循环中,而不是透明性的循环中持续性地评估。","Sen Fang, Weiyuan Ding, Bowen Xu",2025-06-01T21:54:31Z,EVALOOP: Assessing LLM Robustness in Programming from a Self-consistency   Perspective,EVALOOP: Bewertung der Robustheit von LLM in der Programmierung aus einer Perspektive der Selbstkonsistenz,EVALOOP: 从自统一的角度评估方案拟订中的LLM强力,http://arxiv.org/abs/2505.12185v2
93,"Supervised-learning-based vulnerability detectors often fall short due to limited labelled training data. In contrast, Large Language Models (LLMs) like GPT-4 are trained on vast unlabelled code corpora, yet perform only marginally better than coin flips when directly prompted to detect vulnerabilities. In this paper, we reframe vulnerability detection as anomaly detection, based on the premise that vulnerable code is rare and thus anomalous relative to patterns learned by LLMs. We introduce ANVIL, which performs a masked code reconstruction task: the LLM reconstructs a masked line of code, and deviations from the original are scored as anomalies. We propose a hybrid anomaly score that combines exact match, cross-entropy loss, prediction confidence, and structural complexity. We evaluate our approach across multiple LLM families, scoring methods, and context sizes, and against vulnerabilities after the LLM's training cut-off. On the PrimeVul dataset, ANVIL outperforms state-of-the-art supervised detectors-LineVul, LineVD, and LLMAO-achieving up to 2x higher Top-3 accuracy, 75% better Normalized MFR, and a significant improvement on ROC-AUC. Finally, by integrating ANVIL with fuzzers, we uncover two previously unknown vulnerabilities, demonstrating the practical utility of anomaly-guided detection.","受监督的基于学习的脆弱程度探测器往往由于标签限制的培训数据而落后。相比之下,GPT-4等大型语言模型(LLMS)在大量无标签代码公司中接受培训,但在直接促使发现脆弱程度时只比硬币翻转略略好一点。在本文中,我们根据脆弱代码是稀有的,因此与LLMS所学习的模式相比异常,将脆弱性检测重新设定为异常现象检测。我们引入了ANVIL,它执行了一项蒙面代码重建任务:LLM重建了隐藏的代码线,与原代码的偏差被评为异常。我们提出了混合异常得分,将精确匹配、交叉湿度损失、预测信心和结构复杂性结合起来。我们评估了我们跨多个LLM家庭、评分方法和背景大小的方法,并针对LLMMMM公司培训停课后的脆弱性。我们在PinVul数据集中,ANVI公司比实际监管的检测器――LineVul、LineDD和LMAO-Arievingering, 直至2x更高的TA-C公司前期检测。我们正常的常规和常规分析,通过GRAUC公司前的升级化的升级,改进了。","Weizhou Wang, Eric Liu, Xiangyu Guo, Xiao Hu, Ilya Grishchenko, David Lie",2025-06-01T19:41:06Z,ANVIL: Anomaly-based Vulnerability Identification without Labelled   Training Data,ANVIL: Anomaly-basierte Vulnerability-Identifikation ohne gekennzeichnete Trainingsdaten,"ANVIL: 以异常情况为基础的脆弱性识别,无分类培训数据",http://arxiv.org/abs/2408.16028v3
94,"With over 700 stars on GitHub and being part of the official ONNX repository, the ONNX Optimizer is the default tool for applying graph-based optimizations to ONNX models. Despite its widespread use, its ability to maintain model accuracy during optimization has not been thoroughly investigated. In this work, we present OODTE, a utility designed to automatically and comprehensively evaluate the correctness of the ONNX Optimizer. OODTE adopts a straightforward yet powerful differential testing and evaluation methodology, which can be readily adapted for use with other compiler optimizers. Specifically, OODTE takes a collection of ONNX models, applies optimizations, and executes both the original and optimized versions across a user-defined input set, automatically capturing any issues encountered during optimization. When discrepancies in accuracy arise, OODTE iteratively isolates the responsible optimization pass by repeating the process at a finer granularity. We applied OODTE to 130 well-known models from the official ONNX Model Hub, spanning diverse tasks including classification, object detection, semantic segmentation, text summarization, question answering, and sentiment analysis. Our evaluation revealed that 9.2% of the model instances either caused the optimizer to crash or led to the generation of invalid models using default optimization strategies. Additionally, 30% of classification models and 16.6% of object detection and segmentation models exhibited differing outputs across original and optimized versions, whereas models focused on text-related tasks were generally robust to optimization. OODTE uncovered 15 issues-14 previously unknown-affecting 9 of 47 optimization passes and the optimizer overall. All issues were reported to the ONNX Optimizer team. OODTE offers a simple but effective framework for validating AI model optimizers, applicable beyond the ONNX ecosystem.","在 GitHub 上,有700多个恒星在 GitHub 上,并且是 OONX 官方 ONNX 储存库的一部分, ONNX 优化器是将基于图形的优化应用到 ONNX 模型的默认工具。 尽管使用范围很广, 但它在优化过程中保持模型准确性的能力还没有彻底调查。 在这项工作中, 我们展示OOODTE, 这是一种旨在自动和全面地评价 ONX 优化器的正确性能的工具。 OOODTE 采用了一种简单而强大的差异测试和评价方法, 可以在其他编程优化器的优化器中应用。 具体来说, OODDTE 收集了 ONX 模型, 应用了基于图形优化的优化, 应用了基于图形的优化的原版和优化的版本, 在用户定义的数据集中, 自动地捕捉到任何问题。","Nikolaos Louloudakis, Ajitha Rajan",2025-06-01T18:58:34Z,OODTE: A Differential Testing Engine for the ONNX Optimizer,OODTE: Eine Differentialprüfmaschine für den ONNX Optimizer,OODTE:ONNX优化器的差别测试引擎,http://arxiv.org/abs/2505.01892v2
95,"Several studies have explored the mechanisms of large language models (LLMs) in coding tasks, but most have focused on programming languages (PLs) in a monolingual setting. In this paper, we investigate the relationship between multiple PLs and English in the concept space of LLMs. We perform a few-shot translation task on 21 PL pairs using two Llama-based models. By decoding the embeddings of intermediate layers during this task, we observe that the concept space is closer to English (including PL keywords) and assigns high probabilities to English tokens in the second half of the intermediate layers. We analyze neuron activations for 11 PLs and English, finding that while language-specific neurons are primarily concentrated in the bottom layers, those exclusive to each PL tend to appear in the top layers. For PLs that are highly aligned with multiple other PLs, identifying language-specific neurons is not feasible. These PLs also tend to have a larger keyword set than other PLs and are closer to the model's concept space regardless of the input/output PL in the translation task. Our findings provide insights into how LLMs internally represent PLs, revealing structural patterns in the model's concept space. Code is available at https://github.com/cisnlp/code-specific-neurons.","一些研究探索了大语言模型(LLMs)在编码任务方面的机制,但大多数研究侧重于单一语言环境下的英语(PLs)编程机制。在本文中,我们研究了LLMM概念空间中多个PL和英语之间的关系。我们使用两个Llama模型对21个PL配对进行了几分翻译任务。通过在任务期间解码中间层嵌入的中间层,我们观察到概念空间更接近英语(包括PL关键字),在中间层的后半层中为英语标牌分配高概率。我们分析了11个PLS和英语的神经激活,发现语言特有神经元主要集中在底层,而每个PLMS的特有神经元往往出现在顶层。对于与其他多PLlama模型高度一致的PLPS来说,确定语言特有神经元是不可行的。这些PLPS往往有一个比其他PL关键字更大的关键字组,并且更接近模型的概念空间,而不论翻译任务中的输入/输出PLPLS和英文,我们发现LMS-CMs的内部结构代码是如何体现的。 AS-cLGLCS-cis/exemex/ex","Amir Hossein Kargaran, Yihong Liu, François Yvon, Hinrich Schütze",2025-06-01T16:24:13Z,How Programming Concepts and Neurons Are Shared in Code Language Models,Wie Programmierkonzepte und Neuronen in Code Language Models geteilt werden,如何在代码语言模式中共享编程概念和新内容,http://arxiv.org/abs/2506.01074v1
96,"The issue-resolving task, where a model generates patches to fix real-world bugs, has emerged as a critical benchmark for evaluating the capabilities of large language models (LLMs). While SWE-bench and its variants have become standard in this domain, they suffer from key limitations: they have not been updated since their initial releases, cover a narrow set of repositories, and depend heavily on manual effort for instance construction and environment setup. These factors hinder scalability and introduce risks of overfitting and data contamination. In this work, we present SWE-bench-Live, a live-updatable benchmark designed to overcome these challenges. Our initial release consists of 1,319 tasks derived from real GitHub issues created since 2024, spanning 93 repositories. Each task is accompanied by a dedicated Docker image to ensure reproducible execution. Central to our benchmark is \method, an automated curation pipeline that streamlines the entire process from instance creation to environment setup, removing manual bottlenecks and enabling scalability and continuous updates. We evaluate a range of state-of-the-art agent frameworks and LLMs on SWE-bench-Live, revealing a substantial performance gap compared to static benchmarks like SWE-bench, even under controlled evaluation conditions. To better understand this discrepancy, we perform detailed analyses across repository origin, issue recency, and task difficulty. By providing a fresh, diverse, and executable benchmark grounded in live repository activity, SWE-bench-Live facilitates rigorous, contamination-resistant evaluation of LLMs and agents in dynamic, real-world software development settings.","解决问题的任务,即模型产生修补实际世界错误的补丁,已经成为评价大型语言模型(LLMS)能力的关键基准。虽然SWE-Bench及其变体已成为该领域的标准,但它们都受到关键的限制:自最初发布以来,它们一直没有更新,覆盖了一套狭窄的储存库,并严重依赖人工努力,例如建筑和环境设置。这些因素阻碍可扩展性,并引入了过度装配和数据污染的风险。在这项工作中,我们提出了SWE-Bench-Live,这是为克服这些挑战而设计的可更新的基准。我们的初步发布包括来自2024年以来产生的真正的GitHub问题产生的1,319项任务,涵盖93个储存库。每一项任务都有一个专门的Docker图像,以确保可重新执行。我们基准的中心是自动化的曲线管道,将整个过程从创建到环境设置,消除手工基础瓶颈,使可扩展性和持续更新更新更新更新。我们评估了一系列的动态代理框架和LLMS-BMS-RBER系统在SWE-S-RBS-S-C-C-C-LE-C-LVDS-C-LADS-S-C-LDS-C-S-C-C-LVLADS-LADS-S-S-S-S-S-SBY-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-L-L-S-S-L-L-L-L-S-S-S-S-S-S-S-L-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-L-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S","Linghao Zhang, Shilin He, Chaoyun Zhang, Yu Kang, Bowen Li, Chengxing Xie, Junhao Wang, Maoquan Wang, Yufan Huang, Shengyu Fu, Elsie Nallipogu, Qingwei Lin, Yingnong Dang, Saravan Rajmohan, Dongmei Zhang",2025-06-01T14:53:40Z,SWE-bench Goes Live!,SWE-Bench geht live!,SWE -BECHE GOES 现场直播!,http://arxiv.org/abs/2505.23419v2
97,"In software development, technical debt (TD) refers to suboptimal implementation choices made by the developers to meet urgent deadlines and limited resources, posing challenges for future maintenance. Self-Admitted Technical Debt (SATD) is a sub-type of TD, representing specific TD instances ``openly admitted'' by the developers and often expressed through source code comments. Previous research on SATD has focused predominantly on the Java programming language, revealing a significant gap in cross-language SATD. Such a narrow focus limits the generalizability of existing findings as well as SATD detection techniques across multiple programming languages. Our work addresses such limitation by introducing CppSATD, a dedicated C++ SATD dataset, comprising over 531,000 annotated comments and their source code contexts. Our dataset can serve as a foundation for future studies that aim to develop SATD detection methods in C++, generalize the existing findings to other languages, or contribute novel insights to cross-language SATD research.","在软件开发方面,技术债务(TD)是指开发商为满足紧迫的最后期限和有限资源而做出的执行选择不够理想,对今后的维护构成挑战。自认技术债务(SATD)是一种次级TD类型,代表开发商“公开承认”的具体TD案例,并经常通过源代码评论表达。以前关于技术债务的研究主要侧重于爪哇语编程语言,揭示了跨语言SATD的巨大差距。这种狭隘的焦点限制了现有发现以及多种编程语言的SATD探测技术的普遍性。我们的工作通过引入CppSATD(C++ SATD)这一专门的C+数据集来解决这种局限性,该数据集由531,000多份附加说明的评论及其源代码背景组成。我们的数据集可以作为未来研究的基础,目的是开发C++的SATD探测方法,将现有发现结果推广到其他语言,或者为跨语言的SATD研究提供新的见解。","Phuoc Pham, Murali Sridharan, Matteo Esposito, Valentina Lenarduzzi",2025-06-01T12:49:01Z,Descriptor: C++ Self-Admitted Technical Debt Dataset (CppSATD),Deskriptor: C++ Selbstzugelassener technischer Schuldendatensatz (CppSATD),说明:C++自发技术债务数据集(CppSATD),http://arxiv.org/abs/2505.01136v2
98,"Smart contracts can implement and automate parts of legal contracts, but ensuring their legal compliance remains challenging. Existing approaches such as formal specification, verification, and model-based development require expertise in both legal and software development domains, as well as extensive manual effort. Given the recent advances of Large Language Models (LLMs) in code generation, we investigate their ability to generate legally compliant smart contracts directly from natural language legal contracts, addressing these challenges. We propose a novel suite of metrics to quantify legal compliance based on modeling both legal and smart contracts as processes and comparing their behaviors. We select four LLMs, generate 20 smart contracts based on five legal contracts, and analyze their legal compliance. We find that while all LLMs generate syntactically correct code, there is significant variance in their legal compliance with larger models generally showing higher levels of compliance. We also evaluate the proposed metrics against properties of software metrics, showing they provide fine-grained distinctions, enable nuanced comparisons, and are applicable across domains for code from any source, LLM or developer. Our results suggest that LLMs can assist in generating starter code for legally compliant smart contracts with strict reviews, and the proposed metrics provide a foundation for automated and self-improving development workflows.","现有方法,如正式规格、核查和基于模型的发展,都需要法律和软件开发领域的专门知识,以及广泛的人工努力。鉴于大语言模型(LLMS)最近在代码生成方面的最新进步,我们调查其直接从自然语言法律合同产生符合法律的智能合同的能力,应对这些挑战。我们提出一套新颖的衡量标准,根据将法律和智能合同建模为程序并比较其行为,量化法律合规性。我们选择了四大LMS,根据五项法律合同生成20个智能合同,并分析其法律合规性。我们发现,虽然所有LLMS都生成了统一正确的代码,但在法律上遵守总体上显示遵守程度较高的更大模型方面差异很大。我们还评估了针对软件计量特性的拟议衡量标准,表明它们提供了细微的区别,能够进行细微的比较,并且适用于来自任何来源、LMM或开发商的代码。我们的结果表明,LMS可以帮助生成符合法律的智能合同的初始代码,同时进行严格的工作流程审查,并提出自我衡量。","Chanuka Wijayakoon, Hai Dong, H. M. N. Dilum Bandara, Zahir Tari, Anurag Soin",2025-06-01T10:20:13Z,Legal Compliance Evaluation of Smart Contracts Generated By Large   Language Models,"Legal Compliance Bewertung von Smart Contracts, die von großen Sprachmodellen generiert werden",对按大语言模式生成的智能合同的法律合规评价,http://arxiv.org/abs/2506.00943v1
99,"This paper presents the first concolic testing framework explicitly designed for quantum programs. The framework introduces quantum constraint generation methods for quantum control statements that quantify quantum states and offers a symbolization method for quantum variables. Based on this framework, we generate path constraints for each concrete execution path of a quantum program. These constraints guide the exploration of new paths, with a quantum constraint solver determining outcomes to create novel input samples, thereby enhancing branch coverage. Our framework has been implemented in Python and integrated with Qiskit for practical evaluation. Experimental results show that our concolic testing framework improves branch coverage, generates high-quality quantum input samples, and detects bugs, demonstrating its effectiveness and efficiency in quantum programming and bug detection. Regarding branch coverage, our framework achieves more than 74.27% on quantum programs with under 5 qubits.","本文展示了第一个为量子程序明确设计的concolic测试框架。 框架引入了量子控制说明的量子约束生成方法, 以量化量子状态, 并为量子变量提供一种符号化方法。 基于此框架, 我们为量子程序的每一具体执行路径制造路径限制。 这些限制引导了新路径的探索, 量子约束解答器决定了创建新输入样本的结果, 从而扩大了分支覆盖。 我们的框架已经在Python 实施, 并与 Qiskit 整合, 以便进行实际评估。 实验结果显示, 我们的量子测试框架改善了分支覆盖, 生成了高质量的量子输入样本, 检测了错误, 显示了量子规划和错误检测的效果和效率。 在分支覆盖方面, 我们的框架实现了超过74.27 % 的量子方案, 低于 5Q。","Shangzhou Xia, Jianjun Zhao, Fuyuan Zhang, Xiaoyu Guo",2025-06-01T09:21:37Z,Quantum Concolic Testing,Quantenkonkolische Prüfung,量量直控测试,http://arxiv.org/abs/2405.04860v3
100,"Statistical methods have been widely misused and misinterpreted in various scientific fields, raising significant concerns about the integrity of scientific research. To mitigate this problem, we propose a tool-assisted method for formally specifying and automatically verifying the correctness of statistical programs. In this method, programmers are required to annotate the source code of the statistical programs with the requirements for these methods. Through this annotation, they are reminded to check the requirements for statistical methods, including those that cannot be formally verified, such as the distribution of the unknown true population. Our software tool StatWhy automatically checks whether programmers have properly specified the requirements for the statistical methods, thereby identifying any missing requirements that need to be addressed. This tool is implemented using the Why3 platform to verify the correctness of OCaml programs that conduct statistical hypothesis testing. We demonstrate how StatWhy can be used to avoid common errors in various statistical hypothesis testing programs.","统计方法在各种科学领域被广泛滥用和曲解,引起了对科学研究完整性的极大关切。为缓解这一问题,我们提议了一种工具辅助方法,用于正式指定和自动核实统计方案的正确性。在这个方法中,程序设计员必须说明统计方案的源代码,并附上这些方法的要求。通过这个说明,提醒他们检查统计方法的要求,包括无法正式核实的统计方法的要求,例如未知真实人口的分布。我们的软件工具Stathews自动检查程序设计员是否正确指定了统计方法的要求,从而查明任何缺失的、需要解决的要求。这个工具是利用“3:3”平台实施的,以核实进行统计假设测试的OCaml方案是否正确。我们展示了如何利用Stathreight来避免各种统计假设测试方案中的共同错误。","Yusuke Kawamoto, Kentaro Kobayashi, Kohei Suenaga",2025-06-01T09:09:55Z,StatWhy: Formal Verification Tool for Statistical Hypothesis Testing   Programs,StatWhy: Formales Verifikationstool für statistische Hypothesen-Testprogramme,统计假设测试方案的正式核查工具,http://arxiv.org/abs/2405.17492v3
101,"Large language models (LLMs) have shown remarkable capabilities across various software engineering tasks; however, their effectiveness in code migration, adapting code to run in different environments, remains insufficiently studied. In this work, we introduce CODEMENV: Code Migration Across Environment, a new benchmark specifically designed to assess LLMs' abilities in code migration scenarios. CODEMENV consists of 922 examples spanning 19 Python and Java packages, and covers three core tasks: (1) identifying functions incompatible with specific versions, (2) detecting changes in function definitions, and (3) adapting code to target environments. Experimental evaluation with seven LLMs on CODEMENV yields an average pass@1 rate of 26.50%, with GPT-4O achieving the highest score at 43.84%. Key findings include: (i) LLMs tend to be more proficient with newer function versions, which aids in migrating legacy code, and (ii) LLMs sometimes exhibit logical inconsistencies by identifying function changes irrelevant to the intended migration environment. The datasets are available at https://github.com/xdshen-ai/Benchmark-of-Code-Migration.","大型语言模型(LLMS)在各种软件工程任务中表现出了非凡的能力;然而,在代码迁移、调适代码以适应不同环境运行方面,其效力仍未得到充分研究。在这项工作中,我们引入CODEMENV: CODEMENV: CRODMENV: Code Migration over Envil Environment:一个专门用于评估LLMS在代码迁移情景中的能力的新基准。CODEMENV由922个例子组成,共涵盖19个Python和Java软件包,并涵盖三项核心任务:(1) 查明与特定版本不相容的功能,(2) 发现功能定义的变化,(3) 将代码适应目标环境。在CODEMENV上对7个LMS的实验性评估得出平均通过率@1的26.50%,GPT-4O达到最高分,达43.84%。主要结论包括:(一) LLMS往往更熟练,其功能版本有助于迁移遗产代码;(二) LLMS有时通过查明与预期的迁移环境无关的功能变化而表现出逻辑上的不一致。数据可在https://github.com/xd-migrade-Mismation。数据集查阅。","Keyuan Cheng, Xudong Shen, Yihao Yang, Tengyue Wang, Yang Cao, Muhammad Asif Ali, Hanbin Wang, Lijie Hu, Di Wang",2025-06-01T08:29:59Z,CODEMENV: Benchmarking Large Language Models on Code Migration,CODEMENV: Benchmarking großer Sprachmodelle zur Code-Migration,CODEMENV: 确定移徙法中大语言模式的基准,http://arxiv.org/abs/2506.00894v1
102,"The Leadership in Energy and Environmental Design (LEED) certification process is characterized by labor-intensive requirements for data handling, simulation, and documentation. This paper presents an automated platform designed to streamline key aspects of LEED certification. The platform integrates a PySide6-based user interface, a review Manager for process orchestration, and multiple analysis engines for credit compliance, energy modeling via EnergyPlus, and location-based evaluation. Key components include an OpenCV-based preprocessing pipeline for document analysis and a report generation module powered by the Gemma3 large language model with a retrieval-augmented generation framework. Implementation techniques - including computer vision for document analysis, structured LLM prompt design, and RAG-based report generation - are detailed. Initial results from pilot project deployment show improvements in efficiency and accuracy compared to traditional manual workflows, achieving 82% automation coverage and up to 70% reduction in documentation time. The platform demonstrates practical scalability for green building certification automation.","能源和环境设计(LEED)认证过程的特点是数据处理、模拟和文件的劳动密集型要求;本文件展示了一个自动化平台,旨在简化LEED认证的关键方面;该平台整合了一个基于PySide6的用户界面、一个程序协调审查管理员,以及信用合规、通过EnergyPlus进行能源建模和基于地点的评价等多种分析引擎;关键组成部分包括一个基于OpenCV的预处理管道,用于文件分析,以及一个由Gemma3大语言模型驱动、具有检索强化生成框架的报告生成模块;实施技术,包括文件分析计算机愿景、结构化LLOM快速设计和基于RAG的报告生成;试点项目部署的初步结果显示,与传统的手工工作流程相比,效率和准确性有所提高,实现了82%的自动化覆盖率,文件时间缩短了70%;该平台展示了绿色建筑认证自动化的实际可扩展性。",Jooyeol Lee,2025-06-01T08:05:35Z,An Integrated Platform for LEED Certification Automation Using Computer   Vision and LLM-RAG,Eine integrierte Plattform für LEED-Zertifizierungsautomatisierung mit Computer Vision und LLM-RAG,利用计算机愿景和LLM-RAG实现LEED认证自动化综合平台,http://arxiv.org/abs/2506.00888v1
103,"Quantum computers threaten widely deployed cryptographic primitives such as RSA, DSA, and ECC. While NIST has released post-quantum cryptographic (PQC) standards (e.g., Kyber, Dilithium), mobile app ecosystems remain largely unprepared for this transition. We present a large-scale binary analysis of over 4,000 Android apps to assess cryptographic readiness. Our results show widespread reliance on quantum-vulnerable algorithms such as MD5, SHA-1, and RSA, while PQC adoption remains absent in production apps. To bridge the readiness gap, we explore LLM-assisted migration. We evaluate leading LLMs (GPT-4o, Gemini Flash, Claude Sonnet, etc.) for automated cryptographic migration. All models successfully performed simple hash replacements (e.g., SHA-1 to SHA-256). However, none produced correct PQC upgrades due to multi-file changes, missing imports, and lack of context awareness. These results underscore the need for structured guidance and system-aware tooling for post-quantum migration","量子计算机威胁到广泛部署的加密原始物,如RSA、DSA和ECC。虽然NIST已经公布了分子后加密(PQC)标准(例如Kyber、Dilithium),但移动应用程序生态系统仍然基本上没有为这一过渡做好准备。我们对4000多种安非他明的应用程序进行了大规模的二进制分析,以评估加密准备状态。我们的结果显示,在生产应用程序中仍然普遍依赖量子抗变算法,如MD5、SHA-1和RSA,而PQC仍然得不到采用。为弥补准备状态差距,我们探索LLMM协助的迁移。我们评估了自动加密迁移的主要LLMS(GPT-4o、Gemini Flash、Claude Sonnet等),所有模型都成功地进行了简单的散装替换(例如SHA-1至SHA-256)。然而,由于多档案的改变、缺失进口和缺乏背景意识,我们没有产生正确的PQC升级。这些结果突出表明,需要为后区移徙提供结构化指导和系统工具。","Joseph Strauss, Krishna Upadhyay, A. B. Siddique, Ibrahim Baggili, Umar Farooq",2025-06-01T02:42:46Z,Assessing and Enhancing Quantum Readiness in Mobile Apps,Bewertung und Verbesserung der Quantum Readiness in mobilen Apps,评估和加强移动应用程序的量准备状态,http://arxiv.org/abs/2506.00790v1
104,"Automating the enrichment of UML class diagrams with behavioral methods from natural language use cases is a significant challenge. This study evaluates nine large language models (LLMs) in augmenting a methodless UML diagram (21 classes, 17 relationships) using 21 structured waste-management use cases. A total of 90 diagrams (3,373 methods) were assessed across six metrics: method quantity, signature richness (visibility, names, parameters, return types), annotation completeness (linking to use cases/actions), structural fidelity, syntactic correctness (PlantUML compilation), and naming convergence (across models). All LLMs produced valid PlantUML diagrams adhering to UML conventions. Some models excelled in method coverage and annotation accuracy, while others showed richer parameterization but weaker traceability. These results demonstrate that LLMs can generate well-structured methods with consistent naming, advancing automated behavioral modeling. However, inconsistencies in annotations and signatures highlight the need for improved prompt engineering and model selection. The rapid generation of these methods supports Agile practices by enabling faster design iterations. Despite their capabilities, human oversight is essential to ensure accuracy, appropriateness, and semantic alignment. This positions LLMs as collaborative partners in software design. All experimental artifacts (\texttt{.puml}, \texttt{.png}, \texttt{.csv}) are publicly available for reproducibility.","将UML类图与自然语言使用案例的行为方法{行为方法{ { 应用自然语言使用案例的行为方法{ { 自动充实UML类图是一个重大挑战。本研究评估了9个大型语言模型(LLMS),用21个结构化废物管理使用案例来增加无方法的UML图(21个类别,17个关系),共评估了90个图表(3,373个方法),涉及6个指标:方法数量、特征丰富(可见度、名称、参数、返回类型)、说明完整性(与使用案例/行动挂钩)、结构忠诚性、合成正确性(PlantUML汇编)和命名趋同(跨模式)。所有LLLMs都制作了符合UML公约的有效PANUML图(21个类别,17个关系)。有些模型在方法覆盖和注释精确度方面优于方法,而其他模型则显示较富的参数化但可追溯性较弱。这些结果表明LMSMs可以产生结构完善的方法,但说明性和签名需要改进工程和模型选择。这些方法的快速生成支持AgIGLTLTLDUTLD(尽管它们具备了设计精确性) 和Slimtext 正确性) 。","Djaber Rouabhia, Ismail Hadjadj",2025-06-01T02:33:40Z,Behavioral Augmentation of UML Class Diagrams: An Empirical Study of   Large Language Models for Method Generation,Verhaltensvergrößerung von UML-Klassendiagrammen: Eine empirische Studie großer Sprachmodelle für die Methodengenerierung,UMML类图示表行为增强:方法生成大语言模型经验研究,http://arxiv.org/abs/2506.00788v1
105,"Autonomous cyber-physical systems (CPSs) leverage AI for perception, planning, and control but face trust and safety certification challenges due to inherent uncertainties. The neurosymbolic paradigm replaces stochastic layers with interpretable symbolic AI, enabling determinism. While promising, challenges like multisensor fusion, adaptability, and verification remain. This paper introduces NeuroStrata, a neurosymbolic framework to enhance the testing and verification of autonomous CPS. We outline its key components, present early results, and detail future plans.","自主的网络物理系统(CPS)在感知、规划和控制方面利用AI(AI),但由于内在的不确定性而面临信任和安全认证的挑战。神经同步模式以可解释的象征性AI(ATI)取代随机层,从而能够确定性。虽然挑战很有希望,但多传感器聚合、适应性和核查等挑战依然存在。本文介绍了NeuroStrata,这是一个加强自主CPS测试和核查的神经同步框架。我们概述了其关键组成部分,提出了早期结果,并详细介绍了今后的计划。","Xi Zheng, Ziyang Li, Ivan Ruchkin, Ruzica Piskac, Miroslav Pajic",2025-06-01T01:30:25Z,"NeuroStrata: Harnessing Neurosymbolic Paradigms for Improved Design,   Testability, and Verifiability of Autonomous CPS","NeuroStrata: Neurosymbolische Paradigmen für verbessertes Design, Testbarkeit und Überprüfbarkeit autonomer CPS",NeuroStrata: 利用神经元外线模型改进CPS自治设计、可测试性和可核实性,http://arxiv.org/abs/2502.12267v2
106,"The widespread adoption of open source libraries and frameworks can be attributed to their licensing. Open Source Software Licenses (OSS licenses) ensure that software can be sold or distributed as part of aggregate programs from various sources without requiring a royalty or fee. The quality of such code rivals that of commercial software, with open source libraries forming large parts of the supply chain for critical commercial systems in industry. Despite this, most open source projects rely on volunteer contributions, and unpaid library maintainers face significant pressure to sustain their projects. One potential solution for these projects is to change their licensing to ensure that maintainers are compensated accordingly for their work. In this paper, we explore the potential of licensing to help alleviate funding issues, with a review of three different cases where OSS licenses were modified to allow for monetization. In addition, we explore licensing concerns related to the emergence of the use of artificial intelligence (AI) in software development. We argue that open source is at a crossroads, with a growing need to redefine its licensing models and support communities and critical software. We identify specific research opportunities and conclude with a research agenda comprising a series of research questions to guide future studies in this area.","开放源码图书馆和框架的广泛采用可归因于其许可证的发放; 开放源码图书馆和框架的广泛采用可归因于其许可证的发放; 开放源码许可证(OSS许可证)确保软件可以作为各种来源的综合程序的一部分出售或分发,而无需使用特许使用费或收费; 这种代码的质量与商业软件相对应,开放源码图书馆在工业关键商业系统的供应链中占很大比例。尽管如此,大多数开放源码项目依赖志愿人员的捐助,而无报酬的图书馆维护者面临维持项目的巨大压力; 这些项目的一个潜在解决办法是改变其许可证的发放,以确保维护者的工作得到相应的补偿; 在本文件中,我们探讨许可证的发放可能有助于缓解筹资问题的可能性,同时审查三个不同的情况,即对开放源码软件许可证的修改允许货币化; 此外,我们探讨与软件开发中出现人工智能(AI)有关的问题。我们指出,开放源处于十字路口,越来越需要重新定义其许可证模式,支持社区和关键软件。我们查明了具体的研究机会,并以研究议程结尾,其中包括一系列研究问题,以指导该领域的未来研究。","Raula Gaikovina Kula, Brittany Anne Reid, Christoph Treude",2025-06-01T00:34:11Z,Open Source at a Crossroads: The Future of Licensing Driven by   Monetization,Open Source an einer Kreuzung: Die Zukunft der Lizenzierung durch Monetisierung getrieben,《十字路口的开放源码:货币化驱动的许可证发放的未来》,http://arxiv.org/abs/2503.02817v2
107,"Understanding and reasoning about code semantics is essential for enhancing code LLMs' abilities to solve real-world software engineering (SE) tasks. Although several code reasoning benchmarks exist, most rely on synthetic datasets or educational coding problems and focus on coarse-grained reasoning tasks such as input/output prediction, limiting their effectiveness in evaluating LLMs in practical SE contexts. To bridge this gap, we propose CodeSense, the first benchmark that makes available a spectrum of fine-grained code reasoning tasks concerned with the software engineering of real-world code. We collected Python, C and Java software projects from real-world repositories. We executed tests from these repositories, collected their execution traces, and constructed a ground truth dataset for fine-grained semantic reasoning tasks. We then performed comprehensive evaluations on state-of-the-art LLMs. Our results show a clear performance gap for the models to handle fine-grained reasoning tasks. Although prompting techniques such as chain-of-thought and in-context learning helped, the lack of code semantics in LLMs fundamentally limit models' capabilities of code reasoning. Besides dataset, benchmark and evaluation, our work produced an execution tracing framework and tool set that make it easy to collect ground truth for fine-grained SE reasoning tasks, offering a strong basis for future benchmark construction and model post training. Our code and data are located at https://codesense-bench.github.io/.","虽然存在一些代码推理基准,但大多数依赖合成数据集或教育编码问题,并侧重于粗粗的推理任务,如投入/产出预测,从而限制其在实际的SE背景下评估LLMs的效力。为了缩小这一差距,我们提议CocSense,这是第一个提供一系列与真实世界代码软件工程有关的精细代码推理任务的基准。我们从真实世界库收集了Python、C和Java软件项目。我们从这些储存库中进行了测试,收集了它们的执行痕迹,并为精细的语义推理任务建造了一套地面真象数据集。我们随后对“最新”的LLMMs进行了全面评估。我们的结果表明,模型在处理微细推理学任务方面存在着明显的绩效差距。尽管我们的想法链和通识学习等催化技术帮助了LMS根本限制了代码模型在代码推理方面的能力。此外,我们还对这些数据库进行了测试,并建立了一个基础的地面推理学基础。我们的数据、基准和基准提供了一个用于跟踪的SE推理算基础,为我们进行精确的实地推理算工作提供了一个基础。","Monoshi Kumar Roy, Simin Chen, Benjamin Steenhoek, Jinjun Peng, Gail Kaiser, Baishakhi Ray, Wei Le",2025-05-31T23:32:01Z,CodeSense: a Real-World Benchmark and Dataset for Code Semantic   Reasoning,CodeSense: ein Real-World Benchmark und Datensatz für Code Semantic Reasoning,代码编码:用于代码词义理由的现实世界基准和数据集,http://arxiv.org/abs/2506.00750v1
108,"Functional correctness is critical for ensuring the reliability and security of network protocol implementations. Functional bugs, instances where implementations diverge from behaviors specified in RFC documents, can lead to severe consequences, including faulty routing, authentication bypasses, and service disruptions. Detecting these bugs requires deep semantic analysis across specification documents and source code, a task beyond the capabilities of traditional static analysis tools. This paper introduces RFCScan, an autonomous agent that leverages large language models (LLMs) to detect functional bugs by checking conformance between network protocol implementations and their RFC specifications. Inspired by the human auditing procedure, RFCScan comprises two key components: an indexing agent and a detection agent. The former hierarchically summarizes protocol code semantics, generating semantic indexes that enable the detection agent to narrow down the scanning scope. The latter employs demand-driven retrieval to iteratively collect additional relevant data structures and functions, eventually identifying potential inconsistencies with the RFC specifications effectively. We evaluate RFCScan across six real-world network protocol implementations. RFCScan identifies 47 functional bugs with 81.9% precision, of which 20 bugs have been confirmed or fixed by developers.","功能正确性对于确保网络协议执行的可靠性和安全性至关重要。功能错误,即执行与RFC文件规定的行为有差异的功能错误,可能导致严重后果,包括路径错误、认证绕行和服务中断。检测这些错误需要在规格文件和源代码之间进行深度的语义分析,这是传统静态分析工具能力之外的一项任务。本文介绍了RFCScan,这是一个利用大型语言模型(LLLMS)来检测功能错误的自主代理商,它通过检查网络协议执行与其RFC规格的相符性来利用大语言模型(LLMS)来检测功能错误。受人类审计程序的启发,RFCSCCCan由两个关键组成部分组成:一个索引代理商和一个检测代理商。前一个按等级对协议代码语义进行总结的分类指数,使检测代理商能够缩小扫描范围。后者利用需求驱动的检索来迭代收集更多的相关数据结构和功能,最终查明与RFCFC规格的潜在不一致性。我们评估了六个实际世界网络协议执行中的RFCScccan, 受人类审计程序启发,由两个关键部分组成了47个功能错误,其中的精确度为81.9%的开发商。","Mingwei Zheng, Chengpeng Wang, Xuwei Liu, Jinyao Guo, Shiwei Feng, Xiangyu Zhang",2025-05-31T21:13:19Z,An LLM Agent for Functional Bug Detection in Network Protocols,LLM Agent für die Erkennung von Funktionsstörungen in Netzwerkprotokollen,网络协议中功能性臭虫侦测LLM代理代理,http://arxiv.org/abs/2506.00714v1
109,"This paper presents a study of human visual attention during localization of memory bugs in C. Human visual attention refers to the mechanical processes by which we selectively process and prioritize information. Visual attention is important to study because it is central to what information people (who are sighted) use to solve a particular problem. Meanwhile, memory bugs are among the most common types of bugs in C programs that manifest as a variety of program faults. In this paper, we study human visual attention while people attempt to locate memory bugs in code. We recruit 11 programmers to locate between one and six memory bugs in three C programs for 1.5-2 hours each. In total we collected observations of 17 hours of programmer effort. The bugs in our study cover memory leaks, overflows, and double frees, which are among the most common memory bugs. We analyze the task outcomes in terms of success rate and related factors, patterns of visual attention overall such as what lines and functions are read, and finally we explore differences of visual attention patterns during success versus failure cases.","本文介绍了C. 人类视觉关注指的是我们有选择地处理和优先处理信息的机械过程。 视觉关注很重要, 因为它对于人们( 视力人)用什么信息解决特定问题至关重要。 同时, 记忆错误是C程序最常见的错误类型之一, 表现为各种程序错误。 在本文中, 我们研究人类视觉关注, 而人们试图将记忆错误定位在代码中。 我们征聘了11个程序员, 在3个C程序里找到1至6个记忆错误, 每人1.5至2小时。 我们总共收集了17小时的程序员工作观测结果。 我们研究中的错误包括了记忆泄漏、 溢出和双空, 这些都是最常见的记忆错误。 我们从成功率和相关因素的角度分析了任务结果, 视觉关注的总体模式, 比如阅读的线和功能, 最后我们探索了成功与失败案例之间视觉关注模式的差异 。","Emory Smith, Robert Wallace, Matthew Robison, Yu Huang, Collin McMillan",2025-05-31T19:56:16Z,Human Attention During Localization of Memory Bugs in C Programs,Menschliche Aufmerksamkeit bei der Lokalisierung von Speicherfehlern in C-Programmen,C方案中记忆虫地方化过程中的人类关注,http://arxiv.org/abs/2506.00693v1
110,"An upstream task for software bill-of-materials (SBOMs) is the accurate localization of the patch that fixes a vulnerability. Nevertheless, existing work reveals a significant gap in the CVEs whose patches exist but are not traceable. Existing works have proposed several approaches to trace/retrieve the patching commit for fixing a CVE. However, they suffer from two major challenges: (1) They cannot effectively handle long diff code of a commit; (2) We are not aware of existing work that scales to the full repository with satisfactory accuracy. Upon identifying this gap, we propose SITPatchTracer, a scalable and effective retrieval system for tracing known vulnerability patches. To handle the context length challenge, SITPatchTracer proposes a novel hierarchical embedding technique which efficiently extends the context coverage to 6x that of existing work while covering all files in the commit. To handle the scalability challenge, SITPatchTracer utilizes a three-phase framework, balancing the effectiveness/efficiency in each phase.   The evaluation of SITPatchTracer demonstrates it outperforms existing patch tracing methods (PatchFinder, PatchScout, VFCFinder) by a large margin. Furthermore, SITPatchTracer outperforms VoyageAI, the SOTA commercial code embedding LLM (\$1.8 per 10K commits) on the MRR and Recall@10 by 18\% and 28\% on our two datasets. Using SITPatchTracer, we have successfully traced and merged the patch links for 35 new CVEs in the GitHub Advisory database Our ablation study reveals that hierarchical embedding is a practically effective way of handling long context for patch retrieval.","软件材料账单(SBOMs)的上游任务是精确地定位修复脆弱点的补丁。 然而,现有工作显示,在有补丁但无法追踪的CVE中,现有工作显示存在巨大的差距。现有工作提出了跟踪/检索修复 CVE的补丁承诺的几种方法。然而,它们面临两大挑战:(1) 它们无法有效地处理一个承诺的长调码; (2) 我们不知道现有工作是否以令人满意的准确性将标定标定到整个储存库。 在查明这一差距后,我们提议SIMTPatchTracr, 用于追踪已知脆弱点数据库的可缩放和有效检索系统。为了应对上下文挑战, SITPatchTracr提出了一个新的分级嵌入技术, 将现有工作覆盖范围有效扩大到6x。 为了应对可缩放挑战, SITPatchTracer 使用一个三阶段框架, 平衡每个阶段的效能/效率。 SITPatchTracr 显示, 用于跟踪现有补缺误追踪方法( PatchFrightr ) , IMSOLSLSOILSOLE GLOILOLOLODRLO 。","Xueqing Liu, Jiangrui Zheng, Guanqun Yang, Siyan Wen, Qiushi Liu, Xiaoyin Wang",2025-05-31T19:45:52Z,Improving the Context Length and Efficiency of Code Retrieval for   Tracing Security Vulnerability Fixes,Verbesserung der Kontextlänge und Effizienz von Code Retrieval für das Aufspüren von Sicherheitslücken,改进《追踪安全脆弱程度确定法》检索规则的背景长度和效率,http://arxiv.org/abs/2503.22935v2
111,"Context: Modern open-source software ecosystems, such as those managed by GNU/Linux distributions, are composed of numerous packages developed independently by diverse communities. These ecosystems employ package management tools to facilitate software installation and dependency resolution. However, these tools lack robust mechanisms for systematically evaluating the development activity and versioning dynamics within their heterogeneous software environments. Objective: This research aims to introduce a systematic method and a prototype tool for assessing version activity within heterogeneous package manager ecosystems, enabling quantitative analysis of software package updates. Method: We developed a Package Version Activity Categorizer (PVAC) that consists of three components. The Version Categorizer (VC), which categorizes diverse semantic version numbers, a Version Number Delta (VND) component, which calculates a numeric score representing the aggregated semantic version changes across packages at the ecosystem level, and finally, an Activity Categorizer (AC) that categorizes the activity of individual packages within that ecosystem. PVAC utilizes tailored regular expressions to parse semantic versioning details (epoch, major, minor, and patch versions) from diverse package version strings, enabling consistent categorization and quantitative scoring of version changes. Results: PVAC was empirically evaluated using a dataset of 22,535 packages drawn from recent releases of Debian and Ubuntu GNU/Linux distributions. Our findings demonstrate PVAC's effectiveness for accurately categorizing versioning schemes and quantitatively measuring version activity across releases. We provide empirical evidence confirming that semantic versioning, including adapted variations, is predominantly employed across these ecosystems.",": 现代开放源码软件生态系统,例如由 GNU/Linux 分销公司管理的那些开放源码软件生态系统,是由不同社区独立开发的多种软件包组成。这些生态系统使用软件包管理工具,便利软件安装和依赖分辨率。然而,这些工具缺乏强有力的机制,无法系统地评估开发活动和在各种软件环境中的版本动态。 目标:这项研究旨在引入一种系统方法和一个原型工具,用于评估不同软件管理者生态系统内部的版本活动,便于对软件包更新进行定量分析。 方法:我们开发了一个由三个组成部分组成的软件包版活动分类器(PVAC),该软件包分解了多种语义版本的数字管理工具,用于分类不同的语义管理工具,用于分类不同版本的版本的版本的版本的版本的版本(VC),版本的版本的Delta (VND) 组件,该版本计算了一个数字分数,代表了生态系统层面各软件包的总体语义结构变化。","Shane K. Panter, Luke Hindman, Nasir U. Eisty",2025-05-31T19:38:53Z,"PVAC: Package Version Activity Categorizer, Leveraging Semantic   Versioning in a Heterogeneous System","PVAC: Paketversionsaktivität Kategorisierter, Semantische Versionierung in einem heterogenen System","PVAC: 软件包版本活动分类器,利用异种系统中的语义版本",http://arxiv.org/abs/2409.04588v2
112,"Context: As generative AI (GenAI) tools such as ChatGPT and GitHub Copilot become pervasive in education, concerns are rising about students using them to complete rather than learn from coursework-risking overreliance, reduced critical thinking, and long-term skill deficits.   Objective: This paper proposes and empirically applies a causal model to help educators scaffold responsible GenAI use in Software Engineering (SE) education. The model identifies how professor actions, student factors, and GenAI tool characteristics influence students' usage of GenAI tools.   Method: Using a design-based research approach, we applied the model in two contexts: (1) revising four extensive lab assignments of a final-year Software Testing course at Queen's University Belfast (QUB), and (2) embedding GenAI-related competencies into the curriculum of a newly developed SE BSc program at Azerbaijan Technical University (AzTU). Interventions included GenAI usage declarations, output validation tasks, peer-review of AI artifacts, and career-relevant messaging.   Results: In the course-level case, instructor observations and student artifacts indicated increased critical engagement with GenAI, reduced passive reliance, and improved awareness of validation practices. In the curriculum-level case, the model guided integration of GenAI learning outcomes across multiple modules and levels, enabling longitudinal scaffolding of AI literacy.   Conclusion: The causal model served as both a design scaffold and a reflection tool. It helped align GenAI-related pedagogy with SE education goals and can offer a useful framework for instructors and curriculum designers navigating the challenges of GenAI-era education.","目标:本文件提出并实际应用因果模型,以帮助教育家将GenAI负责的GenAI用于软件工程(SE)教育。模型确定教授的行动、学生因素和GenAI工具特点如何影响学生使用GenAI工具。方法:采用基于设计的研究方法,我们应用该模型在两种情况下:(1) 修订皇后大学Belfast(QUB)最后一年软件测试课程的四大实验室任务,而不是从课程风险过度依赖、减少批判性思维和长期技能赤字中学习。目标:本文件提出并实际应用因果模型,以帮助教育师士在软件工程(SE)教育中使用GenAI负责的GenAI课程。模型确定教授的行动、学生因素和GenAI工具特点如何影响学生使用GenAI工具。方法:采用基于设计的研究方法,我们应用该模型在两种情况下:(1) 修订四个广泛的实验室任务,而不是从师范测试课程中学习,将GENAI的终年软件测试课程,降低与GEAI相关的师范的教程,将GenAI相关的能力纳入新设计中,并改进了与AI的师范课程的校内学习标准。","Vahid Garousi, Zafar Jafarov, Aytan Movsumova, Atif Namazov, Huseyn Mirzayev",2025-05-31T19:27:40Z,Encouraging Students' Responsible Use of GenAI in Software Engineering   Education: A Causal Model and Two Institutional Applications,Förderung des verantwortungsvollen Einsatzes von GenAI in der Software-Engineering-Ausbildung: Ein Kausalmodell und zwei institutionelle Anwendungen,鼓励学生在软件工程教育中负责任地利用GenAI:一个因果模型和两个机构应用,http://arxiv.org/abs/2506.00682v1
113,"In this paper, we first report an exploratory study where three participants were instructed to use ChatGPT to implement a simple Web-based application. A key finding of this study revealed that ChatGPT does not offer a user-friendly interface for building applications, even small web systems. For example, one participant with limited experience in software development was unable to complete any of the proposed user stories. Then, and as the primary contribution of this work, we decided to design, implement, and evaluate a tool that offers a customized interface for language models like GPT, specifically targeting the implementation of small web applications without writing code. This tool, called NoCodeGPT, instruments the prompts sent to the language model with useful contextual information (e.g., the files that need to be modified when the user identifies and requests a bug fix). It also saves the files generated by the language model in the correct directories. Additionally, a simple version control feature is offered, allowing users to quickly revert to a previous version of the code when the model enters a hallucination process, generating worthless results. To evaluate our tool, we invited 14 students with limited Web development experience to implement two small web applications using only prompts and NoCodeGPT. Overall, the results of this evaluation were quite satisfactory and significantly better than those of the initial study (the one using the standard ChatGPT interface). More than half of the participants (9 out of 14) successfully completed the proposed applications, while the others completed at least half of the proposed user stories.","在本文中,我们首先报告一项探索性研究,其中3名参与者被指示使用查特GPT实施一个简单的网络应用程序。这项研究的一项关键调查结果显示,查特GPT并不为建筑应用程序,甚至小型网络系统提供一个方便用户的界面。例如,一名在软件开发方面经验有限的参与者无法完成任何拟议的用户故事。随后,作为这项工作的主要贡献,我们决定设计、实施和评价一个工具,为GPT等语言模型提供定制界面,具体针对不写代码的小型网络应用程序的实施。这个工具称为NoCodeGPT,用有用的背景信息(例如,当用户确定和要求纠正错误时需要修改的文件)向语言模型发送的提示工具。它还保存了在正确目录中由语言模型生成的文档。此外,我们提供了一个简单的版本控制功能,使用户在模型进入幻觉过程时能够迅速恢复提议的代码的前一版本,产生毫无价值的结果。为了评估我们的工具,我们邀请14名网络开发经验有限的学生在使用两个最差的网络应用程序时使用有用的背景信息(例如,当用户确定和要求纠正错误时,而仅使用最令人满意的初步的版本的版本)只使用最接近的版本。","Mauricio Monteiro, Bruno Castelo Branco, Samuel Silvestre, Guilherme Avelino, Marco Tulio Valente",2025-05-31T18:22:16Z,NoCodeGPT: A No-Code Interface for Building Web Apps with Language   Models,NoCodeGPT: Ein No-Code Interface zum Erstellen von Web-Apps mit Sprachmodellen,NoCodeGPT: 用语言模型构建网络应用程序的无代码界面,http://arxiv.org/abs/2310.14843v3
114,"In recent years, machine learning technologies have played an important role in robotics, particularly in the development of autonomous robots and self-driving vehicles. As the industry matures, robotics frameworks like ROS 2 have been developed and provides a broad range of applications from research to production. In this work, we introduce AWML, a framework designed to support MLOps for robotics. AWML provides a machine learning infrastructure for autonomous driving, supporting not only the deployment of trained models to robotic systems, but also an active learning pipeline that incorporates auto-labeling, semi-auto-labeling, and data mining techniques.","近年来,机器学习技术在机器人技术中发挥了重要作用,特别是在开发自主机器人和自驾驶车辆方面,随着该行业的成熟,已经开发了RoS 2等机器人框架,从研究到生产提供了广泛的应用;在这项工作中,我们引入了AWML,这是一个旨在支持机器人MLPs的框架;AWML为自主驾驶提供了一个机器学习基础设施,不仅支持将经过训练的模型部署到机器人系统,而且支持一个包含自动标签、半自动标签和数据挖掘技术的积极学习管道。","Satoshi Tanaka, Samrat Thapa, Kok Seang Tan, Amadeusz Szymko, Lobos Kenzo, Koji Minoda, Shintaro Tomie, Kotaro Uetake, Guolong Zhang, Isamu Yamashita, Takamasa Horibe",2025-05-31T17:29:32Z,AWML: An Open-Source ML-based Robotics Perception Framework to Deploy   for ROS-based Autonomous Driving Software,AWML: Ein Open Source ML-basiertes Robotics Perception Framework zur Bereitstellung von ROS-basierter autonomer Fahrsoftware,"AWML:一个开放源码基于ML的机器人感知框架,用于部署基于ROS的自动自动驱动软件",http://arxiv.org/abs/2506.00645v1
115,"Static Application Security Testing (SAST) tools are critical to software quality, identifying potential code issues early in development. However, they often produce false positive warnings that require manual review, slowing down development. Thus, automating false positive mitigation (FPM) is essential. The advent of Large Language Models (LLMs), with their strong abilities in natural language and code understanding, offers promising avenues for FPM. Yet current LLM-based FPM method faces two major limitations: 1. The warning-related code snippets extracted are overly broad and cluttered with irrelevant control/data flows, reducing precision; 2. Critical code contexts are missing, leading to incomplete representations that can mislead LLMs and cause inaccurate assessments. To overcome these limitations, we propose LLM4FPM , a lightweight and efficient false positive mitigation framework. It features eCPG-Slicer, which builds an extended code property graph (eCPG) to extract precise line-level code contexts for warnings. Furthermore, the integrated FARF algorithm builds a file reference graph to identify all files that are relevant to warnings in linear time. This enables eCPG-Slicer to obtain rich contextual information without resorting to expensive whole-program analysis. LLM4FPM outperforms the existing method on the Juliet dataset (F1 > 99% across various Common Weakness Enumerations) and improves label accuracy on the D2A dataset to 86%. By leveraging a lightweight open-source LLM, LLM4FPM can significantly save inspection costs up to \$2758 per run (\$0.384 per warning) on Juliet with an average inspection time of 4.7s per warning. Moreover, real-world tests on popular C/C++ projects demonstrate its practicality.","标准应用安全测试(SAST)工具对于软件质量至关重要,可以确定早期开发中的潜在代码问题。 但是,这些工具往往产生虚假的正面警告,需要手工审查,减缓开发速度。 因此,假正缓解(FPM)的自动化至关重要。 大语言模型(LLM)的出现,具有很强的自然语言和代码理解能力,为FPM提供了充满希望的渠道。然而,目前以LLLMM为基础的FPM方法面临两大限制:1. 提取的与警告相关的代码片段过于宽泛,并且与不相关的控制/数据流密质;2. 关键代码环境缺失,导致出现不完全的表达,可以误导LMM0,导致评估不准确。为了克服这些限制,我们建议LM4FM,一个轻度和高效的虚假缓解框架。它有 eCPG-Sliceraleral, 以扩展的代码属性图(eCPG) 以获取准确的线级代码背景背景背景背景背景环境环境。此外, RalF2 综合的算法将建立一个与直径直径直径直径直径直径直径直径直径直径直径直径直径直径直径直径直径直径直径直径直径直的参考参考参考参考参考参考参考参考参考图。","Jinbao Chen, Hongjing Xiang, Zuohong Zhao, Luhao Li, Yu Zhang, Boyao Ding, Qingwei Li, Songyuan Xiong",2025-05-31T15:52:17Z,Utilizing Precise and Complete Code Context to Guide LLM in Automatic   False Positive Mitigation,"Verwendung präziser und vollständiger Code-Kontext, um LLM in automatischer falscher positiver Milderung zu führen",自动反向积极缓减法LLM指南使用精确和完整的守则背景,http://arxiv.org/abs/2411.03079v2
116,"Recently, LLM agents have made rapid progress in improving their programming capabilities. However, existing benchmarks lack the ability to automatically evaluate from users' perspective, and also lack the explainability of the results of LLM agents' code generation capabilities. Thus, we introduce ProjectEval, a new benchmark for LLM agents project-level code generation's automated evaluation by simulating user interaction. ProjectEval is constructed by LLM with human reviewing. It has three different level inputs of natural languages or code skeletons. ProjectEval can evaluate the generated projects by user interaction simulation for execution, and by code similarity through existing objective indicators. Through ProjectEval, we find that systematic engineering project code, overall understanding of the project and comprehensive analysis capability are the keys for LLM agents to achieve practical projects. Our findings and benchmark provide valuable insights for developing more effective programming agents that can be deployed in future real-world production.","最近,LLM代理商在提高方案拟订能力方面取得了迅速的进展,然而,现有的基准缺乏从用户角度自动评价LLM代理商代码生成能力的能力,也缺乏对LLM代理商代码生成能力结果的解释性,因此,我们引入了ProjectEval,这是LLM代理商项目级代码生成通过模拟用户互动互动进行自动评估的新基准;项目Eval由LLM公司通过人文审查来构建;项目Eval有三种不同层次的自然语言或代码骨架投入;项目Eval可以评价用户互动模拟执行项目产生的项目,而代码通过现有客观指标具有相似性;通过ProjectEval,我们发现系统化工程项目代码、项目的总体理解和全面分析能力是LLM代理商实现实用项目的关键;我们的调查结果和基准为开发更有效的编程代理商提供了宝贵的洞察力,可用于未来的现实世界生产。","Kaiyuan Liu, Youcheng Pan, Yang Xiang, Daojing He, Jing Li, Yexing Du, Tianrun Gao",2025-05-31T12:53:50Z,ProjectEval: A Benchmark for Programming Agents Automated Evaluation on   Project-Level Code Generation,ProjectEval: Ein Benchmark für die automatisierte Evaluierung von Programmierern auf Projektebene,项目Val:方案拟订代理器基准项目一级代码生成自动评价,http://arxiv.org/abs/2503.07010v2
117,"State-of-the-art large language models (LLMs) have demonstrated impressive code generation capabilities but struggle with real-world software engineering tasks, such as revising source code to address code reviews, hindering their practical use. Code review comments are often implicit, ambiguous, and colloquial, requiring models to grasp both code and human intent. This challenge calls for evaluating large language models' ability to bridge both technical and conversational contexts. While existing work has employed the automated code refinement (ACR) task to resolve these comments, current evaluation methods fall short, relying on text matching metrics that provide limited insight into model failures and remain susceptible to training data contamination. To address these limitations, we introduce a novel evaluation benchmark, $\textbf{CodeReviewQA}$ that enables us to conduct fine-grained assessment of model capabilities and mitigate data contamination risks. In CodeReviewQA, we decompose the generation task of code refinement into $\textbf{three essential reasoning steps}$: $\textit{change type recognition}$ (CTR), $\textit{change localisation}$ (CL), and $\textit{solution identification}$ (SI). Each step is reformulated as multiple-choice questions with varied difficulty levels, enabling precise assessment of model capabilities, while mitigating data contamination risks. Our comprehensive evaluation spans 72 recently released large language models on $\textbf{900 manually curated, high-quality examples}$ across nine programming languages. Our results show that CodeReviewQA is able to expose specific model weaknesses in code review comprehension, disentangled from their generative automated code refinement results.","最先进的大型语言模型(LLMS)已经表现出了令人印象深刻的代码生成能力,但与现实世界软件工程任务(例如修订源代码,以解决代码审查问题,阻碍其实际使用)纠缠不休,例如修订源代码,以应对代码审查,阻碍其实际使用。代码审查评论往往含蓄、含混和有余的,要求模型掌握代码和人的意图。这一挑战要求评估大型语言模型在技术和对话背景下的沟通能力。虽然现有工作采用了自动代码改进任务来解决这些意见,但目前的评估方法却落后于此,依靠文本匹配能够对模型失败提供有限洞察力并仍然容易受到数据污染的参数。为了应对这些限制,我们引入了一个新的评估基准,$\ textb{CodectionQ} ,让我们能够对模型能力进行精细评估并减轻数据污染风险。 在代码审查中,我们将生成的代码改进任务分为 $\ textb{3个基本推理法步骤 $: $fletter{Cread lex reflex recoal reduction ex real real deal ex reviewate ex ex dal ex dal disal disal disal ex lex lex lex lex ex ex ex legal dislational dislations legal d legal legal legal legal ex legal lexxxx legal lexxxxxxxx ex legild lection lection.","Hong Yi Lin, Chunhua Liu, Haoyu Gao, Patanamon Thongtanunam, Christoph Treude",2025-05-31T12:26:00Z,CodeReviewQA: The Code Review Comprehension Assessment for Large   Language Models,CodeReviewQA: Das CodeReview-Verständnis für große Sprachmodelle,守则审查QA:对大语言模式的守则审查理解评估,http://arxiv.org/abs/2503.16167v2
118,"Quality assurance of web applications is critical, as web applications play an essential role in people's daily lives. To reduce labor costs, automated web GUI testing (AWGT) is widely adopted, exploring web applications via GUI actions such as clicks and text inputs. However, these approaches face limitations in generating continuous and meaningful action sequences capable of covering complex functionalities. Recent work incorporates large language models (LLMs) for GUI testing. However, these approaches face various challenges, including low efficiency of LLMs, high complexity of rich web application contexts, and a low success rate of LLMs in executing GUI tasks.   To address these challenges, in this paper, we propose Temac, an approach that enhances AWGT using LLM-based multi-agent collaboration to increase code coverage. Temac is motivated by our insight that LLMs can enhance AWGT in executing complex functionalities, while the information discovered during AWGT can, in turn, be provided as the domain knowledge to improve the LLM-based task execution. Specifically, given a web application, Temac initially runs an existing approach to broadly explore application states. When the testing coverage stagnates, Temac then employs LLM-based agents to summarize the collected information to form a knowledge base and to infer not-covered functionalities. Guided by this knowledge base, Temac finally uses specialized LLM-based agents to target and execute the not-covered functionalities, reaching deeper states beyond those explored by the existing approach.   Our evaluation results show that Temac exceeds state-of-the-art approaches from 12.5% to 60.3% on average code coverage on six complex open-source web applications, while revealing 445 unique failures in the top 20 real-world web applications. These results strongly demonstrate the effectiveness and the general applicability of Temac.","网络应用程序的质量保证至关重要,因为网络应用程序在人们日常生活中发挥着必不可少的作用。为了降低劳动力成本,自动化网络界面测试(AWGT)被广泛采用,通过用户和文本投入等用户界面行动探索网络应用程序。然而,这些方法在生成能够覆盖复杂功能的连续和有意义的行动序列方面面临局限性。最近的工作包括了用于用户界面测试的大型语言模型(LLMS)。然而,这些方法面临着各种挑战,包括LLMS效率低、丰富的网络应用程序环境高度复杂以及LLMM公司执行GUI任务的成功率低。为了应对这些挑战,我们在本文件中建议Temac公司采用一种方法,利用基于LMM的多剂合作来增强用户界面应用网络应用程序。Temac公司认为LMSLM公司可以在实施复杂功能方面增强ACTT的连续和有意义的行动序列。这些在互联网应用程序上,Temacal-acal应用在测试范围上,Temacal-lical3号应用中,最终通过Slofal-lical-lictorsal-listrual listrationseral 将Supserviews","Chenxu Liu, Zhiyu Gu, Guoquan Wu, Ying Zhang, Jun Wei, Tao Xie",2025-05-31T11:43:37Z,Temac: Multi-Agent Collaboration for Automated Web GUI Testing,Temac: Multi-Agenten-Kollaboration für automatisierte Web-GUI-Tests,Temac:自动化网络用户界面测试多机构协作,http://arxiv.org/abs/2506.00520v1
119,"Detecting tricky bugs in plausible programs, those that pass existing test suites yet still contain bugs, remains a significant challenge in software testing. To address this problem, we propose TrickCatcher, an LLM-powered approach to generating test cases for uncovering bugs in plausible programs. TrickCatcher operates in three stages: First, it uses an LLM to generate program variants based on the program under test (PUT) and its specification. Second, it employs an LLM to construct an input generator from the specification for producing test inputs. Finally, these inputs are executed on both the PUT and its program variants to detect inconsistencies in their outputs. We evaluate TrickCatcher on two datasets, TrickyBugs and EvalPlus, which include 366 human-written and 151 AI-generated plausible programs with tricky bugs. TrickCatcher achieves recall, precision, and F1 scores that are 1.80x, 2.65x, and 1.66x those of the state-of-the-art baselines, respectively. Code and data used are available at https://github.com/RinCloud/TrickCatcher.","在可信的程序中,那些通过现有测试套房但仍含有错误的棘手错误,在软件测试中检测到的棘手错误仍然是一项重大挑战。为了解决这个问题,我们建议使用TrickCatcher(TrickCatcher),这是一个由LLM(LLM)驱动的方法来生成在可信的程序中发现错误的测试案例。TrickCatcher分三个阶段运作:首先,它使用LLM(LLM)来生成基于测试中的程序及其规格(PUT)及其规格的软件变异程序(PUT及其程序变异软件)来构建一个输入生成器。最后,这些输入器是在PUT(T)及其变异软件上执行的,以检测输出中的不一致之处。我们评估两个数据集的 TrickCatcher( TrickyBugs)和EvalPlus(EvalPlus)的 TrickCer(TryCatcher),其中包括366个人工写和151个人工生成的有棘手错误的可信程序。 TrickCatcher(TRacks)的回顾、精确和F1分数分别为1.80x(2.65xx)和1.6x(State-the)和1.6x-fir),分别。代码和数据都可在http://github.com/RinClacker中提供。代码和数据。","Kaibo Liu, Zhenpeng Chen, Yiyang Liu, Jie M. Zhang, Mark Harman, Yudong Han, Yun Ma, Yihong Dong, Ge Li, Gang Huang",2025-05-31T10:23:39Z,LLM-Powered Test Case Generation for Detecting Bugs in Plausible   Programs,LLM-Powered Test Case Generation zur Erkennung von Fehlern in Plausiblen Programmen,LLM 授权测试生成用于在可视程序中检测臭虫的LLM 测试案例,http://arxiv.org/abs/2404.10304v2
120,"LLM generated code often contains security issues. We address two key challenges in improving secure code generation. First, obtaining high quality training data covering a broad set of security issues is critical. To address this, we introduce a method for distilling a preference dataset of insecure and secure code pairs from frontier LLMs, along with a security reasoning that explains the issues and the fix. The key idea here is to make use of security knowledge sources to devise a systematic prompting strategy that ensures broad coverage. Second, aligning models to secure code requires focusing on localized regions of code. Direct preference optimization methods, like SimPO, are not designed to handle these localized differences and turn out to be ineffective. We address this with a new localized preference optimization algorithm that masks the security related tokens in both the winning (secure) and losing (insecure) responses. To prevent loss in code quality, we also add a regularizer. Evaluations show that both training on our dataset, DiSCo, and the new preference optimization algorithm, LPO, yield substantial reductions in code insecurity while also improving overall code quality. Code and dataset are available at https://github.com/StonyBrookNLP/disco-lpo.","LLM 生成的代码往往包含安全问题。 我们处理的是改善安全代码生成方面的两大挑战。 首先, 获得涵盖广泛安全问题的高质量培训数据至关重要。 为了解决这个问题, 我们引入了一种方法, 将边境LLM 的不安全和安全代码配对的偏好数据集从边境LLM 中蒸馏出来, 以及解释问题和修正的安全推理。 这里的关键想法是利用安全知识源来设计系统化的提示战略, 以确保覆盖广泛的范围。 其次, 统一安全代码模式需要关注本地代码区域。 直接偏好优化方法, 如 SimPO , 不是为了处理这些本地差异, 最终变得无效。 我们用一种新的本地偏好优化算法解决这个问题, 既保护中标( 安全) 也保护( 不安全) 对应的安全符号。 为了防止代码质量损失, 我们还增加了一个常规化工具。 评价显示, 有关我们的数据集、 Disco 和新的偏好优化算法( LPO ) 的两种培训, 都会大幅降低代码不安全性, 同时改善总体代码质量。 代码和数据设置可在 https://githhunyuyNcolyNLLDisl.","Mohammad Saqib, Saikat Chakraborty, Santu Karmaker, Niranjan Balasubramanian",2025-05-31T06:48:12Z,Teaching an Old LLM Secure Coding: Localized Preference Optimization on   Distilled Preferences,Ein altes LLM Secure Coding lehren: Lokalisierte Preference-Optimierung auf destillierten Preferences,教授旧的LLM 安全编码: 当地化的优惠优惠优化,http://arxiv.org/abs/2506.00419v1
121,"Static analysis plays a crucial role in software vulnerability detection, yet faces a persistent precision-scalability tradeoff. In large codebases like the Linux kernel, traditional static analysis tools often generate excessive false positives due to simplified vulnerability modeling and overapproximation of path and data constraints. While large language models (LLMs) demonstrate promising code understanding capabilities, their direct application to program analysis remains unreliable due to inherent reasoning limitations.   We introduce BugLens, a post-refinement framework that significantly enhances static analysis precision for bug detection. BugLens guides LLMs through structured reasoning steps to assess security impact and validate constraints from the source code. When evaluated on Linux kernel taint-style bugs detected by static analysis tools, BugLens improves precision approximately 7-fold (from 0.10 to 0.72), substantially reducing false positives while uncovering four previously unreported vulnerabilities. Our results demonstrate that a well-structured, fully automated LLM-based workflow can effectively complement and enhance traditional static analysis techniques.","常规静态分析工具在Linux内核等大型代码库中,由于简化脆弱性模型的简化和对路径和数据限制的过度理解,往往产生过度的假正数。虽然大型语言模型(LLMS)显示了有希望的代码理解能力,但由于固有的推理限制,其对程序分析的直接应用仍然不可靠。我们引入了BugLens,即一个大大提高对错误检测的静态分析精确度的改进后框架。BugLens通过结构化推理步骤引导LLMS通过结构化推理步骤评估安全影响和验证源代码的制约。在对静态分析工具检测到的Linux内核型内脏虫进行评价时,BugLens提高了精度约7倍(从0.10到0.72),在发现四个先前未报告的弱点的同时,大量减少假正数。我们的结果表明,一个结构完善、完全自动化的LM工作流程可以有效补充和加强传统的静态分析技术。","Haonan Li, Hang Zhang, Kexin Pei, Zhiyun Qian",2025-05-31T06:47:58Z,"The Hitchhiker's Guide to Program Analysis, Part II: Deep Thoughts by   LLMs","Der Hitchhiker's Guide to Program Analysis, Teil II: Deep Thoughts by LLMs","Hitchhiker方案分析指南,第二部分:LLM女士的深刻想法",http://arxiv.org/abs/2504.11711v3
122,"Developing high-performance software is a complex task that requires specialized expertise. We introduce GSO, a benchmark for evaluating language models' capabilities in developing high-performance software. We develop an automated pipeline that generates and executes performance tests to analyze repository commit histories to identify 102 challenging optimization tasks across 10 codebases, spanning diverse domains and programming languages. An agent is provided with a codebase and performance test as a precise specification, and tasked to improve the runtime efficiency, which is measured against the expert developer optimization. Our quantitative evaluation reveals that leading SWE-Agents struggle significantly, achieving less than 5% success rate, with limited improvements even with inference-time scaling. Our qualitative analysis identifies key failure modes, including difficulties with low-level languages, practicing lazy optimization strategies, and challenges in accurately localizing bottlenecks. We release the code and artifacts of our benchmark along with agent trajectories to enable future research.","开发高性能软件是一项复杂的任务,需要专门知识。我们引入了GSO,这是评价语言模型开发高性能软件能力的基准。我们开发了一个自动管道,生成和执行绩效测试,以分析存储库,承诺历史查明10个代码库的102项挑战性优化任务,涵盖不同的领域和编程语言。向代理商提供了一个代码库和性能测试,作为精确的规格,并负责提高运行时间效率,以专家开发师的优化为衡量标准。我们的定量评估显示,领先的SWE-Agency 进行了巨大的斗争,取得了不到5%的成功率,即便在推论时间上也有有限的改进。我们的质量分析确定了关键的失败模式,包括使用低度语言的困难、采用懒惰性优化战略,以及在准确定位瓶颈方面存在的挑战。我们发布了基准的代码和工艺以及代理轨迹,以利今后的研究。","Manish Shetty, Naman Jain, Jinjian Liu, Vijay Kethanaboyina, Koushik Sen, Ion Stoica",2025-05-31T01:53:06Z,GSO: Challenging Software Optimization Tasks for Evaluating SWE-Agents,GSO: Herausfordernde Software-Optimierungsaufgaben zur Bewertung von SWE-Agenten,GSO:评估SWE-Agentics的有挑战的软件优化任务,http://arxiv.org/abs/2505.23671v2
123,"Reinforcement learning (RL) to improve code review comment generation requires handling unstructured outputs, making reinforcement learning (RL) feedback challenging. The two main RL approaches, namely RL with Verifiable Feedback (RLVR) and RL with AI Feedback (RLAIF), offer trade-offs: RLVR provides reliable feedback for structured tasks like code generation, while RLAIF works for unstructured outputs but is subjective. We bridge this gap with CRScore++, an RL framework that leverages both LLM-based subjective feedback and verifiable signals for training. Extending CRScore, a code review evaluation metric integrating LLMs with verifiers like linters and code smell detectors, CRScore++ transforms these signals into training rewards. We show that CRScore++ improves a weaker student model through a combination of supervised fine-tuning and RL critique from a stronger teacher model, thus enabling generalization to novel programming languages.","加强学习(RL)以改善代码审查评论生成,要求处理非结构化产出,使强化学习(RL)反馈具有挑战性。两个主要的RL(RL)方法,即用可核查反馈(RLVR)的RL(RLVR)和用AI反馈(RLAIF)的RL(RL)提供权衡:RLV(RLV)为代码生成等结构化任务提供可靠的反馈,而RLAIF(RL(RLIF)则为非结构化产出工作,但具有主观性。我们缩小了与CRScore++(CRScore+)的这一差距,这是利用基于LLM的主观反馈和可核查的培训信号。扩展CRScore(CRScore)的代码审查评价指标,将LLMs与诸如Linters和代码嗅觉探测器等验证器相结合,CRScenter++(CRS++)将这些信号转化为培训奖励。我们表明,CRSTRC++(C+)将监管的微调和RL(RL)组合从更强的教师模型中改进学生模式改进了较弱的模型,从而使得通用编程语言。","Manav Nitin Kapadnis, Atharva Naik, Carolyn Rose",2025-05-30T22:58:35Z,CRScore++: Reinforcement Learning with Verifiable Tool and AI Feedback   for Code Review,CRScore++: Verstärktes Lernen mit überprüfbarem Tool und KI Feedback für Code Review,"CRSCore++:用可核查工具和AI反馈加强学习,供守则审查",http://arxiv.org/abs/2506.00296v1
124,"In online auctions, fraudulent behaviors such as shill bidding pose significant risks. This paper presents a conceptual framework that applies dynamic, behavior-based penalties to deter auction fraud using blockchain smart contracts. Unlike traditional post-auction detection methods, this approach prevents manipulation in real-time by introducing an economic disincentive system where penalty severity scales with suspicious bidding patterns. The framework employs the proposed Bid Shill Score (BSS) to evaluate nine distinct bidding behaviors, dynamically adjusting the penalty fees to make fraudulent activity financially unaffordable while providing fair competition.   The system is implemented within a decentralized English auction on the Ethereum blockchain, demonstrating how smart contracts enforce transparent auction rules without trusted intermediaries. Simulations confirm the effectiveness of the proposed model: the dynamic penalty mechanism reduces the profitability of shill bidding while keeping penalties low for honest bidders. Performance evaluation shows that the system introduces only moderate gas and latency overhead, keeping transaction costs and response times within practical bounds for real-world use. The approach provides a practical method for behaviour-based fraud prevention in decentralised systems where trust cannot be assumed.","在网上拍卖中,低价竞标等欺诈行为构成了重大风险。本文件提出了一个概念框架,运用动态的、基于行为的处罚来阻止使用轮链智能合同的拍卖欺诈。与传统的拍卖后检测方法不同,这一方法通过采用经济抑制制度防止实时操纵,因为经济抑制制度采用可疑投标模式的处罚严厉程度。这个框架采用拟议的Bid Shill评分(BSS)来评价九种不同的投标行为,动态调整罚款,使欺诈活动在财务上负担不起,同时提供公平竞争。这个系统是在Etheum连锁店的分散式英国拍卖中实施的,它展示了智能合同如何在没有信任的中介机构的情况下执行透明的拍卖规则。模拟确认了拟议模式的有效性:动态处罚机制降低了低价竞标的利润,同时对诚实投标人保持低廉的处罚。绩效评估表明,这个系统只引入中度的气体和低温管理,将交易成本和应对时间保持在现实世界使用的实际界限内。该方法为无法假定信任的分散系统中基于行为的欺诈预防提供了实用方法。","M. A. Bouaicha, G. Destefanis, T. Montanaro, N. Lasla, L. Patrono",2025-05-30T22:23:29Z,Shill Bidding Prevention in Decentralized Auctions Using Smart Contracts,Shill Biding Prevention in dezentralisierten Auktionen mit Smart Contracts,在使用智能合同的分散拍卖中防止电动竞拍,http://arxiv.org/abs/2506.00282v1
125,"A brief, fluent, and relevant summary can be helpful during program comprehension; however, such a summary does require significant human effort to produce. Often, good summaries are unavailable in software projects, which makes maintenance more difficult. There has been a considerable body of research into automated AI-based methods, using Large Language models (LLMs), to generate summaries of code; there also has been quite a bit of work on ways to measure the performance of such summarization methods, with special attention paid to how closely these AI-generated summaries resemble a summary a human might have produced. Measures such as BERTScore and BLEU have been suggested and evaluated with human-subject studies.   However, LLM-generated summaries can be inaccurate, incomplete, etc.: generally, too dissimilar to one that a good developer might write. Given an LLM-generated code summary, how can a user rationally judge if a summary is sufficiently good and reliable? Given just some input source code, and an LLM-generated summary, existing approaches can help judge brevity, fluency and relevance of the summary; however, it's difficult to gauge whether an LLM-generated summary sufficiently resembles what a human might produce, without a ""golden"" human-produced summary to compare against. We study this resemblance question as calibration problem: given just the code & the summary from an LLM, can we compute a confidence measure, that provides a reliable indication of whether the summary sufficiently resembles what a human would have produced in this situation? We examine this question using several LLMs, for several languages, and in several different settings. Our investigation suggests approaches to provide reliable predictions of the likelihood that an LLM-generated summary would sufficiently resemble a summary a human might write for the same code.","简单、流利和相关的摘要在程序理解期间会有帮助; 但是,这样的摘要确实需要大量的人力努力才能制作。 软件项目往往缺乏良好的摘要,使得维护更加困难。 已经对基于自动化的AI型方法进行了大量研究,使用大语言模型(LLMS)生成代码摘要; 在如何测量这种汇总方法的性能方面也做了大量工作; 特别注意这些AI型摘要与人可能编写的摘要的近似程度。 BERTScore 和 BLEU 等措施已经通过人文研究得到建议和评估。 然而, LLM 生成的摘要可能不准确、不完全不准确等等: 一般来说,与一个良好的开发者可能写的代码太不相近。 鉴于LM 代码的生成,用户如何理性地判断这种摘要是否足够好和可靠? 仅仅由于一些输入源代码,LLMM 生成的概要可以帮助判断该摘要的简洁性、流利度和相关性; 然而,很难用人文摘要来判断这种精确性,我们很难判断这种直观的准确性,我们能否用这种直观来比较一个人类的直观。 我们的直观和直观的直观研究可能会从一个问题。","Yuvraj Virk, Premkumar Devanbu, Toufique Ahmed",2025-05-30T21:55:33Z,Calibration of Large Language Models on Code Summarization,Kalibrierung von großen Sprachmodellen zur Code-Zusammenfassung,校准关于代码汇总的大语言模型,http://arxiv.org/abs/2404.19318v3
126,"Fill-in-the-Middle (FIM) is a common pretraining method for code LLMs, where models complete code segments given surrounding context. However, existing LLMs treat code as plain text and mask random character spans. We propose and evaluate AST-FIM, a pretraining strategy that leverages Abstract Syntax Trees (ASTs) to mask complete syntactic structures at scale, ensuring coherent training examples better aligned with universal code structures and common code editing patterns such as blocks, expressions, or functions. To evaluate real-world fill-in-the-middle (FIM) programming tasks, we introduce Real-FIM-Eval, a benchmark derived from 30,000+ GitHub commits across 12 languages. On infilling tasks, experiments on 1B and 8B parameter models show that AST-FIM is particularly beneficial for real-world code editing as it outperforms standard random-character FIM by up to 5 pts on standard FIM benchmarks. Our code is publicly available at https://github.com/gonglinyuan/ast_fim.","填入中枢(FIM)是法规LLM(Cill-in-Middle)的一种常见的预培训方法,模型在周围环境中完成代码的代码部分。然而,现有的LIMs将代码作为纯文本和掩码随机字符间隔处理。我们建议并评估AST-FIM(AST-FIM),这是一个预培训战略,利用Simist 语法树(AST-FIM)来大规模掩盖完整的合成结构,确保连贯的培训范例与通用代码结构和通用代码编辑模式(例如块、表达式或功能)更加一致。为了评估真实世界的中枢(FIM)编程任务,我们引入了Real-FIM-Eval(从30,000+GitHub中得出的一个基准跨越12种语言。关于完成任务、1B和8B参数模型的实验表明,AST-FIM(FIM)特别有利于现实世界代码的编辑,因为它在标准FIM基准上超过标准的随机字符缩图,最多达5pts。我们的代码可在https://github.com/ggganglyniuan/ast_fimm上公开查阅。","Linyuan Gong, Alvin Cheung, Mostafa Elhoushi, Sida Wang",2025-05-30T20:19:39Z,Structure-Aware Fill-in-the-Middle Pretraining for Code,Structure-Aware-Fill-in-the-Middle-Vorschulung für Code,代码结构软件填入中中预科培训,http://arxiv.org/abs/2506.00204v1
127,"Architecture evaluation methods have long been used to evaluate software designs. Several evaluation methods have been proposed and used to analyze tradeoffs between different quality attributes. Having competing qualities leads to conflicts for selecting which quality-attribute scenarios are the most suitable ones that an architecture should tackle and for prioritizing the scenarios required by the stakeholders. In this context, architecture evaluation is carried out manually, often involving long brainstorming sessions to decide which are the most adequate quality scenarios. To reduce this effort and make the assessment and selection of scenarios more efficient, we suggest the usage of LLMs to partially automate evaluation activities. As a first step to validate this hypothesis, this work studies MS Copilot as an LLM tool to analyze quality scenarios suggested by students in a software architecture course and compares the students' results with the assessment provided by the LLM. Our initial study reveals that the LLM produces in most cases better and more accurate results regarding the risks, sensitivity points and tradeoff analysis of the quality scenarios. Overall, the use of generative AI has the potential to partially automate and support the architecture evaluation tasks, improving the human decision-making process.","长期以来,一直在使用建筑评估方法来评价软件设计; 提出了几种评价方法,并用来分析不同质量属性之间的取舍; 具有相互竞争的品质导致在选择哪些质量属性假设情景方面出现冲突,哪些质量属性假设情景是建筑应处理的最合适情景,哪些是利害关系方所要求的情景优先; 在这方面,建筑评估是手工进行的,往往需要长时间集思广益,以决定哪些是最适当的质量假设情景; 为了减少这种努力,使评估和选择假设情景更有效率,我们建议使用LLLMS进行部分自动化评估活动; 作为验证这一假设的第一步,本工作研究将MS Copilot作为一种LOM工具,用于分析软件架构课程中学生建议的质量假设情景,并将学生的结果与LLM提供的评估进行比较。 我们的初步研究表明,LMM在大多数情况下,LM在质量假设情景的风险、敏感点和权衡分析方面产生更好和更准确的结果。 总体而言,使用GNAI有可能部分自动化,支持结构评估任务,改进人类决策过程。","Rafael Capilla, J. Andrés Díaz-Pace, Yamid Ramírez, Jennifer Pérez, Vanessa Rodríguez-Horcajo",2025-05-30T18:42:12Z,Supporting architecture evaluation for ATAM scenarios with LLMs,Unterstützung der Architekturauswertung für ATAM-Szenarien mit LLMs,利用LLMML对ATAM设想情况进行支持性结构评价,http://arxiv.org/abs/2506.00150v1
128,"Context: Diversity can impact team communication, productivity, cohesiveness, and creativity. Analyzing the existing knowledge about diversity in open source software (OSS) projects can provide directions for future research and raise awareness about barriers and biases against underrepresented groups in OSS. Objective: This study aims to analyze the knowledge about minority groups in OSS projects. We investigated which groups were studied in the OSS literature, the study methods used, their implications, and their recommendations to promote the inclusion of minority groups in OSS projects. Method: To achieve this goal, we performed a systematic literature review study that analyzed 42 papers that directly study underrepresented groups in OSS projects. Results: Most papers focus on gender (62.3%), while others like age or ethnicity are rarely studied. The neurodiversity dimension, have not been studied in the context of OSS. Our results also reveal that diversity in OSS projects faces several barriers but brings significant benefits, such as promoting safe and welcoming environments. Conclusion: Most analyzed papers adopt a myopic perspective that sees gender as strictly binary. Dimensions of diversity that affect how individuals interact and function in an OSS project, such as age, tenure, and ethnicity, have received very little attention.","目标:本研究旨在分析开放源码软件项目中少数群体的知识;我们调查了开放源码软件文献中研究哪些群体、所使用的研究方法、其影响及其促进将少数群体纳入开放源码软件项目的建议。 方法:为实现这一目标,我们开展了系统文献审查研究,分析了直接研究开放源码软件项目中代表性不足群体的42份文件。结果:大多数文件侧重于性别问题(62.3%),而诸如年龄或族裔等其他群体很少受到研究。神经多样性方面没有在开放源码软件项目中研究。我们的结果还表明开放源码软件项目的多样性面临若干障碍,但带来重大好处,例如促进安全和欢迎的环境。结论:多数分析文件采用了一种将性别视为纯粹二进制的近视观点。多样性的各个方面影响到个人在开放源码软件项目中的互动和功能,例如年龄、使用权和族裔。","Reydne Santos, Rafa Prado, Ana Paula de Holanda Silva, Kiev Gama, Fernando Castor, Ronnie de Souza Santos",2025-05-30T18:28:09Z,Understanding Underrepresented Groups in Open Source Software,Unterrepräsentierte Gruppen in Open Source Software verstehen,理解开放源码软件中代表不足的群体,http://arxiv.org/abs/2506.00142v1
129,"Effective prioritization of issue reports in software engineering helps to optimize resource allocation and information recovery. However, manual issue classification is laborious and lacks scalability. As an alternative, many open source software (OSS) projects employ automated processes for this task, yet this method often relies on large datasets for adequate training. Traditionally, machine learning techniques have been used for issue classification. More recently, large language models (LLMs) have emerged as powerful tools for addressing a range of software engineering challenges, including code and test generation, mapping new requirements to legacy software endpoints, and conducting code reviews. The following research investigates an automated approach to issue classification based on LLMs. By leveraging the capabilities of such models, we aim to develop a robust system for prioritizing issue reports, mitigating the necessity for extensive training data while also maintaining reliability in classification. In our research, we developed an LLM-based approach for accurately labeling issues by selecting two of the most prominent large language models. We then compared their performance across multiple datasets. Our findings show that GPT-4o achieved the best results in classifying issues from the NLBSE 2024 competition. Moreover, GPT-4o outperformed DeepSeek R1, achieving an F1 score 20% higher when both models were trained on the same dataset from the NLBSE 2023 competition, which was ten times larger than the NLBSE 2024 dataset. The fine-tuned GPT-4o model attained an average F1 score of 80.7%, while the fine-tuned DeepSeek R1 model achieved 59.33%. Increasing the dataset size did not improve the F1 score, reducing the dependence on massive datasets for building an efficient solution to issue classification.","在软件工程中有效确定问题报告的优先次序有助于优化资源分配和信息回收。然而,手工问题分类是困难的,缺乏可缩放性。作为替代办法,许多开放源码软件(OSS)项目为此任务采用自动化程序,但这种方法往往依赖大型数据集进行充分培训。传统上,机器学习技术被用于问题分类。最近,大型语言模型(LLMS)成为解决一系列软件工程挑战的强大工具,包括代码和测试生成、为遗留软件端点绘制新要求以及进行代码审查。以下研究调查了基于LLMS的自动分类方法。作为替代,许多开放源软件(OSS)项目采用自动化程序,为此任务采用了自动化程序,但这种方法往往依赖大型数据集。在我们的研究中,我们开发了一个基于LMM的准确标签方法,选择了两个最突出的大型语言模型。我们比较了它们跨多个数据库的绩效。 GPT-4serveyal SE 2024 高级SEVSE 竞争中的问题分类的最佳结果。我们的目标是,GPT-41 20-Sefer 平均数据比201 高,而经过培训的FSeal RSeal 201 的排名数据比201 的201 的排名都高。","Gabriel Aracena, Kyle Luster, Fabio Santos, Igor Steinmacher, Marco A. Gerosa",2025-05-30T18:02:55Z,Applying Large Language Models to Issue Classification: Revisiting with   Extended Data and New Models,Anwendung großer Sprachmodelle auf die Problemklassifikation: Neubetrachtung mit erweiterten Daten und neuen Modellen,应用大语言模式处理问题分类:与扩展数据和新模式重审,http://arxiv.org/abs/2506.00128v1
130,"While there has been plenty of work on generating tests from existing code, there has been limited work on generating tests from issues. A correct test must validate the code patch that resolves the issue. This paper focuses on the scenario where that code patch does not yet exist. Doing so supports two major use-cases. First, it supports TDD (test-driven development), the discipline of ""test first, write code later"" that has well-documented benefits for human software engineers. Second, it also validates SWE (software engineering) agents, which generate code patches for resolving issues. This paper introduces TDD-Bench-Verified, a benchmark for generating tests from issues, and Otter, an LLM-based solution for this task. Otter augments LLMs with rule-based analysis to check and repair their outputs, and introduces a novel self-reflective action planner. Experiments show Otter outperforming state-of-the-art systems for generating tests from issues, in addition to enhancing systems that generate patches from issues. We hope that Otter helps make developers more productive at resolving issues and leads to more robust, well-tested code.","虽然在从现有代码生成测试方面做了大量工作,但从问题产生测试的工作却有限。 正确的测试必须验证解决问题的代码补丁。 本文侧重于尚未存在代码补丁的情景。 本文侧重于尚未存在代码补丁的情景。 这样做支持两大使用案例。 首先, 它支持TDD( 测试驱动开发) , 即“ 先测试, 后写代码” 的学科, 这对于人类软件工程师具有记录良好的效益 。 其次, 它还验证SWE( 软件工程) 代理商, 从而生成解决问题的代码补丁。 本文介绍了 TDD- Bench- 验证, 这是生成问题测试的基准, 而 Otter( 以LLM为基础的解决方案) 则是用于这项工作的。 Otter通过基于规则的分析增强LM( LLMs) , 以检查和修理其产出, 并引入新的自我反射动行动计划程序。 实验显示Otter 超越了从问题产生测试的状态- 艺术系统, 以及增强从问题产生补补缺的系统 。 我们希望 Otter 能够使开发者在解决问题上更富有成效, 。 我们希望 Otter 。","Toufique Ahmed, Jatin Ganhotra, Rangeet Pan, Avraham Shinnar, Saurabh Sinha, Martin Hirzel",2025-05-30T17:25:04Z,Otter: Generating Tests from Issues to Validate SWE Patches,Otter: Generierung von Tests aus Problemen zur Validierung von SWE Patches,"Otter: 从问题生成测试, 以校验 SWE 补丁",http://arxiv.org/abs/2502.05368v2
131,"Web applications play a crucial role in our daily lives, making it essential to employ testing methods that ensure their quality. Typically, Web testing automation frameworks rely on locators to interact with the graphical user interface, acting as connection points to the elements on a Web page. Nevertheless, locators are widely recognized as a major vulnerability in Web testing, as they are highly sensitive to the frequent changes in Web page structures caused by rapid software evolution. The adoption of the Page Object pattern to separate test logic from structural layout - supporting code reuse and maintainability - has generally led to more robust test cases. However, their implementation is a manually intensive task, and even automated support may require manual realignment efforts. Although gamification strategies have recently been integrated into the Web testing process to boost user engagement, using tasks and rewards aligned with testing activities, they have not yet been employed to enhance the robustness of locators and support the implementation of Page Objects.   In this paper, we introduce TESTQUEST, a tool designed to improve test robustness by applying gamification to locators and Page Objects, boosting user engagement while guiding them toward the adoption of best practices.","网络应用程序在我们日常生活中发挥着关键作用,因此有必要使用测试方法确保其质量。通常,网络测试自动化框架依靠定位器与图形用户界面互动,作为网页内容的连接点。然而,在网络测试中,定位器被普遍认为是主要的脆弱性,因为它们对软件迅速演变导致的网页结构的频繁变化非常敏感。采用“页面对象”模式将测试逻辑与结构布局(支持代码再利用和可维护性)分开,通常导致更稳健的测试案例。然而,其实施是一项人工密集型任务,甚至自动支持可能需要人工调整。虽然最近已将拼写战略纳入网络测试进程,以促进用户的参与,使用与测试活动一致的任务和奖励,但尚未用于加强定位器的稳健性和支持页面对象的实施。在本文件中,我们引入了“TESTQUEST”这一工具,该工具旨在通过对定位器和“页面”应用精准来提高测试强度,同时促进用户的参与,同时指导他们采用最佳做法。","Dario Olianas, Diego Clerissi, Maurizio Leotta, Filippo Ricca",2025-05-30T16:18:10Z,TESTQUEST: A Web Gamification Tool to Improve Locators and Page Objects   Quality,TESTQUEST: Ein Web Gamification Tool zur Verbesserung der Sucher und Seitenobjekte Qualität,TSTSTQUEST:改进定位器和页面对象质量的网上游戏工具,http://arxiv.org/abs/2505.24756v1
132,"In today's digital society, personalization has become a crucial aspect of software applications, significantly impacting user experience and engagement. A new wave of intelligent user interfaces, such as AI-based conversational agents, has the potential to enable such personalization beyond what other types of interfaces could offer in the past. Personalization requires the ability to specify a complete user profile, covering as many dimensions as possible, such as potential accessibility constraints, interaction preferences, and even hobbies. In this sense, this paper presents the concepts of a unified user modeling language, aimed to combine previous approaches in a single proposal. Additionally, a proof of concept has been developed that leverages user profiles modeled using our language to automatically adapt a conversational agent.","在当今的数字化社会,个性化已成为软件应用的一个重要方面,极大地影响用户的经验和参与。 新的智能用户界面浪潮,如AI的谈话代理器,有可能使这种个性化超越其他类型的界面过去所能提供的范围。 个性化要求能够指定一个完整的用户概况,涵盖尽可能多的方面,例如可能的无障碍限制、互动偏好,甚至爱好。 从这个意义上讲,本文件介绍了统一用户模式语言的概念,目的是将以前的做法合并到一个单一的提案中。 此外,还开发了一种概念证明,利用我们语言模型的用户特征来自动调整一个对口代理器。","Aaron Conrardy, Alfredo Capozucca, Jordi Cabot",2025-05-30T15:20:15Z,Towards a unified user modeling language for engineering human centered   AI systems,Auf dem Weg zu einer einheitlichen Benutzer-Modelliersprache für das Engineering von menschlichen zentrierten KI-Systemen,争取为以人为中心的工程用人工智能系统统一用户建模语言,http://arxiv.org/abs/2505.24697v1
133,"Despite the utility that Generative AI (GenAI) tools provide for tasks such as writing code, the use of these tools raises important legal questions and potential risks, particularly those associated with copyright law. As lawmakers and regulators engage with those questions, the views of users can provide relevant perspectives. In this paper, we provide: (1) a survey of 574 developers on the licensing and copyright aspects of GenAI for coding, as well as follow-up interviews; (2) a snapshot of developers' views at a time when GenAI and perceptions of it are rapidly evolving; and (3) an analysis of developers' views, yielding insights and recommendations that can inform future regulatory decisions in this evolving field. Our results show the benefits developers derive from GenAI, how they view the use of AI-generated code as similar to using other existing code, the varied opinions they have on who should own or be compensated for such code, that they are concerned about data leakage via GenAI, and much more, providing organizations and policymakers with valuable insights into how the technology is being used and what concerns stakeholders would like to see addressed.","尽管创制的AI(GenAI)工具对诸如写法等任务很有用处,但使用这些工具会引起重要的法律问题和潜在风险,特别是与版权法相关的风险。当立法者和监管者参与这些问题时,用户的观点可以提供相关观点。在本文件中,我们提供了:(1) 对574名开发者进行关于GenAI的许可和版权方面的调查,以便进行编码,以及后续访谈;(2) 在GenAI迅速演变时,对开发者的观点及其看法进行简要描述;(3) 分析开发者的观点,提出见解和建议,为这个不断发展的领域的未来监管决定提供信息。我们的结果显示,开发者从GenAI获得的利益,他们如何认为AI生成的代码的使用类似于使用其他现有代码,他们对谁应该拥有或应当获得这种代码的补偿持有不同观点,他们关心通过GenAI获得的数据渗漏,而更多的是,为各组织和决策者提供宝贵的见解,说明技术是如何使用的,以及利益攸关方希望得到解决的关切问题。","Trevor Stalnaker, Nathan Wintersgill, Oscar Chaparro, Laura A. Heymann, Massimiliano Di Penta, Daniel M German, Denys Poshyvanyk",2025-05-30T14:54:38Z,Developer Perspectives on Licensing and Copyright Issues Arising from   Generative AI for Software Development,"Entwickler-Perspektiven zu Lizenzierungs- und Urheberrechtsfragen, die sich aus generativen KI für die Softwareentwicklung ergeben",开发者对软件开发创创大赦国际提出的许可证发放和版权问题的看法,http://arxiv.org/abs/2411.10877v4
134,"In recent years, large language models (LLMs) have showcased significant advancements in code generation. However, most evaluation benchmarks are primarily oriented towards Python, making it difficult to evaluate other programming languages, such as Swift, with high quality. By examining widely established multilingual benchmarks like HumanEval-XL and MultiPL-E, we identified critical issues specific to their Swift components, making them insufficient or even irrelevant for assessing LLM coding capabilities on Swift. Unlike these existing approaches, which prioritize rapid scaling and generalization by automatically translating Python-centric benchmarks with LLMs, we adopt a quality-over-quantity methodology. We present SwiftEval, the first Swift-oriented benchmark consisting of 28 carefully hand-crafted problems, and evaluate 44 popular Code LLMs on it. Our results show significant LLM scores drop for problems requiring language-specific features, most noticeable in the models of smaller sizes.","近年来,大型语言模型(LLMS)展示了在代码生成方面取得的重大进步,然而,大多数评价基准主要面向Python, 因而难以对诸如Swift等高品质的其他编程语言进行评价。我们通过审查诸如HumanEval-XL和MultiPL-E等广泛确立的多语种基准,发现了其Swift组成部分特有的关键问题,使其不足以或甚至与评估Swift的LLM编码能力无关。与这些现有方法不同,这些方法通过将Python中心基准与LLMs自动翻译为Python中心基准,将快速扩展和普及列为优先事项,我们采用了一种质量超量的方法。我们介绍了SwiftEval,这是第一个面向Swift的基准,由28个仔细的手工操作问题组成,并评价了44个通用代码LMs。我们的结果显示,LMM在需要语言特点的问题上成绩显著下降,最明显的是较小规模的模型。","Ivan Petrukha, Yana Kurliak, Nataliia Stulova",2025-05-30T08:06:30Z,SwiftEval: Developing a Language-Specific Benchmark for LLM-generated   Code Evaluation,SwiftEval: Entwicklung eines sprachspezifischen Benchmarks für die LLM-generierte Code-Bewertung,SwiftEval:为LLM产生的守则评价制定语言特定基准,http://arxiv.org/abs/2505.24324v1
135,"To alleviate difficulties in writing smart contracts for distributed blockchain applications, as other research, we propose transformation of Business Process Model and Notation (BPMN) models into blockchain smart contracts. Unlike other research, we use Discrete Event Hierarchical State Machine (DE-HSM) multi-modal modeling to identify collaborative trade transactions that need to be supported by the smart contract and describe how the trade transactions, that may be nested, are supported by a transaction mechanism. We describe algorithms to (i) identify the nested trade transactions and to (ii) transform the BPMN model into blockchains smart contracts that include a transaction mechanism to enforce the transactional properties for the identified trade transactions. The developed proof of concept shows that our approach to automated transformation of BPMN models into smart contracts with the support of privacy and cross-chain interoperability is feasible. The thesis examines and evaluates automatically generated alternative transaction mechanisms to support such transactions using three use cases of varying degree of complexity, namely order processing, supply chain management, and a multi-faceted trade use case. The research enriches the academic dialogue on blockchain technology and smart contracts and proposes potential avenues for future research.","为了减轻在为分布式连锁应用程序签订智能合同方面的困难,作为其他研究,我们提议将业务流程模型和批注(BPMN)模型转换成链式智能合同;与其他研究不同,我们采用分立事件高度国家机器(DE-HSM)多模式模型,以确定需要智能合同支持的合作贸易交易,并描述可能嵌套的贸易交易如何得到交易机制的支持;我们将算法描述为(一) 查明嵌套式贸易交易,和(二) 将BPMN模型转换成包括执行已查明贸易交易交易性质交易机制在内的链式智能合同;我们开发的概念证明表明,我们在隐私和跨链互操作性的支持下,将BPMN模型自动转换为智能合同是可行的;研究研究利用三个复杂程度不同的使用案例,即订单处理、供应链管理和多面贸易使用案例,对支持这类交易自动产生替代交易机制,以利支持此类交易;研究丰富了关于链式技术和智能合同的学术对话,并提出未来研究的潜在途径。",Christian Gang Liu,2025-05-30T07:47:06Z,Supporting Long-term Transactions in Smart Contracts Generated from   Business Process Model and Notation (BPMN) Models,"Unterstützung langfristiger Transaktionen in Smart Contracts, die aus Geschäftsmodellen und Notationsmodellen (BPMN) generiert werden",支持从业务流程模型和标记模型生成的智能合同的长期交易,http://arxiv.org/abs/2505.24309v1
136,"In the pursuit of enhancing software reusability and developer productivity, code search has emerged as a key area, aimed at retrieving code snippets relevant to functionalities based on natural language queries. Despite significant progress in self-supervised code pre-training utilizing the vast amount of code data in repositories, existing methods have primarily focused on leveraging contrastive learning to align natural language with function-level code snippets. These studies have overlooked the abundance of fine-grained (such as block-level and statement-level) code snippets prevalent within the function-level code snippets, which results in suboptimal performance across all levels of granularity. To address this problem, we first construct a multi-granularity code search dataset called MGCodeSearchNet, which contains 536K+ pairs of natural language and code snippets. Subsequently, we introduce a novel Multi-Granularity Self-Supervised contrastive learning code Search framework (MGS$^{3}$}). First, MGS$^{3}$ features a Hierarchical Multi-Granularity Representation module (HMGR), which leverages syntactic structural relationships for hierarchical representation and aggregates fine-grained information into coarser-grained representations. Then, during the contrastive learning phase, we endeavor to construct positive samples of the same granularity for fine-grained code, and introduce in-function negative samples for fine-grained code. Finally, we conduct extensive experiments on code search benchmarks across various granularities, demonstrating that the framework exhibits outstanding performance in code search tasks of multiple granularities. These experiments also showcase its model-agnostic nature and compatibility with existing pre-trained code representation models.","在努力提高软件可更新性和开发器生产率的过程中,代码搜索已成为一个关键领域,目的是重新获取与自然语言查询的功能相关的代码片断。尽管在利用存储库的大量代码数据进行自我监管的代码预培训方面取得了重大进展,但现有方法主要侧重于利用对比学习使自然语言与功能级代码片段相匹配。这些研究忽略了功能级基准代码片段中普遍存在的微粒(如块级和语句级)代码片断的丰富性能(如块级和语句级)代码片断,这导致所有颗粒级的功能的亚优性性能。为了解决这一问题,我们首先在使用一个名为MGCodeSearchNet(包含536K+的自然语言和代码片段)的多层代码搜索数据集前,我们引入了一个新型的反动读数模式代码搜索框架(MGS$3} 。首先,MGS$ 3 将精细度多层级模型的代码用于当前结构化的演示,在结构级级级代表性演示模块中, 将高级模型的代码用于当前系统级构建的演示中的行为。","Rui Li, Junfeng Kang, Qi Liu, Liyang He, Zheng Zhang, Yunhao Sha, Linbo Zhu, Zhenya Huang",2025-05-30T06:49:39Z,MGS3: A Multi-Granularity Self-Supervised Code Search Framework,MGS3: Ein selbstüberwachtes Multi-Granularitäts-Code-Such-Framework,MGS3:多种族自我监督守则搜索框架,http://arxiv.org/abs/2505.24274v1
137,"Scaling up executable code data is significant for improving language models' software engineering capability. The intricate nature of the process makes it labor-intensive, time-consuming and expert-knowledge-dependent to build a large number of executable code repositories, limiting the scalability of existing work based on running tests. The primary bottleneck lies in the automated building of test environments for different repositories, which is an essential yet underexplored task. To mitigate the gap, we introduce Repo2Run, the first LLM-based agent aiming at automating the building of executable test environments for any repositories at scale. Specifically, given a code repository, Repo2Run iteratively builds the Docker image, runs unit tests based on the feedback of the building, and synthesizes the Dockerfile until the entire pipeline is executed successfully. The resulting Dockerfile can then be used to create Docker container environments for running code and tests. We created a benchmark containing 420 Python repositories with unit tests for evaluation. The results illustrate that Repo2Run achieves an 86.0% success rate, outperforming SWE-agent by 77.0%. The resources of Repo2Run are available at https://github.com/bytedance/Repo2Run.","增强可执行代码数据对于提高语言模型的软件工程能力非常重要。 这一过程的复杂性性质使得它能够建立大量可执行代码库, 限制基于运行测试的现有工作的可缩放性。 主要的瓶颈在于为不同存储库自动建立测试环境, 这是一个基本但尚未探索的任务。 为了缩小差距, 我们引入了Repo2Run, 这是第一个基于LLLM的代理器, 旨在为任何规模的存储库自动建立可执行测试环境。 具体来说, 程序的复杂性、 耗时和专家- 知识- 依赖于建立大量可执行代码储存库, 以建立大量可执行代码储存库, 限制基于运行测试的现有工作的可缩放性。 主要的瓶颈在于为不同的存储库自动建立测试环境, 这是一项基本任务, 但它是尚未被探索的任务 。 我们创建了包含 420 Python 存储器的基准, 并进行单位测试。 结果表明, Repo2Run 将实现86.0%的成功率, 以77/ Rebbbbrebb 取代了 SW. 0 资源。","Ruida Hu, Chao Peng, Xinchen Wang, Junjielong Xu, Cuiyun Gao",2025-05-30T06:25:20Z,Repo2Run: Automated Building Executable Environment for Code Repository   at Scale,Repo2Run: Automatisiertes Gebäude ausführbare Umgebung für Code-Repository auf Scale,Repo2Run: 用于标准代码仓库的自动建设可执行环境,http://arxiv.org/abs/2502.13681v3
138,"Autonomous vehicles (AVs) have significantly advanced in real-world deployment in recent years, yet safety continues to be a critical barrier to widespread adoption. Traditional functional safety approaches, which primarily verify the reliability, robustness, and adequacy of AV hardware and software systems from a vehicle-centric perspective, do not sufficiently address the AV's broader interactions and behavioral impact on the surrounding traffic environment. To overcome this limitation, we propose a paradigm shift toward behavioral safety, a comprehensive approach focused on evaluating AV responses and interactions within traffic environment. To systematically assess behavioral safety, we introduce a third-party AV safety assessment framework comprising two complementary evaluation components: Driver Licensing Test and Driving Intelligence Test. The Driver Licensing Test evaluates AV's reactive behaviors under controlled scenarios, ensuring basic behavioral competency. In contrast, the Driving Intelligence Test assesses AV's interactive behaviors within naturalistic traffic conditions, quantifying the frequency of safety-critical events to deliver statistically meaningful safety metrics before large-scale deployment. We validated our proposed framework using \texttt{Autoware.Universe}, an open-source Level 4 AV, tested both in simulated environments and on the physical test track at the University of Michigan's Mcity Testing Facility. The results indicate that \texttt{Autoware.Universe} passed 6 out of 14 scenarios and exhibited a crash rate of 3.01e-3 crashes per mile, approximately 1,000 times higher than average human driver crash rate. During the tests, we also uncovered several unknown unsafe scenarios for \texttt{Autoware.Universe}. These findings underscore the necessity of behavioral safety evaluations for improving AV safety performance prior to widespread public deployment.","近年来,自主车辆(AVs)在现实世界部署方面取得了显著进步,但安全仍是广泛采用的关键障碍。传统的功能安全方法主要从以车辆为中心的角度验证AV硬件和软件系统的可靠性、稳健性和充分性,不足以解决AV对周围交通环境的广泛互动和行为影响。为克服这一限制,我们建议向行为安全转变模式,采取侧重于评价AV反应和交通环境互动的全面方法。为了系统评估行为安全,我们引入了第三方AV安全评估框架,包括两个相辅相成的评价组成部分:司机许可证测试和驾驶智能测试。司机许可证测试评估AV硬件和软件系统在控制情景下的反应行为,确保基本的行为能力。相比之下,Drivid Intell Intellital测试AV在自然交通条件下的互动行为,量化安全临界事件频率,以便在大规模部署之前提供具有统计意义的安全指标。我们用以下方法验证了我们提出的框架:更高度的AVSUFserformality AUtward。 Universal Aliversal oralalalal deal deskational destational expressorational destal lax laviews lax laxal lax lax laview.","Henry X. Liu, Xintao Yan, Haowei Sun, Tinghan Wang, Zhijie Qiao, Haojie Zhu, Shengyin Shen, Shuo Feng, Greg Stevens, Greg McGuire",2025-05-30T04:11:11Z,Behavioral Safety Assessment towards Large-scale Deployment of   Autonomous Vehicles,Bewertung der Verhaltenssicherheit im Hinblick auf die großmaßstäbliche Einführung autonomer Fahrzeuge,在大规模部署自治车辆方面进行行为安全评估,http://arxiv.org/abs/2505.16214v2
139,"The rapid evolution of large language models (LLMs) has opened new possibilities for automating various tasks in software development. This paper evaluates the capabilities of the Llama 2-70B model in automating these tasks for scientific applications written in commonly used programming languages. Using representative test problems, we assess the model's capacity to generate code, documentation, and unit tests, as well as its ability to translate existing code between commonly used programming languages. Our comprehensive analysis evaluates the compilation, runtime behavior, and correctness of the generated and translated code. Additionally, we assess the quality of automatically generated code, documentation and unit tests. Our results indicate that while Llama 2-70B frequently generates syntactically correct and functional code for simpler numerical tasks, it encounters substantial difficulties with more complex, parallelized, or distributed computations, requiring considerable manual corrections. We identify key limitations and suggest areas for future improvements to better leverage AI-driven automation in scientific computing workflows.","大型语言模型(LLMS)的迅速演变为软件开发中各种任务自动化开辟了新的可能性。本文评估了Llama 2-70B模型在将这些任务自动化用于以常用编程语言编写的科学应用方面的能力。我们利用代表性测试问题评估了该模型生成代码、文件和单位测试的能力,以及该模型在常用编程语言之间翻译现有代码的能力。我们的全面分析评估了生成和翻译代码的汇编、运行时间行为和正确性。此外,我们评估了自动生成代码、文档和单位测试的质量。我们的结果显示,Llama 2-70B经常生成简单数字任务的合成正确和功能代码,但遇到大量复杂、平行或分布的计算困难,需要大量人工校正。我们确定了关键限制,并提出了未来改进的领域,以更好地利用科学计算工作流程中由AI驱动的自动化。","Patrick Diehl, Nojoud Nader, Maxim Moraru, Steven R. Brandt",2025-05-30T02:20:31Z,LLM Benchmarking with LLaMA2: Evaluating Code Development Performance   Across Multiple Programming Languages,LLM Benchmarking mit LLaMA2: Bewertung der Code-Entwicklungsleistung über mehrere Programmiersprachen hinweg,LLM LLM 与LLamaMA2:评价多种方案编制语言发展守则的业绩,http://arxiv.org/abs/2503.19217v2
140,"Test cases are indispensable for conducting effective fault localization (FL). However, test cases in practice are severely class imbalanced, i.e. the number of failing test cases (i.e. minority class) is much less than that of passing ones (i.e. majority class). The severe class imbalance between failing and passing test cases have hindered the FL effectiveness.   To address this issue, we propose PCD-DAug: a Principal Context-aware Diffusion guided Data Augmentation approach that generate synthesized failing test cases for improving FL. PCD-DAug first combines program slicing with principal component analysis to construct a principal context that shows how a set of statements influences the faulty output via statistical program dependencies. Then, PCD-DAug devises a conditional diffusion model to learn from principle contexts for generating synthesized failing test cases and acquiring a class balanced dataset for FL. We conducted large-scale experiments on six state-of-the-art FL approaches and compare PCD-DAug with six data augmentation baselines. The results show that PCD-DAug significantly improves FL effectiveness, e.g. achieving average improvements of 383.83%, 227.08%, and 224.19% in six FL approaches under the metrics Top-1, Top-3, and Top-5, respectively.","然而,在实践中,测试案例严重分级不平衡,即失败的测试案例(即少数类)数量远远少于通过测试案例(即多数类)的数量。失败和通过测试案例之间的严重阶级不平衡妨碍了FL的有效性。为了解决这一问题,我们提议PCD-Daug:一种主要环境认知引导数据增强方法,该方法产生综合失败的测试案例,用于改进FL. PCD-Daug。 测试案例首先将方案分解与主要组成部分分析结合起来,以构建一个主要背景,表明一组声明如何通过统计方案依赖影响缺陷产出。然后,PCD-Daug设计了一个有条件的传播模式,从理论环境中学习如何生成综合失败案例,并为FL获取一个分类平衡的数据集。 我们对六种状态的FL方法进行了大规模实验,并将PCD-Daug与六个数据增强基线作了比较。结果显示,PCD-Daug与主要组成部分的切分级分析,以构建一个主要背景,表明一组声明如何通过统计方案依赖影响缺陷产出。随后,PCD-Daug-Daug设计了一种有条件的传播模式,以便从理论环境中学习如何生成综合失败测试测试案例,并为FL.83-1、Top 和Topal% 和Topalisx3,在2278-3下分别改进。","Shihao Fu, Yan Lei",2025-05-29T23:54:29Z,Principal Context-aware Diffusion Guided Data Augmentation for Fault   Localization,Wichtigste Context-aware Diffusion Geführte Daten Augmentation für Fehlerlokalisierung,因失事本地化而增加的数据,http://arxiv.org/abs/2505.24079v1
141,"We introduce SWE-Lancer, a benchmark of over 1,400 freelance software engineering tasks from Upwork, valued at \$1 million USD total in real-world payouts. SWE-Lancer encompasses both independent engineering tasks--ranging from \$50 bug fixes to \$32,000 feature implementations--and managerial tasks, where models choose between technical implementation proposals. Independent tasks are graded with end-to-end tests triple-verified by experienced software engineers, while managerial decisions are assessed against the choices of the original hired engineering managers. We evaluate model performance and find that frontier models are still unable to solve the majority of tasks. To facilitate future research, we open-source a unified Docker image and a public evaluation split, SWE-Lancer Diamond (https://github.com/openai/SWELancer-Benchmark). By mapping model performance to monetary value, we hope SWE-Lancer enables greater research into the economic impact of AI model development.","我们引入了SWE-Lancer,这是“Upwork”的1,400多项自由软件工程任务的基准,总价值为100万美元,实际支付额为100万美元;SWE-Lancer既包括独立的工程任务,从50美元错误修正到32 000美元特性执行和管理任务,其中模式在技术实施建议之间作出选择;独立任务的等级由经验丰富的软件工程师对端对端测试进行三级核查,而管理决定则根据最初聘用的工程经理的选择进行评估;我们评估模型业绩,发现前沿模型仍然无法解决大部分任务;为了便利未来的研究,我们打开一个统一的多克尔图像的源源码和公共评价分割,SWE-Lancer Diamond(https://github.com/openai/SWELancer-Benchnock),通过将模型的性能与货币价值挂钩,我们希望SWE-Lancer能够使对AI模型开发的经济影响进行更多的研究。","Samuel Miserendino, Michele Wang, Tejal Patwardhan, Johannes Heidecke",2025-05-29T23:07:34Z,SWE-Lancer: Can Frontier LLMs Earn $1 Million from Real-World Freelance   Software Engineering?,SWE-Lancer: Können Frontier LLMs von Real-World Freelance Software Engineering eine Million Dollar verdienen?,SWE-Lancer:边疆LLMS能否从现实世界自由软件工程中赚取100万美元?,http://arxiv.org/abs/2502.12115v4
142,"This paper provides an overview of how the determination of absence of unreasonable risk can be operationalized. It complements previous theoretical work published by existing developers of Automated Driving Systems (ADS) on the overall engineering practices and methodologies for readiness determination. Readiness determination is, at its core, a risk assessment process. It is aimed at evaluating the residual risk associated with a new deployment. The paper proposes methodological criteria to ground the readiness review process for an ADS release. While informed by Waymo's experience in this domain, the criteria presented are agnostic of any specific ADS technological solution and/or architectural choice, to support broad implementation by others in the industry. The paper continues with a discussion on governance and decision-making toward approval of a new release candidate for the ADS. The implementation of the presented criteria requires the existence of appropriate safety management practices in addition to many other cultural, procedural, and operational considerations. As such, the paper is concluded by a statement of limitations for those wishing to replicate part or all of its content.","本文件概述了如何确定不存在不合理风险的问题,补充了自动化驾驶系统现有开发商先前发表的关于总体工程做法和确定准备状态方法的理论工作; 准备程度的确定是风险评估程序的核心; 旨在评估与新部署有关的残余风险; 该文件提出方法标准,为自动驾驶系统释放的准备状态审查进程提供依据; 依据Waymo在这方面的经验, 所提出的标准是对任何特定自动驾驶系统技术解决方案和/或建筑选择的不可知性,以支持行业内其他人的广泛实施; 该文件继续讨论治理和决策问题,争取核准新的自动驾驶系统释放候选人; 所提出的标准的实施除了许多其他文化、程序和业务考虑之外,还要求存在适当的安全管理做法; 因此,本文件最后对希望复制部分或全部内容的人作了限制说明。","Francesca Favaro, Scott Schnelle, Laura Fraade-Blanar, Trent Victor, Mauricio Peña, Nick Webb, Holland Broce, Craig Paterson, Dan Smith",2025-05-29T22:17:49Z,Determining Absence of Unreasonable Risk: Approval Guidelines for an   Automated Driving System Deployment,Ermittlung des Fehlens von unangemessenem Risiko: Zulassungsrichtlinien für die Einführung eines automatisierten Fahrsystems,认定不存在不合理风险:自动驾驶系统部署核准准则,http://arxiv.org/abs/2505.09880v2
143,"Code auditing is the process of reviewing code with the aim of identifying bugs. Large Language Models (LLMs) have demonstrated promising capabilities for this task without requiring compilation, while also supporting user-friendly customization. However, auditing a code repository with LLMs poses significant challenges: limited context windows and hallucinations can degrade the quality of bug reports, and analyzing large-scale repositories incurs substantial time and token costs, hindering efficiency and scalability.   This work introduces an LLM-based agent, RepoAudit, designed to perform autonomous repository-level code auditing. Equipped with agent memory, RepoAudit explores the codebase on demand by analyzing data-flow facts along feasible program paths within individual functions. It further incorporates a validator module to mitigate hallucinations by verifying data-flow facts and checking the satisfiability of path conditions associated with potential bugs, thereby reducing false positives. RepoAudit detects 40 true bugs across 15 real-world benchmark projects with a precision of 78.43%, requiring on average only 0.44 hours and $2.54 per project. Also, it detects 185 new bugs in high-profile projects, among which 174 have been confirmed or fixed. We have open-sourced RepoAudit at https://github.com/PurCL/RepoAudit.","大型语言模型(LLMS)在不要求编纂的同时,也支持方便用户的定制;然而,用LLMS审计一个代码存储库带来了重大挑战:有限的背景窗口和幻觉可以降低错误报告的质量,分析大型存储库会产生大量的时间和象征性成本,从而妨碍效率和可缩放性。这项工作引入了一个基于LLM的代理机构RepoAudit, 目的是进行自主存储库级代码审计。用代理存储器进行配置,RepoAudit根据需求对代码库进行探索,按照单个功能中可行的程序路径分析数据流事实。它还包含一个验证模块,通过核查数据流事实和检查与潜在错误相关的路径条件的可视性来减轻幻觉,从而降低错误的阳性。RepoAudit在15个真实世界基准项目中检测40个真正的错误,精确度为78.43%,平均只需要0.44小时,每个项目2.54。此外,它还检测了高清晰度A/Recom项目中的185个新错误,其中174个已经确认。","Jinyao Guo, Chengpeng Wang, Xiangzhe Xu, Zian Su, Xiangyu Zhang",2025-05-29T22:08:26Z,RepoAudit: An Autonomous LLM-Agent for Repository-Level Code Auditing,RepoAudit: Ein autonomer LLM-Agent für Repository-Level Code Auditing,重审:主管仓库一级守则审计的自治LLM-Agent,http://arxiv.org/abs/2501.18160v3
144,"Automatic code generation has gained significant momentum with the advent of Large Language Models (LLMs) such as GPT-4. Although many studies focus on improving the effectiveness of LLMs for code generation, very limited work tries to understand the generated code's characteristics and leverage that to improve failed cases. In this paper, as the most straightforward characteristic of code, we investigate the relationship between code complexity and the success of LLM generated code. Using a large set of standard complexity metrics, we first conduct an empirical analysis to explore their correlation with LLM's performance on code generation (i.e., Pass@1). Using logistic regression models, we identify which complexity metrics are most predictive of code correctness. Building on these findings, we propose an iterative feedback method, where LLMs are prompted to generate correct code based on complexity metrics from previous failed outputs. We validate our approach across multiple benchmarks (i.e., HumanEval, MBPP, LeetCode, and BigCodeBench) and various LLMs (i.e., GPT-4o, GPT-3.5 Turbo, Llama 3.1, and GPT-o3 mini), comparing the results with two baseline methods: (a) zero-shot generation, and (b) iterative execution-based feedback without our code complexity insights. Experiment results show that our approach makes notable improvements, particularly with a smaller LLM (GPT3.5 Turbo), where, e.g., Pass@1 increased by 35.71% compared to the baseline's improvement of 12.5% on the HumanEval dataset. The study expands experiments to BigCodeBench and integrates the method with the Reflexion code generation agent, leading to Pass@1 improvements of 20% (GPT-4o) and 23.07% (GPT-o3 mini). The results highlight that complexity-aware feedback enhances both direct LLM prompting and agent-based workflows.","随着大语言模型(LLMs)的出现,例如GPT-4, 自动代码的生成获得了巨大的动力。虽然许多研究侧重于提高LLMs在代码生成方面的效力,但只有非常有限的工作才试图理解生成的代码的特性,并试图利用它来改进失败的案例。在本文中,作为代码最直截了当的特征,我们调查代码复杂性与LLM生成代码成功之处之间的关系。我们使用一套庞大的标准复杂度指标,首先进行实证分析,以探索它们与LLLMM在代码生成(即,Pass@1)方面的性能(即,Pass@1)。我们利用物流回归模型,确定哪些复杂度指标最能预测代码的正确性能。基于这些研究结果,我们提出了一种迭代相反馈方法,促使LLMSM公司根据先前失败产出的复杂度来生成正确的代码。我们验证了我们跨越多个基准(例如,HRVV、MPPP、LetCoco、BobeB-Brobe) 和各种LMMM(例如,GPT-PT-3.5,GT-LM-LM)的改进率的改进率方法比前两个基的改进率方法。我们的数据比比前更细化了。","Melika Sepidband, Hamed Taherkhani, Song Wang, Hadi Hemmati",2025-05-29T19:06:14Z,Enhancing LLM-Based Code Generation with Complexity Metrics: A   Feedback-Driven Approach,Verbesserung der LLM-basierten Code-Generierung mit Komplexitäts-Metriken: Ein feedbackgetriebener Ansatz,加强基于LLM的具有复杂度计量法的以LLM为基础的代码生成:反馈驱动方法,http://arxiv.org/abs/2505.23953v1
145,"Recent studies show that LLMs possess different skills and specialize in different tasks. In fact, we observe that their varied performance occur in several levels of granularity. For example, in the code optimization task, code LLMs excel at different optimization categories and no one dominates others. This observation prompts the question of how one leverages multiple LLM agents to solve a coding problem without knowing their complementary strengths a priori. We argue that a team of agents can learn from each other's successes and failures so as to improve their own performance. Thus, a lesson is the knowledge produced by an agent and passed on to other agents in the collective solution process. We propose a lesson-based collaboration framework, design the lesson solicitation--banking--selection mechanism, and demonstrate that a team of small LLMs with lessons learned can outperform a much larger LLM and other multi-LLM collaboration methods.","最近的研究显示,LLMs拥有不同的技能,并且专门从事不同的工作。事实上,我们观察到,它们的不同性能发生在几个颗粒层次上。例如,在代码优化任务中,代码LLM在不同的优化类别中非常出色,而没有一人在其他方面占优势。这一观察促使了一个问题,即如何利用多个LLM代理商来解决编码问题而不先知其互补优势。我们争辩说,一个代理商团队可以从彼此的成败中吸取教训,以便提高自身的性能。因此,一个教训就是代理人在集体解决方案过程中产生的知识,并传递给其他代理商。我们提出了一个基于经验的合作框架,设计了招标-银行-选择机制,并表明一个拥有经验教训的小型LLMM团队能够超越一个更大的LM和其他多LLM合作方法。","Yuanzhe Liu, Ryan Deng, Tim Kaler, Xuhao Chen, Charles E. Leiserson, Yao Ma, Jie Chen",2025-05-29T18:56:20Z,Lessons Learned: A Multi-Agent Framework for Code LLMs to Learn and   Improve,Learned Lessons: Ein Multi-Agenten-Rahmen für Code-LLMs zu lernen und zu verbessern,"经验教训:一个多机构框架,供《守则》 "" 学习和改进 "" 的 "" 学习 "" 、 "" 学习 "" 、 "" 学习 "" 、 "" 改进 "" 、 "" 学习 "" 、 "" 学习 "" 、 "" 学习 "" 、 "" 改进 "" 、 "" 学习 "" 和 "" 改进 "" 的 "" 守则 "" 、 "" 学习 "" 、 "" 学习 "" 、 "" 改进 "" 、 "" 学习 "" 、 "" 学习 "" 、 "" 改进 "" 、 "" 学习 "" 、 "" 学习 "" 、 "" 和 "" 改进 "" 、 "" 学习 "" 、 "" 学习 "" 、 "" 、 "" 规范 "" 、 "" 学习 "" 、 "" 、 "" 学习 "" 、 "" 学习 "" 、 "" 学习 "" 、 "" 、 "" 、 "" 学习 "" 、 "" 学习 "" 、 "" 学习 "" 、 "" 学习 "" 、 "" 学习 "" 、 "" 学习 "" 学习 "" 、 "" 学习 "" 、 "" 学习 "" 、 "" 、 "" 、 "" 、 "" 学习 "" 学习 "" 学习 "" 、 "" 、 "" 、 "" 学习 "" 学习 "" 、 "" 、 "" 、 "" 学习 "" 、 "" 、 "" 、 "" 、 "" 、 "" 学习 "" 、 "" 、 "" 学习 "" 、 "" 、 "" 、 "" 、 "" 、 "" 、 "" 、 "" 、 "" 、 "" 、 "" 、 """,http://arxiv.org/abs/2505.23946v1
146,"With the increasing adoption of large language models (LLMs) in software engineering, the Chain of Thought (CoT) reasoning paradigm has become an essential approach for automated code repair. However, the explicit multi-step reasoning in CoT leads to substantial increases in token consumption, reducing inference efficiency and raising computational costs, especially for complex code repair tasks. Most prior research has focused on improving the correctness of code repair while largely overlooking the resource efficiency of the reasoning process itself. To address this challenge, this paper proposes three targeted optimization strategies: Context Awareness, Responsibility Tuning, and Cost Sensitive. Context Awareness guides the model to focus on key contextual information, Responsibility Tuning refines the structure of the reasoning process through clearer role and responsibility assignment, and Cost Sensitive incorporates resource-awareness to suppress unnecessary token generation during inference. Experiments across diverse code repair scenarios demonstrate that these methods can significantly reduce token consumption in CoT-based reasoning without compromising repair quality. This work provides novel insights and methodological guidance for enhancing the efficiency of LLM-driven code repair tasks in software engineering.","由于软件工程越来越多地采用大型语言模型(LLMs),思维链(CoT)推理范式已成为自动化代码修理的基本方法,然而,CoT中明确的多步推理导致象征性消费大幅增加,降低推论效率和提高计算成本,特别是复杂的代码修理任务。大多数先前的研究侧重于改进代码修理的正确性,同时基本上忽略了推理过程本身的资源效率。为了应对这一挑战,本文件提出了三项有针对性的优化战略:背景认识、责任调整和成本敏感。背景认识指导模式侧重于关键背景信息,责任调整通过更明确的角色和责任分配改进推理过程的结构,成本敏感性包括资源意识,以制止在推断过程中不必要的象征性生成。各种代码修理设想的实验表明,这些方法可以大大减少基于CoT推理的象征性消费,同时不损害修理质量。这项工作为提高软件工程LLM驱动的代码修理任务的效率提供了新的见解和方法指导。","Junwei Hu, Weicheng Zheng, Yihan Liu, Yan Liu",2025-05-29T18:29:37Z,Optimizing Token Consumption in LLMs: A Nano Surge Approach for Code   Reasoning Efficiency,Optimierung des Token-Verbrauchs in LLMs: Ein Nano Surge-Ansatz für Code-Reasoning-Effizienz,在LLMM中优化口服消费:用纳米蒸蒸蒸蒸法计算成本效率,http://arxiv.org/abs/2504.15989v2
147,"As software systems grow increasingly complex, explainability has become a crucial non-functional requirement for transparency, user trust, and regulatory compliance. Eliciting explainability requirements is challenging, as different methods capture varying levels of detail and structure. This study examines the efficiency and effectiveness of three commonly used elicitation methods - focus groups, interviews, and online surveys - while also assessing the role of taxonomy usage in structuring and improving the elicitation process. We conducted a case study at a large German IT consulting company, utilizing a web-based personnel management software. A total of two focus groups, 18 interviews, and an online survey with 188 participants were analyzed. The results show that interviews were the most efficient, capturing the highest number of distinct needs per participant per time spent. Surveys collected the most explanation needs overall but had high redundancy. Delayed taxonomy introduction resulted in a greater number and diversity of needs, suggesting that a two-phase approach is beneficial. Based on our findings, we recommend a hybrid approach combining surveys and interviews to balance efficiency and coverage. Future research should explore how automation can support elicitation and how taxonomies can be better integrated into different methods.","由于软件系统日益复杂,解释性已成为对透明度、用户信任和监管合规的关键非功能性要求,解释性要求具有挑战性,因为不同方法可以捕捉不同程度的细节和结构。本研究报告审查了三种常用的引人方法(焦点小组、访谈和在线调查)的效率和效力,同时还评估了分类学使用在结构和改进引人进程中的作用。我们利用网上人事管理软件,在一家大型德国信息技术咨询公司进行了案例研究。共分析了两个焦点小组,即18次访谈和188名参与者的在线调查。结果显示,访谈效率最高,每个参与者每次花费的时间都有最多的不同需求。调查收集了大多数解释需求,但有大量的冗余度。推迟采用分类学带来了更多和更多的需求,表明分两个阶段的方法是有益的。我们建议采用混合方法,将调查和访谈结合起来,以平衡效率和覆盖面。未来研究应探索自动化如何支持征求,如何更好地将纳税人纳入不同方法。","Martin Obaidi, Jakob Droste, Hannah Deters, Marc Herrmann, Raymond Ochsner, Jil Klünder, Kurt Schneider",2025-05-29T17:23:14Z,"How to Elicit Explainability Requirements? A Comparison of Interviews,   Focus Groups, and Surveys","Wie zu Elicit Erklärbarkeit Anforderungen? Ein Vergleich von Interviews, Fokusgruppen und Umfragen",如何制定明确的解释要求?访谈、焦点小组和调查的比较,http://arxiv.org/abs/2505.23684v1
148,"Quantum computing has demonstrated potential for solving computationally intensive problems more efficiently than classical methods. Many software engineering tasks, such as test case selection, static analysis, code clone detection, and defect prediction, involve complex optimization, search, or classification, making them candidates for quantum enhancement. In this paper, we propose Quantum-Based Software Engineering (QBSE), a potential research direction for applying quantum computing to classical software engineering problems. We outline its scope, clarify its distinction from quantum software engineering (QSE), and identify key problem types that may benefit from quantum optimization, search, and learning techniques. We also summarize existing research efforts that remain fragmented. Finally, we sketch a preliminary research agenda that may help guide the future development of QBSE as a structured and meaningful direction within software engineering.","量子计算显示出了比古典方法更高效地解决计算密集问题的潜力。许多软件工程任务,如测试案例选择、静态分析、代码克隆检测和缺陷预测,涉及复杂的优化、搜索或分类,使它们成为量子增强的候选。在本文件中,我们提议了量子软件工程(QBSE),这是将量子计算应用于古典软件工程问题的潜在研究方向。我们概述了其范围,澄清了与量子软件工程(QSE)的区别,并确定了可能受益于量子优化、搜索和学习技术的关键问题类型。我们还总结了仍然支离破碎的现有研究工作。最后,我们勾画了一个初步研究议程,它可能有助于指导QBSE的未来发展,作为软件工程中的一个结构化和有意义的方向。",Jianjun Zhao,2025-05-29T17:19:38Z,Quantum-Based Software Engineering,Quantenbasierte Software-Engineering,基于量子的软件工程,http://arxiv.org/abs/2505.23674v1
149,"Language models (LMs) perform well on standardized coding benchmarks but struggle with real-world software engineering tasks such as resolving GitHub issues in SWE-Bench, especially when model parameters are less than 100B. While smaller models are preferable in practice due to their lower computational cost, improving their performance remains challenging. Existing approaches primarily rely on supervised fine-tuning (SFT) with high-quality data, which is expensive to curate at scale. An alternative is test-time scaling: generating multiple outputs, scoring them using a verifier, and selecting the best one. Although effective, this strategy often requires excessive sampling and costly scoring, limiting its practical application. We propose Evolutionary Test-Time Scaling (EvoScale), a sample-efficient method that treats generation as an evolutionary process. By iteratively refining outputs via selection and mutation, EvoScale shifts the output distribution toward higher-scoring regions, reducing the number of samples needed to find correct solutions. To reduce the overhead from repeatedly sampling and selection, we train the model to self-evolve using reinforcement learning (RL). Rather than relying on external verifiers at inference time, the model learns to self-improve the scores of its own generations across iterations. Evaluated on SWE-Bench-Verified, EvoScale enables our 32B model, Satori-SWE-32B, to match or exceed the performance of models with over 100B parameters while using a few samples. Code, data, and models will be fully open-sourced.","语言模型(LMS)在标准化编码基准上表现良好,但与现实世界软件工程任务,例如解决SWE-Bench的GitHub问题,特别是在模型参数低于100B的情况下,在SWE-Bench中解决GitHub问题,特别是在模型参数低于100B的情况下。虽然较小的模型在实践中因其计算成本较低而更可取,但其性能仍具有挑战性。现有方法主要依靠监督的微调(SFT),具有高质量的数据,而这种数据在规模上是昂贵的。另一个办法是测试时间缩放:生成多种产出,使用核查器进行评分,并选择最佳的参数。虽然有效,但这一战略往往需要过多的取样和昂贵的评分,并限制其实际应用。我们建议采用将新一代作为进化过程的样本的测试时间缩放(EvoSUA),通过筛选和变异的输出,EvoSWES-S-S-SB 将产出分配的模型变为自我评估。","Guangtao Zeng, Maohao Shen, Delin Chen, Zhenting Qi, Subhro Das, Dan Gutfreund, David Cox, Gregory Wornell, Wei Lu, Zhang-Wei Hong, Chuang Gan",2025-05-29T16:15:36Z,Satori-SWE: Evolutionary Test-Time Scaling for Sample-Efficient Software   Engineering,Satori-SWE: Evolutionäre Test-Zeit-Skalierung für probeneffiziente Software-Engineering,Satori-SWE:样本高效软件工程的进化测试-时间尺度,http://arxiv.org/abs/2505.23604v1
150,"This paper investigates the ability of large language models (LLMs) to recognise and solve tasks which have been obfuscated beyond recognition. Focusing on competitive programming and benchmark tasks (LeetCode and MATH), we compare performance across multiple models and obfuscation methods, such as noise and redaction. We demonstrate that all evaluated LLMs can solve tasks obfuscated to a level where the text would be unintelligible to human readers, and does not contain key pieces of instruction or context. We introduce the concept of eager pattern matching to describe this behaviour, which is not observed in tasks published after the models' knowledge cutoff date, indicating strong memorisation or overfitting to training data, rather than legitimate reasoning about the presented problem. We report empirical evidence of distinct performance decay patterns between contaminated and unseen datasets. We discuss the implications for benchmarking and evaluations of model behaviour, arguing for caution when designing experiments using standard datasets. We also propose measuring the decay of performance under obfuscation as a possible strategy for detecting dataset contamination and highlighting potential safety risks and interpretability issues for automated software systems.","本文调查了大型语言模型(LLMS)认识和解决超出认知范围的任务的能力。我们把注意力集中在竞争性编程和基准任务(LeetCode和MATH)上,比较了多种模型和模糊方法(例如噪音和编辑)的性能。我们证明,所有经过评价的LLMS都能够解决被模糊的任务,使其达到对人类读者不易理解的程度,而没有包含关键的指示或背景。我们引入了渴望模式匹配的概念来描述这种行为,在模型知识截止日期之后公布的任务中没有观察到这种行为,表明高度的记忆化或过度适应培训数据,而不是对所提出的问题进行合理的推理。我们报告了被污染的数据集和不可见的数据集之间不同性能衰减模式的经验证据。我们讨论了在使用标准数据集设计实验时对基准和行为评价的影响,我们主张谨慎。我们还提议测量模糊状态下性能的衰败,作为发现数据污染和突出潜在安全风险以及自动化软件系统可解释性问题的可能战略。","Radzim Sendyka, Christian Cabrera, Andrei Paleyes, Diana Robinson, Neil Lawrence",2025-05-29T16:11:18Z,LLM Performance for Code Generation on Noisy Tasks,LLM-Performance für Code-Generierung bei lauten Aufgaben,LLM 噪音任务代码生成的LLM性能,http://arxiv.org/abs/2505.23598v1
151,"Cyber-physical systems (CPSs) are complex systems that integrate physical, computational, and communication subsystems. The heterogeneous nature of these systems makes their safety assurance challenging. In this paper, we propose a novel automated approach for guardrailing cyber-physical systems using property-based tests (PBTs) generated by Large Language Models (LLMs). Our approach employs an LLM to extract properties from the code and documentation of CPSs. Next, we use the LLM to generate PBTs that verify the extracted properties on the CPS. The generated PBTs have two uses. First, they are used to test the CPS before it is deployed, i.e., at design time. Secondly, these PBTs can be used after deployment, i.e., at run time, to monitor the behavior of the system and guardrail it against unsafe states. We implement our approach in ChekProp and conduct preliminary experiments to evaluate the generated PBTs in terms of their relevance (how well they match manually crafted properties), executability (how many run with minimal manual modification), and effectiveness (coverage of the input space partitions). The results of our experiments and evaluation demonstrate a promising path forward for creating guardrails for CPSs using LLM-generated property-based tests.","网络物理系统(CPS)是综合物理、计算和通信子系统的复杂系统。这些系统的多样化性质使其安全保障具有挑战性。在本文中,我们提议对使用大语言模型产生的基于财产的测试(PBT)来保护网络物理系统采用新的自动化方法。我们的方法是使用LLM来从CPS的代码和文档中提取属性。接下来,我们利用LLM来生成PBT,以核实在CPS上提取的属性。生成的PBT有两个用途。首先,它们用来在部署之前测试CPS,即设计时间。第二,这些PBT在部署后可以使用,即运行时,用来监测系统的行为,并保护它不受不安全状态的影响。我们在ChekProp中采用的方法,并进行初步实验,以评价产生的PBT的相关性(如何与手工制作的属性相匹配)、可操作性、可操作性(许多操作的手动修改是最低限度的),以及用于前方空间分区的安全性(对C进行有希望的磁性磁性测试)。","Khashayar Etemadi, Marjan Sirjani, Mahshid Helali Moghadam, Per Strandberg, Paul Pettersson",2025-05-29T15:27:52Z,LLM-based Property-based Test Generation for Guardrailing Cyber-Physical   Systems,LLM-basierte property-based Test Generation for Guardrailing Cyber-Physical Systems,以LLM为基础的保护网络-物理系统基于财产的,http://arxiv.org/abs/2505.23549v1
152,"Software is an essential component of research. However, little attention has been paid to it compared with that paid to research data. Recently, there has been an increase in efforts to acknowledge and highlight the importance of software in research activities.   Structured metadata from platforms like bio.tools, Bioconductor, and Galaxy ToolShed offers valuable insights into research software in the Life Sciences. Although originally intended to support discovery and integration, this metadata can be repurposed for large-scale analysis of software practices. However, its quality and completeness vary across platforms, reflecting diverse documentation practices.   To gain a comprehensive view of software development and sustainability, consolidating this metadata is necessary, but requires robust mechanisms to address its heterogeneity and scale.   This article presents an evaluation of instruction-tuned large language models for the task of software metadata identity resolution, a critical step in assembling a cohesive collection of research software. Such a collection is the reference component for the Software Observatory at OpenEBench, a platform that aggregates metadata to monitor the FAIRness of research software in the Life Sciences.   We benchmarked multiple models against a human-annotated gold standard, examined their behavior on ambiguous cases, and introduced an agreement-based proxy for high-confidence automated decisions. The proxy achieved high precision and statistical robustness, while also highlighting the limitations of current models and the broader challenges of automating semantic judgment in FAIR-aligned software metadata across registries and repositories.","与研究数据相比,软件是研究的一个基本组成部分。然而,与研究数据相比,对软件的注意很少。最近,人们更加努力承认和强调软件在研究活动中的重要性。生物工具、生物导体和Galaxy ToolShed等平台的结构化元数据为生命科学研究软件提供了宝贵的见解。虽然该元数据最初旨在支持发现和整合,但可以重新用于大规模分析软件实践。然而,该元数据的质量和完整性在平台上各有差异,反映了各种文件做法。为了全面了解软件的开发和可持续性,有必要巩固这一元数据,但需要建立强有力的机制来解决其差异性和规模。本文章对用于软件元数据解析任务的指示调整型大语言模型进行了评价,这是构建统一研究软件库的关键一步。这种收集是OpenEbeench软件观测台的参考部分,该台是一个将元数据汇总成一个平台,用以监测生命科学研究软件的FAIR性。我们用多种模型比对有附加说明的黄金标准进行了基准,需要加以巩固,但需要建立强有力的机制来应对其模棱不全案例和规模和规模的不均匀性,同时,还引入了高额的可靠、高额的统计模型决定。","Eva Martín del Pico, Josep Lluís Gelpí, Salvador Capella-Gutiérrez",2025-05-29T14:47:31Z,Identity resolution of software metadata using Large Language Models,Identitätsauflösung von Software-Metadaten mit großen Sprachmodellen,使用大语言模式的软件元数据的识别分辨率,http://arxiv.org/abs/2505.23500v1
153,"Large Language Models (LLMs) have been increasingly used to optimize code efficiency. Evaluating their effectiveness and further suggesting optimization opportunities often rely on high-quality tests to demonstrate the performance bottlenecks presented in the program. However, existing approaches rely on a limited set of hand-curated inputs or LLM-generated uninteresting length-stressing tests, failing to reveal more nuanced optimization opportunities. We present WEDGE, a framework for generating performance-stressing input given the program under test. WEDGE synthesizes explicit performance-characterizing constraints in the form of branch conditions to partition the programs' execution space into performance-specific regions. When integrated with the coverage-guided fuzzer, reaching different regions introduces explicit rewards for test generation to explore inefficient implementations. Our evaluation shows that WEDGE introduces a significant slowdown compared to the tests in CodeContests and those claimed to be optimized by existing approaches. From the utility perspective, integrating our tests substantially improves the existing code optimization approaches that rely on test-driven execution feedback. We release PERFFORGE, the performance tests generated by WEDGE, to benchmark future approaches for efficient code generation at https://github.com/UChiSeclab/perfforge.","大型语言模型(LLMS)被越来越多地用于优化代码效率。评估其有效性和进一步建议优化机会往往依赖于高质量的测试,以证明该方案中出现的绩效瓶颈。然而,现有方法依靠有限的一组手工加工投入或LLM产生的无兴趣长伸测试,未能揭示出更细微的优化机会。我们介绍了WEDGE,这是一个根据所测试的方案生成绩效压力投入的框架。WEDGE综合了以分支条件形式出现的明确的绩效特征化限制,以将方案的执行空间划分为具体绩效区域。当与覆盖指导的模糊数据整合到不同区域时,为测试生成探索效率低下的实施带来明确回报。我们的评估表明,WEDGE与代码测试和声称通过现有方法优化的测试相比,速度大大放缓。从实用角度出发,我们的综合极大地改进了现有代码优化方法,依靠测试驱动的执行反馈。我们发布了PERFFFFORGE,WEGE生成的绩效测试,为探索低效实施提供了明确的回报。我们的评价显示,为探索低效执行效果的生成方法提供了明确的奖励。我们的评价表明,与代CECD/CRUSGUGUC。","Jun Yang, Cheng-Chi Wang, Bogdan Alexandru Stoica, Kexin Pei",2025-05-29T14:26:22Z,Synthesizing Performance Constraints for Evaluating and Improving Code   Efficiency,Synthese von Leistungsbeschränkungen zur Bewertung und Verbesserung der Code-Effizienz,综合评估和提高《守则》效率的绩效制约因素,http://arxiv.org/abs/2505.23471v1
154,"Opinion mining plays a vital role in analysing user feedback and extracting insights from textual data. While most research focuses on sentiment polarity (e.g., positive, negative, neutral), fine-grained emotion classification in app reviews remains underexplored. This paper addresses this gap by identifying and addressing the challenges and limitations in fine-grained emotion analysis in the context of app reviews. Our study adapts Plutchik's emotion taxonomy to app reviews by developing a structured annotation framework and dataset. Through an iterative human annotation process, we define clear annotation guidelines and document key challenges in emotion classification. Additionally, we evaluate the feasibility of automating emotion annotation using large language models, assessing their cost-effectiveness and agreement with human-labelled data. Our findings reveal that while large language models significantly reduce manual effort and maintain substantial agreement with human annotators, full automation remains challenging due to the complexity of emotional interpretation. This work contributes to opinion mining by providing structured guidelines, an annotated dataset, and insights for developing automated pipelines to capture the complexity of emotions in app reviews.","意见挖掘在分析用户反馈和从文本数据中提取见解方面发挥着至关重要的作用。虽然大多数研究侧重于情绪极化(如正面、负面、中性),但应用审查中微微薄情感分类仍未得到充分探讨。本文件通过查明和解决在应用审查中微薄情感分析的挑战和局限性来解决这一差距。我们的研究使普卢奇克的情感分类适应于通过开发结构化说明框架和数据集来应用审查。我们通过一个迭代人类批注过程,界定明确的说明指南并记录情感分类方面的关键挑战。此外,我们评估使用大型语言模型将情感批注自动化的可行性,评估其成本效益和与人类标注数据的一致。我们的调查结果显示,虽然大型语言模型大大减少了人工工作,并保持与人类顾问的实质性协议,但由于情感解释的复杂性,完全自动化仍然具有挑战性。这项工作通过提供结构化指南、附加说明的数据集和见解挖掘,有助于开发自动化管道,以捕捉到应用程序审查中情绪的复杂性。","Quim Motger, Marc Oriol, Max Tiessler, Xavier Franch, Jordi Marco",2025-05-29T13:58:38Z,What About Emotions? Guiding Fine-Grained Emotion Extraction from Mobile   App Reviews,Was ist mit Emotionen? Guiding Fine-Grained Emotion Extraction aus Mobile App Bewertungen,情感呢?指导从移动应用程序评论中抽取精美情感的导师,http://arxiv.org/abs/2505.23452v1
155,"We introduce CTIM-Rover, an AI agent for Software Engineering (SE) built on top of AutoCodeRover (Zhang et al., 2024) that extends agentic reasoning frameworks with an episodic memory, more specifically, a general and repository-level Cross-Task-Instance Memory (CTIM). While existing open-source SE agents mostly rely on ReAct (Yao et al., 2023b), Reflexion (Shinn et al., 2023), or Code-Act (Wang et al., 2024), all of these reasoning and planning frameworks inefficiently discard their long-term memory after a single task instance. As repository-level understanding is pivotal for identifying all locations requiring a patch for fixing a bug, we hypothesize that SE is particularly well positioned to benefit from CTIM. For this, we build on the Experiential Learning (EL) approach ExpeL (Zhao et al., 2024), proposing a Mixture-Of-Experts (MoEs) inspired approach to create both a general-purpose and repository-level CTIM. We find that CTIM-Rover does not outperform AutoCodeRover in any configuration and thus conclude that neither ExpeL nor DoT-Bank (Lingam et al., 2024) scale to real-world SE problems. Our analysis indicates noise introduced by distracting CTIM items or exemplar trajectories as the likely source of the performance degradation.","我们引入了 CTIM-Rover , 这个软件工程的AI 代理机构( AI 代理机构 ) , 建在 AutoCodeRover 之上( 张等人, 2024 ) , 扩展了代理逻辑框架, 并带有偶数内存, 更具体地说, 是一个普通和仓库级跨任务内存( CTIM ) 。 虽然现有的开放源 SE 代理机构主要依赖 ReAct ( Yao等人, 2023b) , Reflexion (Shinn等人, 2023 等人, 或代码法案( Wang等人, 2024 ) , 所有这些理论和规划框架都低效地丢弃了长期内存。 由于仓库一级的理解对于确定所有需要补丁来修复错误的地点至关重要, 我们假设 SEEE特别适合受益于 CT 。 为此, 我们以Expecial Level Level Legress (Zha et al.) 2024) , 提议一个混合- Extransurive- 方法来创建普通 和存储级内端端端端端 的系统或深层直基分析。","Tobias Lindenbauer, Georg Groh, Hinrich Schütze",2025-05-29T13:19:29Z,From Knowledge to Noise: CTIM-Rover and the Pitfalls of Episodic Memory   in Software Engineering Agents,Vom Wissen zum Lärm: CTIM-Rover und die Pitfalls des episodischen Gedächtnisses in Software Engineering Agents,从知识到噪音:CTIM-Rover和软件工程代理器中电离内存的空洞,http://arxiv.org/abs/2505.23422v1
156,"Artificial Intelligence (AI) governance is the practice of establishing frameworks, policies, and procedures to ensure the responsible, ethical, and safe development and deployment of AI systems. Although AI governance is a core pillar of Responsible AI, current literature still lacks synthesis across such governance frameworks and practices. Objective: To identify which frameworks, principles, mechanisms, and stakeholder roles are emphasized in secondary literature on AI governance. Method: We conducted a rapid tertiary review of nine peer-reviewed secondary studies from IEEE and ACM (20202024), using structured inclusion criteria and thematic semantic synthesis. Results: The most cited frameworks include the EU AI Act and NIST RMF; transparency and accountability are the most common principles. Few reviews detail actionable governance mechanisms or stakeholder strategies. Conclusion: The review consolidates key directions in AI governance and highlights gaps in empirical validation and inclusivity. Findings inform both academic inquiry and practical adoption in organizations.","人工智能(AI)治理是建立框架、政策和程序以确保负责任、道德和安全地发展和部署AI系统的做法。尽管AI治理是负责任的AI的核心支柱,但目前的文献仍然缺乏对此类治理框架和做法的综合。目标:确定AI治理的次级文献强调了哪些框架、原则、机制和利益攸关方的作用。方法:我们利用结构化的包容性标准和专题语义综合,对IEEE和ACM(20202024年)的九项经同行审查的次级研究进行了快速三级审查。结果:引用最多的框架包括欧盟AI法和NIST RMF;透明度和问责制是最常见的原则。很少详细审查可操作的治理机制或利益攸关方战略。结论:审查综合了AI治理的主要方向,突出了经验验证和包容性方面的差距。调查结果为各组织的学术调查和实际采用提供了信息。","Danilo Ribeiro, Thayssa Rocha, Gustavo Pinto, Bruno Cartaxo, Marcelo Amaral, Nicole Davila, Ana Camargo",2025-05-29T13:07:45Z,Toward Effective AI Governance: A Review of Principles,Auf dem Weg zu einer effektiven KI-Governance: Eine Überprüfung der Grundsätze,实现有效的独立大赦国际治理:原则审查,http://arxiv.org/abs/2505.23417v1
157,"Mobile application development is a fast-paced process where maintaining high-quality user experiences is crucial. Bug reproduction, a key aspect of maintaining app quality, often faces significant challenges. Specifically, when descriptions in bug reports are ambiguous or difficult to comprehend, current approaches fail to extract accurate information. Moreover, modern applications exhibit inherent complexity with multiple pages and diverse functionalities, making it challenging for existing methods to map the relevant information in bug reports to the corresponding UI elements that need to be manipulated. To address these challenges, we propose BugRepro, a novel technique that integrates domain-specific knowledge to enhance the accuracy and efficiency of bug reproduction. BugRepro adopts a Retrieval-Augmented Generation (RAG) approach. It retrieves similar bug reports along with their corresponding steps to reproduce (S2R) entities from an example-rich RAG document. In addition, BugRepro explores the graphical user interface (GUI) of the app and extracts transition graphs from the user interface to incorporate app-specific knowledge to guide large language models (LLMs) in their exploration process. Our experiments demonstrate that BugRepro significantly outperforms two state-of-the-art methods (ReCDroid and AdbGPT). For S2R entity extraction accuracy, it achieves a 7.57 to 28.89 percentage point increase over prior methods. For the bug reproduction success rate, the improvement reaches 74.55% and 152.63%. In reproduction efficiency, the gains are 0.72% and 76.68%.","移动应用程序开发是一个快速过程, 保持高质量的用户经验至关重要。 错误复制是维护应用程序质量的一个关键方面, 常常面临重大挑战。 具体地说, 当错误报告中的说明含混不清或难以理解时, 当前的方法无法获取准确信息。 此外, 现代应用程序具有多页和多种功能的内在复杂性, 使得现有方法难以将错误报告中的相关信息映射到需要操作的相应界面中。 为了应对这些挑战, 我们提议 BugRepro, 这是一种将特定域知识整合到提高错误复制的准确性和效率的新技术。 BugRepro 采用了回收源代(RAG) 的方法。 它回收了类似的错误报告, 以及它们从具有丰富实例的 RAG文档中复制(S2R) 实体的相应步骤。 此外, BugRepro 探索了应用程序的图形用户界面( GUI) , 并从用户界面中提取过渡图, 以纳入具体应用知识, 指导大语言模型( LLMS) 的精确性。 我们的实验显示 BugRepro 明显超出 Reval- Arestationalationalations the timal- pain- passationalational- brush- brus the pain the priew- brus.","Hongrong Yin, Jinhong Huang, Yao Li, Yunwei Dong, Tao Zhang",2025-05-29T13:03:01Z,BugRepro: Enhancing Android Bug Reproduction with Domain-Specific   Knowledge Integration,BugRepro: Verbesserung der Android Bug Reproduction mit Domain-spezifischer Wissensintegration,Bugrepro: 利用特定域知识集成增强Android虫复制,http://arxiv.org/abs/2505.14528v2
158,"Code generation, the automatic creation of source code from natural language descriptions, has garnered significant attention due to its potential to streamline software development. Inspired by research that links task-personality alignment with improved development outcomes, we conduct an empirical study on personality-guided code generation using large language models (LLMs). Specifically, we investigate how emulating personality traits appropriate to the coding tasks affects LLM performance. We extensively evaluate this approach using seven widely adopted LLMs across four representative datasets. Our results show that personality guidance significantly enhances code generation accuracy, with improved pass rates in 23 out of 28 LLM-dataset combinations. Notably, in 11 cases, the improvement exceeds 5%, and in 5 instances, it surpasses 10%, with the highest gain reaching 12.9%. Additionally, personality guidance can be easily integrated with other prompting strategies to further boost performance. We open-source our code and data at https://github.com/IanWalls/Persona-Code.","代码的生成,即自然语言描述源代码的自动生成,因其在简化软件开发方面的潜力而引起极大关注。在将任务-个性协调与改进发展成果联系起来的研究的启发下,我们开展了一项关于使用大型语言模型(LLMs)进行个性指导代码生成的经验性研究。具体地说,我们调查了与编码任务相适应的个性特征如何影响LLM的性能。我们利用四个具有代表性的数据集广泛采用的7个LLMs广泛评估了这一方法。我们的结果表明,个性指导大大提高了代码生成的准确性,28个LLM-数据集组合中的23个提高了通过率。值得注意的是,在11个案例中,改进率超过5%,在5个案例中超过10%,最高收益达到12.9 %。此外,个性指导很容易与其他快速战略相结合,以进一步提升性能。我们在https://github.com/IanWalls/Percena-Codead中打开了我们的代码和数据。","Yaoqi Guo, Zhenpeng Chen, Jie M. Zhang, Yang Liu, Yun Ma",2025-05-29T11:26:39Z,Personality-Guided Code Generation Using Large Language Models,Personalitätsgeführte Code-Generierung mit großen Sprachmodellen,使用大语言模式的 个人 使用大语言模式的 人 性 指导 代码 生成,http://arxiv.org/abs/2411.00006v2
159,"Usability evaluation is critical to the impact and adoption of open source software (OSS), yet traditional methods relying on human evaluators suffer from high costs and limited scalability. To address these limitations, we introduce OSS-UAgent, an automated, configurable, and interactive agent-based usability evaluation framework specifically designed for open source software. Our framework employs intelligent agents powered by large language models (LLMs) to simulate developers performing programming tasks across various experience levels (from Junior to Expert). By dynamically constructing platform-specific knowledge bases, OSS-UAgent ensures accurate and context-aware code generation. The generated code is automatically evaluated across multiple dimensions, including compliance, correctness, and readability, providing a comprehensive measure of the software's usability. Additionally, our demonstration showcases OSS-UAgent's practical application in evaluating graph analytics platforms, highlighting its effectiveness in automating usability evaluation.","可用性评价对于影响和采用开放源码软件(OSS)至关重要,但依赖人类评估员的传统方法却成本高,可扩展性有限。为了应对这些限制,我们引入了开放源码软件自动、可配置和互动代理工具专用使用性评价框架,这是专门为开放源码软件设计的自动、可配置和基于互动代理工具的可用性评价框架。我们的框架使用由大语言模型(LLLMS)驱动的智能代理器,模拟开发者执行不同层次(从初级到专家)的编程任务。通过动态构建平台特定知识库,OSS-UAgency确保准确和符合背景的代码生成。生成的代码将自动评估多个层面,包括合规性、正确性和可读性,为软件的可用性提供了全面衡量标准。此外,我们的演示展示展示了OSS-UAgency在评价图表分析平台方面的实际应用,突出其在提高可用性评价效率方面的效果。","Lingkai Meng, Yu Shao, Long Yuan, Longbin Lai, Peng Cheng, Wenyuan Yu, Wenjie Zhang, Xuemin Lin, Jingren Zhou",2025-05-29T08:40:10Z,OSS-UAgent: An Agent-based Usability Evaluation Framework for Open   Source Software,OSS-UAgent: Ein Agent-basiertes Usability Evaluation Framework für Open Source Software,OSS-UUA代理:基于代理的开放源码软件使用性评价框架,http://arxiv.org/abs/2505.23239v1
160,"Server-side request forgery (SSRF) vulnerabilities are inevitable in PHP web applications. Existing static tools in detecting vulnerabilities in PHP web applications neither contain SSRF-related features to enhance detection accuracy nor consider PHP's dynamic type features. In this paper, we present Artemis, a static taint analysis tool for detecting SSRF vulnerabilities in PHP web applications. First, Artemis extracts both PHP built-in and third-party functions as candidate source and sink functions. Second, Artemis constructs both explicit and implicit call graphs to infer functions' relationships. Third, Artemis performs taint analysis based on a set of rules that prevent over-tainting and pauses when SSRF exploitation is impossible. Fourth, Artemis analyzes the compatibility of path conditions to prune false positives. We have implemented a prototype of Artemis and evaluated it on 250 PHP web applications. Artemis reports 207 true vulnerable paths (106 true SSRFs) with 15 false positives. Of the 106 detected SSRFs, 35 are newly found and reported to developers, with 24 confirmed and assigned CVE IDs.","在PHP网络应用中,发现PHP网络应用中的弱点的现有静态工具既不含SERF相关特性,也非用于提高检测准确性,也非考虑到PHP动态类型特征。在本文件中,我们介绍了Artemis,这是一个用于检测PHP网络应用中SERF脆弱性的静态污点分析工具。首先,Artemis提取了PHP内在和第三方功能,作为候选源和汇的功能。第二,Artemis构建了明确和隐含的调用图,以推断功能的关系。第三,Artemis根据一套规则进行了污点分析,以防止在SSRF无法开发时过度拉扯和暂停。第四,Artemis分析了用于提取假阳点的路径条件的兼容性。我们实施了Artemis原型,并对250 PHP网络应用进行了评估。Artemis报告207条真实的脆弱路径(106个真正的SSRF),有15个假阳点。在106个测得的SSRF中,新发现并向开发商报告了35条,有24个确认和指定的CVEID。","Yuchen Ji, Ting Dai, Zhichao Zhou, Yutian Tang, Jingzhu He",2025-05-29T07:34:13Z,Artemis: Toward Accurate Detection of Server-Side Request Forgeries   through LLM-Assisted Inter-Procedural Path-Sensitive Taint Analysis,Artemis: Auf dem Weg zur genauen Erkennung von Server-Side Request Forgeries durch LLM-Assisted Inter-Procedural Path-Sensitive Taint Analysis,"人工制品:通过LLM协助的跨程序间路由感知性图解分析,力求准确探测服务器-Side请求的伪造情况",http://arxiv.org/abs/2502.21026v3
161,"Scaling Low-Rank Adaptation (LoRA)-based Mixture-of-Experts (MoE) facilitates large language models (LLMs) to efficiently adapt to diverse tasks. However, traditional gating mechanisms that route inputs to the best experts may fundamentally hinder LLMs' scalability, leading to poor generalization and underfitting issues. We identify that the root cause lies in the restricted expressiveness of existing weighted-sum mechanisms, both within and outside the convex cone of LoRA representations. This motivates us to propose RadarGate, a novel geometrically inspired gating method that introduces rotational operations of LoRAs representations to boost the expressiveness and facilitate richer feature interactions among multiple LoRAs for scalable LLMs. Specifically, we first fuse each LoRA representation to other LoRAs using a learnable component and then feed the output to a rotation matrix. This matrix involves learnable parameters that define the relative angular relationship between LoRA representations. Such a simple yet effective mechanism provides an extra degree of freedom, facilitating the learning of cross-LoRA synergies and properly tracking the challenging poor generalization and underfitting issues as the number of LoRA grows. Extensive experiments on 6 public benchmarks across 21 tasks show the effectiveness of our RadarGate for scaling LoRAs. We also provide valuable insights, revealing that the rotations to each pair of representations are contrastive, encouraging closer alignment of semantically similar representations during geometrical transformation while pushing distance ones further apart. We will release our code to the community.","低朗适应(LORA)基于低朗适应(LORA)的低朗适应(LOE)的混合物(MOE)有助于大型语言模型(LLMS)有效适应各种任务;然而,将投入投入输送给最佳专家的传统机制可能会从根本上阻碍LLMS的伸缩性,导致LLMS的简化和不适当问题;我们发现,根源在于现有加权和加权机制在LORA的表层内和外的表达方式的清晰度有限;这促使我们提出雷达Gate(RadarGate),这是一种具有地貌灵感的新型定位方法,引入LORA代表方式的旋转性操作,以提升其清晰度,便利多个LORA的伸缩性,促进多个LLOMS之间的更丰富性特征互动。具体地说,我们首先将每个LORA代表方式与其他LAM的伸缩性整合起来,然后将输出到轮值矩阵中。这种简单但有效的机制提供了额外的自由度,有助于学习LARA的交叉互动协作,并正确跟踪具有挑战性的缩缩缩略缩缩缩缩的缩缩缩缩缩缩图表。","Hongcan Guo, Guoshun Nan, Yuan Yang, Diyang Zhang, Haotian Li, Zhican Chen, Qinchuan Zhou, Yuhan Ran, Xinye Cao, Sicong Leng, Xiaofeng Tao, Xudong Jiang",2025-05-29T07:22:43Z,Two Is Better Than One: Rotations Scale LoRAs,Zwei ist besser als eins: Rotationsskala LoRAs,二比一好:轮作规模LORAs,http://arxiv.org/abs/2505.23184v1
162,"In recent years, there is a growing need and opportunity to use online platforms for psychophysics research. Online experiments make it possible to evaluate large and diverse populations remotely and quickly, complementing laboratory-based research. However, developing and running online psychophysics experiments poses several challenges: i) a high barrier-to-entry for researchers who often need to learn complex code-based platforms, ii) an uncontrolled experimental environment, and iii) questionable credibility of the participants. Here, we introduce an open-source Modular Online Psychophysics Platform (MOPP) to address these challenges. Through the simple web-based interface of MOPP, researchers can build modular experiments, share them with others, and copy or modify tasks from each others environments. MOPP provides built-in features to calibrate for viewing distance and to measure visual acuity. It also includes email-based and IP-based authentication, and reCAPTCHA verification. We developed five example psychophysics tasks, that come preloaded in the environment, and ran a pilot experiment which was hosted on the AWS (Amazon Web Services) cloud. Pilot data collected for these tasks yielded similar results to those reported in laboratory settings. MOPP can thus help researchers collect large psychophysics datasets online, with reduced turnaround time, and in a standardized manner.","近年来,利用在线平台进行心理物理学研究的需求和机会日益增长。在线实验使得能够对大量和多样化的人口进行远程和快速的评估,从而补充实验室研究。然而,开发并运行在线心理物理学实验带来了若干挑战:(1) 研究人员往往需要学习复杂的基于代码的平台,(2) 不受控制的实验环境,以及(3) 参与者的可信度令人怀疑。在这里,我们引入了一个开放源的模块在线心理物理学平台(MOPP)来应对这些挑战。通过MOP的简单网络界面,研究人员可以建立模块化实验,与其他人共享这些实验,并复制或修改来自其他每个环境的任务。MOPP提供了校准距离和测量视觉能力的内在特征。它还包括基于电子邮件和基于IP的认证以及 reCAPTCHA的核查。我们开发了五个在环境中预先加载的心理物理学任务,并在AWS(Azon Web Servic Servic)云上进行了试点实验。为这些任务收集的试点数据可以将这些标准化数据转化为实验室的大规模数据。","Yuval Samoilov-Kats, Matan Noach, Noam Beer, Yuval Efrati, Adam Zaidel",2025-05-29T06:24:36Z,An open-source Modular Online Psychophysics Platform (MOPP),Eine Open-Source-Plattform für modulare Online-Psychophysik (MOPP),开放源码模块在线心理物理学平台(MOPP),http://arxiv.org/abs/2505.23137v1
163,"Large language models (LLMs) are increasingly integrated in software development, but ensuring correctness in LLM-generated code remains challenging and often requires costly manual review. Verifiable code generation -- jointly generating code, specifications, and proofs of code-specification alignment -- offers a promising path to address this limitation and further unleash LLMs' benefits in coding. Yet, there exists a significant gap in evaluation: current benchmarks often lack support for end-to-end verifiable code generation. In this paper, we introduce Verina (Verifiable Code Generation Arena), a high-quality benchmark enabling a comprehensive and modular evaluation of code, specification, and proof generation as well as their compositions. Verina consists of 189 manually curated coding tasks in Lean, with detailed problem descriptions, reference implementations, formal specifications, and extensive test suites. Our extensive evaluation of state-of-the-art LLMs reveals significant challenges in verifiable code generation, especially in proof generation, underscoring the need for improving LLM-based theorem provers in verification domains. The best model, OpenAI o4-mini, generates only 61.4% correct code, 51.0% sound and complete specifications, and 3.6% successful proofs, with one trial per task. We hope Verina will catalyze progress in verifiable code generation by providing a rigorous and comprehensive benchmark. We release our dataset on https://huggingface.co/datasets/sunblaze-ucb/verina and our evaluation code on https://github.com/sunblaze-ucb/verina.","大型语言模型(LLMS)日益融入软件开发,但确保LLM生成的代码的正确性仍具有挑战性,而且往往需要花费昂贵的人工审查。可验证代码的生成 -- -- 共同生成代码、规格和具体编码协调的证明 -- -- 为解决这一限制和进一步释放LLMS的编码好处提供了一条充满希望的道路。然而,在评价方面存在着巨大的差距:目前的基准往往缺乏对端至端可核查代码生成的支持。在本文件中,我们引入了一个高质量基准,从而能够对代码、规格和证据生成及其构成进行全面和模块化评价。Verina由189个手工拼凑的编码任务组成,其中有详细的问题描述、参考执行、正式规格和广泛的测试套件。我们对目前最先进的LLMSM(可验证代码生成的DLMSUCSDS/Arencrearetures)的生成存在重大挑战。我们的最佳模型(OO4minirea)只能生成61.4%的代码,51.0%的硬度和3.6%的精确度的代码,我们将提供我们精确度数据生成的进度和3.6%的数据。","Zhe Ye, Zhengxu Yan, Jingxuan He, Timothe Kasriel, Kaiyu Yang, Dawn Song",2025-05-29T06:12:52Z,VERINA: Benchmarking Verifiable Code Generation,VERINA: Benchmarking der überprüfbaren Code-Generierung,VERINA:可核实代码生成基准,http://arxiv.org/abs/2505.23135v1
164,"Large Language Models (LLMs) are increasingly being used to automate programming tasks. Yet, LLMs' capabilities in reasoning about program semantics are still inadequately studied, leaving significant potential for further exploration. This paper introduces FormalBench, a comprehensive benchmark designed to evaluate LLMs' reasoning abilities on program semantics, particularly via the task of synthesizing formal program specifications to assist verifying program correctness. This task requires both comprehensive reasoning over all possible program executions and the generation of precise, syntactically correct expressions that adhere to formal syntax and semantics. Using this benchmark, we evaluated the ability of LLMs in synthesizing consistent and complete specifications. Our findings show that LLMs perform well with simple control flows but struggle with more complex structures, especially loops, even with advanced prompting. Additionally, LLMs exhibit limited robustness against semantic-preserving transformations. We also highlight common failure patterns and design self-repair prompts, improving success rates by 25%.","大型语言模型(LLMs)正越来越多地被用于使程序设计任务自动化。然而,LLMs在程序语义学的推理能力仍然没有得到充分的研究,从而留下了进一步探索的巨大潜力。本文介绍了旨在评估LLMs在程序语义学上的推理能力的全面基准“正式Bench”,尤其是通过综合正式程序规格协助核实程序正确性的任务。这项任务要求对所有可能的方案执行进行综合推理,并生成精确、统一和正确的表达方式,以坚持正式的语义学和语义学。我们利用这一基准,评估LLMs在综合一致和完整的规格方面的能力。我们的研究结果显示LMs在简单控制流程方面表现良好,但与更复杂的结构,特别是圆环进行斗争,即使有先进的提示。此外,LLMs在反对语义-保留转换方面表现出有限的强健性。我们还强调了常见的失败模式和设计自我修复的提示,使成功率提高了25%。","Thanh Le-Cong, Bach Le, Toby Murray",2025-05-29T06:07:32Z,Can LLMs Reason About Program Semantics? A Comprehensive Evaluation of   LLMs on Formal Specification Inference,Kann LLMs Grund über Programm Semantik? Eine umfassende Bewertung von LLMs auf formale Spezifikation Inferenz,CLLMs 方案语义学理由:全面评价关于正式具体推断的LLMs,http://arxiv.org/abs/2503.04779v4
165,"Diffusion LLMs have emerged as a promising alternative to conventional autoregressive LLMs, offering significant potential for improved runtime efficiency. However, existing diffusion models lack the ability to provably enforce user-specified formal constraints, such as regular expressions, which makes them unreliable for tasks that require structured outputs, such as fixed-schema JSON generation. Unlike autoregressive models that generate tokens sequentially, diffusion LLMs predict a block of tokens in parallel. This parallelism makes traditional constrained decoding algorithms, which are designed for sequential token prediction, ineffective at preserving the true output distribution. To address this limitation, we propose DINGO, a dynamic programming-based constrained decoding strategy that is both efficient and provably distribution-preserving. DINGO enables sampling of output strings with the highest probability under the model's predicted distribution, while strictly satisfying any user-specified regular expression. On standard symbolic math and JSON generation benchmarks, DINGO achieves up to a 68 percentage point improvement over unconstrained inference","与传统自动递减的LMS相比,LMS已成为一种大有希望的替代传统自动递减的LMS,它为提高运行时间效率提供了巨大的潜力;然而,现有的推广模式缺乏能力,无法对用户指定的正式限制,例如常规表达方式,使其不适于执行需要结构化产出的任务,例如固定的JSON 生成。与自动递减模式不同,扩散LMS同时预测一系列象征性。这种平行使得传统的受限制解码算法(这些算法是为按顺序进行象征性预测而设计的,在保存真正的产出分布方面无效)。为了应对这一限制,我们建议DINGO,这是一个动态的、基于程序化的受限解码战略,既高效又可可移动的分布保存。DINGO能够根据模型预测的分布,在严格满足用户指定的任何常规表达方式时,以最高概率取样产出字符。关于标准的象征性数学和JSONS生成基准,DINGO在未受限制的推算之外,实现了68个百分点的改进。","Tarun Suresh, Debangshu Banerjee, Shubham Ugare, Sasa Misailovic, Gagandeep Singh",2025-05-29T04:04:54Z,DINGO: Constrained Inference for Diffusion LLMs,DINGO: Beschränkte Schlussfolgerung für Diffusion LLMs,DINGO: 扩散长效LMM的连续推论,http://arxiv.org/abs/2505.23061v1
166,"HarmonyOS is emerging as a popular distributed operating system for diverse mobile devices. One of its standout features is app-hopping, which allows users to seamlessly transition apps across different HarmonyOS devices. However, when apps playing audio streams hop between devices, they can easily trigger Hopping-related Audio-stream Conflict (HAC) scenarios. Improper resolution of HAC will lead to significant HAC issues, which are harder to detect compared to single-device audio-stream conflicts, due to the unclear semantics of HarmonyOS's app-hopping mechanism and the lack of effective multi-app hopping testing methods. To fill the gap, this paper introduces an automated and efficient approach to detecting HAC issues. We formalized the operational semantics of HarmonyOS's app-hopping mechanism for audio streams for the first time. Leveraging this formalization, we designed an Audio Service Transition Graph (ASTG) to model the behaviors of audio-API-related services and proposed a model-based approach to detect HAC issues automatically. Our techniques were implemented in a tool, HACMony, and evaluated on 20 real-world HarmonyOS apps. Experimental results reveal that 11 of the 20 apps exhibit HAC issues. Additionally, we summarized the detected issues into two typical types, namely MoD and MoR, and analyzed their characteristics to assist and guide both app and OS developers.","与各种移动设备流行的分布式操作系统类似,哈玛尔内斯正在形成一个流行型号的和谐操作系统。它的一个外观功能是购买应用程序,使用户能够无缝地转换不同哈玛尔诺斯设备之间的应用软件。然而,当在设备之间播放音流跳动应用程序时,它们很容易触发与霍普相关的音流冲突(HAC)情景。HAC的不恰当解决将带来重大的HAC问题,由于哈玛尔诺斯应用程序购买机制的含混不清的词义和缺乏有效的多功能购物测试方法,因此与单一的音频流冲突相比,这些问题更难以被察觉。为了填补空白,本文引入了一种自动和高效的方法来探测HAC问题。我们首次正式确定了哈玛斯系统用于音流的应用程序购物机制。利用这一正规化,我们设计了一个音频服务过渡图(ASTG)来模拟与声音-API有关的服务的行为,并提出了一种基于模型的方法来自动检测HAC问题。为了填补这一空白,我们的技术在20个实体-CMony(HCony)和在20个现实-D-ASimal-Appalimalal Appalevulation Apps上,也就是20个H-H-hal 和两个HIS App-halevalevalevalevalevalevalal 的模拟了我们检测了20个HAL-haldaldaldaldals。","Jinlong He, Binru Huang, Changwei Xia, Hengqin Yang, Jiwei Yan, Jun Yan",2025-05-29T03:22:21Z,HACMony: Automatically Detecting Hopping-related Audio-stream Conflict   Issues on HarmonyOS,HACMony: Automatische Erkennung von Hopping-bezogenen Audio-Stream-Konflikten auf HarmonyOS,HACMonny:自动检测与Happing有关的和谐OS音频流冲突问题,http://arxiv.org/abs/2504.07472v2
167,"The use of Large Language Models (LLMs) for code generation has gained significant attention in recent years. Existing methods often aim to improve the quality of generated code by incorporating additional contextual information or guidance into input prompts. Many of these approaches adopt sequential reasoning strategies, mimicking human-like step-by-step thinking. However, such strategies may constrain flexibility, as they do not always align with the structured characteristics of programming languages. This paper introduces the Chain of Grounded Objectives (CGO), a method that embeds functional objectives into input prompts to enhance code generation. By leveraging appropriately structured objectives as input and avoiding explicit sequential procedures, CGO adapts effectively to the structured nature of programming tasks. Empirical evaluations demonstrate that CGO effectively enhances code generation, addressing limitations of existing approaches.","近些年来,使用大语言模式生成代码的问题引起了人们的极大注意,现有方法往往旨在通过将更多的背景信息或指导纳入投入提示来提高生成代码的质量,其中许多方法采用顺序推理战略,仿照人式的逐步思维,但是,这些战略可能限制灵活性,因为它们并不总是与编程语言的结构特征相一致。本文件介绍了 "" 定点目标链 "" (CGO),这是将功能目标嵌入投入的一种方法,它将功能目标嵌入投入中,从而推动加强代码生成。通过利用结构适当的目标作为投入,避免明确的顺序程序,CGO有效地适应了方案编制任务的结构性。经验性评估表明,CGO有效地加强了编程,解决了现有方法的局限性。","Sangyeop Yeo, Seung-won Hwang, Yu-Seung Ma",2025-05-29T02:28:30Z,Chain of Grounded Objectives: Bridging Process and Goal-oriented   Prompting for Code Generation,Kette der geerdeten Ziele: Überbrückungsprozess und zielorientiertes Prompting für die Codegenerierung,基本目标链链:搭桥进程和以目标为导向的促进代码生成,http://arxiv.org/abs/2501.13978v2
168,"Safety verification of robot applications is extremely challenging due to the complexity of the environment that a robot typically operates in. Formal verification with model-checking provides guarantees but it may often take too long or even fail for complex models of the environment. A usual solution approach is abstraction, more precisely behavioral abstraction. Our new approach introduces structural abstraction instead, which we investigated in the context of voxel representation of the robot environment. This kind of abstraction leads to abstract voxels. We also propose a complete and automated verification workflow, which is based on an already existing methodology for robot applications, and inspired by the key ideas behind counterexample-guided abstraction refinement (CEGAR) - performing an initial abstraction and successively introducing refinements based on counterexamples, intertwined with model-checker runs. Hence, our approach uses selective refinement of structural abstractions to improve the runtime efficiency of model-checking. A fully-automated implementation of our approach showed its feasibility, since counterexamples have been found for a realistic scenario with a fairly high (maximal) resolution in a few minutes, while direct model-checker runs led to a crash after a couple of days.","由于机器人通常操作的环境的复杂性,对机器人应用的安全性进行核查极具挑战性。通过模型检查进行的正式核查提供了保证,但对于复杂的环境模型来说往往需要过长甚至失败。通常的解决办法是抽象化,更准确地说是行为抽象化。我们的新办法引入了结构抽象化,而我们是在机器人环境的 voxel 代表范围内调查的。这种抽象化导致抽象的氧化物。我们还提议了一个完整和自动化的核查工作流程,该流程以机器人应用的现有方法为基础,并受到反比照制抽象精化(CEGAR)背后的关键想法的启发——在反比照样本的基础上进行初步抽象化和连续地引入改进,与模型检查机运行相交织。因此,我们的办法采用结构抽象化的选择性改进,以提高模型检查的运行效率。我们方法的完全自动化实施显示了其可行性,因为在几分钟内发现有相当高(最大)分辨率的现实情景,而直接的模型检查结果在几天后导致坠毁。","Christoph Luckeneder, Ralph Hoch, Hermann Kaindl",2025-05-29T01:44:47Z,Structural Abstraction and Selective Refinement for Formal Verification,Strukturelle Abstraktion und selektive Verfeinerung für formale Verifizierung,正式核查的结构性抽象和选择性改进,http://arxiv.org/abs/2505.22982v1
169,"Existing methods fail to effectively steer Large Language Models (LLMs) between textual reasoning and code generation, leaving symbolic computing capabilities underutilized. We introduce CodeSteer, an effective method for guiding LLM code/text generation. We construct a comprehensive benchmark SymBench comprising 37 symbolic tasks with adjustable complexity and also synthesize datasets of 12k multi-turn guidance/generation trajectories and 5.5k guidance comparison pairs. We fine-tune the Llama-3-8B model with a newly designed multi-turn supervised fine-tuning (SFT) and direct preference optimization (DPO). The resulting model, CodeSteerLLM, augmented with the proposed symbolic and self-answer checkers, effectively guides the code/text generation of larger models. Augmenting GPT-4o with CodeSteer raises its average performance score from 53.3 to 86.4, even outperforming the existing best LLM OpenAI o1 (82.7), o1-preview (74.8), and DeepSeek R1 (76.8) across all 37 tasks (28 seen, 9 unseen). Trained for GPT-4o, CodeSteer demonstrates superior generalizability, providing an average 41.8 performance boost on Claude, Mistral, and GPT-3.5. CodeSteer-guided LLMs fully harness symbolic computing to maintain strong performance on highly complex tasks. Models, Datasets, and Codes are available at https://github.com/yongchao98/CodeSteer-v1.0 and https://huggingface.co/yongchao98.","现有方法未能在文本推理和代码生成之间有效引导大型语言模型(LLMS),使得象征性的计算能力未得到充分利用。我们引入了CodeSteer,这是指导LLM代码/文本生成的有效方法。我们构建了一个全面的基准SymBench,由37项具有可调整复杂性的象征性任务组成,还合成了12k多方向指导/生成轨迹和5.5k指导比较对数据集。我们用新设计的多方向监管微调(SFT)和直接优惠优化(DPO)对Llama-3-8B模型进行了微调(LLMOM OpenAI o 1 (82.7)、 o1-preview (74.8) 和 DeepSebelb R1 (76.8) 在所有37项任务(28个可见,9个可见)。GPT-98/SpeetellM(C-Sil-GLODO)上,对GPLO-G-BS-deal-deal-deal-deal-deal Studal Studal Stal Ser)进行了训练,在GPDS-de-deal-deal-deal-deal-dealxxxxxxxlal 上,全面性能能能。在GPLDSlal-de 上,在GPB-dexxlalgal-dealxxxxxxxxxxxxxxxxxxxxx。","Yongchao Chen, Yilun Hao, Yueying Liu, Yang Zhang, Chuchu Fan",2025-05-29T00:38:10Z,CodeSteer: Symbolic-Augmented Language Models via Code/Text Guidance,CodeSteer: Symbolisch-Augmentierte Sprachmodelle über Code/Text Anleitung,代码器:通过编码/文本指导的代码/文本指导的代码器:代号辅助语言模式,http://arxiv.org/abs/2502.04350v2
170,"Operating System (OS) kernel tuning involves systematically adjusting kernel configurations to optimize system performance. Despite recent advancements in large language models (LLMs), kernel tuning remains a critical challenge due to: (1) the semantic gap between abstract tuning objective and concrete config options, (2) insufficient environmental interaction induces LLM hallucinations, and (3) the rapid evolution of kernel versions. To address these challenges, we propose BYOS, a LLM-powered framework that automates kernel tuning through three key innovations: structured knowledge construction and mapping, knowledge-driven configuration generation, and continuous knowledge maintenance. Extensive experiments show that BYOS achieves 7.1%-155.4% performance improvements over default configurations across standard OS benchmarks and real-world applications, demonstrating structured knowledge representation can overcome key limitations of pure LLM solutions for system optimization. Our code is available at https://github.com/LHY-24/BYOS.","操作系统(OS)内核调导涉及系统地调整内核配置以优化系统性能,尽管大型语言模型(LLMs)最近有所进步,但内核调导仍是一个重大挑战,因为:(1) 抽象调控目标和具体配置选项之间的语义差距,(2) 环境互动不足导致LM幻觉,(3) 内核版本的迅速演变。为应对这些挑战,我们提议BYOS,一个LLM驱动框架,通过三个关键创新自动调控内核:结构化知识建设和绘图、知识驱动的配置生成和持续的知识维护。广泛的实验显示,BYOS在标准OS基准和现实世界应用的默认配置方面实现了7.1%至155.4%的性能改进,展示有结构化的知识代表可以克服纯粹LM解决方案的关键限制,实现系统优化。我们的代码可在https://github.com/LHY-24/BYOS查阅。","Hongyu Lin, Yuchen Li, Haoran Luo, Kaichun Yao, Libo Zhang, Mingjie Xing, Yanjun Wu",2025-05-29T00:35:55Z,BYOS: Knowledge-driven Large Language Models Bring Your Own Operating   System More Excellent,BYOS: Wissensgetriebene große Sprachmodelle bringen Ihr eigenes Betriebssystem hervorragender,BYOS: 知识驱动的大型语言模式使自己的操作系统更加出色,http://arxiv.org/abs/2503.09663v2

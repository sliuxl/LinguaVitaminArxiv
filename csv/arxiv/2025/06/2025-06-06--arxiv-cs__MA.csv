,abstract,abstract-zh,authors,date,title,title-de,title-zh,url
0,"LLMs are used predominantly in synchronous communication, where a human user and a model communicate in alternating turns. In contrast, many real-world settings are inherently asynchronous. For example, in group chats, online team meetings, or social games, there is no inherent notion of turns; therefore, the decision of when to speak forms a crucial part of the participant's decision making. In this work, we develop an adaptive asynchronous LLM-agent which, in addition to determining what to say, also decides when to say it. To evaluate our agent, we collect a unique dataset of online Mafia games, including both human participants, as well as our asynchronous agent. Overall, our agent performs on par with human players, both in game performance, as well as in its ability to blend in with the other human players. Our analysis shows that the agent's behavior in deciding when to speak closely mirrors human patterns, although differences emerge in message content. We release all our data and code to support and encourage further research for more realistic asynchronous communication between LLM agents. This work paves the way for integration of LLMs into realistic human group settings, from assistance in team discussions to educational and professional environments where complex social dynamics must be navigated.","LLMS主要用于同步通信, 即人类用户和模式交替交流。 相反, 许多真实世界的设置本质上是非同步的。 例如, 在集体聊天、 在线团队会议或社交游戏中, 不存在固有的旋转概念; 因此, 何时发言的决定是参与者决策的关键部分 。 在这项工作中, 我们开发了一个适应性和非同步的LM- 代理, 除了决定要说什么外, 还要决定何时说什么。 为了评估我们的代理, 我们收集了一个独特的网上黑手党游戏数据集, 包括人类参与者, 以及我们的不同步代理。 总的来说, 我们的代理在游戏表演中, 以及与其他人类玩家融合的能力上, 都不存在固有的转折概念。 我们的分析表明, 代理决定何时发言时的行为反映了人类模式, 尽管在信息内容上出现差异。 我们发布所有的数据和代码, 支持并鼓励进一步开展研究, 以便让LMPM 代理进行更现实的同步通信。 这项工作为将LMS 整合到现实的团队的复杂动态环境提供了帮助。","Niv Eckhaus, Uri Berger, Gabriel Stanovsky",2025-06-05T17:53:44Z,Time to Talk: LLM Agents for Asynchronous Group Communication in Mafia   Games,Time to Talk: LLM-Agenten für asynchrone Gruppenkommunikation in Mafia-Spielen,讨论时间:黑手党运动会Asynconomic Group通讯的LLM代理商,http://arxiv.org/abs/2506.05309v1
1,"Effective teamwork is essential across diverse domains. During the team formation stage, a key challenge is forming teams that effectively balance user preferences with task objectives to enhance overall team satisfaction. In the team performing stage, maintaining cohesion and engagement is critical for sustaining high team performance. However, existing computational tools and algorithms for team optimization often rely on static data inputs, narrow algorithmic objectives, or solutions tailored for specific contexts, failing to account for the dynamic interplay of team members personalities, evolving goals, and changing individual preferences. Therefore, teams may encounter member dissatisfaction, as purely algorithmic assignments can reduce members commitment to team goals or experience suboptimal engagement due to the absence of timely, personalized guidance to help members adjust their behaviors and interactions as team dynamics evolve. Ultimately, these challenges can lead to reduced overall team performance. My Ph.D. dissertation aims to develop AI-augmented team optimization frameworks and practical systems that enhance team satisfaction, engagement, and performance. First, I propose a team formation framework that leverages a multi-armed bandit algorithm to iteratively refine team composition based on user preferences, ensuring alignment between individual needs and collective team goals to enhance team satisfaction. Second, I introduce tAIfa (Team AI Feedback Assistant), an AI-powered system that utilizes large language models (LLMs) to deliver immediate, personalized feedback to both teams and individual members, enhancing cohesion and engagement. Finally, I present PuppeteerLLM, an LLM-based simulation framework that simulates multi-agent teams to model complex team dynamics within realistic environments, incorporating task-driven collaboration and long-term coordination.","在团队组建阶段,一个关键的挑战是如何组建团队,使用户偏好与任务目标有效平衡,以提高团队总体满意度。在团队绩效阶段,保持凝聚力和接触对于保持团队高绩效至关重要。然而,现有的团队优化计算工具和算法往往依赖于静态数据投入、狭隘的算法目标或适合具体情况的解决方案,无法说明团队成员个人动态的相互作用、不断变化的目标和个人偏好。因此,团队可能会遇到成员不满,因为纯粹的逻辑性任务可能降低成员对团队目标或工作目标的承诺,从而降低成员对团队目标或工作不优化的承诺,因为缺乏及时、个性化的指导,帮助成员随着团队动态的变化调整行为和互动。归根结底,这些挑战可能导致团队总体绩效的绩效下降。 我的Ph.D. 评分旨在开发AI-建议团队优化框架和实际系统,以提高团队的满意度、参与和业绩。 首先,我提议一个团队组建模块框架,根据用户偏好,确保个人需要和集体团队目标之间保持一致,以便随着团队的动态变化,提高团队的满意度。",Mohammed Almutairi,2025-06-05T17:24:37Z,"Teaming in the AI Era: AI-Augmented Frameworks for Forming, Simulating,   and Optimizing Human Teams","Teaming in der AI-Ära: AI-Augmented Frameworks für die Bildung, Simulation und Optimierung menschlicher Teams",AI时代的团队合作:AI-AF 构建、模拟和优化人类团队的增强框架,http://arxiv.org/abs/2506.05265v1
2,"Machine learning is now ubiquitous in societal decision-making, for example in evaluating job candidates or loan applications, and it is increasingly important to take into account how classified agents will react to the learning algorithms. The majority of recent literature on strategic classification has focused on reducing and countering deceptive behaviors by the classified agents, but recent work of Attias et al. identifies surprising properties of learnability when the agents genuinely improve in order to attain the desirable classification, such as smaller generalization error than standard PAC-learning. In this paper we characterize so-called learnability with improvements across multiple new axes. We introduce an asymmetric variant of minimally consistent concept classes and use it to provide an exact characterization of proper learning with improvements in the realizable setting. While prior work studies learnability only under general, arbitrary agent improvement regions, we give positive results for more natural Euclidean ball improvement sets. In particular, we characterize improper learning under a mild generative assumption on the data distribution. We further show how to learn in more challenging settings, achieving lower generalization error under well-studied bounded noise models and obtaining mistake bounds in realizable and agnostic online learning. We resolve open questions posed by Attias et al. for both proper and improper learning.","在社会决策中,机器学习现已普遍存在,例如在评价求职者或贷款申请时,机器学习现已在社会决策中无处不在,而且越来越重要的是要考虑分类代理人如何对学习算法作出反应。最近关于战略分类的文献大多侧重于减少和打击分类代理人的欺骗行为,但Attias等人最近的工作指出,当代理人为了达到理想的分类而真正改进时,学习能力就具有惊人的特性,例如比标准PAC学习的简单化错误要小一些。在本文中,我们描述所谓的可学习性,并改进了多个新轴。我们引入了最低限度一致概念类的不对称变异,并用它来提供对适当学习的准确描述,在可实现的环境下加以改进。虽然以前的工作研究只在一般、任意的代理人改进地区才具有学习能力,但我们为更自然的Euclidean球改进组合提供了积极的结果。特别是,我们把不适当学习定性在数据分发的较温和的基因化假设之下。我们进一步说明如何在更具挑战性的环境中学习,在经过充分研究的噪音模型下实现较低的一般化错误。我们通过正确和不适当的在线学习来作出正确的选择。","Dravyansh Sharma, Alec Sun",2025-06-05T17:13:59Z,Conservative classifiers do consistently well with improving agents:   characterizing statistical and online learning,Konservative Klassifikatoren tun konsequent gut mit Verbesserung Agenten: Charakterisierung statistischer und Online-Lernen,保守的分类机构与改进机构保持一贯的很好:将统计和在线学习定性为特征,http://arxiv.org/abs/2506.05252v1
3,"Communication is a fundamental aspect of coordinated behavior in multi-agent reinforcement learning. Yet, most prior works in this field have focused on emergent communication protocols developed from scratch, often resulting in inefficient or non-interpretable systems. Inspired by the role of language in natural intelligence, we investigate how grounding agents in a human-defined language can improve learning and coordination of multiple embodied agents. We propose a framework in which agents are trained not only to act but also to produce and interpret natural language descriptions of their observations. This language-augmented learning serves a dual role: enabling explicit communication between agents and guiding representation learning. We demonstrate that agents trained with our method outperform traditional emergent communication baselines across various tasks. Our analysis reveals that language grounding leads to more informative internal representations, better generalization to new partners, and improved capability for human-agent interaction. These findings demonstrate the effectiveness of integrating structured language into multi-agent learning and open avenues for more interpretable and capable multi-agent systems.","多代理人强化学习的协调行为是多代理人强化学习中协调行为的一个基本方面。然而,该领域以前的工作大多侧重于从零开始开发的紧急通信协议,往往导致效率低下或无法解释的系统。在语言在自然智能中的作用的启发下,我们调查以人为定义的语言定位的代理人如何能改善多种体现的代理人的学习和协调。我们提出了一个框架,使代理人不仅能够采取行动,而且能够制作和解释其观察意见的自然语言描述。这种语言强化学习具有双重作用:使代理人之间能够进行明确的沟通,指导代表性学习。我们证明,接受过我们方法培训的代理人超越了各种任务的传统紧急通信基线。我们的分析表明,语言基础化导致更加信息化的内部陈述,更好地概括新的合作伙伴,并提高了人类代理人互动的能力。这些结论表明,将结构化语言纳入多代理人学习和开放的渠道对于更易解释、更有能力的多代理人系统是有效的。","Maxime Toquebiau, Jae-Yun Jun, Faïz Benamar, Nicolas Bredeche",2025-06-05T16:55:52Z,Towards Language-Augmented Multi-Agent Deep Reinforcement Learning,"Auf dem Weg zu einem sprachverstärkten, multiagenten, tiefen Stärkungslernen",走向语文升级多机构深入强化学习,http://arxiv.org/abs/2506.05236v1
4,"Social scientists increasingly use the concept of opportunity hoarding to explain the formation of Black-White educational inequalities. However, this concept is often loosely defined, leading to varied interpretations of the inequality-producing mechanisms it captures. To bring clarity to this valuable sociological concept, this theoretical paper, informed by the concept's original definition and existing empirical research, proposes a more precise definition of opportunity hoarding and formalizes it through a computational model. For concreteness, the model focuses on one context: how White families can hoard access to advanced high school coursework from Black students attending the same school. Through simulations, the paper highlights the necessary and sufficient conditions under which the hoarding of advanced course-taking opportunities emerges. Results demonstrate that, in contrast to traditional accounts, White actors do not need to engage in exclusionary behaviors to hoard valuable resources. Rather, through the byproduct of network segregation and class inequalities, opportunity hoarding can emerge even when individuals act in race-neutral ways -- a process I conceptualize as hoarding without hoarders.","社会科学家越来越多地利用机会囤积的概念来解释黑白教育不平等的形成。然而,这一概念往往定义松散,导致对其所捕捉的不平等产生机制的不同解释。为了澄清这一宝贵的社会学概念,根据概念的原始定义和现有的实证研究,这份理论文件提出了一个更精确的关于机会囤积的定义,并通过一个计算模型将其正规化。关于具体性,模型侧重于一个背景:白人家庭如何能从同一学校的黑人学生手中囤积高级高中课程课程。通过模拟,文件强调了储存先进课程机会所必须和充分的条件。结果表明,与传统账户不同,白人行为者不需要从事排他性行为来囤积宝贵的资源。相反,通过网络隔离和阶级不平等的副产品,即使个人以种族中立的方式行事,机会囤积也可以出现。 我将这一过程概念化为没有囤积者。",João M. Souto-Maior,2025-06-05T15:26:43Z,Conceptualizing educational opportunity hoarding: the emergence of   hoarding without hoarders,Konzeptualisierung der Bildungschancen Horten: das Entstehen von Horten ohne Horten,将教育机遇概念化:囤积:无囤积者的囤积的出现,http://arxiv.org/abs/2305.14653v3
5,"Offline cooperative multi-agent reinforcement learning (MARL) faces unique challenges due to distributional shifts, particularly stemming from the high dimensionality of joint action spaces and the presence of out-of-distribution joint action selections. In this work, we highlight that a fundamental challenge in offline MARL arises from the multi-equilibrium nature of cooperative tasks, which induces a highly multimodal joint behavior policy space coupled with heterogeneous-quality behavior data. This makes it difficult for individual policy regularization to align with a consistent coordination pattern, leading to the policy distribution shift problems. To tackle this challenge, we design a sequential score function decomposition method that distills per-agent regularization signals from the joint behavior policy, which induces coordinated modality selection under decentralized execution constraints. Then we leverage a flexible diffusion-based generative model to learn these score functions from multimodal offline data, and integrate them into joint-action critics to guide policy updates toward high-reward, in-distribution regions under a shared team reward. Our approach achieves state-of-the-art performance across multiple particle environments and Multi-agent MuJoCo benchmarks consistently. To the best of our knowledge, this is the first work to explicitly address the distributional gap between offline and online MARL, paving the way for more generalizable offline policy-based MARL methods.","在这项工作中,我们强调,由于合作任务具有多重平衡性质,因此,离线性MARL在离线性多剂强化学习方面面临一个根本性挑战,因为分配变化,特别是由于联合行动空间的高度多维性和存在分配的联合行动选择。在这项工作中,我们强调,离线性MARL面临一个根本性挑战,因为合作任务具有多重平衡性质,这导致高度多式联运联合行为政策空间,并伴之以不同质量的行为数据。这使得个人政策规范化难以与一致的协调模式保持一致,从而导致政策分配转变问题。为了应对这一挑战,我们设计了一种顺序分数分数分数法,从联合行为政策中提取每个代理人的正规化信号,从而导致在分散执行的限制下以协调的方式选择模式。然后,我们利用一个灵活的基于传播基础的基因化模型,从多式联运离线性数据中学习这些分数功能,并将其纳入联合行动批评者中,以指导政策向高回报、分布区的方向,从而导致政策分配出现问题。为了应对这一挑战,我们的方法在多个粒子环境中实现最先进的业绩表现,多剂 MuJoco基准,这使我们的知识得到最佳的在线分配方式,这是在离MAR通用方法之间的最可靠方法。","Dan Qiao, Wenhao Li, Shanchao Yang, Hongyuan Zha, Baoxiang Wang",2025-06-05T09:41:09Z,Offline Multi-agent Reinforcement Learning via Score Decomposition,Offline-Multi-Agenten-Verstärkung Lernen über Score-Dekomposition,通过计分分分分分分化进行离线多剂强化学习,http://arxiv.org/abs/2505.05968v2
6,"Memory effects play a crucial role in social interactions and decision-making processes. This paper proposes a novel fractional-order bounded confidence opinion dynamics model to characterize the memory effects in system states. Building upon the Hegselmann-Krause framework and fractional-order difference, a comprehensive model is established that captures the persistent influence of historical information. Through rigorous theoretical analysis, the fundamental properties including convergence and consensus is investigated. The results demonstrate that the proposed model not only maintains favorable convergence and consensus characteristics compared to classical opinion dynamics, but also addresses limitations such as the monotonicity of bounded opinions. This enables a more realistic representation of opinion evolution in real-world scenarios. The findings of this study provide new insights and methodological approaches for understanding opinion formation and evolution, offering both theoretical significance and practical applications.","内存效应在社会互动和决策过程中发挥着关键作用。本文件提出了一个新的分级封闭式信任意见动态模型,以描述系统状态中的记忆效应。在Hegselmann-Krause框架和分级顺序差异的基础上,建立了一个综合模型,记录历史信息的持久影响。通过严格的理论分析,对包括趋同和共识在内的基本特性进行了调查。结果显示,拟议的模型不仅保持了与古典观点动态相比的有利趋同和共识特征,而且还解决了约束式观点的单一性等局限性。这样可以更现实地反映现实世界情景中的观点演变。这项研究的结果为理解意见形成和演变提供了新的见解和方法,提供了理论意义和实际应用。","Meiru Jiang, Wei Su, Guojian Ren, Yongguang Yu",2025-06-05T07:23:06Z,Memory-Driven Bounded Confidence Opinion Dynamics: A Hegselmann-Krause   Model Based on Fractional-Order Methods,Memory-Driven Bounded Confidence Opinion Dynamics: Ein Hegselmann-Krause-Modell basierend auf fraktional-Order Methoden,记忆-记忆-记忆破封信任意见动态:基于分形排列法的Hegselmann-Krause模型,http://arxiv.org/abs/2506.04701v1
7,"Recently, Large Language Models (LLMs) and Vision Large Language Models (VLLMs) have demonstrated impressive performance as agents across various tasks while data scarcity and label noise remain significant challenges in computer vision tasks, such as object detection and instance segmentation. A common solution for resolving these issues is to generate synthetic data. However, current synthetic data generation methods struggle with issues, such as multiple objects per mask, inaccurate segmentation, and incorrect category labels, limiting their effectiveness. To address these issues, we introduce Gen-n-Val, a novel agentic data generation framework that leverages Layer Diffusion (LD), LLMs, and VLLMs to produce high-quality, single-object masks and diverse backgrounds. Gen-n-Val consists of two agents: (1) The LD prompt agent, an LLM, optimizes prompts for LD to generate high-quality foreground instance images and segmentation masks. These optimized prompts ensure the generation of single-object synthetic data with precise instance masks and clean backgrounds. (2) The data validation agent, a VLLM, which filters out low-quality synthetic instance images. The system prompts for both agents are refined through TextGrad. Additionally, we use image harmonization to combine multiple instances within scenes. Compared to state-of-the-art synthetic data approaches like MosaicFusion, our approach reduces invalid synthetic data from 50% to 7% and improves performance by 1% mAP on rare classes in COCO instance segmentation with YOLOv9c and YOLO11m. Furthermore, Gen-n-Val shows significant improvements (7. 1% mAP) over YOLO-Worldv2-M in open-vocabulary object detection benchmarks with YOLO11m. Moreover, Gen-n-Val improves the performance of YOLOv9 and YOLO11 families in instance segmentation and object detection.","最近,大语言模型(LLMS)和视觉大语言模型(VLLMS)作为各种任务的代理机构表现出了令人印象深刻的业绩,而数据稀缺和标签噪音仍然是计算机视觉任务中的重大挑战,例如物体探测和实例分割。解决这些问题的一个共同解决办法是生成合成数据。然而,目前的合成数据生成方法与各种问题,例如每面罩多颗物体、不准确的分解和不正确的分类标签等有困难,限制了它们的效力。为了解决这些问题,我们引入了Gen-n-Val,一个新型的代理数据生成框架,利用了层扩散(LD)、LLMS和VLLMMS来生成高质量的、单球面具和不同背景的图像。Gen-n-Val由两种代理机构组成:(1) LDLT加速剂、LLMMM,优化LD的提示来生成高质量的地面图像和分解面罩。这些最优化的提示确保生成带有精确实例面具和清洁背景的单项合成物体合成数据。(2)数据验证工具,VLLM,它过滤了低质量的合成物体图像图像图像、单项9级面面面面面面面面面面面面面面、UPLOLMLMMLMSUS-UD 将实时数据通过我们通过GLOGLS-S-S-S-GLVGMS-S-S-GMS-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-GNLVGLO-S-S-S-S-S-S-O-S-S-S-S-S-S-O-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S","Jing-En Huang, I-Sheng Fang, Tzuhsuan Huang, Chih-Yu Wang, Jun-Cheng Chen",2025-06-05T06:52:26Z,Gen-n-Val: Agentic Image Data Generation and Validation,Gen-n-Val: Gen-n-Val: Agentische Bilddatengenerierung und -validierung,Gen-n-Val: 代理图像数据生成和校验,http://arxiv.org/abs/2506.04676v1
8,"Conventional biomedical research is increasingly labor-intensive due to the exponential growth of scientific literature and datasets. Artificial intelligence (AI), particularly Large Language Models (LLMs), has the potential to revolutionize this process by automating various steps. Still, significant challenges remain, including the need for multidisciplinary expertise, logicality of experimental design, and performance measurements. This paper introduces BioResearcher, the first end-to-end automated system designed to streamline the entire biomedical research process involving dry lab experiments. BioResearcher employs a modular multi-agent architecture, integrating specialized agents for search, literature processing, experimental design, and programming. By decomposing complex tasks into logically related sub-tasks and utilizing a hierarchical learning approach, BioResearcher effectively addresses the challenges of multidisciplinary requirements and logical complexity. Furthermore, BioResearcher incorporates an LLM-based reviewer for in-process quality control and introduces novel evaluation metrics to assess the quality and automation of experimental protocols. BioResearcher successfully achieves an average execution success rate of 63.07% across eight previously unmet research objectives. The generated protocols, on average, outperform typical agent systems by 22.0% on five quality metrics. The system demonstrates significant potential to reduce researchers' workloads and accelerate biomedical discoveries, paving the way for future innovations in automated research systems.","由于科学文献和数据集的成倍增长,常规生物医学研究日益成为劳动力密集型研究。人工智能(AI),特别是大语言模型(LLMS)有可能通过使各种步骤自动化而使这一过程发生革命性变革。然而,依然存在着重大挑战,包括需要多学科的专门知识、实验设计的合理性和性以及性能测量。本文件介绍生物研究(BioResearch),这是第一个端到端自动化系统,旨在精简涉及干实验的整个生物医学研究过程;生物研究(BioResearch)使用模块式多试剂结构,整合了用于搜索、文学处理、实验设计和编程的专门剂。生物研究(BioResearch)将复杂的任务分解成与逻辑相关的子任务,并采用等级学习方法,从而有效地应对多学科要求和逻辑复杂性的挑战。此外,生物研究(BioResearch)采用基于LM(LM)的审查器,用于控制过程质量,并引入新的评估实验协议质量和自动化的评价指标。生物研究(BioResearter)成功地在八个前未完成的研究目标中实现了63.07%的平均执行成功率。生成的规程,平均、超出典型代理研究系统,以22.0提高未来研究质量研究的系统的风险提升了未来系统。","Yi Luo, Linghang Shi, Yihao Li, Aobo Zhuang, Yeyun Gong, Ling Liu, Chen Lin",2025-06-05T05:44:18Z,From Intention To Implementation: Automating Biomedical Research via   LLMs,Von der Absicht zur Umsetzung: Automatisierung der biomedizinischen Forschung über LLMs,从实施目的出发:通过LLMs实现生物医学研究自动化,http://arxiv.org/abs/2412.09429v4
9,"We introduce an Implicit Game-Theoretic MPC (IGT-MPC), a decentralized algorithm for two-agent motion planning that uses a learned value function that predicts the game-theoretic interaction outcomes as the terminal cost-to-go function in a model predictive control (MPC) framework, guiding agents to implicitly account for interactions with other agents and maximize their reward. This approach applies to competitive and cooperative multi-agent motion planning problems which we formulate as constrained dynamic games. Given a constrained dynamic game, we randomly sample initial conditions and solve for the generalized Nash equilibrium (GNE) to generate a dataset of GNE solutions, computing the reward outcome of each game-theoretic interaction from the GNE. The data is used to train a simple neural network to predict the reward outcome, which we use as the terminal cost-to-go function in an MPC scheme. We showcase emerging competitive and coordinated behaviors using IGT-MPC in scenarios such as two-vehicle head-to-head racing and un-signalized intersection navigation. IGT-MPC offers a novel method integrating machine learning and game-theoretic reasoning into model-based decentralized multi-agent motion planning.","我们引入了隐性游戏-理论MPC(IGT-MPC),这是一种分权的双试剂运动规划算法,它使用一种知识价值函数,预测游戏-理论互动结果,作为模型预测控制(MPC)框架内的终端成本到运行功能,指导代理商隐含地说明与其他代理商的互动,并最大限度地奖励他们。这个方法适用于我们作为受制约的动态游戏而形成的竞争性和合作性多试剂运动规划问题。鉴于一种有限的动态游戏,我们随机抽样初步条件并解决普惠制纳什平衡(GNE),以生成一套GNE解决方案的数据集,计算GNE的每次游戏-理论互动的奖励结果。这些数据用于培训简单的神经网络,以预测奖励结果,我们在MPC计划中将这种结果用作终端成本到运行功能。我们用IGT-MPC展示了在两种车辆头对头赛和未发式交叉导航等情景中新出现的竞争和协调行为。IGT-MPC提供了一种新型的方法,将机器学习和游戏-理论推论纳入基于模型分散的多试管规划。","Hansung Kim, Edward L. Zhu, Chang Seok Lim, Francesco Borrelli",2025-06-05T04:38:52Z,Learning Two-agent Motion Planning Strategies from Generalized Nash   Equilibrium for Model Predictive Control,Lernen von Zwei-Agenten-Bewegungsplanungsstrategien aus dem generalisierten Nash-Equilibrium für Modellvorhersagesteuerung,"从一般纳什平衡中学习双剂动力规划战略,用于模型预测控制",http://arxiv.org/abs/2411.13983v4
10,"Compound Al Systems (CAIS) is an emerging paradigm that integrates large language models (LLMs) with external components, such as retrievers, agents, tools, and orchestrators, to overcome the limitations of standalone models in tasks requiring memory, reasoning, real-time grounding, and multimodal understanding. These systems enable more capable and context-aware behaviors by composing multiple specialized modules into cohesive workflows. Despite growing adoption in both academia and industry, the CAIS landscape remains fragmented, lacking a unified framework for analysis, taxonomy, and evaluation. In this survey, we define the concept of CAIS, propose a multi-dimensional taxonomy based on component roles and orchestration strategies, and analyze four foundational paradigms: Retrieval-Augmented Generation (RAG), LLM Agents, Multimodal LLMs (MLLMs), and orchestration-centric architectures. We review representative systems, compare design trade-offs, and summarize evaluation methodologies across these paradigms. Finally, we identify key challenges-including scalability, interoperability, benchmarking, and coordination-and outline promising directions for future research. This survey aims to provide researchers and practitioners with a comprehensive foundation for understanding, developing, and advancing the next generation of system-level artificial intelligence.","综合大型语言模型(LLMs)与外部组成部分(如检索器、代理器、工具和管弦乐团)相结合,以克服独立模型在需要记忆、推理、实时定位和多式联运理解的任务方面的局限性。这些系统通过将多个专门模块组合成具有凝聚力的工作流程,使得行为更有能力和符合实际情况。尽管学术界和工业界日益采用,但CAIS景观仍然支离破碎,缺乏分析、分类和评估的统一框架。在这次调查中,我们界定了CAIS的概念,提出了基于组成部分作用和协同战略的多维分类,并分析了四种基本模式:检索启动型一代(RAG)、LLMMM代理、多模式LMMMS(MLMS)和调控中心架构。我们审查代表性系统,比较设计权衡,并总结了这些模式的评价方法。最后,我们确定了关键的挑战,包括可扩展性、互操作性、基准、协调性以及未来研究的展望方向。本调查旨在为发展研究的研究人员和人造系统提供全面基础、发展基础。","Jiayi Chen, Junyi Ye, Guiling Wang",2025-06-05T02:34:43Z,From Standalone LLMs to Integrated Intelligence: A Survey of Compound Al   Systems,Von Standalone LLMs bis hin zu integrierter Intelligenz: Eine Übersicht über zusammengesetzte Al-Systeme,从独立的LMLM公司到综合情报公司:对Al Complical Systems的调查,http://arxiv.org/abs/2506.04565v1
11,"Optimization is instrumental for improving operations of large-scale socio-technical infrastructures of Smart Cities, for instance, energy and traffic systems. In particular, understanding the performance of multi-agent discrete-choice combinatorial optimization under distributed adversary attacks is a compelling and underexplored problem, since multi-agent systems exhibit a large number of remote control variables that can influence in an unprecedented way the cost-effectiveness of distributed optimization heuristics. This paper unravels for the first time the trajectories of distributed optimization from resilience to vulnerability, and finally to collapse under varying adversary influence. Using real-world data to emulate over 28 billion multi-agent optimization scenarios, we exhaustively assess how the number of agents with different adversarial severity and network positioning influences optimization performance, including the influence on Pareto optimal points. With this novel large-scale dataset, made openly available as a benchmark, we disentangle how optimization remains resilient to adversaries and which adversary conditions are required to make optimization vulnerable or collapsed. These new findings can provide new insights for designing self-healing strategies for fault-tolerance and fault-correction in adversarial distributed optimization that have been missing so far.","优化有助于改善智能城市大规模社会技术基础设施的运作,例如能源和交通系统; 特别是,了解在分布式敌手攻击下多剂离散的混合组合优化的性能是一个令人信服和未得到充分探讨的问题,因为多剂系统展示了大量遥控变量,这些变量能够以前所未有的方式影响分布式优化超强力的成本效益。本文首次揭示了分散式优化的轨迹,从复原力到脆弱性,最终在不同的对手影响下崩溃。利用真实世界数据来模仿280亿多剂优化情景,我们详尽评估了不同对抗性严重程度和网络定位的剂数量如何影响优化性能,包括对Pareto最佳点的影响。有了这一新的大规模数据集,我们公开提供了一个基准,我们分清了优化对对手的适应性如何,以及使优化变得脆弱或崩溃需要对抗性的条件。这些新发现可以提供新的见解,用于设计在分配式对称式优化中错误容忍与错误纠正错误的自愈合战略,而这种战略已经远远丢失了。","Amal Aldawsari, Evangelos Pournaras",2025-06-04T21:56:24Z,"Optimization under Attack: Resilience, Vulnerability, and the Path to   Collapse","Optimierung unter Angriff: Resilienz, Vulnerabilität und der Weg zum Zusammenbruch",最优化遭受攻击:复原力、脆弱性和崩溃之路,http://arxiv.org/abs/2502.05954v2
12,"As AI agents are increasingly adopted to collaborate on complex objectives, ensuring the security of autonomous multi-agent systems becomes crucial. We develop simulations of agents collaborating on shared objectives to study these security risks and security trade-offs. We focus on scenarios where an attacker compromises one agent, using it to steer the entire system toward misaligned outcomes by corrupting other agents. In this context, we observe infectious malicious prompts - the multi-hop spreading of malicious instructions. To mitigate this risk, we evaluated several strategies: two ""vaccination"" approaches that insert false memories of safely handling malicious input into the agents' memory stream, and two versions of a generic safety instruction strategy. While these defenses reduce the spread and fulfillment of malicious instructions in our experiments, they tend to decrease collaboration capability in the agent network. Our findings illustrate potential trade-off between security and collaborative efficiency in multi-agent systems, providing insights for designing more secure yet effective AI collaborations.","随着AI代理商越来越多地被采纳为复杂目标的合作,确保自主多试剂系统的安全变得至关重要。我们开发了为共同目的合作研究这些安全风险和安全权衡的代理商模拟模型。我们侧重于攻击者妥协一个代理商的情景,利用它来引导整个系统通过腐蚀其他代理商而产生错误的结果。在这方面,我们观察了传染性恶意信号-恶意指令的多机会传播。为了减轻这一风险,我们评估了几个战略:两种“防疫”方法,将安全处理恶意输入代理商记忆流的假记忆和两种通用安全指导战略。虽然这些防御方法减少了我们实验中恶意指令的传播和履行,但它们倾向于降低代理商网络的协作能力。我们的调查结果说明了多代理系统安全与协作效率之间的潜在权衡,为设计更加安全有效的AI协作提供了深刻的见解。","Pierre Peigne-Lefebvre, Mikolaj Kniejski, Filip Sondej, Matthieu David, Jason Hoelscher-Obermaier, Christian Schroeder de Witt, Esben Kran",2025-06-04T18:25:06Z,Multi-Agent Security Tax: Trading Off Security and Collaboration   Capabilities in Multi-Agent Systems,Multi-Agent Security Tax: Handel mit Sicherheit und Kollaborationsfähigkeiten in Multi-Agent-Systemen,多机构安全税:多机构系统的安全与合作能力交易,http://arxiv.org/abs/2502.19145v2
13,"Decentralized Partially Observable Markov Decision Processes (Dec-POMDPs) are known to be NEXP-Complete and intractable to solve. However, for problems such as cooperative navigation, obstacle avoidance, and formation control, basic assumptions can be made about local visibility and local dependencies. The work DeWeese and Qu 2024 formalized these assumptions in the construction of the Locally Interdependent Multi-Agent MDP. In this setting, it establishes three closed-form policies that are tractable to compute in various situations and are exponentially close to optimal with respect to visibility. However, it is also shown that these solutions can have poor performance when the visibility is small and fixed, often getting stuck during simulations due to the so called ""Penalty Jittering"" phenomenon. In this work, we establish the Extended Cutoff Policy Class which is, to the best of our knowledge, the first non-trivial class of near optimal closed-form partially observable policies that are exponentially close to optimal with respect to the visibility for any Locally Interdependent Multi-Agent MDP. These policies are able to remember agents beyond their visibilities which allows them to perform significantly better in many small and fixed visibility settings, resolve Penalty Jittering occurrences, and under certain circumstances guarantee fully observable joint optimal behavior despite the partial observability. We also propose a generalized form of the Locally Interdependent Multi-Agent MDP that allows for transition dependence and extended reward dependence, then replicate our theoretical results in this setting.","众所周知,部分可观察的离散Markov 决策程序(Dec-POMDPs)是NEXP-Complite 和难以解决的问题,但是,对于合作导航、避免障碍和形成控制等问题,可以对当地可见度和地方依赖性进行基本假设。Deweese和Qu 2024的工作将这些假设正式化了,以构建地方互依赖的多位代理MDP。在这一背景下,它确立了三种封闭式的封闭式政策,可以在不同情况下进行计算,并且非常接近于能见度的最佳程度。然而,还表明,当能见度小而固定时,这些解决方案的性能可能很差,而且往往由于所谓的“潘蒂·希贝克”现象而在模拟期间被固定地固定下来。在这项工作中,我们建立了扩大的封闭式政策等级,这是我们所了解的第一个非三角的最佳封闭式部分可观察性政策,与任何地方互依赖的多度多位DP的能见度非常接近最佳的能见度相当。这些政策还表明,当其可见性很小时,这些办法可能会造成不良的性,而且往往会由于所谓的“潘”现象而使得这种不稳性能保持某种最佳的稳定性。","Alex DeWeese, Guannan Qu",2025-06-04T17:57:30Z,Thinking Beyond Visibility: A Near-Optimal Policy Framework for Locally   Interdependent Multi-Agent MDPs,Über die Sichtbarkeit hinaus denken: Ein nahezu optimaler politischer Rahmen für lokal voneinander abhängige Multi-Agenten-MDPs,超越可见度的思考:关于地方相互依存的多需要多方驱动的近最佳政策框架,http://arxiv.org/abs/2506.04215v1
14,"AI for Industrial Asset Lifecycle Management aims to automate complex operational workflows -- such as condition monitoring, maintenance planning, and intervention scheduling -- to reduce human workload and minimize system downtime. Traditional AI/ML approaches have primarily tackled these problems in isolation, solving narrow tasks within the broader operational pipeline. In contrast, the emergence of AI agents and large language models (LLMs) introduces a next-generation opportunity: enabling end-to-end automation across the entire asset lifecycle. This paper envisions a future where AI agents autonomously manage tasks that previously required distinct expertise and manual coordination. To this end, we introduce AssetOpsBench -- a unified framework and environment designed to guide the development, orchestration, and evaluation of domain-specific agents tailored for Industry 4.0 applications. We outline the key requirements for such holistic systems and provide actionable insights into building agents that integrate perception, reasoning, and control for real-world industrial operations. The software is available at https://github.com/IBM/AssetOpsBench.","工业资产生命周期管理大赦国际旨在将复杂的工作流程自动化 -- -- 如条件监测、维护规划和干预时间安排 -- -- 以减少人的工作量和尽量减少系统故障时间;传统的AI/ML方法主要孤立地处理这些问题,在更广泛的业务管道内解决狭隘的任务;相比之下,AI代理商和大型语言模型的出现带来了下一代机会:在整个资产生命周期内促成端到端自动化;本文件设想了这样一个未来,即AI代理商自主地管理以前需要不同专门知识和人工协调的任务。为此,我们引入了AssetOpsBench -- -- 一个统一框架和环境,旨在指导为工业4.0应用量身定制的域专用代理商的发展、协调和评价。我们概述了这种整体系统的关键要求,并为建筑代理商提供可操作的见解,将现实世界工业业务的观念、推理和控制结合起来。软件可在https://github.com/IBM/AsseetOpsbench查阅。","Dhaval Patel, Shuxin Lin, James Rayfield, Nianjun Zhou, Roman Vaculin, Natalia Martinez, Fearghal O'donncha, Jayant Kalagnanam",2025-06-04T10:57:35Z,AssetOpsBench: Benchmarking AI Agents for Task Automation in Industrial   Asset Operations and Maintenance,AssetOpsBench: Benchmarking von KI-Agenten für die Task-Automatisierung im industriellen Asset-Betrieb und in der Wartung,AssetOpsBench:为工业资产业务和维护任务自动化确定AI代理基准,http://arxiv.org/abs/2506.03828v1
15,"Traditional Business Process Management (BPM) struggles with rigidity, opacity, and scalability in dynamic environments while emerging Large Language Models (LLMs) present transformative opportunities alongside risks. This paper explores four real-world use cases that demonstrate how LLMs, augmented with trustworthy process intelligence, redefine process modeling, prediction, and automation. Grounded in early-stage research projects with industrial partners, the work spans manufacturing, modeling, life-science, and design processes, addressing domain-specific challenges through human-AI collaboration. In manufacturing, an LLM-driven framework integrates uncertainty-aware explainable Machine Learning (ML) with interactive dialogues, transforming opaque predictions into auditable workflows. For process modeling, conversational interfaces democratize BPMN design. Pharmacovigilance agents automate drug safety monitoring via knowledge-graph-augmented LLMs. Finally, sustainable textile design employs multi-agent systems to navigate regulatory and environmental trade-offs. We intend to examine tensions between transparency and efficiency, generalization and specialization, and human agency versus automation. By mapping these trade-offs, we advocate for context-sensitive integration prioritizing domain needs, stakeholder values, and iterative human-in-the-loop workflows over universal solutions. This work provides actionable insights for researchers and practitioners aiming to operationalize LLMs in critical BPM environments.","本文探讨四个现实世界使用的案例,这些案例展示了LLMM如何以值得信赖的过程情报、重新定义过程模型、预测和自动化加以增强; 以工业伙伴的早期研究项目为基础,工作范围包括制造、建模、生命科学和设计过程,通过人类-AI合作解决特定领域的挑战; 在制造业,由LLM驱动的框架将具有可解释性的不确定性的机器学习(ML)与互动对话相结合,将不透明的预测转化为可审计工作流程; 在程序建模方面,对话界面使BPMN设计民主化; 药效调和代理自动化药物安全监测,通过知识-绘图推荐LMMMs进行; 最后,可持续纺织设计采用多试系统,以管理监管和环境交易; 我们打算研究透明度和效率、一般化和专业化以及人力资源与自动化之间的紧张关系; 通过绘制这些取舍的图解,我们倡导将这种对背景敏感的一体化,使BPM工作流程成为对领域需要的民主化。","Peter Pfeiffer, Alexander Rombach, Maxim Majlatow, Nijat Mehdiyev",2025-06-04T10:12:09Z,"From Theory to Practice: Real-World Use Cases on Trustworthy LLM-Driven   Process Modeling, Prediction and Automation","Von der Theorie zur Praxis: Real-World Use Cases on Trustworthy LLM-Driven Process Modeling, Prediction and Automation",从理论到实践:关于可信赖的LLM-驱动过程建模、预测和自动化的真实世界使用案例,http://arxiv.org/abs/2506.03801v1
16,"The origins of economic behavior remain unresolved-not only in the social sciences but also in AI, where dominant theories often rely on predefined incentives or institutional assumptions. Contrary to the longstanding myth of barter as the foundation of exchange, converging evidence from early human societies suggests that reciprocity-not barter-was the foundational economic logic, enabling communities to sustain exchange and social cohesion long before formal markets emerged. Yet despite its centrality, reciprocity lacks a simulateable and cognitively grounded account. Here, we introduce a minimal behavioral framework based on three empirically supported cognitive primitives-individual recognition, reciprocal credence, and cost--return sensitivity-that enable agents to participate in and sustain reciprocal exchange, laying the foundation for scalable economic behavior. These mechanisms scaffold the emergence of cooperation, proto-economic exchange, and institutional structure from the bottom up. By bridging insights from primatology, developmental psychology, and economic anthropology, this framework offers a unified substrate for modeling trust, coordination, and economic behavior in both human and artificial systems.","经济行为的起源不仅在社会科学方面仍然没有解决,而且在AI中也没有解决。 AI中,占主导地位的理论往往依赖预先确定的激励或体制假设。 与长期以来以易货交易作为交换基础的神话相反,早期人类社会汇集的证据表明,互惠而非易货交易是基础性经济逻辑,使社区能够在正式市场出现之前很久维持交流和社会凝聚力。 然而,尽管其中心地位,互惠缺乏可模拟和基于认知的账户。 在这里,我们引入了基于三种经验支持的认知原始人 — — 个人认知、对等依赖和成本回报敏感度 — — 的最低行为框架,使代理人能够参与和维持互惠交流,为可扩展的经济行为奠定基础。 这些机制将合作、原始经济交流和体制结构的出现隐藏在自下而上。 通过弥合从原始学、发展心理学和经济人类学的洞察力,这一框架为人类和人工系统的信任、协调和经济行为的建模提供了统一的基底。",Egil Diau,2025-06-04T09:19:16Z,The Cognitive Foundations of Economic Exchange: A Modular Framework   Grounded in Behavioral Evidence,"Kognitive Grundlagen des wirtschaftlichen Austauschs: Ein modularer Rahmen, der in Verhaltensnachweisen begründet ist",经济交流认知基础:行为证据的模块框架,http://arxiv.org/abs/2505.02945v3
17,"Advancements in generative models have enabled multi-agent systems (MAS) to perform complex virtual tasks such as writing and code generation, which do not generalize well to physical multi-agent robotic teams. Current frameworks often treat agents as conceptual task executors rather than physically embodied entities, and overlook critical real-world constraints such as spatial context, robotic capabilities (e.g., sensing and navigation). To probe this gap, we reconfigure and stress-test a hierarchical multi-agent robotic team built on the CrewAI framework in a simulated emergency department onboarding scenario. We identify five persistent failure modes: role misalignment; tool access violations; lack of in-time handling of failure reports; noncompliance with prescribed workflows; bypassing or false reporting of task completion. Based on this analysis, we propose three design guidelines emphasizing process transparency, proactive failure recovery, and contextual grounding. Our work informs the development of more resilient and robust multi-agent robotic systems (MARS), including opportunities to extend virtual multi-agent frameworks to the real world.","基因模型的进步使多试剂系统(MAS)能够执行复杂的虚拟任务,如写作和代码生成,这些任务并不向物理多试剂机器人团队全面推广。目前的框架往往将代理商视为概念任务执行者,而不是实际体现的实体,忽视了空间环境、机器人能力(例如遥感和导航)等关键的现实世界制约因素。为探索这一差距,我们在模拟紧急登机部的模拟紧急情况假设中重新配置并测试了以CrewAI框架为基础的一个等级级多试剂机器人小组。我们确定了五种持续的失败模式:角色不匹配;工具准入违规;不及时处理故障报告;不遵守规定的工作流程;绕过或错误地报告任务完成情况。我们根据这一分析,提出了三项设计准则,强调程序透明度、主动故障恢复和背景定位。我们的工作为开发更具弹性和强大的多试剂机器人系统提供了信息,包括将虚拟多试剂框架推广到真实世界的机会。","Yuanchen Bai, Zijian Ding, Angelique Taylor",2025-06-04T04:05:38Z,From Virtual Agents to Robot Teams: A Multi-Robot Framework Evaluation   in High-Stakes Healthcare Context,Von virtuellen Agenten zu Roboterteams: Eine Multi-Roboter-Rahmenbewertung im High-Stakes-Gesundheitskontext,从虚拟代理机构到机器人团队:高保健背景下的多机器人框架评价,http://arxiv.org/abs/2506.03546v1
18,"Current large language model (LLM) agents lack authentic human psychological processes necessary for genuine digital twins and social AI applications. To address this limitation, we present a computational implementation of Global Workspace Theory (GNWT) that integrates human cognitive architecture principles into LLM agents, creating specialized sub-agents for emotion, memory, social norms, planning, and goal-tracking coordinated through a global workspace mechanism. However, authentic digital twins require accurate personality initialization. We therefore develop a novel adventure-based personality test that evaluates true personality through behavioral choices within interactive scenarios, bypassing self-presentation bias found in traditional assessments. Building on these innovations, our CogniPair platform enables digital twins to engage in realistic simulated dating interactions and job interviews before real encounters, providing bidirectional cultural fit assessment for both romantic compatibility and workplace matching. Validation using 551 GNWT-Agents and Columbia University Speed Dating dataset demonstrates 72% correlation with human attraction patterns, 77.8% match prediction accuracy, and 74% agreement in human validation studies. This work advances psychological authenticity in LLM agents and establishes a foundation for intelligent dating platforms and HR technology solutions.","目前大型语言模式(LLM)代理商缺乏真正数字双胞胎和社会AI应用所需的真实人类心理过程。为了应对这一局限性,我们介绍了全球工作空间理论(GNWT)的计算实施,该理论将人类认知架构原则纳入LLM代理商,为情感、记忆、社会规范、规划和通过全球工作空间机制协调的目标跟踪创建了专门的子代理商。然而,真正的数字双胞胎需要准确的个性初始化。因此,我们开发了一个基于冒险的性格测试,通过互动情景中的行为选择评估真实人格,绕过传统评估中发现的自我展示偏见。基于这些创新,我们的CogniPair平台使数字双胞胎能够在真正相遇之前进行现实的模拟约会互动和工作面试,为浪漫兼容性和工作场所匹配提供双向文化匹配评估。使用551 GNWT-Agents和哥伦比亚大学速度数据集显示72%与人类吸引模式、77.8%的预测准确性以及74%的人类验证研究协议。这项工作在LLM代理商的心理真实性的基础上,并为智能约会平台和人权技术解决方案奠定基础。","Wanghao Ye, Sihan Chen, Yiting Wang, Shwai He, Bowei Tian, Guoheng Sun, Ziyi Wang, Ziyao Wang, Yexiao He, Zheyu Shen, Meng Liu, Yuning Zhang, Meng Feng, Yang Wang, Siyuan Peng, Yilong Dai, Zhenle Duan, Hanzhang Qin, Ang Li",2025-06-04T03:54:30Z,CogniPair: From LLM Chatbots to Conscious AI Agents -- GNWT-Based   Multi-Agent Digital Twins for Social Pairing -- Dating & Hiring Applications,CogniPair: Von LLM-Chatbots zu bewussten KI-Agenten -- GNWT-basierte Multi-Agenten-Digital Twins für Social Pairing -- Dating & Hiring-Anwendungen,CogniPair:从LLM Chatbots到有意识的AI代理 -- -- 以GNWT为基础的多代理数字双对促进社会公平 -- -- 约会和雇用应用,http://arxiv.org/abs/2506.03543v1
19,"Designing effective reward functions in multi-agent reinforcement learning (MARL) is a significant challenge, often leading to suboptimal or misaligned behaviors in complex, coordinated environments. We introduce Multi-agent Reinforcement Learning from Multi-phase Human Feedback of Mixed Quality ($\text{M}^3\text{HF}$), a novel framework that integrates multi-phase human feedback of mixed quality into the MARL training process. By involving humans with diverse expertise levels to provide iterative guidance, $\text{M}^3\text{HF}$ leverages both expert and non-expert feedback to continuously refine agents' policies. During training, we strategically pause agent learning for human evaluation, parse feedback using large language models to assign it appropriately and update reward functions through predefined templates and adaptive weights by using weight decay and performance-based adjustments. Our approach enables the integration of nuanced human insights across various levels of quality, enhancing the interpretability and robustness of multi-agent cooperation. Empirical results in challenging environments demonstrate that $\text{M}^3\text{HF}$ significantly outperforms state-of-the-art methods, effectively addressing the complexities of reward design in MARL and enabling broader human participation in the training process.","在多试剂强化学习(MARL)中设计有效的奖赏功能是一项重大挑战,往往导致在复杂、协调的环境中出现不最优化或不匹配的行为。我们引入了多试剂强化学习,从混合质量的多阶段人类反馈中进行(text{M3\ text{HF}$),这是一个新颖的框架,将混合质量的多阶段人类反馈纳入多阶段人类学习过程。通过让具有不同专业知识水平的人参与提供迭接指导,$\text{M3\ text{HF}在具有挑战性的环境中利用专家和非专家反馈不断完善代理人的政策。在培训期间,我们从战略上暂停代理人学习人类评价,利用大语言模型分析反馈,通过预先定义的模板和适应权重来适当分配和更新奖励功能,方法是使用重量衰减和基于绩效的调整。我们的方法使得不同质量层次的人类洞察力得以整合,提高多剂合作的可解释性和稳健性。在富有挑战性的环境中取得的经验性结果表明,在更广泛的人力奖赏设计方法中,有效地处理较复杂的参与。","Ziyan Wang, Zhicheng Zhang, Fei Fang, Yali Du",2025-06-04T02:00:12Z,M3HF: Multi-agent Reinforcement Learning from Multi-phase Human Feedback   of Mixed Quality,M3HF: Multi-Agenten-Verstärkung Lernen aus mehrphasigen menschlichen Feedbacks gemischter Qualität,M3HF:从人类对混合质量的多阶段反馈反馈中学习多试剂加强学习,http://arxiv.org/abs/2503.02077v3
20,"Natural disasters have caused significant losses to human society, and the timely and efficient acquisition of post-disaster environmental information is crucial for the effective implementation of rescue operations. Due to the complexity of post-disaster environments, existing sensing technologies face challenges such as weak environmental adaptability, insufficient specialized sensing capabilities, and limited practicality of sensing solutions. This paper explores the heterogeneous multi-agent online autonomous collaborative scheduling algorithm HoAs-PALN, aimed at achieving efficient collection of post-disaster environmental information. HoAs-PALN is realized through adaptive dimensionality reduction in the matching process and local Nash equilibrium game, facilitating autonomous collaboration among time-dependent UAVs, workers and vehicles to enhance sensing scheduling. (1) In terms of adaptive dimensionality reduction during the matching process, HoAs-PALN significantly reduces scheduling decision time by transforming a five-dimensional matching process into two categories of three-dimensional matching processes; (2) Regarding the local Nash equilibrium game, HoAs-PALN combines the softmax function to optimize behavior selection probabilities and introduces a local Nash equilibrium determination mechanism to ensure scheduling decision performance. Finally, we conducted detailed experiments based on extensive real-world and simulated data. Compared with the baselines (GREEDY, K-WTA, MADL and MARL), HoAs-PALN improves task completion rates by 64.12%, 46.48%, 16.55%, and 14.03% on average, respectively, while each online scheduling decision takes less than 10 seconds, demonstrating its effectiveness in dynamic post-disaster environments.","由于灾后环境的复杂性,现有遥感技术面临各种挑战,例如环境适应能力薄弱、专业遥感能力不足、以及遥感解决方案的实用性有限等。本文探讨了多种多试性在线自主排期算法HoAs-PALN,目的是有效地收集灾后环境信息。HAS-PALN通过在匹配过程和当地纳什平衡游戏中适应性地减少行为选择概率和引入本地纳什平衡确定机制来确保决策性业绩的时间安排,实现了HAS-PALN。 (1)在匹配过程中,从适应性维度减少方面,HAS-PALN显著缩短了决策时间,将五维匹配进程转化为两类三维匹配进程;(2)关于本地纳什平衡游戏,HAs-PALN将软式功能结合起来,以优化行为选择概率和地方纳什平衡游戏,引入本地纳什平衡确定机制,以确保根据广泛实际、平均比例、最低水平、最低水平、最低水平、最低水平、最低水平、最低水平、最低水平,分别对实际水平、最低水平、最低水平、最低水平、最低水平进行详细测试。","Lei Han, Yitong Guo, Pengfei Yang, Zhiyong Yu, Liang Wang, Quan Wang, Zhiwen Yu",2025-06-04T01:58:05Z,"Autonomous Collaborative Scheduling of Time-dependent UAVs, Workers and   Vehicles for Crowdsensing in Disaster Response","Autonome kollaborative Planung von zeitabhängigen UAVs, Arbeitern und Fahrzeugen für Crowdsensing in Katastrophenreaktion",灾害应对中需要时间的无人驾驶航空器、工人和车辆用于人群遥感的自动合作安排,http://arxiv.org/abs/2506.04276v1
21,"Effective group decision-making is critical in Multi-Agent Systems (MAS). Yet, how different mechanisms for reaching consensus impact collaboration quality and efficiency remains understudied. We conduct a systematic study on group decision-making mechanisms in a decentralized setting. Through controlled experiments, we analyze how different voting rules affect decision quality and efficiency in a multi-round collaboration. Results reveal that majority voting often cause inefficient collaboration due to its strict acceptance criteria. At the extreme, unanimous voting gives 87% lower initial performance than the best-performing method. Our qualitative analysis of cross-agent communication shows that messages become longer and more repetitive over time: while message length increases by 84%, similarity to the previous round increases to 90%. Based on these insights, language-based early stopping methods make the performance 13% closer to oracle while reducing rounds by 50%. Our findings highlight the crucial role of group decision-making in optimizing MAS collaboration.","有效的群体决策在多机构系统(MAS)中至关重要。然而,达成共识的不同机制对协作质量和效率的影响影响影响程度和效率如何仍然没有得到充分研究。我们在一个分散的环境中对集团决策机制进行系统研究。我们通过受控制的实验,分析不同的投票规则如何影响多层次合作的决策质量和效率。结果显示,多数投票往往因其严格的接受标准而导致效率低下的合作。在极端的情况下,一致投票使初期业绩比最佳业绩方法低87%。我们对跨机构通信的质量分析表明,信息随着时间推移而变得更长,重复性也更大:信息长度增加了84%,与上一轮相似程度增加到90%。基于这些洞见,基于语言的早期停止方法使13%的绩效接近于交汇点,同时将回合减少50%。我们的调查结果强调了集团决策在优化MAS合作方面的关键作用。","Young-Min Cho, Raphael Shu, Nilaksh Das, Tamer Alkhouli, Yi-An Lai, Jason Cai, Monica Sunkara, Yi Zhang, Dan Roth",2025-06-03T22:35:00Z,RoundTable: Investigating Group Decision-Making Mechanism in Multi-Agent   Collaboration,RoundTable: Untersuchung des Entscheidungsmechanismus der Gruppe für die Zusammenarbeit mit mehreren Akteuren,圆桌会议:多方机构合作调查组决策机制,http://arxiv.org/abs/2411.07161v2
22,"Compound AI systems, comprising multiple interacting components such as LLMs, foundation models, and external tools, have demonstrated remarkable improvements compared to single models in various tasks. To ensure their effective deployment in real-world applications, aligning these systems with human preferences is crucial. However, aligning the compound system via policy optimization, unlike the alignment of a single model, is challenging for two main reasons: (i) non-differentiable interactions between components make end-to-end gradient-based optimization method inapplicable, and (ii) system-level preferences cannot be directly transformed into component-level preferences. To address these challenges, we first formulate compound AI systems as Directed Acyclic Graphs (DAGs), explicitly modeling both component interactions and the associated data flows. Building on this formulation, we introduce $\textbf{SysDPO}$, a framework that extends Direct Preference Optimization (DPO) to enable joint system-level alignment. We propose two variants, SysDPO-Direct and SysDPO-Sampling, tailored for scenarios depending on whether we construct a system-specific preference dataset. We empirically demonstrate the effectiveness of our approach across two applications: the joint alignment of a language model and a diffusion model, and the joint alignment of an LLM collaboration system.","由LLMM、基础模型和外部工具等多个互动组成部分组成的复合AI系统,与各种任务中的单一模型相比,已经显示出显著的改进。为确保在现实世界应用中有效部署这些系统,使这些系统与人类偏好相匹配至关重要。然而,通过政策优化调整复合系统,与单一模型的一致不同,具有挑战性,主要原因有两大:(一)各组成部分之间互不区别的互动使得端对端梯度优化方法无法适用,以及(二)系统一级的偏好不能直接转化为组成部分一级的偏好。为了应对这些挑战,我们首先开发复合AI系统,作为定向循环图(DAGs),明确模拟各组成部分的相互作用和相关数据流。我们在此公式的基础上,引入了美元(textbf{SysDPO}$)的组合系统组合系统,这是一个扩展直接偏差优化(DPO)框架,以便能够实现联合系统一级的协调。我们提出了两种变式,即SysDPO-Direct和SysDPO-Samping,根据我们是否建立系统特定模式的模型扩散数据集而根据两种应用而专门设计,我们共同展示了两种应用的LLSAL调整方法。","Xiangwen Wang, Yibo Jacky Zhang, Zhoujie Ding, Katherine Tsai, Haolun Wu, Sanmi Koyejo",2025-06-03T20:03:48Z,Aligning Compound AI Systems via System-level DPO,Ausrichtung von Compound AI-Systemen über DPO-Systeme auf Systemebene,通过全系统一级的DPO对调大院AI系统,http://arxiv.org/abs/2502.17721v2
23,"We investigate the algorithmic problem of uniformly dispersing a swarm of robots in an unknown, gridlike environment. In this setting, our goal is to study the relationships between performance metrics and robot capabilities. We introduce a formal model comparing dispersion algorithms based on makespan, traveled distance, energy consumption, sensing, communication, and memory. Using this framework, we classify uniform dispersion algorithms according to their capability requirements and performance. We prove that while makespan and travel can be minimized in all environments, energy cannot, if the swarm's sensing range is bounded. In contrast, we show that energy can be minimized by ``ant-like'' robots in synchronous settings and asymptotically minimized in asynchronous settings, provided the environment is topologically simply connected, by using our ``Find-Corner Depth-First Search'' (FCDFS) algorithm. Our theoretical and experimental results show that FCDFS significantly outperforms known algorithms. Our findings reveal key limitations in designing swarm robotics systems for unknown environments, emphasizing the role of topology in energy-efficient dispersion.","我们调查了在未知的网状环境中统一分散成群的机器人的算法问题。 在这种环境下, 我们的目标是研究性能量度和机器人能力之间的关系。 我们引入了一种正式模型, 比较基于 manspan、 移动的距离、 能源消耗、 感知、 通讯和记忆的分散算法。 我们使用这个框架, 根据它们的能力要求和性能, 将统一的分散算法分类。 我们证明, 在制造和旅行可以在所有环境中都尽量缩小, 能量是无法的, 如果将群状的感测范围捆绑在一起的话。 相反, 我们的发现表明, 在设计未知环境中的热量机器人系统时, 可以用“ ant- like” 机器人来最小化能量, 并且以无同步的设置为最小化, 只要环境在表面学上是简单的连接, 我们的理论和实验结果显示, FCDFSFSF 大大超出已知的算法。 我们的发现, 在设计未知环境中的热量机器人系统时, 在设计中存在着关键性的局限性, 强调了顶层学在节能分布中所起的作用 。","Michael Amir, Alfred M. Bruckstein",2025-06-03T17:42:56Z,"Time, Travel, and Energy in the Uniform Dispersion Problem","Zeit, Reise und Energie im einheitlichen Dispersionsproblem",统一分布问题中的时间、旅行和能源,http://arxiv.org/abs/2404.19564v2
24,"Traditional AI safety evaluations on isolated LLMs are insufficient as multi-agent AI ensembles become prevalent, introducing novel emergent risks. This paper introduces the Multi-Agent Emergent Behavior Evaluation (MAEBE) framework to systematically assess such risks. Using MAEBE with the Greatest Good Benchmark (and a novel double-inversion question technique), we demonstrate that: (1) LLM moral preferences, particularly for Instrumental Harm, are surprisingly brittle and shift significantly with question framing, both in single agents and ensembles. (2) The moral reasoning of LLM ensembles is not directly predictable from isolated agent behavior due to emergent group dynamics. (3) Specifically, ensembles exhibit phenomena like peer pressure influencing convergence, even when guided by a supervisor, highlighting distinct safety and alignment challenges. Our findings underscore the necessity of evaluating AI systems in their interactive, multi-agent contexts.","对孤立的LLMs进行传统的AI安全评价是不够的,因为多试剂AI联合体变得很普遍,带来新的新风险。本文件介绍了多代理新兴行为评价(MAEBE)框架,以系统评估此类风险。我们利用MAEBE和最伟大的良好基准(以及一种新型的双重反向问题技术)来证明:(1)LLM道德偏好,特别是工具伤害的道德偏好,在单一代理体和组合体中都令人惊讶地变得脆弱,随着问题设置而发生重大变化。 (2)LLM联合体的道德推理不能直接从新出现的集团动态造成的孤立的代理体行为中预见出来。(3)具体地说,集合体展示了影响趋同的同行压力等现象,即使由上司指导,也突出了不同的安全和一致性挑战。我们的调查结果强调,有必要在其互动的多剂环境中评价AI系统。","Sinem Erisken, Timothy Gothard, Martin Leitgab, Ram Potham",2025-06-03T16:33:47Z,MAEBE: Multi-Agent Emergent Behavior Framework,MAEBE: Multi-Agent Emergent Behavior Framework,多边代理新兴行为框架,http://arxiv.org/abs/2506.03053v1
25,"Large Language Model (LLM) based multi-agent systems have shown remarkable performance in various tasks, especially when enhanced through collaborative communication. However, current methods often rely on a fixed number of agents and static communication structures, limiting their ability to adapt to varying task complexities. In this paper, we propose Adaptive Graph Pruning (AGP), a novel task-adaptive multi-agent collaboration framework that jointly optimizes agent quantity (hard-pruning) and communication topology (soft-pruning). Specifically, our method employs a two-stage training strategy: firstly, independently training soft-pruning networks for different agent quantities to determine optimal agent-quantity-specific complete graphs and positional masks across specific tasks; and then jointly optimizing hard-pruning and soft-pruning within a maximum complete graph to dynamically configure the number of agents and their communication topologies per task. Extensive experiments demonstrate that our approach is: (1) High-performing, achieving state-of-the-art results across six benchmarks and consistently generalizes across multiple mainstream LLM architectures, with a increase in performance of $2.58\%\sim 9.84\%$; (2) Task-adaptive, dynamically constructing optimized communication topologies tailored to specific tasks, with an extremely high performance in all three task categories (general reasoning, mathematical reasoning, and code generation); (3) Token-economical, having fewer training steps and token consumption at the same time, with a decrease in token consumption of $90\%+$; and (4) Training-efficient, achieving high performance with very few training steps compared with other methods. The performance will surpass the existing baselines after about ten steps of training under six benchmarks.","以大型语言模型(LLM)为基础的大型多试剂系统在各种任务中表现显著,特别是在通过协作通信而得到加强的情况下。然而,目前的方法往往依赖固定数量的代理商和静态通信结构,从而限制了它们适应不同任务复杂性的能力。在本文件中,我们建议采用适应性图形普鲁宁(AGP),这是一个新颖的任务适应性多试剂协作框架,共同优化代理商数量(硬调整)和通信地形(软调整)。具体地说,我们的方法采用一个两阶段培训战略:首先,独立培训不同代理商数量的软运行网络,以确定最佳的代理商-q具体数量完整图表和定位掩体,从而确定具体任务的最佳性能;然后,在最大完整图表中联合优化硬调整和软运行,以便动态地配置代理商数量及其通信结构(软调整)。 广泛的实验表明,我们的方法是:(1) 高绩效,在六个基准中达到最先进的标准,在多个主流LLM结构中持续地将最低的消费基准进行比较,将业绩提高2.5-QQ-eximal 完整完整完整的图表;在最高标准上,在最高标准上,在最高级培训中实现最高水平和最精确的顺序上,在最精确的进度上,在最精确的进度上,在最精确的排序上,在最精确的排序上,在最精确地进行最精确地推。","Boyi Li, Zhonghan Zhao, Der-Horng Lee, Gaoang Wang",2025-06-03T14:46:00Z,Adaptive Graph Pruning for Multi-Agent Communication,Adaptives Graph Pruning für Multi-Agent Kommunikation,多机构通信调节图,http://arxiv.org/abs/2506.02951v1
26,"This paper presents ThinkTank, a comprehensive and scalable framework designed to transform specialized AI agent systems into versatile collaborative intelligence platforms capable of supporting complex problem-solving across diverse domains. ThinkTank systematically generalizes agent roles, meeting structures, and knowledge integration mechanisms by adapting proven scientific collaboration methodologies. Through role abstraction, generalization of meeting types for iterative collaboration, and the integration of Retrieval-Augmented Generation with advanced knowledge storage, the framework facilitates expertise creation and robust knowledge sharing. ThinkTank enables organizations to leverage collaborative AI for knowledge-intensive tasks while ensuring data privacy and security through local deployment, utilizing frameworks like Ollama with models such as Llama3.1. The ThinkTank framework is designed to deliver significant advantages in cost-effectiveness, data security, scalability, and competitive positioning compared to cloud-based alternatives, establishing it as a universal platform for AI-driven collaborative problem-solving. The ThinkTank code is available at https://github.com/taugroup/ThinkTank","本文介绍“ThinkTank”这一全面且可扩展的框架,这一框架旨在将专门的AI代理系统转化为多用途合作情报平台,能够支持解决不同领域的复杂问题。“Think”通过调整经过实践证明的科学合作方法,系统地概括代理作用、会议结构和知识整合机制。通过角色抽象化、迭代协作会议类型普遍化以及将“再获取型启动型”与先进知识储存相结合,该框架促进了专门知识的创造和强有力的知识共享。“ThinkTank”使各组织能够利用合作AI开展知识密集型工作,同时利用Ollama等框架,利用Llama3.1等模型确保数据隐私和安全。“ThinkTank”框架旨在提供成本效益、数据安全性、可缩放性和竞争性定位方面的重大优势,将其建立为由AI驱动的协作解决问题的普遍平台。“ThinkTank”代码可在https://github.com/toug/ThinkTankTank网站上查阅。","Praneet Sai Madhu Surabhi, Dheeraj Reddy Mudireddy, Jian Tao",2025-06-03T14:32:48Z,ThinkTank: A Framework for Generalizing Domain-Specific AI Agent Systems   into Universal Collaborative Intelligence Platforms,ThinkTank: Ein Framework zur Generalisierung von Domain-spezifischen AI-Agenten-Systemen in universelle Kollaborative Intelligence-Plattformen,ThinkTank:将特定域内AI 代理系统普遍化为全球合作情报平台的框架,http://arxiv.org/abs/2506.02931v1
27,"Picker-to-parts pallet warehouses often face inefficiencies due to conventional layouts causing excessive travel distances and high labor requirements. This study introduces a novel layout design inspired by CPU architecture, partitioning warehouse space into specialized zones, namely Performance (P), Efficiency (E), and Shared (S). Discrete-event simulation is used to evaluate this design against traditional rectangular (random and ABC storage) and Flying-V layouts. Results demonstrate significant improvements in throughput time and reduced labor requirements, highlighting the potential for CPU-based layouts in optimizing warehouse operations.","Picker-Parts 托盘仓库经常面临效率低下的问题,因为传统布局导致旅行距离过长和劳动力需求高。本研究引入了由CPU结构启发的新版布局设计,将仓库空间分割到专门区,即绩效(P)、效率(E)和共享(S)区。使用分层活动模拟来对照传统的矩形(随机和ABC储存)和飞行-V型布局来评价这一设计。结果显示,在吞吐时间和劳动力需求方面有显著改进,并减少了劳动力需求,突出了CPU在优化仓储业务方面的潜在布局。","Timo Looms, Lin Xie",2025-06-03T11:33:58Z,CPU-Based Layout Design for Picker-to-Parts Pallet Warehouses,CPU-basiertes Layout-Design für Picker-to-Parts Palettenlager,Picker-Parts 托盘仓库基于 CPU 的布局设计,http://arxiv.org/abs/2506.04266v1
28,"This work focuses on the credit assignment problem in cooperative multi-agent reinforcement learning (MARL). Sharing the global advantage among agents often leads to suboptimal policy updates as it fails to account for the distinct contributions of agents. Although numerous methods consider global or individual contributions for credit assignment, a detailed analysis at the coalition level remains lacking in many approaches. This work analyzes the over-updating problem during multi-agent policy updates from a coalition-level perspective. To address this issue, we propose a credit assignment method called Coalitional Rational Advantage Decomposition (CORA). CORA evaluates coalitional advantages via marginal contributions from all possible coalitions and decomposes advantages using the core solution from cooperative game theory, ensuring coalitional rationality. To reduce computational overhead, CORA employs random coalition sampling. Experiments on matrix games, differential games, and multi-agent collaboration benchmarks demonstrate that CORA outperforms strong baselines, particularly in tasks with multiple local optima. These findings highlight the importance of coalition-aware credit assignment for improving MARL performance.","这项工作侧重于多试剂合作强化学习中的信用分配问题。在代理人之间分享全球优势往往导致政策更新不足,因为它没有考虑到代理人的独特贡献。虽然有许多方法考虑到全球或个人对信用分配的贡献,但在联盟一级仍缺乏许多方法的详细分析。这项工作从联盟一级的角度分析了多试剂政策更新过程中的过度更新问题。为了解决这一问题,我们提议了一种称为联合合理优势解体的信用分配方法。 CoRA通过所有可能的联盟的边际贡献来评估联合优势,并利用合作游戏理论的核心解决方案来消除优势,确保联合合理性。为了减少计算间接费用,CORA采用随机联合抽样。在矩阵游戏、差异游戏和多试剂合作基准方面的实验表明,CORA超越了强大的基线,特别是在多个地方选择任务中。这些研究结果突出表明了联盟-认知信用分配对于改善MARL业绩的重要性。","Mengda Ji, Genjiu Xu, Liying Wang",2025-06-03T08:04:43Z,CORA: Coalitional Rational Advantage Decomposition for Multi-Agent   Policy Gradients,CORA: Coalitional Rational Advantage Zersetzung für Multi-Agent Policy Gradienten,CORA: 多重利益政策梯度联合合理优势分解,http://arxiv.org/abs/2506.04265v1
29,"In many parts of the world - particularly in developing countries - the demand for electricity exceeds the available supply. In such cases, it is impossible to provide electricity to all households simultaneously. This raises a fundamental question: how should electricity be allocated fairly? In this paper, we explore this question through the lens of egalitarianism - a principle that emphasizes equality by prioritizing the welfare of the worst-off households. One natural rule that aligns with this principle is to maximize the egalitarian welfare - the smallest utility across all households. We show that computing such an allocation is NP-hard, even under strong simplifying assumptions. Leximin is a stronger fairness notion that generalizes the egalitarian welfare: it also requires to maximize the smallest utility, but then, subject to that, the second-smallest, then the third, and so on. The hardness results extends directly to leximin as well. Despite this, we present a Fully Polynomial-Time Approximation Scheme (FPTAS) for leximin in the special case where the network connectivity graph is a tree. This means that we can efficiently approximate leximin - and, in particular, the egalitarian welfare - to any desired level of accuracy.","在世界许多地方,特别是发展中国家,电力需求超过现有供应。在这种情况下,不可能同时为所有家庭提供电力。这提出了一个根本问题:如何公平地分配电力?在本文件中,我们通过平等主义的视角来探讨这一问题,这项原则强调平等,优先照顾最穷家庭的福利;与这一原则相一致的一个自然规则是最大限度地扩大所有家庭的平等福利——这是所有家庭中最小的效用。我们表明,计算这种分配是硬的,即使是在强有力的简化假设下也是如此。Leximin是一个更强有力的公平概念,它普遍地普及平等福利:它也需要最大限度地扩大最小的效用,但随后,在第二小、第三等情况下,硬性的结果直接延伸到了法系。尽管如此,我们还是提出了一个完全的多米-时适应法化计划(PFTAS),在网络连接图是一棵树的特殊案例中,我们可高效地近近格利基明,特别是平等福利,达到任何理想的精确度。","Eden Hartman, Dinesh Kumar Baghel, Erel Segal-Halevi",2025-06-02T19:30:03Z,Fairly Wired: Towards Leximin-Optimal Division of Electricity,Fairly Wired: Auf dem Weg zu Leximin-Optimal Division of Electricity,公平接线:迈向Leximin-Optima电力司,http://arxiv.org/abs/2506.02193v1
30,"Game-theoretic agents must make plans that optimally gather information about their opponents. These problems are modeled by partially observable stochastic games (POSGs), but planning in fully continuous POSGs is intractable without heavy offline computation or assumptions on the order of belief maintained by each player. We formulate a finite history/horizon refinement of POSGs which admits competitive information gathering behavior in trajectory space, and through a series of approximations, we present an online method for computing rational trajectory plans in these games which leverages particle-based estimations of the joint state space and performs stochastic gradient play. We also provide the necessary adjustments required to deploy this method on individual agents. The method is tested in continuous pursuit-evasion and warehouse-pickup scenarios (alongside extensions to $N > 2$ players and to more complex environments with visual and physical obstacles), demonstrating evidence of active information gathering and outperforming passive competitors.","游戏理论剂必须制定最佳收集对手信息的计划。 这些问题以部分可见的随机游戏(POSGs)为模型,但完全连续的 POSGs的规划不按每个玩家的信仰顺序进行沉重的离线计算或假设,是难以解决的。 我们对POSGs进行有限的历史/横向改进,承认在轨道空间收集竞争性信息的行为,并通过一系列近似,在这些游戏中提出计算合理轨迹计划的在线方法,利用基于粒子对国家联合空间的估计,并进行随机梯度游戏。我们还提供了将这种方法运用于单个代理商的必要调整。该方法在连续的追逐和仓储准备情景中(长期延伸至2 000美元以上玩家,在视觉和物理障碍的更复杂的环境中进行测试)中进行测试,以显示积极的信息收集证据和优于被动竞争者。","Mel Krusniak, Hang Xu, Parker Palermo, Forrest Laine",2025-06-02T17:45:58Z,Online Competitive Information Gathering for Partially Observable   Trajectory Games,Online-Wettbewerbsinformationen Sammeln für teilweise beobachtbare Trajektorien Spiele,部分可观测轨迹运动会在线竞争性信息收集,http://arxiv.org/abs/2506.01927v1
31,"Though Large Vision-Language Models (LVLMs) are being actively explored in medicine, their ability to conduct telemedicine consultations combining accurate diagnosis with professional dialogue remains underexplored. In this paper, we present 3MDBench (Medical Multimodal Multi-agent Dialogue Benchmark), an open-source framework for simulating and evaluating LVLM-driven telemedical consultations. 3MDBench simulates patient variability through four temperament-based Patient Agents and an Assessor Agent that jointly evaluate diagnostic accuracy and dialogue quality. It includes 3013 cases across 34 diagnoses drawn from real-world telemedicine interactions, combining textual and image-based data. The experimental study compares diagnostic strategies for popular LVLMs, including GPT-4o-mini, LLaVA-3.2-11B-Vision-Instruct, and Qwen2-VL-7B-Instruct. We demonstrate that multimodal dialogue with internal reasoning improves F1 score by 6.5% over non-dialogue settings, highlighting the importance of context-aware, information-seeking questioning. Moreover, injecting predictions from a diagnostic convolutional network into the LVLM's context boosts F1 by up to 20%. Source code is available at https://anonymous.4open.science/r/3mdbench_acl-0511.","虽然在医学领域正在积极探索大型视力-语言模型(LVLM),但其进行将准确诊断与专业对话相结合的远程医疗咨询能力仍未得到充分探讨。本文介绍了3MMMBench(Medical Multimodal-代理对话基准),这是一个用于模拟和评价LVM驱动的远程医疗咨询的开放源码框架。3MDBench通过4个基于温情的病人代理和一个联合评价诊断准确性和对话质量的评估员,模拟病人变异性。其中包括从现实世界远程医疗互动中提取的34个诊断中共3 013个案例,其中结合了文本和图像数据。实验研究比较了流行的LMTMS的诊断战略,包括GPT-4-o-mini、LalVA-3-11B-Vision-Instruct和Quwen2-VLB-7B-Instruct。我们显示,与内部推理的多式对话比非对话环境提高了6.5%的F1分,强调背景认识、信息查询的重要性。此外,从诊断性革命-clus-clational-cons 20M 的预测数据-rus 由LM的20mxmxmxm 提供。","Ivan Sviridov, Amina Miftakhova, Artemiy Tereshchenko, Galina Zubkova, Pavel Blinov, Andrey Savchenko",2025-06-02T16:50:59Z,3MDBench: Medical Multimodal Multi-agent Dialogue Benchmark,3MDBench: Medical Multimodal Multi-Agent Dialog Benchmark,3MMDBench:医疗多式联运多机构对话基准,http://arxiv.org/abs/2504.13861v2
32,"As large language models (LLMs) transition from static tools to fully agentic systems, their potential for transforming social science research has become increasingly evident. This paper introduces a structured framework for understanding the diverse applications of LLM-based agents, ranging from simple data processors to complex, multi-agent systems capable of simulating emergent social dynamics. By mapping this developmental continuum across six levels, the paper clarifies the technical and methodological boundaries between different agentic architectures, providing a comprehensive overview of current capabilities and future potential. It highlights how lower-tier systems streamline conventional tasks like text classification and data annotation, while higher-tier systems enable novel forms of inquiry, including the study of group dynamics, norm formation, and large-scale social processes. However, these advancements also introduce significant challenges, including issues of reproducibility, ethical oversight, and the risk of emergent biases. The paper critically examines these concerns, emphasizing the need for robust validation protocols, interdisciplinary collaboration, and standardized evaluation metrics. It argues that while LLM-based agents hold transformative potential for the social sciences, realizing this promise will require careful, context-sensitive deployment and ongoing methodological refinement. The paper concludes with a call for future research that balances technical innovation with ethical responsibility, encouraging the development of agentic systems that not only replicate but also extend the frontiers of social science, offering new insights into the complexities of human behavior.","由于大型语言模型(LLMS)从静态工具向完全代理系统过渡,其转变社会科学研究的潜力日益明显,本文件为理解以LLM为主的代理人的各种应用提出了结构化框架,从简单的数据处理器到能够模拟突发社会动态的复杂、多试剂系统等,这些应用范围从简单的数据处理器到能够模拟突发社会动态的复杂、多试剂系统不等。文件通过在六个层面绘制这一发展连续体图,澄清了不同代理结构之间的技术和方法界限,全面概述了目前的能力和未来潜力。文件着重说明了较低层次的系统如何精简文本分类和数据说明等常规任务,而较高层次的系统则能够促成新的调查形式,包括研究团体动态、规范形成和大规模社会进程。然而,这些进展也带来了重大挑战,包括再生、道德监督以及突发偏见的风险。文件批判了这些关切,强调需要强有力的验证协议、跨学科合作以及标准化的评价指标。文件指出,尽管基于LLMM的代理人具有对社会科学的变革潜力,但实现这一承诺需要谨慎、对背景有敏感认识的部署和不断进行方法上的改进。文件最后也提出了重要的挑战,文件最后提出了关于未来研究、道德创新的社会责任,也要求,为人类科学的发展提供了新的研究的复制。","Jennifer Haase, Sebastian Pokutta",2025-06-02T16:27:29Z,Beyond Static Responses: Multi-Agent LLM Systems as a New Paradigm for   Social Science Research,Beyond Static Responses: Multi-Agent LLM-Systeme als neues Paradigma für die sozialwissenschaftliche Forschung,""" 超越静态反应:作为社会科学研究新范例的多种机构LLM系统 """,http://arxiv.org/abs/2506.01839v1
33,"To balance the quality and inference cost of a Foundation Model (FM, such as large language models (LLMs)) powered software, people often opt to train a routing model that routes requests to FMs with different sizes and capabilities. Existing routing models rely on learning the optimal routing decision from carefully curated data, require complex computations to be updated, and do not consider the potential evolution of weaker FMs. In this paper, we propose Real-time Adaptive Routing (RAR), an approach to continuously adapt FM routing decisions while using guided in-context learning to enhance the capabilities of weaker FM. The goal is to reduce reliance on stronger, more expensive FMs. We evaluate our approach on different subsets of the popular MMLU benchmark. Over time, our approach routes 50.2% fewer requests to computationally expensive models while maintaining around 90.5% of the general response quality. In addition, the guides generated from stronger models have shown intra-domain generalization and led to a better quality of responses compared to an equivalent approach with a standalone weaker FM.","为了平衡基础模型(FM,如大型语言模型(LLMs))的增能软件的质量和推论成本,人们往往选择培训一个路线模型,该模型可以将不同规模和能力的请求传送到不同规模和能力的调频中。现有的路线模型依赖于从仔细整理的数据中学习最佳路线决定,需要更新复杂的计算方法,而不考虑较弱调频的潜在演变。在本文件中,我们建议采用实时适应性调频路程(RAR),这是不断调整调频路程决定的一种方法,同时使用有指导的内文学习来提高调频能力。目标是减少对更强大、更昂贵调频调频的依赖。我们评估我们对流行的MMMLU基准的不同子集采用的方法。随着时间的推移,我们的方法是减少50.2%的关于计算昂贵模式的要求,同时保持总响应质量的大约90.5%。此外,更强模型产生的指南显示了内部的概括性,并导致应对措施的质量高于与独立较弱调频的同等方法。","Kirill Vasilevski, Dayi Lin, Ahmed E. Hassan",2025-06-02T14:54:12Z,Real-time Adapting Routing (RAR): Improving Efficiency Through   Continuous Learning in Software Powered by Layered Foundation Models,"Real-time Adapting Routing (RAR): Effizienzsteigerung durch kontinuierliches Lernen in Software, angetrieben durch Layered Foundation Models",实时调整运行规则(RAR):通过由多层基金会模型驱动的软件的持续学习提高效率,http://arxiv.org/abs/2411.09837v2
34,"As large language models (LLMs) start interacting with each other and generating an increasing amount of text online, it becomes crucial to better understand how information is transformed as it passes from one LLM to the next. While significant research has examined individual LLM behaviors, existing studies have largely overlooked the collective behaviors and information distortions arising from iterated LLM interactions. Small biases, negligible at the single output level, risk being amplified in iterated interactions, potentially leading the content to evolve towards attractor states. In a series of telephone game experiments, we apply a transmission chain design borrowed from the human cultural evolution literature: LLM agents iteratively receive, produce, and transmit texts from the previous to the next agent in the chain. By tracking the evolution of text toxicity, positivity, difficulty, and length across transmission chains, we uncover the existence of biases and attractors, and study their dependence on the initial text, the instructions, language model, and model size. For instance, we find that more open-ended instructions lead to stronger attraction effects compared to more constrained tasks. We also find that different text properties display different sensitivity to attraction effects, with toxicity leading to stronger attractors than length. These findings highlight the importance of accounting for multi-step transmission dynamics and represent a first step towards a more comprehensive understanding of LLM cultural dynamics.","随着大型语言模型(LLMS)开始彼此互动并产生越来越多的在线文本,更好地了解信息如何从一个LLM传到下一个LLM,就变得至关重要了。虽然重要的研究已经考察了单个LLM行为,但现有的研究基本上忽视了由迭代LLM相互作用产生的集体行为和信息扭曲。微小的偏差,在单一产出一级微不足道,迭代互动中可能会扩大,可能导致内容向吸引国演变。在一系列电话游戏实验中,我们采用从人类文化进化文献中借用的传输链设计:LLM代理物反复接收、制作和传输从先前的文本到链中下一个代理物。通过跟踪文本毒性的演变、可预期性、难度和跨传输链的长度,我们发现偏见和吸引者的存在,并研究他们对初始文本、指令、语言模型和模型大小的依赖性。例如,我们发现,较开放性的指示导致吸引力的效应比更强。我们还发现,不同的文本属性在吸引力方面表现出不同的敏感度,其毒性导致吸引者对吸引者的理解程度高于全面动态。这些发现,其重要性代表了多种动态。","Jérémy Perez, Grgur Kovač, Corentin Léger, Cédric Colas, Gaia Molinaro, Maxime Derex, Pierre-Yves Oudeyer, Clément Moulin-Frier",2025-06-02T14:34:39Z,When LLMs Play the Telephone Game: Cultural Attractors as Conceptual   Tools to Evaluate LLMs in Multi-turn Settings,"Wenn LLMs das Telefon Spiel spielen: Kulturelle Attrectors als konzeptionelle Tools, um LLMs in Multi-Turn-Einstellungen zu bewerten",当LLMs玩电话游戏时:文化吸引者作为在多轮转环境中评价LLMs的概念工具,http://arxiv.org/abs/2407.04503v3
35,"The terms Agentic AI and Multiagentic AI have recently gained popularity in discussions on generative artificial intelligence, often used to describe autonomous software agents and systems composed of such agents. However, the use of these terms confuses these buzzwords with well-established concepts in AI literature: intelligent agents and multi-agent systems. This article offers a critical analysis of this conceptual misuse. We review the theoretical origins of ""agentic"" in the social sciences (Bandura, 1986) and philosophical notions of intentionality (Dennett, 1971), and then summarise foundational works on intelligent agents and multi-agent systems by Wooldridge, Jennings and others. We examine classic agent architectures, from simple reactive agents to Belief-Desire-Intention (BDI) models, and highlight key properties (autonomy, reactivity, proactivity, social capability) that define agency in AI. We then discuss recent developments in large language models (LLMs) and agent platforms based on LLMs, including the emergence of LLM-powered AI agents and open-source multi-agent orchestration frameworks. We argue that the term AI Agentic is often used as a buzzword for what are essentially AI agents, and AI Multiagentic for what are multi-agent systems. This confusion overlooks decades of research in the field of autonomous agents and multi-agent systems. The article advocates for scientific and technological rigour and the use of established terminology from the state of the art in AI, incorporating the wealth of existing knowledge, including standards for multi-agent system platforms, communication languages and coordination and cooperation algorithms, agreement technologies (automated negotiation, argumentation, virtual organisations, trust, reputation, etc.), into the new and promising wave of LLM-based AI agents, so as not to end up reinventing the wheel.","人工智能和多试剂AI这两个术语最近在关于人工智能基因学的讨论中越来越受欢迎,这些术语常常用来描述自主软件代理商和由这些代理商组成的系统。然而,这些术语的用法混淆了AI文献中这些古老的概念:智能代理商和多试剂系统。本文章对这种概念滥用进行了批判性分析。我们审视了社会科学(班杜拉,1986年)中的“试剂”的理论起源和基于LLMS的理论概念(Dennet,1971年),然后由Wooldridge、Jenning等人对智能代理商和多试剂系统的基础工作进行总结。我们论证了典型的代理商结构,从简单的被动反应剂到信仰-死亡(BDI)(BDI)模型和多试剂(I)模型的理论基础。我们接着讨论了大型语言模型(LEM)和基于LMMM的理论平台的最新发展,包括LLMUDER的出现和开放源多源协议的多试剂组织。我们指出,AI的术语术语常常被用来将多层次的理论和多层次的理论化的理论的理论用于AI 。",V. Botti,2025-06-02T09:19:11Z,Agentic AI and Multiagentic: Are We Reinventing the Wheel?,Agentische KI und Multiagentik: Erfinden wir das Rad neu?,A.A.A.和多剂:我们是否在重新发明轮子?,http://arxiv.org/abs/2506.01463v1
36,"This paper introduces an innovative error feedback framework designed to mitigate quantization noise in distributed graph filtering, where communications are constrained to quantized messages. It comes from error spectrum shaping techniques from state-space digital filters, and therefore establishes connections between quantized filtering processes over different domains. In contrast to existing error compensation methods, our framework quantitatively feeds back the quantization noise for exact compensation. We examine the framework under three key scenarios: (i) deterministic graph filtering, (ii) graph filtering over random graphs, and (iii) graph filtering with random node-asynchronous updates. Rigorous theoretical analysis demonstrates that the proposed framework significantly reduces the effect of quantization noise, and we provide closed-form solutions for the optimal error feedback coefficients. Moreover, this quantitative error feedback mechanism can be seamlessly integrated into communication-efficient decentralized optimization frameworks, enabling lower error floors. Numerical experiments validate the theoretical results, consistently showing that our method outperforms conventional quantization strategies in terms of both accuracy and robustness.","本文介绍了一个创新的错误反馈框架,旨在减少分布式图过滤中的量化噪声,因为通信受量化信息的限制。它来自来自来自州-空间数字过滤器的错误频谱塑造技术,从而建立了不同领域量化过滤过程之间的联系。与现有的错误补偿方法不同,我们的框架在数量上反馈量化噪声以获得准确补偿。我们在三个关键情景下审查了框架:(一) 确定式图形过滤,(二) 随机图形过滤,以及(三) 以随机节点不同步更新方式过滤图形过滤。严格的理论分析表明,拟议框架大大降低了量化噪声的效果,我们为最佳错误反馈系数提供了封闭式解决方案。此外,这种定量错误反馈机制可以无缝地纳入通信高效的分散优化框架,从而降低错误层。数字实验验证了理论结果,不断显示我们的方法在准确性和稳健度方面都超过了常规的量化策略。","Xue Xian Zheng, Weihang Liu, Xin Lou, Stefan Vlaski, Tareq Al-Naffouri",2025-06-02T07:57:04Z,Quantitative Error Feedback for Quantization Noise Reduction of   Filtering over Graphs,Quantitatives Fehler-Feedback für Quantisierungsgeräusche Reduzierung der Filterung über Graphen,"数量错误反馈,用于减少图表过滤的量化噪声",http://arxiv.org/abs/2506.01404v1
37,"This article introduces a modeling framework to characterize evacuee response to environmental stimuli during emergency egress. The model is developed in consistency with stress theory, which explains how an organism reacts to environmental stressors. We integrate the theory into the well-known social-force model, and develop a framework to simulate crowd evacuation behavior in multi-compartment buildings. Our method serves as a theoretical basis to study crowd movement at bottlenecks, and simulate their herding and way-finding behavior in normal and hazardous conditions. The pre-movement behavior is also briefly investigated by using opinion dynamics with social group model. The algorithms have been partly tested in FDS+EVAC as well as our simulation platform crowdEgress.","本文介绍了一个模型框架,用以描述疏散人员在紧急情况下对环境刺激的反应特征。该模型是与压力理论相一致的,该模型解释了生物体对环境压力的反应方式。我们将该理论纳入著名的社会力量模型,并开发一个框架,以模拟多区建筑中的人群疏散行为。我们的方法作为理论基础,用于研究人群在瓶颈中的移动,并模拟其在正常和危险条件下的放牧和方式探索行为。运动前的行为也通过使用社会团体模型的见解动态进行简要调查。算法已经在FDS+EVAC以及模拟平台人群中进行了部分测试。","Peng Wang, Xiaoda Wang, Peter Luh, Christian Wilkie, Timo Korhonen, Neal Olderman",2025-06-02T07:53:08Z,Simulation of Crowd Egress with Environmental Stressors,Simulation von Crowd Egress mit Umweltstressoren,以环境压力因素模拟人群反弹,http://arxiv.org/abs/2206.01393v8
38,"Recent advances in Large Language Models (LLMs) have enabled multi-agent systems that simulate real-world interactions with near-human reasoning. While previous studies have extensively examined biases related to protected attributes such as race, the emergence and propagation of biases on socially contentious issues in multi-agent LLM interactions remain underexplored. This study explores how LLM agents shape public opinion through debates on five contentious topics. By simulating over 2,500 debates, we analyze how initially neutral agents, assigned a centrist disposition, adopt specific stances over time. Statistical analyses reveal significant group conformity mirroring human behavior; LLM agents tend to align with numerically dominant groups or more intelligent agents, exerting a greater influence. These findings underscore the crucial role of agent intelligence in shaping discourse and highlight the risks of bias amplification in online interactions. Our results emphasize the need for policy measures that promote diversity and transparency in LLM-generated discussions to mitigate the risks of bias propagation within anonymous online environments.","大语言模型(LLMs)的最近进展使模拟现实世界互动与近乎人性的推理的多试剂系统得以建立。虽然以前的研究广泛审查了种族等受保护属性的偏见,但在多试剂LLM相互作用中,对社会争议问题的偏见的出现和传播仍然未得到充分探讨。本研究探讨了LLM代理人如何通过对五个有争议的议题的辩论影响舆论。我们模拟了2 500多场辩论,分析了最初中立的代理人、指派了中分者、采取特定立场的方式。统计分析显示,在群体上明显符合反映人类行为;LLM代理人往往与数字上占支配地位的群体或更聪明的代理人相配合,施加更大的影响。这些研究结果强调了代理人情报在塑造言论方面的关键作用,并强调了网上互动中扩大偏见的风险。我们的结果强调,在LMM产生的讨论中需要采取政策措施,促进多样性和透明度,以减少匿名在线环境中的偏见传播风险。","Min Choi, Keonwoo Kim, Sungwon Chae, Sangyeob Baek",2025-06-02T05:22:29Z,An Empirical Study of Group Conformity in Multi-Agent Systems,Eine empirische Studie der Gruppenkonformität in Multi-Agent-Systemen,关于多机构机构系统小组合规性的经验研究,http://arxiv.org/abs/2506.01332v1
39,"Failure attribution in LLM multi-agent systems-identifying the agent and step responsible for task failures-provides crucial clues for systems debugging but remains underexplored and labor-intensive. In this paper, we propose and formulate a new research area: automated failure attribution for LLM multi-agent systems. To support this initiative, we introduce the Who&When dataset, comprising extensive failure logs from 127 LLM multi-agent systems with fine-grained annotations linking failures to specific agents and decisive error steps. Using the Who&When, we develop and evaluate three automated failure attribution methods, summarizing their corresponding pros and cons. The best method achieves 53.5% accuracy in identifying failure-responsible agents but only 14.2% in pinpointing failure steps, with some methods performing below random. Even SOTA reasoning models, such as OpenAI o1 and DeepSeek R1, fail to achieve practical usability. These results highlight the task's complexity and the need for further research in this area. Code and dataset are available at https://github.com/mingyin1/Agents_Failure_Attribution","在LLM多试剂系统中,LLM多试剂的失败归属由127个LLM多试剂系统的大量失败日志组成,附有细微的标记,将失败与具体代理人和决定性的错误步骤联系起来。我们利用“谁和何时”来开发和评价三种自动失败归属方法,总结相应的利弊。最佳方法在确定失败责任性剂方面达到53.5%的准确度,但在确定失败步骤方面只有14.2%的准确度,有些方法在随机操作下进行。即使SOTA推理模型,如OpenAI o1和DeepSeek R1, 也未能实现实用的可用性。这些结果突出了任务的复杂性和在这一领域进行进一步研究的必要性。代码和数据集可在https://github.com/mingy1/Agents_Faillure_Atarition上查阅。","Shaokun Zhang, Ming Yin, Jieyu Zhang, Jiale Liu, Zhiguang Han, Jingyang Zhang, Beibin Li, Chi Wang, Huazheng Wang, Yiran Chen, Qingyun Wu",2025-06-02T03:25:55Z,Which Agent Causes Task Failures and When? On Automated Failure   Attribution of LLM Multi-Agent Systems,Welcher Agent verursacht Aufgabenausfälle und wann? Über automatisierte Fehlerzuweisung von LLM-Multiagentensystemen,哪些代理原因任务失败和何时发生?关于LLM多机构系统自动失败归属,http://arxiv.org/abs/2505.00212v3
40,"State-of-the-art methods for Human-AI Teaming and Zero-shot Cooperation focus on task completion, i.e., task rewards, as the sole evaluation metric while being agnostic to how the two agents work with each other. Furthermore, subjective user studies only offer limited insight into the quality of cooperation existing within the team. Specifically, we are interested in understanding the cooperative behaviors arising within the team when trained agents are paired with humans -- a problem that has been overlooked by the existing literature. To formally address this problem, we propose the concept of constructive interdependence -- measuring how much agents rely on each other's actions to achieve the shared goal -- as a key metric for evaluating cooperation in human-agent teams. We interpret interdependence in terms of action interactions in a STRIPS formalism, and define metrics that allow us to assess the degree of reliance between the agents' actions. We pair state-of-the-art agents HAT with learned human models as well as human participants in a user study for the popular Overcooked domain, and evaluate the task reward and teaming performance for these human-agent teams. Our results demonstrate that although trained agents attain high task rewards, they fail to induce cooperative behavior, showing very low levels of interdependence across teams. Furthermore, our analysis reveals that teaming performance is not necessarily correlated with task reward, highlighting that task reward alone cannot reliably measure cooperation arising in a team.","人类-AI团队和零点合作的最先进方法注重任务的完成,即任务奖励,以此作为唯一的评价标准,同时对两个代理人之间如何合作持不可知的态度。此外,主观用户研究只能对团队内部现有合作的质量提供有限的洞察力。具体地说,当训练有素的代理人与人对齐时,我们有兴趣了解团队内部的合作行为 -- -- 这个问题已被现有文献所忽视。为了正式解决这一问题,我们提出建设性相互依存的概念 -- -- 衡量代理人对彼此行动的依赖程度,以实现共同目标 -- -- 作为评价两个代理人之间合作情况的关键衡量标准。我们解释的是,从行动互动角度对团队内部现有的合作质量的认识有限。具体地说,当训练有素的代理人与人打交道时,我们有兴趣了解团队内部的合作行为 -- -- 在现有文献忽视了这一问题。为了正式解决这一问题,我们提出了建设性相互依存的概念 -- -- 衡量代理人之间如何依靠彼此的行动来达到共同目标 -- -- 以衡量这些代理人之间如何实现共同目标 -- -- 作为评价人员代理人团队之间合作的关键衡量标准。我们把行动互动的相互依存性解释为我们评估代理人之间依赖行为的程度。我们的工作表现得分不甚甚深。","Upasana Biswas, Vardhan Palod, Siddhant Bhambri, Subbarao Kambhampati",2025-06-02T01:06:41Z,Who is Helping Whom? Analyzing Inter-dependencies to Evaluate   Cooperation in Human-AI Teaming,Wer hilft wem? Analysieren von Interdependenzen zur Evaluierung der Zusammenarbeit im Mensch-KI-Teaming,分析评价人类-AI团队合作的相互依存关系,http://arxiv.org/abs/2502.06976v2
41,"Data standardization is a crucial part of the data science life cycle. While tools like Pandas offer robust functionalities, their complexity and the manual effort required for customizing code to diverse column types pose significant challenges. Although large language models (LLMs) like ChatGPT have shown promise in automating this process through natural language understanding and code generation, it still demands expert-level programming knowledge and continuous interaction for prompt refinement. To solve these challenges, our key idea is to propose a Python library with declarative, unified APIs for standardizing different column types, simplifying the LLM's code generation with concise API calls. We first propose Dataprep.Clean, a component of the Dataprep Python Library, significantly reduces the coding complexity by enabling the standardization of specific column types with a single line of code. Then, we introduce the CleanAgent framework integrating Dataprep.Clean and LLM-based agents to automate the data standardization process. With CleanAgent, data scientists only need to provide their requirements once, allowing for a hands-free process. To demonstrate the practical utility of CleanAgent, we developed a user-friendly web application, allowing users to interact with it using real-world datasets.","数据标准化是数据科学生命周期的一个关键部分。虽然像熊猫这样的工具提供了强大的功能,但其复杂性和为定制不同柱型代码所需的手工工作带来了巨大的挑战。虽然像查特格伯特这样的大型语言模型(LLMs)在通过自然语言理解和代码生成实现这一进程自动化方面显示了希望,但它仍然要求专家级编程知识和持续互动,以便迅速完善。为了应对这些挑战,我们的关键想法是提出一个配有声明性、统一的单体标准化信息源的Python图书馆,用于规范不同柱型的标准化,简化LLM的代码生成,并使用简洁的API电话。我们首先提议Dataprep.Clean,这是Dataprep Python图书馆的一个组件,通过允许单行代码中特定柱型条目的标准化,大大降低了编码的复杂度。然后,我们引入了将 Dataprep.Clean和LLM 代理器整合数据标准化进程的清洁化框架。有了清洁的科学家,只需要一次提供其要求,从而可以进行手动程序。为了展示CleAgentient,我们开发了一个方便用户的网络应用。","Danrui Qi, Zhengjie Miao, Jiannan Wang",2025-06-02T00:45:04Z,CleanAgent: Automating Data Standardization with LLM-based Agents,CleanAgent: Automatisierung der Datenstandardisierung mit LLM-basierten Agenten,清洁剂:与LLM代理商实现数据标准化自动化,http://arxiv.org/abs/2403.08291v4
42,"Existing work on the alignment problem has focused mainly on (1) qualitative descriptions of the alignment problem; (2) attempting to align AI actions with human interests by focusing on value specification and learning; and/or (3) focusing on a single agent or on humanity as a monolith. Recent sociotechnical approaches highlight the need to understand complex misalignment among multiple human and AI agents. We address this gap by adapting a computational social science model of human contention to the alignment problem. Our model quantifies misalignment in large, diverse agent groups with potentially conflicting goals across various problem areas. Misalignment scores in our framework depend on the observed agent population, the domain in question, and conflict between agents' weighted preferences. Through simulations, we demonstrate how our model captures intuitive aspects of misalignment across different scenarios. We then apply our model to two case studies, including an autonomous vehicle setting, showcasing its practical utility. Our approach offers enhanced explanatory power for complex sociotechnical environments and could inform the design of more aligned AI systems in real-world applications.","关于调整问题的现有工作主要侧重于:(1) 对调整问题进行定性描述;(2) 试图通过注重价值规格和学习,使大赦国际的行动与人类利益保持一致;和/或(3) 侧重于单一的代理人或将人类作为单一体;最近的社会技术方法强调需要理解多种人类和大赦国际代理人之间复杂的不协调问题;我们通过将人类争论的计算社会科学模型与调整问题相适应来弥补这一差距;我们的模型量化了大型、多样化的代理人群体在各种问题领域的目标可能相互冲突时的不匹配。我们框架中的错配分取决于所观察到的代理人人口、所涉领域以及代理人的加权偏好之间的冲突。我们通过模拟,展示我们的模型如何捕捉到不同情景之间不协调的直观方面。我们然后将我们的模型应用于两个案例研究,包括自主的车辆设置,展示其实际效用。我们的方法为复杂的社会技术环境提供了更强的解释力,并为设计现实世界应用中更加一致的AI系统提供了参考。","Aidan Kierans, Avijit Ghosh, Hananel Hazan, Shiri Dori-Hacohen",2025-06-01T17:41:48Z,Quantifying Misalignment Between Agents: Towards a Sociotechnical   Understanding of Alignment,Quantifizierung der Fehlausrichtung zwischen Agenten: Auf dem Weg zu einem soziotechnischen Verständnis der Ausrichtung,量化代理人之间的不匹配:争取从社会技术上理解协调问题,http://arxiv.org/abs/2406.04231v4
43,"Rapid Large Language Model (LLM) advancements are fueling autonomous Multi-Agent System (MAS) development. However, current frameworks often lack flexibility, resource awareness, model diversity, and autonomous tool creation. This paper introduces HASHIRU (Hierarchical Agent System for Hybrid Intelligent Resource Utilization), a novel MAS framework enhancing flexibility, resource efficiency, and adaptability. HASHIRU features a ""CEO"" agent dynamically managing specialized ""employee"" agents, instantiated based on task needs and resource constraints (cost, memory). Its hybrid intelligence prioritizes smaller, local LLMs (via Ollama) while flexibly using external APIs and larger models when necessary. An economic model with hiring/firing costs promotes team stability and efficient resource allocation. The system also includes autonomous API tool creation and a memory function. Evaluations on tasks like academic paper review (58% success), safety assessments (100% on a JailbreakBench subset), and complex reasoning (outperforming Gemini 2.0 Flash on GSM8K: 96% vs. 61%; JEEBench: 80% vs. 68.3%; SVAMP: 92% vs. 84%) demonstrate HASHIRU's capabilities. Case studies illustrate its self-improvement via autonomous cost model generation, tool integration, and budget management. HASHIRU offers a promising approach for more robust, efficient, and adaptable MAS through dynamic hierarchical control, resource-aware hybrid intelligence, and autonomous functional extension. Source code and benchmarks are available at https://github.com/HASHIRU-AI/HASHIRU and https://github.com/HASHIRU-AI/HASHIRUBench respectively, and a live demo is available at https://hashiruagentx-hashiruai.hf.space upon request.","快速大语言模型(LLM)的进步正在推动自主的多机构系统(MAS)的开发。然而,当前的框架往往缺乏灵活性、资源意识、模式多样性和自主工具创建。本文介绍了HASHIRU(混合智能资源利用高级代理系统),这是一个创新的MAS框架,提高了灵活性、资源效率和适应性。HSHIRU有一个“CE”代理机构,根据任务需要和资源限制(成本、记忆)即时管理专门的“雇员”代理机构。它的混合情报优先考虑的是较小、本地LMS(通过Ollama),同时在必要时使用外部API和更大的智能模型。一个雇用/firing成本促进团队稳定和高效资源分配的经济模型。这个系统还包括自主的API工具创建和记忆功能。对学术文件审查(58%的成功)、安全评估(在Jilbreak Benchench分集中100%),以及复杂的推理(GSMO8K:96% 和RURURR-RU 分别用于GSU 和61%;JEB:80% Vs 模式:68.3%;SAIS-harmax-ral-ral-ral-ral-ral Restal Restal Restal ex) ex ex ex areal ex ex ex ex ex ex destyalmailmal ex ex ex ex ex ex ex ex ex ex ex a.","Kunal Pai, Parth Shah, Harshil Patel",2025-06-01T17:33:16Z,HASHIRU: Hierarchical Agent System for Hybrid Intelligent Resource   Utilization,HASHIRU: Hierarchisches Agentensystem für hybride intelligente Ressourcennutzung,HHHHIRU:混合智能资源利用等级代理系统,http://arxiv.org/abs/2506.04255v1
44,"Deep multi-agent reinforcement learning (MARL) has been demonstrated effectively in simulations for many multi-robot problems. For autonomous vehicles, the development of vehicle-to-vehicle (V2V) communication technologies provide opportunities to further enhance safety of the system. However, zero-shot transfer of simulator-trained MARL policies to hardware dynamic systems remains challenging, and how to leverage communication and shared information for MARL has limited demonstrations on hardware. This problem is challenged by discrepancies between simulated and physical states, system state and model uncertainties, practical shared information design, and the need for safety guarantees in both simulation and hardware. This paper introduces RSR-RSMARL, a novel Robust and Safe MARL framework that supports Real-Sim-Real (RSR) policy adaptation for multi-agent systems with communication among agents, with both simulation and hardware demonstrations. RSR-RSMARL leverages state (includes shared state information among agents) and action representations considering real system complexities for MARL formulation. The MARL policy is trained with robust MARL algorithm to enable zero-shot transfer to hardware considering the sim-to-real gap. A safety shield module using Control Barrier Functions (CBFs) provides safety guarantee for each individual agent. Experiment results on F1/10th-scale autonomous vehicles with V2V communication demonstrate the ability of RSR-RSMARL framework to enhance driving safety and coordination across multiple configurations. These findings emphasize the importance of jointly designing robust policy representations and modular safety architectures to enable scalable, generalizable RSR transfer in multi-agent autonomy.","对于自动车辆而言,车辆对车辆(V2V)通信技术的开发为进一步加强系统安全提供了机会,然而,将模拟器培训的MARL政策零发式地转移到硬件动态系统仍然具有挑战性,如何为MARL利用通信和共享信息进行硬件示范有限,由于模拟状态和物理状态、系统状态和模型不确定性、实际共享信息设计以及模拟和硬件的安全保障需要之间存在差异,这一问题受到挑战。本文介绍了RSR-RSMARL,一个新型的Robust 和安全MARL框架,支持实时实时(RSR)政策调整,与代理商进行沟通,同时进行模拟和硬件演示。RSR-RSML的杠杆状态(包括代理商之间共享国家信息)以及考虑到制定MARL的真实系统复杂性、系统状态和模式、实际共享信息设计以及模拟和硬件安全保障的需要。","Keshawn Smith, Zhili Zhang, H M Sabbir Ahmad, Ehsan Sabouni, Maniak Mondal, Song Han, Wenchao Li, Fei Miao",2025-06-01T12:29:53Z,Robust and Safe Multi-Agent Reinforcement Learning Framework with   Communication for Autonomous Vehicles,Robustes und sicheres Multi-Agenten-Verstärkungs-Lernkonzept mit Kommunikation für autonome Fahrzeuge,"强力和安全的多机构强化多机构强化学习框架,与自治车辆沟通",http://arxiv.org/abs/2506.00982v1
45,"Autonomous multi-agent AI systems are poised to transform various industries, particularly software development and knowledge work. Understanding current perceptions among professionals is crucial for anticipating adoption challenges, ethical considerations, and future workforce development. This study analyzes responses from 130 participants to a survey on the capabilities, impact, and governance of AI agents. We explore expected timelines for AI replacing programmers, identify perceived barriers to deployment, and examine beliefs about responsibility when agents make critical decisions. Key findings reveal three distinct clusters of respondents. While the study explored factors associated with current AI agent deployment, the initial logistic regression model did not yield statistically significant predictors, suggesting that deployment decisions are complex and may be influenced by factors not fully captured or that a larger sample is needed. These insights highlight the need for organizations to address compliance concerns (a commonly cited barrier) and establish clear governance frameworks as they integrate autonomous agents into their workflows.","多试剂AI系统正在准备改变各种行业,特别是软件开发和知识工作。理解专业人员目前的看法对于预测采用方面的挑战、道德考虑和未来的劳动力发展至关重要。本研究报告分析了130名参与者对AI代理的能力、影响和治理调查的答复。我们探讨了AI替换程序员的预期时间表,确定了部署的已知障碍,并审查了代理商作出关键决定时对责任的信念。主要结论揭示了三个不同的答复者组。虽然研究探讨了与目前AI代理商部署有关的各种因素,但初步后勤回归模型并没有产生具有统计意义的预测数据,表明部署决定是复杂的,可能受到未完全捕捉到的因素的影响,或者需要更大的抽样。这些见解突出表明,各组织需要解决合规问题(通常提到的障碍),并在将自主代理商纳入工作流程时建立明确的治理框架。",Nikola Balic,2025-06-01T11:02:52Z,Will Agents Replace Us? Perceptions of Autonomous Multi-Agent AI,Werden Agenten uns ersetzen? Wahrnehmungen von autonomen Multi-Agenten-KI,代理人会取代我们吗?,http://arxiv.org/abs/2506.02055v1
46,"Model merging has become one of the key technologies for enhancing the capabilities and efficiency of Large Language Models (LLMs). However, our understanding of the expected performance gains and principles when merging any two models remains limited. In this work, we introduce model kinship, the degree of similarity or relatedness between LLMs, analogous to biological evolution. With comprehensive empirical analysis, we find that there is a certain relationship between model kinship and the performance gains after model merging, which can help guide our selection of candidate models. Inspired by this, we propose a new model merging strategy: Top-k Greedy Merging with Model Kinship, which can yield better performance on benchmark datasets. Specifically, we discover that using model kinship as a criterion can assist us in continuously performing model merging, alleviating the degradation (local optima) in model evolution, whereas model kinship can serve as a guide to escape these traps. Code is available at https://github.com/zjunlp/ModelKinship.","合并模式已成为提高大语言模型能力和效率的关键技术之一。然而,我们在合并任何两个模型时对预期业绩收益和原则的理解仍然有限。在这项工作中,我们引入了模型亲属关系、类似生物进化的LLM公司之间的相似程度或关联性。通过全面的实证分析,我们发现模型亲属关系与合并后的业绩收益之间存在某种关系,有助于指导我们选择候选模型。受此启发,我们提出了一个新的模型合并战略:与模型亲子公司进行高端贪婪合并,这可以在基准数据集上产生更好的业绩。具体地说,我们发现使用模型亲子关系作为标准可以帮助我们持续进行模型合并,减轻模型演变中的退化(当地选择),而模型亲属关系可以作为摆脱这些陷阱的指南。《守则》可在https://github.com/zjunlp/ModelKinship查阅。","Yedi Hu, Yunzhi Yao, Shumin Deng, Huajun Chen, Ningyu Zhang",2025-06-01T10:39:29Z,Exploring Model Kinship for Merging Large Language Models,Erforschung von Modellkinship für das Zusammenführen von großen Sprachmodellen,探索合并大语言模式模式的示范关系,http://arxiv.org/abs/2410.12613v2
47,"In the interaction between agents and their environments, agents expand their capabilities by planning and executing actions. However, LLM-based agents face substantial challenges when deployed in novel environments or required to navigate unconventional action spaces. To empower agents to autonomously explore environments, optimize workflows, and enhance their understanding of actions, we propose SynWorld, a framework that allows agents to synthesize possible scenarios with multi-step action invocation within the action space and perform Monte Carlo Tree Search (MCTS) exploration to effectively refine their action knowledge in the current environment. Our experiments demonstrate that SynWorld is an effective and general approach to learning action knowledge in new environments. Code is available at https://github.com/zjunlp/SynWorld.","在代理商及其环境之间的互动中,代理商通过规划和执行行动扩大其能力;然而,LLM代理商在部署于新环境或需要导航非常规行动空间时面临巨大挑战;为增强代理商自主探索环境、优化工作流程和增进对行动的理解的能力,我们提议SynWorld,这是一个允许代理商在行动空间内以多步行动方式综合可能情景的框架,并进行蒙特卡洛树搜索(MCTS)探索,以有效完善其在目前环境中的行动知识。我们的实验证明SynWorld是在新环境中学习行动知识的有效和一般方法。代码可在https://github.com/zjunlp/SynWorld上查阅。","Runnan Fang, Xiaobin Wang, Yuan Liang, Shuofei Qiao, Jialong Wu, Zekun Xi, Ningyu Zhang, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen",2025-06-01T07:35:07Z,SynWorld: Virtual Scenario Synthesis for Agentic Action Knowledge   Refinement,SynWorld: Virtual Scenario Synthesis for Agentic Action Knowledge Refinement,Synworld: 用于改进制剂行动知识的虚拟情景合成,http://arxiv.org/abs/2504.03561v3
48,"This paper introduces LLM-MARL, a unified framework that incorporates large language models (LLMs) into multi-agent reinforcement learning (MARL) to enhance coordination, communication, and generalization in simulated game environments. The framework features three modular components of Coordinator, Communicator, and Memory, which dynamically generate subgoals, facilitate symbolic inter-agent messaging, and support episodic recall. Training combines PPO with a language-conditioned loss and LLM query gating. LLM-MARL is evaluated in Google Research Football, MAgent Battle, and StarCraft II. Results show consistent improvements over MAPPO and QMIX in win rate, coordination score, and zero-shot generalization. Ablation studies demonstrate that subgoal generation and language-based messaging each contribute significantly to performance gains. Qualitative analysis reveals emergent behaviors such as role specialization and communication-driven tactics. By bridging language modeling and policy learning, this work contributes to the design of intelligent, cooperative agents in interactive simulations. It offers a path forward for leveraging LLMs in multi-agent systems used for training, games, and human-AI collaboration.","本文件介绍LLMM-MARL,这是一个将大型语言模型(LLMS)纳入多试剂强化学习的统一框架,目的是在模拟游戏环境中加强协调、沟通和普及,该框架包括协调员、通信员和记忆的三个模块组成部分,这些组成部分动态地产生次级目标,促进象征性的代理信息,并支持偶然的回忆;培训将PPO与语言限制的损失和LLM查询结合起来;LLM-MARL在谷歌研究足球、MAGent Bight和StarCraft II中进行了评价。结果显示,在赢率、协调得分和零弹分方面比MAPOPO和QMIX取得了一致的改进。减缩研究表明,次级目标生成和基于语言的信息对业绩收益都有重大贡献。定性分析显示,角色专业化和沟通驱动策略等新出现的行为。通过连接语言模型和政策学习,这项工作有助于设计互动模拟中的智能、合作剂。它为在培训、游戏和人类-AI合作中使用的多试系统中利用LMS提供了一条前方途径。",Zhengyang Li,2025-06-01T06:46:49Z,Language-Guided Multi-Agent Learning in Simulations: A Unified Framework   and Evaluation,Sprachenorientiertes Multi-Agent-Lernen in Simulationen: Ein einheitliches Rahmenwerk und Bewertung,模拟中以语言指导的多机构模拟学习:统一框架和评价,http://arxiv.org/abs/2506.04251v1
49,"We introduce EvoGit, a decentralized multi-agent framework for collaborative software development driven by autonomous code evolution. EvoGit deploys a population of independent coding agents, each proposing edits to a shared codebase without centralized coordination, explicit message passing, or shared memory. Instead, all coordination emerges through a Git-based phylogenetic graph that tracks the full version lineage and enables agents to asynchronously read from and write to the evolving code repository. This graph-based structure supports fine-grained branching, implicit concurrency, and scalable agent interaction while preserving a consistent historical record. Human involvement is minimal but strategic: users define high-level goals, periodically review the graph, and provide lightweight feedback to promote promising directions or prune unproductive ones. Experiments demonstrate EvoGit's ability to autonomously produce functional and modular software artifacts across two real-world tasks: (1) building a web application from scratch using modern frameworks, and (2) constructing a meta-level system that evolves its own language-model-guided solver for the bin-packing optimization problem. Our results underscore EvoGit's potential to establish a new paradigm for decentralized, automated, and continual software development. EvoGit is open-sourced at https://github.com/BillHuang2001/evogit.","我们引入了由自主代码演变驱动的合作软件开发的分散式多试剂框架EvoGit。 EvoGit 配置了一组独立的编码代理人,每个都提议编辑到一个共用的代码库,而没有集中协调、明确传递信息或共享记忆。相反,所有协调都通过基于Git的植物基因图示出现,该图示跟踪整个版本线条,使代理商能够从正在演变的代码库中无动于衷地读写。这个基于图形的结构支持精细的分支、隐含的货币和可扩展的代理人互动,同时保存一致的历史记录。人类参与是最小的,但具有战略意义:用户定义高层次目标,定期审查图表,并提供轻量反馈,以促进有希望的方向或无益的记忆。实验表明EvoGit有能力在两种现实世界任务中自主地制作功能和模块软件工艺品:(1) 利用现代框架从零开始建立网络应用程序,(2) 构建一个元级系统,以发展自己的语言模范式/导导式解决方案,同时保存一致的历史记录。人类参与是最低限度的,但具有战略意义:用户定义、定期审查图表,并提供自动化的EvoGit/BIFormax。","Beichen Huang, Ran Cheng, Kay Chen Tan",2025-06-01T05:20:42Z,EvoGit: Decentralized Code Evolution via Git-Based Multi-Agent   Collaboration,EvoGit: Dezentralisierte Code-Evolution über die Git-basierte Multi-Agent-Kollaboration,"EvoGit:通过基建多机构协作,分散化代码演变",http://arxiv.org/abs/2506.02049v1
50,"Cooperative perception enables vehicles to share sensor readings and has become a new paradigm to improve driving safety, where the key enabling technology for realizing this vision is to real-time and accurately align and fuse the perceptions. Recent advances to align the views rely on high-density LiDAR data or fine-grained image feature representations, which however fail to meet the requirements of accuracy, real-time, and adaptability for autonomous driving. To this end, we present MMatch, a lightweight system that enables accurate and real-time perception fusion with mmWave radar point clouds. The key insight is that fine-grained spatial information provided by the radar present unique associations with all the vehicles even in two separate views. As a result, by capturing and understanding the unique local and global position of the targets in this association, we can quickly find out all the co-visible vehicles for view alignment. We implement MMatch on both the datasets collected from the CARLA platform and the real-world traffic with over 15,000 radar point cloud pairs. Experimental results show that MMatch achieves decimeter-level accuracy within 59ms, which significantly improves the reliability for autonomous driving.","合作感知使车辆能够分享感官读数,并已成为改善驾驶安全的新范例,实现这一愿景的关键赋能技术是实时和准确地对准和融合这些感知。最近为调和观点而取得的进展依赖于高密度的LIDAR数据或细微放大图像特征显示,然而,这些数据未能满足对自主驾驶的准确性、实时性和适应性的要求。为此,我们推出一个轻量级系统MMatch,这是一个能够准确和实时地将感知与mmWave雷达点云相融合的轻量系统。关键洞察力是雷达提供的细微空间信息,它甚至以两种不同的观点与所有车辆形成独特的联系。因此,通过捕捉和了解这个关系中目标的独特本地和全球位置,我们可以迅速发现所有可共同观察到的车辆,以便进行视觉调整。我们在从CARLA平台收集的数据集和以超过15 000个雷达点云谱的实时交通中实施MMatch。实验结果显示,Match在59米内实现解析度的精确度水平,这大大改进了自主驾驶的可靠性。","Zhiqing Luo, Yi Wang, Yingying He, Wei Wang",2025-06-01T04:58:33Z,Improving Multi-Vehicle Perception Fusion with Millimeter-Wave Radar   Assistance,Verbesserung der Multi-Vehicle Perception Fusion mit Millimeter-Wave Radar Assistance,"改进多维球感知融合,提供毫米瓦子雷达援助",http://arxiv.org/abs/2506.00837v1
51,"This paper introduces the HAIG framework for analysing trust dynamics across evolving human-AI relationships. Current categorical frameworks (e.g., ""human-in-the-loop"" models) inadequately capture how AI systems evolve from tools to partners, particularly as foundation models demonstrate emergent capabilities and multi-agent systems exhibit autonomous goal-setting behaviours. As systems advance, agency redistributes in complex patterns that are better represented as positions along continua rather than discrete categories, though progression may include both gradual shifts and significant step changes. The HAIG framework operates across three levels: dimensions (Decision Authority Distribution, Process Autonomy, and Accountability Configuration), continua (gradual shifts along each dimension), and thresholds (critical points requiring governance adaptation). Unlike risk-based or principle-based approaches, HAIG adopts a trust-utility orientation, focusing on maintaining appropriate trust relationships that maximise utility while ensuring sufficient safeguards. Our analysis reveals how technical advances in self-supervision, reasoning authority, and distributed decision-making drive non-uniform trust evolution across both contextual variation and technological advancement. Case studies in healthcare and European regulation demonstrate how HAIG complements existing frameworks while offering a foundation for alternative approaches that anticipate governance challenges before they emerge.","本文介绍了用于分析不断变化的人类-AI关系中信任动态的HAIG框架。目前的绝对框架(例如“流动中的人类”模式)没有充分说明AI系统如何从工具向伙伴演变,特别是因为基础模型显示了突发的能力和多试剂系统表现出自主的目标制定行为。作为系统推进,机构在复杂模式中重新分配,这些模式在连续类别而不是分散类别中更能反映位置,尽管进展可能包括逐步转变和重大步骤变化。HAIG框架在三个层面运作:层面(决策当局分配、流程自主和问责配置)、continua(每个层面的渐进变化)和门槛(需要适应治理的临界点) 。与基于风险或基于原则的方法不同,HAIG采用信任-利用率导向,侧重于保持适当的信任关系,在确保充分保障的同时最大限度地发挥效用。我们的分析揭示了自我监督、推理权威和分配决策的技术进步如何推动不同背景和技术进步的不统一信任演变。HAIG的案例研究表明HAIG如何补充现有框架,同时为预测治理挑战的替代方法提供基础。",Zeynep Engin,2025-06-01T00:20:31Z,Human-AI Governance (HAIG): A Trust-Utility Approach,Human-AI-Governance (HAIG): Ein Ansatz der Vertrauens-Utility,人类-AI 治理:信托-公用事业办法,http://arxiv.org/abs/2505.01651v2
52,"Text-to-image (T2I) generation has made remarkable progress, yet existing systems still lack intuitive control over spatial composition, object consistency, and multi-step editing. We present $\textbf{LayerCraft}$, a modular framework that uses large language models (LLMs) as autonomous agents to orchestrate structured, layered image generation and editing. LayerCraft supports two key capabilities: (1) $\textit{structured generation}$ from simple prompts via chain-of-thought (CoT) reasoning, enabling it to decompose scenes, reason about object placement, and guide composition in a controllable, interpretable manner; and (2) $\textit{layered object integration}$, allowing users to insert and customize objects -- such as characters or props -- across diverse images or scenes while preserving identity, context, and style. The system comprises a coordinator agent, the $\textbf{ChainArchitect}$ for CoT-driven layout planning, and the $\textbf{Object Integration Network (OIN)}$ for seamless image editing using off-the-shelf T2I models without retraining. Through applications like batch collage editing and narrative scene generation, LayerCraft empowers non-experts to iteratively design, customize, and refine visual content with minimal manual effort. Code will be released at https://github.com/PeterYYZhang/LayerCraft.","文本到图像生成( T2I) 取得了显著的进展, 但现有的系统仍然缺乏对空间构成、 对象一致性和多步编辑的直觉控制。 我们展示了 $\ textbf{ LayerCraft}$, 这个模块框架使用大语言模型( LLIMs) 作为自主代理器, 以协调结构化、 分层的图像生成和编辑。 ThileCraft 支持两个关键能力:(1) $\ textitle{ 结构化生成}$, 通过思考链推理( Cot) 的简单提示, 使得它能够以可控制、 可解释的方式解析的场景、 目标放置的理由和导出构成; (2) $\ textitleit{ 保护身份、 上层图像生成和图像编辑。 系统由协调员代理 $\ textb{ Chain Artagtalth} , 和 $\ textleftf{Obroduction 整合网络网络 (OIN} $, 用来在不使用常规- develilfliflifliflectional- develop diversal diversal distration distrational distrational2 distrutal distrational distrational distrutdal distrutal distrutdal diviews) diviewtals) diviewtal distrital distrital distrital distritaldaldaldaldaldaldaldaldald","Yuyao Zhang, Jinghao Li, Yu-Wing Tai",2025-05-31T20:45:55Z,LayerCraft: Enhancing Text-to-Image Generation with CoT Reasoning and   Layered Object Integration,LayerCraft: Verbesserung der Text-zu-Bild-Generation mit CoT-Reasoning und Layered Object Integration,图层控件:加强具有 CoT 理由和多层物体集成的文本到图像生成,http://arxiv.org/abs/2504.00010v2
53,"We present an adaptive control scheme to enable the emergence of order within distributed, autonomous multi-agent systems. Past studies showed that under high-density conditions, order generated from traffic-following behavior reduces travel times, while under low densities, choosing direct paths is more beneficial. In this paper, we leveraged those findings to allow aircraft to independently and dynamically adjust their degree of traffic-following behavior based on the current state of the airspace. This enables aircraft to follow other traffic only when beneficial. Quantitative analyses revealed that dynamic traffic-following behavior results in lower aircraft travel times at the cost of minimal levels of additional disorder to the airspace. The sensitivity of these benefits to temporal and spatial horizons was also investigated. Overall, this work highlights the benefits, and potential necessity, of incorporating self-organizing behavior in making distributed, autonomous multi-agent systems scalable.","我们提出了一个适应性控制计划,以便在分布式自主多试剂系统内出现秩序。过去的研究显示,在高密度条件下,交通跟踪行为产生的秩序减少了旅行时间,而在低密度情况下,选择直接路径则更有益。在本文件中,我们利用这些发现使飞机能够根据空气空间的目前状况独立和动态地调整其交通跟踪行为的程度。这只使飞机能够在有利的情况下跟踪其他交通。定量分析显示,动态的交通跟踪行为导致飞机旅行时间减少,其代价是空气空间的额外紊乱程度最小。这些好处对时间和空间视野的敏感性也得到了调查。总体而言,这项工作突出表明了将自我组织行为纳入分布式自主多试剂系统的可伸缩性的好处和潜在必要性。","Anahita Jain, Husni Idris, John-Paul Clarke, Daniel Delahaye",2025-05-31T20:18:35Z,Adaptive Traffic-Following Scheme for Orderly Distributed Control of   Multi-Vehicle Systems,Adaptives Verkehrs-Following-System zur geordneten Verteilung der Kontrolle von Multi-Fahrzeugsystemen,多车辆系统有秩序分配控制的适应性交通监测计划,http://arxiv.org/abs/2506.00703v1
54,"Distributed aggregative optimization methods are gaining increased traction due to their ability to address cooperative control and optimization problems, where the objective function of each agent depends not only on its own decision variable but also on the aggregation of other agents' decision variables. Nevertheless, existing distributed aggregative optimization methods implicitly assume all agents to be truthful in information sharing, which can be unrealistic in real-world scenarios, where agents may act selfishly or strategically. In fact, an opportunistic agent may deceptively share false information in its own favor to minimize its own loss, which, however, will compromise the network-level global performance. To solve this issue, we propose a new distributed aggregative optimization algorithm that can ensure truthfulness of agents and convergence performance. To the best of our knowledge, this is the first algorithm that ensures truthfulness in a fully distributed setting, where no ""centralized"" aggregator exists to collect private information/decision variables from participating agents. We systematically characterize the convergence rate of our algorithm under nonconvex/convex/strongly convex objective functions, which generalizes existing distributed aggregative optimization results that only focus on convex objective functions. We also rigorously quantify the tradeoff between convergence performance and the level of enabled truthfulness under different convexity conditions. Numerical simulations using distributed charging of electric vehicles confirm the efficacy of our algorithm.","分散式优化方法由于其处理合作控制和优化问题的能力而越来越具有牵引力,因为每个代理商的客观功能不仅取决于其自身的决定变量,而且取决于其他代理商决定变量的汇总。然而,现有的分布式集中优化方法暗含地假定所有代理商在信息共享方面都是真实的,在现实世界中,代理商可能自私行事或具有战略意义,这可能不切实际,在现实世界中,代理商可能采取自私或具有战略意义的行为。事实上,机会代理商可能自欺欺人地分享虚假信息,以尽量减少自身损失,但这将损害网络一级的全球绩效。为解决这一问题,我们提议一种新的分布式集中优化算法,可以确保代理商的真实性和趋同性。根据我们的知识,这是确保完全分布式共享环境中真实性的第一个算法,在现实世界中,不存在“集中式”的聚合聚合器,从参与代理商那里收集私人信息/决定变量。我们系统化地将我们的算法的趋同率描述在非对等/凝固/凝固性目标功能下的趋同率。为了解决这个问题,我们提出了一个新的分布式集中式优化算法,可以确保代理人和趋同性优化结果,而仅以稳定化的递化的电算法化的趋和稳定化的递合为我们之间,在稳定化的递合性平化的递化的递化的递合度上,在稳定化的递合算法下,在稳定度上也只能性上也只对等的计算。","Ziqin Chen, Magnus Egerstedt, Yongqiang Wang",2025-05-31T19:07:47Z,Ensuring Truthfulness in Distributed Aggregative Optimization,Gewährleistung von Wahrhaftigkeit in verteilter Aggregation,确保分配分配最佳最佳办法的真相,http://arxiv.org/abs/2501.08512v3
55,"Directly training Large Language Models (LLMs) for Multi-Agent Systems (MAS) remains challenging due to intricate reward modeling, dynamic agent interactions, and demanding generalization requirements. This paper explores whether post-training techniques, specifically Supervised Fine-Tuning (SFT) and Reinforcement Learning with Verifiable Rewards (RLVR), can effectively $\textit{generalize}$ to multi-agent scenarios. We use economic reasoning as a testbed, leveraging its strong foundations in mathematics and game theory, its demand for structured analytical reasoning, and its relevance to real-world applications such as market design, resource allocation, and policy analysis. We introduce $\textbf{Recon}$ ($\textbf{R}$easoning like an $\textbf{ECON}$omist), a 7B-parameter open-source LLM post-trained on a hand-curated dataset of 2,100 high-quality economic reasoning problems. Comprehensive evaluation on economic reasoning benchmarks and multi-agent games reveals clear improvements in structured reasoning and economic rationality. These results underscore the promise of domain-aligned post-training for enhancing reasoning and agent alignment, shedding light on the roles of SFT and RL in shaping model behavior. Code is available at https://github.com/MasterZhou1/Recon .","直接培训多机构系统(MAS)的大型语言模型(LLMS)仍然具有挑战性,因为奖赏模型、动态代理互动和要求普遍化的要求错综复杂,本文件探讨了培训后技术,特别是监督的美工(SFT)和用可验证的奖赏加强学习(RLVR)能否有效地用美元(textit{clusization})对多种试办方案进行直接培训。我们用经济推理作为试金,利用其在数学和游戏理论方面的坚实基础、对结构化分析推理的需求以及它与市场设计、资源分配和政策分析等现实世界应用的相关性。我们引入了$\textbf{Recon}($\textbf{R}$)等培训后技术(RLVRVR)是否能够有效地使用,一个7B参数开源的LM(LM)在2 100个高品质经济推理学问题的手译数据集上受过培训。我们对经济推理基准和多机构游戏进行了全面评价,这显示了结构推理学和经济合理性和经济合理性等现实应用的明显改进。这些结果突出表明,强调在改进后/再校准/再校正的校正的校正的校正的校正。","Yufa Zhou, Shaobo Wang, Xingyu Dong, Xiangqi Jin, Yifang Chen, Yue Min, Kexin Yang, Xingzhang Ren, Dayiheng Liu, Linfeng Zhang",2025-05-31T14:22:40Z,Reasoning Like an Economist: Post-Training on Economic Problems Induces   Strategic Generalization in LLMs,Reasoning Like a Economist: Post-Training zu wirtschaftlichen Problemen führt zu einer strategischen Generalisierung in LLMs,象一名经济学家一样的理由:关于经济问题的培训后在LLM中将战略普遍化,http://arxiv.org/abs/2506.00577v1
56,"The Deferred Acceptance (DA) algorithm is an elegant procedure for finding a stable matching in two-sided matching markets. It ensures that no pair of agents prefers each other to their matched partners. In this work, we initiate the study of two-sided manipulations in matching markets as non-cooperative games. We introduce the accomplice manipulation game, where a man misreports to help a specific woman obtain a better partner, whenever possible. We provide a polynomial time algorithm for finding a pure strategy Nash equilibrium (NE) and show that our algorithm always yields a stable matching - although not every Nash equilibrium corresponds to a stable matching. Additionally, we show how our analytical techniques for the accomplice manipulation game can be applied to other manipulation games in matching markets, such as one-for-many and the standard self-manipulation games. We complement our theoretical findings with empirical evaluations of different properties of the resulting NE, such as the welfare of the agents.","推迟接受算法(DA)是在双面匹配市场中找到稳定匹配的优雅程序。 它确保没有一对代理人相互偏向于对方的伴侣。 在这项工作中, 我们开始研究在匹配市场中的双向操纵作为不合作的游戏。 我们引入共犯操纵游戏, 男性在其中错误报告帮助特定女性尽可能获得更好的伴侣。 我们提供了一种多元时间算法, 用于寻找纯策略的纳什平衡( NE ) , 并显示我们的算法总能产生稳定的匹配 — — 尽管不是每个纳什平衡都匹配稳定匹配。 此外, 我们展示了如何将共犯操纵游戏的分析技术应用到匹配市场的其他操纵游戏中, 比如一对一和标准的自我操纵游戏。 我们用对由此产生的NE的不同属性的经验评估来补充我们的理论发现, 比如代理人的福利。","Hadi Hosseini, Grzegorz Lisowski, Shraddha Pathak",2025-05-31T13:19:31Z,Two-Sided Manipulation Games in Stable Matching Markets,Zweiseitige Manipulationsspiele in stabilen Matching-Märkten,稳定相匹配市场中的双层操纵游戏,http://arxiv.org/abs/2506.00554v1
57,"Hanabi has become a popular game for research when it comes to reinforcement learning (RL) as it is one of the few cooperative card games where you have incomplete knowledge of the entire environment, thus presenting a challenge for a RL agent. We explored different tabular and deep reinforcement learning algorithms to see which had the best performance both against an agent of the same type and also against other types of agents. We establish that certain agents played their highest scoring games against specific agents while others exhibited higher scores on average by adapting to the opposing agent's behavior. We attempted to quantify the conditions under which each algorithm provides the best advantage and identified the most interesting interactions between agents of different types. In the end, we found that temporal difference (TD) algorithms had better overall performance and balancing of play types compared to tabular agents. Specifically, tabular Expected SARSA and deep Q-Learning agents showed the best performance.","在强化学习(RL)方面,Hanabi已成为一种热门的研究游戏,因为它是你对整个环境不完全了解的为数不多的合作纸牌游戏之一,因此对一个RL代理人提出了挑战。我们探索了不同的表格和深层强化学习算法,以确定哪种方法对同一类型的代理人和其他类型的代理人具有最佳性能。我们确定某些代理人对特定代理人玩最高评分游戏,而另一些代理人则通过适应对立代理人的行为,平均得分较高。我们试图量化每种算法提供最佳优势的条件,并查明不同类型代理人之间最有趣的互动。最后,我们发现时间差异(TD)算法与表代理人相比,总体性能和游戏类型之间的平衡性能更好。具体地说,SARSA表格和深层次的Q-学习代理人表现出最佳的性能。","Nina Cohen, Kordel K. France",2025-05-31T08:24:16Z,Reinforcement Learning for Hanabi,Verstärkungslernen für Hanabi,汉纳比强化学习,http://arxiv.org/abs/2506.00458v1
58,"We introduce Sorrel (https://github.com/social-ai-uoft/sorrel), a simple Python interface for generating and testing new multi-agent reinforcement learning environments. This interface places a high degree of emphasis on simplicity and accessibility, and uses a more psychologically intuitive structure for the basic agent-environment loop, making it a useful tool for social scientists to investigate how learning and social interaction leads to the development and change of group dynamics. In this short paper, we outline the basic design philosophy and features of Sorrel.","我们引入Sorrel(https://github.com/social-ai-uoft/sorrel),这是一个简单的Python界面,用于生成和测试新的多剂强化学习环境。这个界面高度强调简便和无障碍性,并使用一种更具有心理直观的结构,用于基本代理物-环境循环,使社会科学家能够调查学习和社会互动如何导致群体动态的发展和变化。在这个简短的文件中,我们概述了Sorrel的基本设计理念和特征。","Rebekah A. Gelpí, Yibing Ju, Ethan C. Jackson, Yikai Tang, Shon Verch, Claas Voelcker, William A. Cunningham",2025-05-30T21:04:47Z,Sorrel: A simple and flexible framework for multi-agent reinforcement   learning,Sorrel: Ein einfacher und flexibler Rahmen für Multi-Agenten-Verstärkung,Sorrel:一个简单灵活的多剂强化学习框架,http://arxiv.org/abs/2506.00228v1
59,"The Computing Continuum (CC) is an emerging Internet-based computing paradigm that spans from local Internet of Things sensors and constrained edge devices to large-scale cloud data centers. Its goal is to orchestrate a vast array of diverse and distributed computing resources to support the next generation of Internet-based applications. However, the distributed, heterogeneous, and dynamic nature of CC platforms demands distributed intelligence for adaptive and resilient service management. This article introduces a distributed stream processing pipeline as a CC use case, where each service is managed by an Active Inference (AIF) agent. These agents collaborate to fulfill service needs specified by SLOiDs, a term we introduce to denote Service Level Objectives that are aware of its deployed devices, meaning that non-functional requirements must consider the characteristics of the hosting device. We demonstrate how AIF agents can be modeled and deployed alongside distributed services to manage them autonomously. Our experiments show that AIF agents achieve over 90% SLOiD fulfillment when using tested transition models, and around 80% when learning the models during deployment. We compare their performance to a multi-agent reinforcement learning algorithm, finding that while both approaches yield similar results, MARL requires extensive training, whereas AIF agents can operate effectively from the start. Additionally, we evaluate the behavior of AIF agents in offloading scenarios, observing a strong capacity for adaptation. Finally, we outline key research directions to advance AIF integration in CC platforms.","Econtinuum (CC) 是一个新兴的基于互联网的计算模式,它从当地互联网的事物传感器和受限边缘装置传感器和受限边缘装置到大型云层数据中心,从当地互联网到大型云层数据中心,其宗旨是安排各种各样的分布式和分布式计算资源,以支持下一代基于互联网的应用;然而,CC平台的分布式、多样性和动态性质要求分配适应性和弹性服务管理情报。本篇文章将分布式流处理管道作为CC使用案例,其中每项服务都由积极的推断(AIF)代理商管理。这些代理商合作满足SLOIDs规定的服务需求,这是我们介绍的术语,用来表示服务级目标了解其部署装置,这意味着非功能性要求必须考虑托管装置的特性。我们展示了如何将AIFA代理商的模型模型模型模型模型模型模型模型模型模型模型和大约80%的功能。我们将其业绩与多代理商强化学习算法进行比较,发现两种方法都能够产生类似的结果,这意味着非功能性要求考虑托管平台的特性特性特性特性。 我们要求对AIFFA的代理人进行广泛的演化,而后,我们从ARIFIFA的模型的模型的模型进行广泛的演算。","Victor Casamayor Pujol, Boris Sedlak, Tommaso Salvatori, Karl Friston, Schahram Dustdar",2025-05-30T14:10:33Z,Distributed Intelligence in the Computing Continuum with Active   Inference,Verteilte Intelligenz im Computing Continuum mit aktiver Schlussfolgerung,具有主动推断力的计算机连续体中传播的情报,http://arxiv.org/abs/2505.24618v1
60,"Multi-agent systems (MAS) have emerged as a promising approach for enhancing the reasoning capabilities of large language models in complex problem-solving; however, current MAS frameworks suffer from poor flexibility and scalability with underdeveloped optimization strategies. To address these challenges, we propose ReSo, which integrates task graph generation with a reward-driven two-stage agent selection process centered on our Collaborative Reward Model that provides fine-grained reward signals to optimize MAS cooperation. We also introduce an automated data synthesis framework for generating MAS benchmarks without any human annotations. Experimental results show that ReSo matches or outperforms existing methods, achieving 33.7 percent accuracy on Math-MAS and 32.3 percent accuracy on SciBench-MAS, where other approaches completely fail.","多试剂系统(MAS)已成为加强大型语言模型在复杂的解决问题过程中的推理能力的一个很有希望的方法;然而,目前的MAS框架的灵活性和可伸缩性差,与欠发达的优化战略不尽相同。为了应对这些挑战,我们提议ReSo,将任务图生成与以我们的合作奖励奖励模式为核心的两阶段代理物选择过程结合起来,该模式为优化MAS合作提供细微的奖赏信号。我们还引入了一个自动数据合成框架,在没有人文说明的情况下生成MAS基准。实验结果显示,ReSo与现有方法相匹配或优于现有方法,在数学-MAS中实现了33.7%的准确性,在SciBench-MAS中实现了32.3%的准确性,在其他方法完全失败的情况下,SciBench-MAS中实现了33.3%的准确性。","Heng Zhou, Hejia Geng, Xiangyuan Xue, Li Kang, Yiran Qin, Zhiyong Wang, Zhenfei Yin, Lei Bai",2025-05-30T11:40:44Z,ReSo: A Reward-driven Self-organizing LLM-based Multi-Agent System for   Reasoning Tasks,"ReSo: Ein reward-getriebenes, selbstorganisierendes LLM-basiertes Multi-Agenten-System zur Begründung von Aufgaben",Reso:一个以奖利为驱动的以LLM为基础的自行组织、以LLM为基础的多机构提出说明任务理由的多机构机构系统,http://arxiv.org/abs/2503.02390v3
61,"Crowdsourcing services, such as Waze, leverage a mass of mobile users to learn massive point-of-interest (PoI) information while traveling and share it as a public good. Given that crowdsourced users mind their travel costs and possess various preferences over the PoI information along different paths, we formulate the problem as a novel non-atomic multi-path routing game with positive network externalities among users in social information sharing. In the absence of any incentive design, our price of anarchy (PoA) analysis shows that users' selfish routing on the path with the lowest cost will limit information diversity and lead to $PoA = 0$ with an arbitrarily large efficiency loss from the social optimum. This motivates us to design effective incentive mechanisms to remedy while upholding desirable properties such as individual rationality, incentive compatibility, and budget balance for practical users. Without requiring a specific user's path preference, we present a non-monetary mechanism called Adaptive Information Restriction (AIR) that reduces non-cooperative users' access to the public good as an indirect penalty, which meets all the desirable properties. By meticulously adapting penalty fractions to the actual user flows along different paths, our AIR achieves non-trivial $PoA = \frac{1}{4}$ with low complexity $O(k\log k+\log m)$, where $k$ and $m$ denote the numbers of involved paths and user types, respectively. If the system can further enable pricing for users, we then propose a new monetary mechanism called Adaptive Side-Payment (ASP), which adaptively charges and rewards users according to their chosen paths, respectively. Our ASP mechanism successively achieves a $PoA = \frac{1}{2}$ with even reduced complexity $O(k\log k)$. Finally, our theoretical findings are well corroborated by our experimental results using a real-world public dataset.","例如Waze, 利用大批移动用户在旅行时学习大量利益点(PoI)信息, 并将其作为公益物分享。 鉴于众源用户在旅行费用上心思,并拥有对PoI信息的不同偏好, 我们将问题发展成一个新的非原子多路路路游戏, 用户在社会信息共享中拥有积极的网络外差。 在缺乏任何激励设计的情况下, 我们的无政府状态分析(PoA) 表明用户自私地以最低成本在路上学习大量利益点(PoI) 信息多样性, 并导致美元=0美元, 社会最佳的任意地大幅效率损失。 这激励我们设计有效的激励机制, 在维护个人合理性、 激励兼容性和实际用户预算平衡等适当性特性的同时, 我们提出一个非货币机制, 适应性信息限制(AIR) , 减少不合作用户对公共福利的接触, 从而进一步满足了所有理想的特性。 通过精确地将罚款部分调整到实际用户流动的 $( $ 美元 ) a dirik) a lioral deal rial yalalalalal ad) a falation 。","Songhua Li, Lingjie Duan",2025-05-30T09:45:20Z,On Incentivizing Social Information Sharing Through Routing Games,Auf Anreize für den Austausch von sozialen Informationen durch Routing-Spiele,通过巡回运动会鼓励社会信息共享,http://arxiv.org/abs/2308.13301v5
62,"Recently, many approaches, such as Chain-of-Thought (CoT) prompting and Multi-Agent Debate (MAD), have been proposed to further enrich Large Language Models' (LLMs) complex problem-solving capacities in reasoning scenarios. However, these methods may fail to solve complex problems due to the lack of ability to find optimal solutions. Swarm Intelligence has been serving as a powerful tool for finding optima in the field of traditional optimization problems. To this end, we propose integrating swarm intelligence into the reasoning process by introducing a novel Agent-based Swarm Intelligence (ASI) paradigm. In this paradigm, we formulate LLM reasoning as an optimization problem and use a swarm intelligence scheme to guide a group of LLM-based agents in collaboratively searching for optimal solutions. To avoid swarm intelligence getting trapped in local optima, we further develop a Swarm Intelligence Enhancing Reasoning (SIER) framework, which develops a density-driven strategy to enhance the reasoning ability. To be specific, we propose to perform kernel density estimation and non-dominated sorting to optimize both solution quality and diversity simultaneously. In this case, SIER efficiently enhances solution space exploration through expanding the diversity of the reasoning path. Besides, a step-level quality evaluation is used to help agents improve solution quality by correcting low-quality intermediate steps. Then, we use quality thresholds to dynamically control the termination of exploration and the selection of candidate steps, enabling a more flexible and efficient reasoning process. Extensive experiments are ...","最近,提出了许多办法,例如“链路”促进和多机构辩论(MAD),以进一步丰富大语言模型(LLM)复杂的解决问题能力;然而,由于缺乏找到最佳解决办法的能力,这些办法可能无法解决复杂的问题;Swarm Intell一直作为在传统优化问题领域寻找选择的有力工具;为此,我们提议采用新的基于代理的“快速智能”模式,将群状情报纳入推理过程;在这一模式中,我们将LLM推理作为优化问题,并使用一种以LLLM为基础的代理机构在协作寻求最佳解决办法方面采用温和情报计划;为避免散乱情报被困在本地优化问题领域,我们进一步开发了Swarm Intreme Indistrictation Exating(SIER)框架,以开发一种以密度驱动的战略,以提高推理能力;具体地说,我们提议进行以核心密度估算和非主导方式排序,以优化解决方案的质量和多样性;同时,我们建议采用一种扶持性推理方法指导以优化候选人质量和多样性。","Ying Zhu, Heng Zhou, Rui Su, Peiqin Zhuang, Lei Bai",2025-05-30T08:59:59Z,Swarm Intelligence Enhanced Reasoning: A Density-Driven Framework for   LLM-Based Multi-Agent Optimization,Swarm Intelligence Enhanced Reasoning: Ein dichtegetriebenes Framework für die LLM-basierte Multi-Agent-Optimierung,蜂群情报强化理由:基于LLM的多重行为者优化的密度驱动框架,http://arxiv.org/abs/2505.17115v2
63,"Multi-agent reinforcement learning (MARL) has achieved significant progress in large-scale traffic control, autonomous vehicles, and robotics. Drawing inspiration from biological systems where roles naturally emerge to enable coordination, role-based MARL methods have been proposed to enhance cooperation learning for complex tasks. However, existing methods exclusively derive roles from an agent's past experience during training, neglecting their influence on its future trajectories. This paper introduces a key insight: an agent's role should shape its future behavior to enable effective coordination. Hence, we propose Role Discovery and Diversity through Dynamics Models (R3DM), a novel role-based MARL framework that learns emergent roles by maximizing the mutual information between agents' roles, observed trajectories, and expected future behaviors. R3DM optimizes the proposed objective through contrastive learning on past trajectories to first derive intermediate roles that shape intrinsic rewards to promote diversity in future behaviors across different roles through a learned dynamics model. Benchmarking on SMAC and SMACv2 environments demonstrates that R3DM outperforms state-of-the-art MARL approaches, improving multi-agent coordination to increase win rates by up to 20%.","多试剂强化学习(MARL)在大规模交通控制、自主车辆和机器人领域取得了显著进展。从自然产生协调作用的生物系统中汲取灵感,提出了基于角色的MARL方法,以加强复杂任务的合作学习。然而,现有方法完全取自代理人以往在培训期间的经验,忽视了他们对未来轨迹的影响。本文件介绍了一个关键见解:代理人的作用应影响其未来行为,以便能够进行有效的协调。因此,我们提议通过动态模型(R3DM),即基于角色的新型框架,即基于角色的发现和多样性框架,通过最大限度地利用代理人作用、观察轨迹和预期未来行为之间的相互信息来学习新兴作用。R3DM优化了拟议目标,方法是对过去的轨迹进行对比性学习,首先通过一个学习的动态模型,形成内在的奖励,以促进今后不同角色的行为的多样性。我们提议通过动态模型(R3DMAR)和SMACv2环境的基准显示,R3DMAR超越了最新状态,更新MARL方法,改进了多试率,以赢率提高20。","Harsh Goel, Mohammad Omama, Behdad Chalaki, Vaishnav Tadiparthi, Ehsan Moradi Pari, Sandeep Chinchali",2025-05-30T06:40:19Z,R3DM: Enabling Role Discovery and Diversity Through Dynamics Models in   Multi-agent Reinforcement Learning,R3DM: Rollenfindung und Diversität durch Dynamics-Modelle im Multi-Agenten-Verstärkungs-Lernen,R3DM:通过多机构强化学习中的动态模型发现扶持作用和多样性,http://arxiv.org/abs/2505.24265v1
64,"While multi-agent LLM systems show strong capabilities in various domains, they are highly vulnerable to adversarial and low-performing agents. To resolve this issue, in this paper, we introduce a general and adversary-resistant multi-agent LLM framework based on credibility scoring. We model the collaborative query-answering process as an iterative game, where the agents communicate and contribute to a final system output. Our system associates a credibility score that is used when aggregating the team outputs. The credibility scores are learned gradually based on the past contributions of each agent in query answering. Our experiments across multiple tasks and settings demonstrate our system's effectiveness in mitigating adversarial influence and enhancing the resilience of multi-agent cooperation, even in the adversary-majority settings.","虽然多试剂LLM系统在不同领域表现出很强的能力,但它们极易受到敌对和低效代理人的伤害。为了解决这个问题,我们在本文件中采用基于信誉评分的通用和对抗性多试剂LLM框架。我们把合作问答过程模拟为迭接游戏,让代理人交流和为最终系统产出作出贡献。我们的系统将一个信用评分作为组合团队产出时使用的。根据每个代理人过去在问答中的贡献,逐渐获得信誉评分。我们跨越多种任务和背景的实验表明我们的系统在减轻对抗影响和加强多剂合作的复原力方面的效力,即使在对抗占多数的情况下也是如此。","Sana Ebrahimi, Mohsen Dehghankar, Abolfazl Asudeh",2025-05-30T05:57:37Z,An Adversary-Resistant Multi-Agent LLM System via Credibility Scoring,Ein gegnerisch-beständiges Multi-Agent-LLM-System über die Bewertung der Glaubwürdigkeit,通过信用度测分系统建立逆向-相对性多业务性多业务性LLM系统,http://arxiv.org/abs/2505.24239v1
65,"This paper studies the networked multi-agent reinforcement learning (NMARL) problem, where the objective of agents is to collaboratively maximize the discounted average cumulative rewards. Different from the existing methods that suffer from poor expression due to linear function approximation, we propose a distributed neural policy gradient algorithm that features two innovatively designed neural networks, specifically for the approximate Q-functions and policy functions of agents. This distributed neural policy gradient algorithm consists of two key components: the distributed critic step and the decentralized actor step. In the distributed critic step, agents receive the approximate Q-function parameters from their neighboring agents via a time-varying communication networks to collaboratively evaluate the joint policy. In contrast, in the decentralized actor step, each agent updates its local policy parameter solely based on its own approximate Q-function. In the convergence analysis, we first establish the global convergence of agents for the joint policy evaluation in the distributed critic step. Subsequently, we rigorously demonstrate the global convergence of the overall distributed neural policy gradient algorithm with respect to the objective function. Finally, the effectiveness of the proposed algorithm is demonstrated by comparing it with a centralized algorithm through simulation in the robot path planning environment.","本文研究了网络化多试剂强化学习(NMARL)问题,代理商的目标是通过协作最大限度地扩大折扣平均累积收益。不同于由于线性功能近似而表现不佳的现有方法,我们建议了分布式神经政策梯度算法,它有两种创新设计的神经网络,具体针对代理商的近似功能和政策功能。这种分布式神经政策梯度算法由两个关键部分组成:分布式评论器步骤和分散式行为者步骤。在分布式评论器步骤中,代理商通过一个时间变化通信网络从邻居那里获得大约的Q功能参数,以合作评价联合政策。相比之下,在分散式行为者步骤中,每个代理商仅根据其本身的近似Q功能更新其当地政策参数。在趋同式分析中,我们首先在分布式评论器步骤中确定联合政策评价的代理商的全球趋同性。随后,我们严格地证明分布式神经梯度算法与目标功能的全球趋同性。最后,通过机器人路径规划环境的模拟将其与中央算法进行比较,从而证明拟议的算法的有效性。","Pengcheng Dai, Yuanqiu Mo, Wenwu Yu, Wei Ren",2025-05-30T01:23:14Z,Distributed Neural Policy Gradient Algorithm for Global Convergence of   Networked Multi-Agent Reinforcement Learning,Verteilter neuraler politischer Gradienten-Algorithmus für globale Konvergenz des vernetzten Multi-Agenten-Verstärkungs-Lernens,网络化多机构强化学习全球趋同分布式神经政策梯度,http://arxiv.org/abs/2505.24113v1
66,"Recent studies show that LLMs possess different skills and specialize in different tasks. In fact, we observe that their varied performance occur in several levels of granularity. For example, in the code optimization task, code LLMs excel at different optimization categories and no one dominates others. This observation prompts the question of how one leverages multiple LLM agents to solve a coding problem without knowing their complementary strengths a priori. We argue that a team of agents can learn from each other's successes and failures so as to improve their own performance. Thus, a lesson is the knowledge produced by an agent and passed on to other agents in the collective solution process. We propose a lesson-based collaboration framework, design the lesson solicitation--banking--selection mechanism, and demonstrate that a team of small LLMs with lessons learned can outperform a much larger LLM and other multi-LLM collaboration methods.","最近的研究显示,LLMs拥有不同的技能,并且专门从事不同的工作。事实上,我们观察到,它们的不同性能发生在几个颗粒层次上。例如,在代码优化任务中,代码LLM在不同的优化类别中非常出色,而没有一人在其他方面占优势。这一观察促使了一个问题,即如何利用多个LLM代理商来解决编码问题而不先知其互补优势。我们争辩说,一个代理商团队可以从彼此的成败中吸取教训,以便提高自身的性能。因此,一个教训就是代理人在集体解决方案过程中产生的知识,并传递给其他代理商。我们提出了一个基于经验的合作框架,设计了招标-银行-选择机制,并表明一个拥有经验教训的小型LLMM团队能够超越一个更大的LM和其他多LLM合作方法。","Yuanzhe Liu, Ryan Deng, Tim Kaler, Xuhao Chen, Charles E. Leiserson, Yao Ma, Jie Chen",2025-05-29T18:56:20Z,Lessons Learned: A Multi-Agent Framework for Code LLMs to Learn and   Improve,Learned Lessons: Ein Multi-Agenten-Rahmen für Code-LLMs zu lernen und zu verbessern,"经验教训:一个多机构框架,供《守则》 "" 学习和改进 "" 的 "" 学习 "" 、 "" 学习 "" 、 "" 学习 "" 、 "" 改进 "" 、 "" 学习 "" 、 "" 学习 "" 、 "" 学习 "" 、 "" 改进 "" 、 "" 学习 "" 和 "" 改进 "" 的 "" 守则 "" 、 "" 学习 "" 、 "" 学习 "" 、 "" 改进 "" 、 "" 学习 "" 、 "" 学习 "" 、 "" 改进 "" 、 "" 学习 "" 、 "" 学习 "" 、 "" 和 "" 改进 "" 、 "" 学习 "" 、 "" 学习 "" 、 "" 、 "" 规范 "" 、 "" 学习 "" 、 "" 、 "" 学习 "" 、 "" 学习 "" 、 "" 学习 "" 、 "" 、 "" 、 "" 学习 "" 、 "" 学习 "" 、 "" 学习 "" 、 "" 学习 "" 、 "" 学习 "" 、 "" 学习 "" 学习 "" 、 "" 学习 "" 、 "" 学习 "" 、 "" 、 "" 、 "" 、 "" 学习 "" 学习 "" 学习 "" 、 "" 、 "" 、 "" 学习 "" 学习 "" 、 "" 、 "" 、 "" 学习 "" 、 "" 、 "" 、 "" 、 "" 、 "" 学习 "" 、 "" 、 "" 学习 "" 、 "" 、 "" 、 "" 、 "" 、 "" 、 "" 、 "" 、 "" 、 "" 、 "" 、 """,http://arxiv.org/abs/2505.23946v1
67,"The rapid advancement of large language models (LLMs) has enabled the development of multi-agent systems where multiple LLM-based agents collaborate on complex tasks. However, existing systems often rely on centralized coordination, leading to scalability bottlenecks, reduced adaptability, and single points of failure. Privacy and proprietary knowledge concerns further hinder cross-organizational collaboration, resulting in siloed expertise. We propose AgentNet, a decentralized, Retrieval-Augmented Generation (RAG)-based framework that enables LLM-based agents to specialize, evolve, and collaborate autonomously in a dynamically structured Directed Acyclic Graph (DAG). Unlike prior approaches with static roles or centralized control, AgentNet allows agents to adjust connectivity and route tasks based on local expertise and context. AgentNet introduces three key innovations: (1) a fully decentralized coordination mechanism that eliminates the need for a central orchestrator, enhancing robustness and emergent intelligence; (2) dynamic agent graph topology that adapts in real time to task demands, ensuring scalability and resilience; and (3) a retrieval-based memory system for agents that supports continual skill refinement and specialization. By minimizing centralized control and data exchange, AgentNet enables fault-tolerant, privacy-preserving collaboration across organizations. Experiments show that AgentNet achieves higher task accuracy than both single-agent and centralized multi-agent baselines.","大型语言模型(LLMS)的迅速发展使得能够发展多种试剂系统,使以LLM为基础的多个代理商在复杂的任务上进行合作,然而,现有系统往往依赖集中协调,导致可扩展性瓶颈、降低适应性和单一的失败点。隐私和专有性知识问题进一步阻碍跨组织合作,导致专门知识的分散。我们提议AgritNet(一个分散的、检索和启动的一代(RAG)框架),使以LLM为基础的代理商能够在动态结构的定向循环图(DAG)中进行专门化、演化和自主协作。与以前具有固定作用或集中控制的方法不同,AgentNet允许代理商根据当地专长和背景调整连通性和路线任务。AgritNet引入了三项关键创新:(1) 完全分散的协调机制,消除对中央管弦乐器的需求,加强稳健性和新兴情报;(2) 动态代理商图示表,在实时时间上适应任务要求,确保可扩展性和复原力;(3) 用于支持持续技能改进和专业化的代理商检索的记忆系统。通过尽可能减少中央控制和中央级数据库,使高级数据库能够显示各种保密性任务基准。","Yingxuan Yang, Huacan Chai, Shuai Shao, Yuanyi Song, Siyuan Qi, Renting Rui, Weinan Zhang",2025-05-29T18:55:08Z,AgentNet: Decentralized Evolutionary Coordination for LLM-based   Multi-Agent Systems,AgentNet: Dezentralisierte Evolutionskoordination für LLM-basierte Multi-Agent-Systeme,AgentNet: 以LLM为基础的多机构系统分散化演进协调,http://arxiv.org/abs/2504.00587v2
68,"Tool use has turned large language models (LLMs) into powerful agents that can perform complex multi-step tasks by dynamically utilising external software components. However, these tools must be implemented in advance by human developers, hindering the applicability of LLM agents in domains demanding large numbers of highly specialised tools, like in life sciences and medicine. Motivated by the growing trend of scientific studies accompanied by public code repositories, we propose ToolMaker, an agentic framework that autonomously transforms papers with code into LLM-compatible tools. Given a GitHub URL and short task description, ToolMaker autonomously installs dependencies and generates code to perform the task, using a closed-loop self-correction mechanism for debugging. To evaluate our approach, we introduce a benchmark comprising 15 complex computational tasks spanning various domains with over 100 unit tests to assess correctness and robustness. Our method correctly implements 80% of the tasks, substantially outperforming current state-of-the-art software engineering agents. ToolMaker therefore is a step towards fully autonomous agent-based scientific workflows. Our code and benchmark are publicly available at https://github.com/KatherLab/ToolMaker.","工具的使用已经使大型语言模型(LLMs)变成强大的代理商,能够通过动态地使用外部软件组件来执行复杂的多步任务。然而,这些工具必须由人类开发者事先实施,从而妨碍LLM代理商在生命科学和医学等要求大量高度专业化工具的领域的适用性。受公共代码库伴随科学研究不断增长的趋势的驱动,我们建议TolMaker,这是一个将带有代码的文件自动转换成符合LLM兼容工具的代理框架。鉴于GitHub URL和短期任务描述,TowerMaker自动安装依赖性并生成执行任务的代码,使用封闭式环形自我校正机制进行调试。为了评估我们的方法,我们引入了一个由15个复杂计算任务组成的基准,覆盖了多个领域,有100多个单位测试来评估正确性和稳健健性。我们的方法正确地执行了80%的任务,大大超过当前最先进的软件工程代理商的绩效。因此,Tol-Maker是朝着完全自主的代理商基础科学工作流程迈出的一步。我们的代码和基准可以在 https://Mgustorker/Towker.","Georg Wölflein, Dyke Ferber, Daniel Truhn, Ognjen Arandjelović, Jakob Nikolas Kather",2025-05-29T18:47:41Z,LLM Agents Making Agent Tools,"LLM-Agenten, die Agenten-Werkzeuge herstellen",LLM LLM 代理代理代理代理代理商工具,http://arxiv.org/abs/2502.11705v2
69,"AI agents are increasingly used in consumer-facing applications to assist with tasks such as product search, negotiation, and transaction execution. In this paper, we explore a future scenario where both consumers and merchants authorize AI agents to fully automate negotiations and transactions. We aim to answer two key questions: (1) Do different LLM agents vary in their ability to secure favorable deals for users? (2) What risks arise from fully automating deal-making with AI agents in consumer markets? To address these questions, we develop an experimental framework that evaluates the performance of various LLM agents in real-world negotiation and transaction settings. Our findings reveal that AI-mediated deal-making is an inherently imbalanced game -- different agents achieve significantly different outcomes for their users. Moreover, behavioral anomalies in LLMs can result in financial losses for both consumers and merchants, such as overspending or accepting unreasonable deals. These results underscore that while automation can improve efficiency, it also introduces substantial risks. Users should exercise caution when delegating business decisions to AI agents.","以消费者为对象的大赦国际代理人越来越多地被用于消费者为对象的应用程序,以协助完成产品搜索、谈判和交易执行等任务。在本文件中,我们探讨了消费者和商人授权大赦国际代理人使谈判和交易完全自动化的未来情景。我们的目标是回答两个关键问题:(1) 不同的LLM代理商在为用户争取优惠交易的能力方面是否各不相同?(2) 在消费者市场上与AI代理商进行完全自动化交易会产生什么风险?为了解决这些问题,我们制定了一个实验框架,评估各种LM代理商在现实世界谈判和交易环境中的表现。我们的调查结果显示,AI中介交易的制作是一种固有的不平衡游戏,不同的代理商为其用户取得了显著不同的结果。此外,LLMMS的行为异常可能会给消费者和商人造成财务损失,例如过度支出或接受不合理的交易。这些结果强调,自动化可以提高效率,但也带来很大风险。用户在将商业决定委托给AI代理商时,应该谨慎行事。","Shenzhe Zhu, Jiao Sun, Yi Nian, Tobin South, Alex Pentland, Jiaxin Pei",2025-05-29T17:41:39Z,The Automated but Risky Game: Modeling Agent-to-Agent Negotiations and   Transactions in Consumer Markets,"Das automatisierte, aber riskante Spiel: Modellierung von Agent-zu-Agent-Verhandlungen und Transaktionen in Verbrauchermärkten",自动但有风险游戏:消费者市场代理对代理谈判和交易的模拟,http://arxiv.org/abs/2506.00073v1
70,"Developing AI agents capable of collaborating with previously unseen partners is a fundamental generalization challenge in multi-agent learning, known as Ad Hoc Teamwork (AHT). Existing AHT approaches typically adopt a two-stage pipeline, where first, a fixed population of teammates is generated with the idea that they should be representative of the teammates that will be seen at deployment time, and second, an AHT agent is trained to collaborate well with agents in the population. To date, the research community has focused on designing separate algorithms for each stage. This separation has led to algorithms that generate teammate pools with limited coverage of possible behaviors, and that ignore whether the generated teammates are easy to learn from for the AHT agent. Furthermore, algorithms for training AHT agents typically treat the set of training teammates as static, thus attempting to generalize to previously unseen partner agents without assuming any control over the distribution of training teammates. In this paper, we present a unified framework for AHT by reformulating the problem as an open-ended learning process between an ad hoc agent and an adversarial teammate generator. We introduce ROTATE, a regret-driven, open-ended training algorithm that alternates between improving the AHT agent and generating teammates that probe its deficiencies. Extensive experiments across diverse AHT environments demonstrate that ROTATE significantly outperforms baselines at generalizing to an unseen set of evaluation teammates, thus establishing a new standard for robust and generalizable teamwork.","在多试剂学习(称为特设团队工作(AHT)中,发展能够与先前的隐蔽伙伴合作的AI代理机构是一项基本的概括性挑战。 现有的AHT方法通常采用两阶段管道,第一,固定的队友组成,其想法是他们应当代表部署时将看到的队友,第二,AHT代理机构受过培训,能够与人口中的代理人进行良好合作。到目前为止,研究界一直侧重于为每个阶段设计不同的算法。这种分离导致了一种算法,这种算法产生了团队间集合,对可能的行为的覆盖面有限,而且忽视了所形成的队友是否容易向AHT代理机构学习。此外,培训AHT代理机构的算法通常将一组培训队友视为静态,从而试图向以前不为人所知的伙伴代理人推广,而没有对培训队的分布实行任何控制。在本文中,我们提出了一个AHT的统一框架,作为特设代理和对抗性团队之间开放式学习过程。我们引入了对AHATT机构进行简单性评估的方法,因此,对AOT公司进行一个公开的实验室,对ABATT团队进行多样化的升级。","Caroline Wang, Arrasy Rahman, Jiaxun Cui, Yoonchang Sung, Peter Stone",2025-05-29T17:24:54Z,ROTATE: Regret-driven Open-ended Training for Ad Hoc Teamwork,ROTATE: Bedauern-getriebenes Open-End-Training für Ad-Hoc-Teamwork,对特设团队工作不限成员名额培训的遗憾驱动的不限名额培训,http://arxiv.org/abs/2505.23686v1
71,"The rapid growth of e-commerce and the increasing demand for timely, cost-effective last-mile delivery have increased interest in collaborative logistics. This research introduces a novel collaborative synchronized multi-platform vehicle routing problem with drones and robots (VRP-DR), where a fleet of $\mathcal{M}$ trucks, $\mathcal{N}$ drones and $\mathcal{K}$ robots, cooperatively delivers parcels. Trucks serve as mobile platforms, enabling the launching, retrieving, and en-route charging of drones and robots, thereby addressing critical limitations such as restricted payload capacities, limited range, and battery constraints. The VRP-DR incorporates five realistic features: (1) multi-visit service per trip, (2) multi-trip operations, (3) flexible docking, allowing returns to the same or different trucks (4) cyclic and acyclic operations, enabling return to the same or different nodes; and (5) en-route charging, enabling drones and robots to recharge while being transported on the truck, maximizing operational efficiency by utilizing idle transit time. The VRP-DR is formulated as a mixed-integer linear program (MILP) to minimize both operational costs and makespan. To overcome the computational challenges of solving large-scale instances, a scalable heuristic algorithm, FINDER (Flexible INtegrated Delivery with Energy Recharge), is developed, to provide efficient, near-optimal solutions. Numerical experiments across various instance sizes evaluate the performance of the MILP and heuristic approaches in terms of solution quality and computation time. The results demonstrate significant time savings of the combined delivery mode over the truck-only mode and substantial cost reductions from enabling multi-visits. The study also provides insights into the effects of en-route charging, docking flexibility, drone count, speed, and payload capacity on system performance.","电子商务的迅速增长和对及时、具有成本效益的最后一英里交货的需求不断增加,增加了对合作物流的兴趣。这一研究引入了新型的协同性多平台机动车辆航线问题,无人机和机器人(VRP-DR)都存在这种新型的多平台车辆航线问题。 在这样的车队中,由一辆卡车、一辆卡车和一辆汽车组成的多路卡车、$mathcal{N}美元和$mathcal{K}机器人,它们合作运送包裹。卡车作为移动平台,能够启动、回收和绕行收取无人机和机器人的费用,从而解决诸如有限有效载荷能力、有限射程和电池限制等关键限制。 VRP-DR包含五个现实的特征:(1) 每趟多路服务,(2)多路业务,(3)灵活的对接,允许返回相同或不同的卡车(4) 自行车和自行车作业,能够返回相同或不同的节点;以及(5) 定期收费,使无人机和机器人能够进行再补给,同时在卡车上运输,通过近距离的流运时间实现最大操作效率。","Sumbal Malik, Majid Khonji, Khaled Elbassioni, Jorge Dias",2025-05-29T15:58:01Z,Collaborative Last-Mile Delivery: A Multi-Platform Vehicle Routing   Problem With En-route Charging,Collaborative Last-Mile Lieferung: Ein Multi-Platform Fahrzeug Routing Problem mit en-route Laden,合作性最后一式交付:多平台车辆运行问题与连路充电,http://arxiv.org/abs/2505.23584v1
72,"LLM-based multi-agent systems (MAS) have shown promise in tackling complex tasks. However, existing solutions often suffer from limited agent coordination and heavy reliance on predefined Standard Operating Procedures (SOPs), which demand extensive human input. To address these limitations, we propose MegaAgent, a large-scale autonomous LLM-based multi-agent system. MegaAgent generates agents based on task complexity and enables dynamic task decomposition, parallel execution, efficient communication, and comprehensive system monitoring of agents. In evaluations, MegaAgent demonstrates exceptional performance, successfully developing a Gobang game within 800 seconds and scaling up to 590 agents in a national policy simulation to generate multi-domain policies. It significantly outperforms existing systems, such as MetaGPT, in both task completion efficiency and scalability. By eliminating the need for predefined SOPs, MegaAgent demonstrates exceptional scalability and autonomy, setting a foundation for advancing true autonomy in MAS. Our code is available at https://github.com/Xtra-Computing/MegaAgent .","以LLM为主的多试剂系统(MAS)在应对复杂任务方面表现出了希望,然而,现有解决办法往往因代理人协调有限和严重依赖预先确定的标准作业程序(SOPs)而受到影响,这些程序需要大量的人力投入。为解决这些限制,我们建议MegaAgency,这是一个大型自主LMM多试剂系统。MegaAgency根据任务的复杂性产生代理人,使任务能够动态分解、平行执行、高效通信和对代理人的全面系统监测。在评价中,MegaAgency展示了杰出的业绩,在800秒内成功开发了Gobang游戏,并在国家政策模拟中推广到590个代理人,以产生多域政策。它在任务完成效率和可扩缩性方面大大优于MetaGPT等现有系统。通过消除对预先确定的SOPs的需要,MegaAgency展示了异常的可扩展性和自主性,为推进MAS的真正自治奠定了基础。我们的代码可在https://github.com/Xtra-Computing/MegaAgentient查阅。","Qian Wang, Tianyu Wang, Zhenheng Tang, Qinbin Li, Nuo Chen, Jingsheng Liang, Bingsheng He",2025-05-29T14:51:49Z,MegaAgent: A Large-Scale Autonomous LLM-based Multi-Agent System Without   Predefined SOPs,MegaAgent: Ein autonomes LLM-basiertes Multi-Agent-System ohne vordefinierte SOPs,大型机构:一个以大型自治LLM为基础的没有预先界定的SOP的多机构系统,http://arxiv.org/abs/2408.09955v3
73,"Large Language Models (LLMs) have achieved considerable performance across various agentic planning tasks. However, traditional agent planning approaches adopt a ""flood irrigation"" methodology that indiscriminately injects gold trajectories, external feedback, and domain knowledge into agent models. This practice overlooks the fundamental human cognitive principle of situational self-awareness during decision-making-the ability to dynamically assess situational demands and strategically employ resources during decision-making. We propose agentic knowledgeable self-awareness to address this gap, a novel paradigm enabling LLM-based agents to autonomously regulate knowledge utilization. Specifically, we propose KnowSelf, a data-centric approach that applies agents with knowledgeable self-awareness like humans. Concretely, we devise a heuristic situation judgement criterion to mark special tokens on the agent's self-explored trajectories for collecting training data. Through a two-stage training process, the agent model can switch between different situations by generating specific special tokens, achieving optimal planning effects with minimal costs. Our experiments demonstrate that KnowSelf can outperform various strong baselines on different tasks and models with minimal use of external knowledge. Code is available at https://github.com/zjunlp/KnowSelf.","大型语言模型(LLMS)在各种代理规划任务中取得了相当大的成绩,然而,传统代理规划方法采用了一种“洪水灌溉”方法,不加区别地将金轨、外部反馈和领域知识注入代理模型中,这种做法忽略了在决策过程中对情况自我认识的基本人类认知原则,即动态地评估形势需求和在决策中战略性地利用资源的能力。我们提出了一种具有代理知识的自我意识来解决这一差距的新模式,使以LLM为基础的代理能够自主地规范知识的利用。具体地说,我们提出了一种以数据为中心的方法,将具有了解情况的自我认识的代理人应用到像人类那样有知识的自我意识的代理人。具体地说,我们设计了一种超常状况判断标准,以标志该代理人收集培训数据的自我探索轨迹的特殊标志。通过两阶段的培训过程,该代理模型可以在不同情况之间转换,产生特定的特殊标志,以最低的成本实现最佳的规划效果。我们的实验表明,“了解自我”可以超越不同任务和模型上的各种强的基线,而很少使用外部知识。《准则》可在 https://gimb/commus.","Shuofei Qiao, Zhisong Qiu, Baochang Ren, Xiaobin Wang, Xiangyuan Ru, Ningyu Zhang, Xiang Chen, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen",2025-05-29T14:15:53Z,Agentic Knowledgeable Self-awareness,Agentisch sachkundiges Selbstbewußtsein,A. 动态知识自觉意识,http://arxiv.org/abs/2504.03553v2
74,"Multi-agent large language models (MA-LLMs) are a rapidly growing research area that leverages multiple interacting language agents to tackle complex tasks, outperforming single-agent large language models. This literature review synthesizes the latest research on agent profiles, communication structures, and decision-making processes, drawing insights from both traditional multi-agent systems and state-of-the-art MA-LLM studies. In doing so, it aims to address the lack of direct comparisons in the field, illustrating how factors like scalability, communication structure, and decision-making processes influence MA-LLM performance. By examining frequent practices and outlining current challenges, the review reveals that multi-agent approaches can yield superior results but also face elevated computational costs and under-explored challenges unique to MA-LLM. Overall, these findings provide researchers and practitioners with a roadmap for developing robust and efficient multi-agent AI solutions.","多试剂大型语言模型(MA-LLM)是一个迅速增长的研究领域,它利用多种互动语言代理处理复杂任务,优于优秀的单一试剂大型语言模型。这一文献审查综合了有关物剂概况、通信结构和决策过程的最新研究,从传统的多试系统和最先进的MA-LLM研究中汲取了深刻的见解。在这样做时,它旨在解决实地缺乏直接比较的问题,说明可扩缩性、通信结构和决策进程等因素如何影响MA-LM的绩效。审查通过审查经常做法和概述当前挑战,揭示了多试剂方法可以产生优异的结果,但也面临高额的计算成本以及MA-LLM所独有的探索不足的挑战。总体而言,这些研究结果为研究人员和从业人员提供了制定强有力和高效的多试剂AI解决方案的路线图。",Arne Tillmann,2025-05-29T13:57:00Z,Literature Review Of Multi-Agent Debate For Problem-Solving,Literaturüberblick über die Mehr-Agenten-Debatte für Problemlösung,关于解决问题的多机构辩论的文献评论,http://arxiv.org/abs/2506.00066v1
75,"Sometimes we benefit from actions that others have taken even when we are unaware that they took those actions. For example, if your neighbor chooses not to take a parking spot in front of your house when you are not there, you can benefit, even without being aware that they took this action. These ""hidden gifts"" represent an interesting challenge for multi-agent reinforcement learning (MARL), since assigning credit when the beneficial actions of others are hidden is non-trivial. Here, we study the impact of hidden gifts with a very simple MARL task. In this task, agents in a grid-world environment have individual doors to unlock in order to obtain individual rewards. As well, if all the agents unlock their door the group receives a larger collective reward. However, there is only one key for all of the doors, such that the collective reward can only be obtained when the agents drop the key for others after they use it. Notably, there is nothing to indicate to an agent that the other agents have dropped the key, thus the act of dropping the key for others is a ""hidden gift"". We show that several different state-of-the-art RL algorithms, including MARL algorithms, fail to learn how to obtain the collective reward in this simple task. Interestingly, we find that independent model-free policy gradient agents can solve the task when we provide them with information about their own action history, but MARL agents still cannot solve the task with action history. Finally, we derive a correction term for these independent agents, inspired by learning aware approaches, which reduces the variance in learning and helps them to converge to collective success more reliably. These results show that credit assignment in multi-agent settings can be particularly challenging in the presence of ""hidden gifts"", and demonstrate that learning awareness in independent agents can benefit these settings.","有时我们从其他人的行动中受益,即使我们不知道他们采取了这些行动。例如,如果邻居选择不在其家中时不在其家门前停泊,即使不知道他们采取了这一行动,也可以受益。这些“隐藏的礼物”代表了多试剂强化学习(MARL)的一个有趣的挑战,因为当其他人的有益行动被隐藏起来时,就分配信用是非三角的。在这里,我们研究隐藏的礼品的影响,任务很简单,MARL的任务非常简单。在这个任务中,网格世界环境中的代理商有单独的门可以打开,以获得个人报酬。同样,如果所有代理商都打开了他们的家门,他们也可以得到更大的集体奖赏。然而,所有这些“隐藏的礼物”只是当代理人在其他人的有益行动被隐藏起来的时候,集体奖赏才能得到。 值得注意的是,没有什么可以告诉代理商其他代理商已经放下了钥匙,因此,放弃他人的钥匙的行为就是“隐藏的礼物”。我们用不同的门打开门打开了自己的门来获得个人奖赏。同样,如果所有的代理商都打开他们的门门, 包括MAL 算算,那么,我们就能在他们自己学习了一个真正的历史任务中,我们如何在学习这些任务中,我们如何在学习这些任务中,我们是如何学习了。","Dane Malenfant, Blake A. Richards",2025-05-29T13:37:25Z,The challenge of hidden gifts in multi-agent reinforcement learning,Die Herausforderung der versteckten Gaben in Multi-Agenten-Verstärkung Lernen,多试剂强化学习中隐藏礼品的挑战,http://arxiv.org/abs/2505.20579v2
76,"The communication topology in large language model-based multi-agent systems fundamentally governs inter-agent collaboration patterns, critically shaping both the efficiency and effectiveness of collective decision-making. While recent studies for communication topology automated design tend to construct sparse structures for efficiency, they often overlook why and when sparse and dense topologies help or hinder collaboration. In this paper, we present a causal framework to analyze how agent outputs, whether correct or erroneous, propagate under topologies with varying sparsity. Our empirical studies reveal that moderately sparse topologies, which effectively suppress error propagation while preserving beneficial information diffusion, typically achieve optimal task performance. Guided by this insight, we propose a novel topology design approach, EIB-leanrner, that balances error suppression and beneficial information propagation by fusing connectivity patterns from both dense and sparse graphs. Extensive experiments show the superior effectiveness, communication cost, and robustness of EIB-leanrner.","大型语言模型多试剂系统中的通信表层从根本上制约了机构间协作模式,对集体决策的效率和成效都产生了重要影响。虽然最近关于通信表层自动化设计的研究往往为提高效率而建立稀少的结构,但它们往往忽略了为什么以及何时稀有和密集的地形有助于或阻碍合作。在本文件中,我们提出了一个因果框架,分析代理产出如何在具有不同广度的地形下传播,无论是正确还是错误。我们的实证研究表明,中度稀疏的地形在保存有益的信息传播的同时有效地抑制错误传播,通常能够取得最佳的任务性。我们根据这一洞察,提出了一种新型的地形设计方法,即EIB-leorner,通过利用密度和稀薄的图形的连接模式来平衡错误抑制和有益的信息传播。广泛的实验显示了EIB-leanner的优越性、通信成本和坚固性。","Xu Shen, Yixin Liu, Yiwei Dai, Yili Wang, Rui Miao, Yue Tan, Shirui Pan, Xin Wang",2025-05-29T11:21:48Z,Understanding the Information Propagation Effects of Communication   Topologies in LLM-based Multi-Agent Systems,Verständnis der Informationsverbreitungseffekte von Kommunikationstopologien in LLM-basierten Multi-Agent-Systemen,了解基于LLOM的多机构机构系统中的通信地形对信息传播的影响,http://arxiv.org/abs/2505.23352v1
77,"Social conventions are the backbone of social coordination, shaping how individuals form a group. As growing populations of artificial intelligence (AI) agents communicate through natural language, a fundamental question is whether they can bootstrap the foundations of a society. Here, we present experimental results that demonstrate the spontaneous emergence of universally adopted social conventions in decentralized populations of large language model (LLM) agents. We then show how strong collective biases can emerge during this process, even when agents exhibit no bias individually. Last, we examine how committed minority groups of adversarial LLM agents can drive social change by imposing alternative social conventions on the larger population. Our results show that AI systems can autonomously develop social conventions without explicit programming and have implications for designing AI systems that align, and remain aligned, with human values and societal goals.","社会公约是社会协调的支柱,塑造个人如何组成一个群体。随着越来越多的人工智能(AI)人员通过自然语言进行交流,一个根本问题是他们是否能够奠定一个社会的基础。在这里,我们提出实验结果,表明在分散的大型语言模式(LLM)人员群体中,普遍通过的社会公约是自发产生的。然后,我们表明在这个过程中如何产生强烈的集体偏见,即使代理人没有表现出个别的偏见。最后,我们研究有决心的对抗性LLM人员少数群体如何通过将其他社会公约强加给更多的人口来推动社会变革。我们的结果表明,AI系统可以在没有明确规划的情况下自主地制定社会公约,并对设计与人类价值观和社会目标一致的AI系统具有影响。","Ariel Flint Ashery, Luca Maria Aiello, Andrea Baronchelli",2025-05-29T09:50:31Z,Emergent social conventions and collective bias in LLM populations,Emergente soziale Konventionen und kollektive Voreingenommenheit in LLM-Populationen,新出现的社会习俗和LLM人口的集体偏见,http://arxiv.org/abs/2410.08948v2
78,"Agents built with large language models (LLMs) have shown great potential across a wide range of domains. However, in complex decision-making tasks, pure LLM-based agents tend to exhibit intrinsic bias in their choice of actions, which is inherited from the model's training data and results in suboptimal performance. To develop strategic language agents, i.e., agents that generate flexible language actions and possess strong decision-making abilities, we propose a novel framework that powers LLM-based agents with reinforcement learning (RL). We consider Werewolf, a popular social deduction game, as a challenging testbed that emphasizes versatile communication and strategic gameplay. To mitigate the intrinsic bias in language actions, our agents use an LLM to perform deductive reasoning and generate a diverse set of action candidates. Then an RL policy trained to optimize the decision-making ability chooses an action from the candidates to play in the game. Extensive experiments show that our agents overcome the intrinsic bias and outperform existing LLM-based agents in the Werewolf game. We also conduct human-agent experiments and find that our agents achieve human-level performance and demonstrate strong strategic play.","然而,在复杂的决策任务中,纯粹的LLM代理商往往在选择行动时表现出内在的偏见,这种偏见是从该模式的培训数据所继承的,其结果不尽人意。为了发展战略语言代理商,即产生灵活语言行动和拥有强大决策能力的代理商,我们提议了一个赋予LLM代理商以强化学习能力的新框架。我们认为Wrewolf是一种流行的社会推理游戏,是一种具有挑战性的试金,它强调多功能的沟通和战略游戏。为了减轻语言行动的内在偏见,我们的代理商利用LLM进行推理推理和产生一套不同的行动候选人。然后,为优化决策能力而培训的RL政策从候选人中选择了在游戏中玩的动作。广泛的实验表明,我们的代理商克服了内在的偏见,超越了在Werewolf游戏中现有的LM代理商。我们还进行人力代理实验,发现我们的代理商取得了人的水平表现并展示了强有力的战略游戏。","Zelai Xu, Chao Yu, Fei Fang, Yu Wang, Yi Wu",2025-05-29T08:46:38Z,Language Agents with Reinforcement Learning for Strategic Play in the   Werewolf Game,Sprachagenten mit Verstärkung Lernen für strategisches Spiel im Werwolf Spiel,在狼人游戏中进行战略游戏强化学习的语文代理,http://arxiv.org/abs/2310.18940v4
79,"Large Language Model-based multi-agent systems (MAS) have shown remarkable progress in solving complex tasks through collaborative reasoning and inter-agent critique. However, existing approaches typically treat each task in isolation, resulting in redundant computations and limited generalization across structurally similar tasks. To address this, we introduce multi-agent cross-task experiential learning (MAEL), a novel framework that endows LLM-driven agents with explicit cross-task learning and experience accumulation. We model the task-solving workflow on a graph-structured multi-agent collaboration network, where agents propagate information and coordinate via explicit connectivity. During the experiential learning phase, we quantify the quality for each step in the task-solving workflow and store the resulting rewards along with the corresponding inputs and outputs into each agent's individual experience pool. During inference, agents retrieve high-reward, task-relevant experiences as few-shot examples to enhance the effectiveness of each reasoning step, thereby enabling more accurate and efficient multi-agent collaboration. Experimental results on diverse datasets demonstrate that MAEL empowers agents to learn from prior task experiences effectively-achieving faster convergence and producing higher-quality solutions on current tasks.","语言模型型大型多试剂系统(MAS)在通过协作推理和机构间评析解决复杂任务方面取得了显著进展,然而,现有办法一般都是孤立地处理每项任务,导致重复计算和对结构相似的任务进行有限的概括化。为了解决这个问题,我们引入了多试剂跨任务体验学习(MAEL),这是一个新颖的框架,使LLM驱动的代理商具有明确的跨任务学习和经验积累能力。我们把任务解决工作流程建在一个图形结构多试剂合作网络上,使代理商通过明确的连通性传播信息和协调。在经验学习阶段,我们量化任务解决工作流程中每个步骤的质量,并将由此产生的奖励与相应的投入和产出一起储存到每个代理商的个人经验库中。在推断过程中,代理商检索高回报、任务相关的经验,作为少见的例子,以提高每个推理步骤的有效性,从而能够更准确和高效地进行多试剂合作。关于各种数据集的实验结果显示MAEL使代理商能够从以往的任务经验中学习如何有效实现更快的趋同和提出更高质量的解决办法。","Yilong Li, Chen Qian, Yu Xia, Ruijie Shi, Yufan Dang, Zihao Xie, Ziming You, Weize Chen, Cheng Yang, Weichuan Liu, Ye Tian, Xuantang Xiong, Lei Han, Zhiyuan Liu, Maosong Sun",2025-05-29T07:24:37Z,Cross-Task Experiential Learning on LLM-based Multi-Agent Collaboration,Erfahrungsübergreifendes Lernen auf LLM-basierter Multi-Agent-Kollaboration,关于基于LLM的多机构合作的跨任务跨任务经验学习,http://arxiv.org/abs/2505.23187v1
80,"Large Language Model-based Multi-Agent Systems (MASs) have emerged as a powerful paradigm for tackling complex tasks through collaborative intelligence. Nevertheless, the question of how agents should be structurally organized for optimal cooperation remains largely unexplored. In this position paper, we aim to gently redirect the focus of the MAS research community toward this critical dimension: develop topology-aware MASs for specific tasks. Specifically, the system consists of three core components - agents, communication links, and communication patterns - that collectively shape its coordination performance and efficiency. To this end, we introduce a systematic, three-stage framework: agent selection, structure profiling, and topology synthesis. Each stage would trigger new research opportunities in areas such as language models, reinforcement learning, graph learning, and generative modeling; together, they could unleash the full potential of MASs in complicated real-world applications. Then, we discuss the potential challenges and opportunities in the evaluation of multiple systems. We hope our perspective and framework can offer critical new insights in the era of agentic AI.","大型语言模型多行为者系统(MAS)已成为通过协作情报处理复杂任务的有力范例,然而,关于应如何从结构上组织代理人以实现最佳合作的问题基本上尚未探讨。在本立场文件中,我们的目标是将MAS研究界的重点轻轻地转向这一关键方面:为具体任务开发具有地貌意识的MAS。具体地说,该系统由三个核心组成部分组成:代理、通信联系和通信模式,共同决定其协调性能和效率。为此,我们引入了一个系统化的、三阶段的框架:代理选择、结构特征分析和地形综合。每个阶段都将在语言模型、强化学习、图表学习和基因模型等领域触发新的研究机会;它们一起可以充分发挥MAS在复杂的现实世界应用中的潜力。然后,我们讨论在评估多种系统方面的潜在挑战和机遇。我们希望我们的观点和框架能够在代理性AI时代提供重要的新见解。","Jiaxi Yang, Mengqi Zhang, Yiqiao Jin, Hao Chen, Qingsong Wen, Lu Lin, Yi He, Weijie Xu, James Evans, Jindong Wang",2025-05-29T04:17:13Z,Topological Structure Learning Should Be A Research Priority for   LLM-Based Multi-Agent Systems,Topologisches Strukturlernen sollte eine Forschungspriorität für LLM-basierte Multi-Agent-Systeme sein,地形结构学习应成为以LLM为基础的多种机构系统的研究重点,http://arxiv.org/abs/2505.22467v2
81,"Chest X-rays (CXRs) play an integral role in driving critical decisions in disease management and patient care. While recent innovations have led to specialized models for various CXR interpretation tasks, these solutions often operate in isolation, limiting their practical utility in clinical practice. We present MedRAX, the first versatile AI agent that seamlessly integrates state-of-the-art CXR analysis tools and multimodal large language models into a unified framework. MedRAX dynamically leverages these models to address complex medical queries without requiring additional training. To rigorously evaluate its capabilities, we introduce ChestAgentBench, a comprehensive benchmark containing 2,500 complex medical queries across 7 diverse categories. Our experiments demonstrate that MedRAX achieves state-of-the-art performance compared to both open-source and proprietary models, representing a significant step toward the practical deployment of automated CXR interpretation systems. Data and code have been publicly available at https://github.com/bowang-lab/MedRAX","切斯特X光片(CXRs)在推动疾病管理和病人护理的关键决定方面发挥着不可或缺的作用。虽然最近的创新导致了各种CXR解释任务的专门模式,但这些解决方案往往孤立地运作,限制了其在临床实践中的实用性。我们介绍MedRAX,这是第一个将最先进的CXR分析工具和多式大型语言模型无缝地纳入统一框架的全方位AI代理。MedRAX积极利用这些模型处理复杂的医疗问题,而不需要额外的培训。为了严格评估其能力,我们引入了ChestAgentBench,这是一个包含7个不同类别2 500个复杂医疗查询的综合基准。我们的实验表明,MedRAX取得了与开放源和专利模型相比的最新的最新业绩,这是向实际部署自动CXR解释系统迈出的重要一步。数据和代码已公布在https://github.com/bowang-lab/MedRAX上。","Adibvafa Fallahpour, Jun Ma, Alif Munim, Hongwei Lyu, Bo Wang",2025-05-29T01:45:45Z,MedRAX: Medical Reasoning Agent for Chest X-ray,MedRAX: Medizinischer Reasoning Agent für Bruströntgen,MedraX: 胸前X光医疗理疗代理,http://arxiv.org/abs/2502.02673v2
82,"An important challenge in non-cooperative game theory is coordinating on a single (approximate) equilibrium from many possibilities - a challenge that becomes even more complex when players hold private information. Recommender mechanisms tackle this problem by recommending strategies to players based on their reported type profiles. A key consideration in such mechanisms is to ensure that players are incentivized to participate, report their private information truthfully, and follow the recommendations. While previous work has focused on designing recommender mechanisms for one-shot and extensive-form games, these approaches cannot be effectively applied to stochastic games, particularly if we constrain recommendations to be Markov stationary policies. To bridge this gap, we introduce a novel bi-level reinforcement learning approach for automatically designing recommender mechanisms in Bayesian stochastic games. Our method produces a mechanism represented by a parametric function (such as a neural network), and is therefore highly efficient at execution time. Experimental results on two repeated and two stochastic games demonstrate that our approach achieves social welfare levels competitive with cooperative multi-agent reinforcement learning baselines, while also providing significantly improved incentive properties.","在不合作的游戏理论中,一个重要挑战是从多种可能性中协调单一(近似)平衡 -- -- 当玩家持有私人信息时,这一挑战就变得更加复杂。建议机制解决这一问题,根据所报告类型向玩家推荐战略。这种机制中的一个关键考虑是确保玩家受到激励,能够参与,真实地报告其私人信息,并遵循建议。虽然以前的工作重点是为一次性和广泛形式的游戏设计推荐机制,但这些方法无法有效地适用于随机游戏,特别是如果我们限制建议成为Markov固定政策,那么就更复杂了。为了弥合这一差距,我们采用了一种新的双级强化学习方法,在Bayesian 类游戏中自动设计推荐机制。我们的方法产生了一种以参数函数(例如神经网络)为代表的机制,因此在执行时效率很高。两次重复的和两次随机游戏的实验结果表明,我们的方法达到了社会福利水平,具有竞争性,合作性多剂强化学习基线,同时提供显著改进的奖励性特性。","Bengisu Guresti, Chongjie Zhang, Yevgeniy Vorobeychik",2025-05-29T01:34:54Z,Learning Recommender Mechanisms for Bayesian Stochastic Games,Lern-Empfänger-Mechanismen für Bayesian Stochastic Games,贝耶斯沙沙运动会学习建议机制,http://arxiv.org/abs/2505.22979v1
83,"Objective: To demonstrate the capabilities of Large Language Models (LLMs) as autonomous agents to reproduce findings of published research studies using the same or similar dataset.   Materials and Methods: We used the ""Quick Access"" dataset of the National Alzheimer's Coordinating Center (NACC). We identified highly cited published research manuscripts using NACC data and selected five studies that appeared reproducible using this dataset alone. Using GPT-4o, we created a simulated research team of LLM-based autonomous agents tasked with writing and executing code to dynamically reproduce the findings of each study, given only study Abstracts, Methods sections, and data dictionary descriptions of the dataset.   Results: We extracted 35 key findings described in the Abstracts across 5 Alzheimer's studies. On average, LLM agents approximately reproduced 53.2% of findings per study. Numeric values and range-based findings often differed between studies and agents. The agents also applied statistical methods or parameters that varied from the originals, though overall trends and significance were sometimes similar.   Discussion: In some cases, LLM-based agents replicated research techniques and findings. In others, they failed due to implementation flaws or missing methodological detail. These discrepancies show the current limits of LLMs in fully automating reproducibility assessments. Still, this early investigation highlights the potential of structured agent-based systems to provide scalable evaluation of scientific rigor.   Conclusion: This exploratory work illustrates both the promise and limitations of LLMs as autonomous agents for automating reproducibility in biomedical research.","目标:展示大语言模型(LLMs)作为自主代理机构利用相同或类似数据集复制已公布的研究成果的能力。材料和方法:我们使用国家阿尔茨海默氏症协调中心(NACC)的“快速存取”数据集。我们利用全国阿尔茨海默症协调中心(NACC)的数据查明了大量引用的已出版研究手稿,并选择了5项似乎仅使用该数据集即可复制的研究手稿。我们利用GPT-4o,建立了一个以LLM为主的自主代理机构模拟研究小组,负责编写和执行代码,以动态复制每项研究的结果,只提供数据集摘要、方法章节和数据词典描述。结果:我们从5项研究《摘要》中提取了35项关键结论。平均而言,LLM代理机构大约复制了每项研究结果的53.2%。数字值和基于范围的调查结果往往因使用该数据集而不同。我们还运用了不同于原始数据的统计方法和参数,尽管总的趋势和重要性有时相似。讨论:在某些情况下,LLMM代理机构复制研究技术和调查结果。在5项摘要中,他们未能利用摘要中35关键结论性的主要结论性评估,从而充分说明目前对LMLMsralexralvialvialvil的深度评估。","Nic Dobbins, Christelle Xiong, Kristine Lan, Meliha Yetisgen",2025-05-29T01:31:55Z,Large Language Model-Based Agents for Automated Research   Reproducibility: An Exploratory Study in Alzheimer's Disease,Large Language model-based agents for Automated Research Reproduzierbarkeit: Eine explorative Studie zur Alzheimer-Krankheit,自动化研究可复制性:阿尔茨海默氏病探索性研究,http://arxiv.org/abs/2505.23852v1
84,"Despite the promise of autonomous agentic reasoning, existing workflow generation methods frequently produce fragile, unexecutable plans due to unconstrained LLM-driven construction. We introduce MermaidFlow, a framework that redefines the agentic search space through safety-constrained graph evolution. At its core, MermaidFlow represent workflows as a verifiable intermediate representation using Mermaid, a structured and human-interpretable graph language. We formulate domain-aware evolutionary operators, i.e., crossover, mutation, insertion, and deletion, to preserve semantic correctness while promoting structural diversity, enabling efficient exploration of a high-quality, statically verifiable workflow space. Without modifying task settings or evaluation protocols, MermaidFlow achieves consistent improvements in success rates and faster convergence to executable plans on the agent reasoning benchmark. The experimental results demonstrate that safety-constrained graph evolution offers a scalable, modular foundation for robust and interpretable agentic reasoning systems.","尽管有自主代理推理的希望,但现有的工作流程生成方法往往由于不受限制的LLM驱动的建设而产生脆弱、无法执行的计划。我们引入了美人鱼Flow,这是一个通过安全限制的图形演进重新定义代理搜索空间的框架。在本质上,美人鱼Flow代表工作流程作为可核实的中间代表,使用美人鱼这一结构化和人文解释的图表语言。我们设计了有域觉的演进操作器,即交叉、突变、插入和删除,以便在促进结构多样性的同时保持语义正确性,从而能够有效地探索一个高质量、静态可核查的工作流程空间。在不修改任务设置或评估协议的情况下,美人鱼Flow在成功率方面实现了一致,并更快地与代理推理基准的可执行计划接轨。实验结果表明,受安全限制的图形演进为稳健和可解释的代理推理系统提供了一个可扩展的模块基础。","Chengqi Zheng, Jianda Chen, Yueming Lyu, Wen Zheng Terence Ng, Haopeng Zhang, Yew-Soon Ong, Ivor Tsang, Haiyan Yin",2025-05-29T01:08:36Z,MermaidFlow: Redefining Agentic Workflow Generation via   Safety-Constrained Evolutionary Programming,MermaidFlow: Neudefinition der agentischen Workflow-Generierung durch sicherheitsbeschränkte evolutionäre Programmierung,"美人鱼:通过受安全限制的进化方案拟订,重新确定干燥性工作流的产生",http://arxiv.org/abs/2505.22967v1

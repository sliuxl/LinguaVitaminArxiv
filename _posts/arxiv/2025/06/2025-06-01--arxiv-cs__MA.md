---
title: cs.MA @ 2025-06-01
date: 2025-06-01
layout: post
---

- [00](#article-0) | 05-29 | ROTATE: Regret-driven Open-ended Training for Ad Hoc Teamwork | ROTATE: Bedauern-getriebenes Open-End-Training für Ad-Hoc-Teamwork | 对特设团队工作不限成员名额培训的遗憾驱动的不限名额培训 | [2505.23686v1](http://arxiv.org/abs/2505.23686v1)
- [01](#article-1) | 05-29 | Collaborative Last-Mile Delivery: A Multi-Platform Vehicle Routing   Problem With En-route Charging | Collaborative Last-Mile Lieferung: Ein Multi-Platform Fahrzeug Routing Problem mit en-route Laden | 合作性最后一式交付:多平台车辆运行问题与连路充电 | [2505.23584v1](http://arxiv.org/abs/2505.23584v1)
- [02](#article-2) | 05-29 | MegaAgent: A Large-Scale Autonomous LLM-based Multi-Agent System Without   Predefined SOPs | MegaAgent: Ein autonomes LLM-basiertes Multi-Agent-System ohne vordefinierte SOPs | 大型机构:一个以大型自治LLM为基础的没有预先界定的SOP的多机构系统 | [2408.09955v3](http://arxiv.org/abs/2408.09955v3)
- [03](#article-3) | 05-29 | Agentic Knowledgeable Self-awareness | Agentisch sachkundiges Selbstbewußtsein | A. 动态知识自觉意识 | [2504.03553v2](http://arxiv.org/abs/2504.03553v2)
- [04](#article-4) | 05-29 | The challenge of hidden gifts in multi-agent reinforcement learning | Die Herausforderung der versteckten Gaben in Multi-Agenten-Verstärkung Lernen | 多试剂强化学习中隐藏礼品的挑战 | [2505.20579v2](http://arxiv.org/abs/2505.20579v2)
- [05](#article-5) | 05-29 | Understanding the Information Propagation Effects of Communication   Topologies in LLM-based Multi-Agent Systems | Verständnis der Informationsverbreitungseffekte von Kommunikationstopologien in LLM-basierten Multi-Agent-Systemen | 了解基于LLOM的多机构机构系统中的通信地形对信息传播的影响 | [2505.23352v1](http://arxiv.org/abs/2505.23352v1)
- [06](#article-6) | 05-29 | Emergent social conventions and collective bias in LLM populations | Emergente soziale Konventionen und kollektive Voreingenommenheit in LLM-Populationen | 新出现的社会习俗和LLM人口的集体偏见 | [2410.08948v2](http://arxiv.org/abs/2410.08948v2)
- [07](#article-7) | 05-29 | Language Agents with Reinforcement Learning for Strategic Play in the   Werewolf Game | Sprachagenten mit Verstärkung Lernen für strategisches Spiel im Werwolf Spiel | 在狼人游戏中进行战略游戏强化学习的语文代理 | [2310.18940v4](http://arxiv.org/abs/2310.18940v4)
- [08](#article-8) | 05-29 | Cross-Task Experiential Learning on LLM-based Multi-Agent Collaboration | Erfahrungsübergreifendes Lernen auf LLM-basierter Multi-Agent-Kollaboration | 关于基于LLM的多机构合作的跨任务跨任务经验学习 | [2505.23187v1](http://arxiv.org/abs/2505.23187v1)
- [09](#article-9) | 05-29 | Topological Structure Learning Should Be A Research Priority for   LLM-Based Multi-Agent Systems | Topologisches Strukturlernen sollte eine Forschungspriorität für LLM-basierte Multi-Agent-Systeme sein | 地形结构学习应成为以LLM为基础的多种机构系统的研究重点 | [2505.22467v2](http://arxiv.org/abs/2505.22467v2)
- [10](#article-10) | 05-29 | MedRAX: Medical Reasoning Agent for Chest X-ray | MedRAX: Medizinischer Reasoning Agent für Bruströntgen | MedraX: 胸前X光医疗理疗代理 | [2502.02673v2](http://arxiv.org/abs/2502.02673v2)
- [11](#article-11) | 05-29 | Learning Recommender Mechanisms for Bayesian Stochastic Games | Lern-Empfänger-Mechanismen für Bayesian Stochastic Games | 贝耶斯沙沙运动会学习建议机制 | [2505.22979v1](http://arxiv.org/abs/2505.22979v1)
- [12](#article-12) | 05-29 | MermaidFlow: Redefining Agentic Workflow Generation via   Safety-Constrained Evolutionary Programming | MermaidFlow: Neudefinition der agentischen Workflow-Generierung durch sicherheitsbeschränkte evolutionäre Programmierung | 美人鱼:通过受安全限制的进化方案拟订,重新确定干燥性工作流的产生 | [2505.22967v1](http://arxiv.org/abs/2505.22967v1)
- [13](#article-13) | 05-28 | A Large Language Model-Enabled Control Architecture for Dynamic Resource   Capability Exploration in Multi-Agent Manufacturing Systems | Eine großsprachige modellfähige Steuerungsarchitektur für dynamische Ressourcenkapazitäts-Exploration in Multi-Agent-Produktionssystemen | 多机构制造系统动态资源能力探索大语言模型化控制结构 | [2505.22814v1](http://arxiv.org/abs/2505.22814v1)
- [14](#article-14) | 05-28 | Dynamic Task Adaptation for Multi-Robot Manufacturing Systems with Large   Language Models | Dynamische Aufgabenanpassung für Multi-Roboter-Produktionssysteme mit großen Sprachmodellen | 具有大语言模型的多机器人制造系统动态任务适应 | [2505.22804v1](http://arxiv.org/abs/2505.22804v1)
- [15](#article-15) | 05-28 | Enhancing Lifelong Multi-Agent Path-finding by Using Artificial   Potential Fields | Verbesserung der lebensbegleitenden multi-agenten Path-Finding durch den Einsatz künstlicher Potenzialfelder | 利用人造潜在潜力领域加强终身多机构探索 | [2505.22753v1](http://arxiv.org/abs/2505.22753v1)
- [16](#article-16) | 05-28 | A Novel Zero-Trust Identity Framework for Agentic AI: Decentralized   Authentication and Fine-Grained Access Control | Ein neuartiges Null-Vertrauens-Identitäts-Framework für Agentische KI: Dezentrale Authentisierung und feinkörnige Zugriffskontrolle | AI:分散认证和精密访问控制 | [2505.19301v2](http://arxiv.org/abs/2505.19301v2)
- [17](#article-17) | 05-28 | HDDLGym: A Tool for Studying Multi-Agent Hierarchical Problems Defined   in HDDL with OpenAI Gym | HDDLGym: Ein Tool zum Studieren multi-agenter Hierarchischer Probleme, definiert in HDDL mit OpenAI Gym | HDDLGym: 与 OpenAI Gym 一起研究在HDDL 中界定的多代理等级问题的工具 | [2505.22597v1](http://arxiv.org/abs/2505.22597v1)
- [18](#article-18) | 05-28 | SynWorld: Virtual Scenario Synthesis for Agentic Action Knowledge   Refinement | SynWorld: Virtual Scenario Synthesis for Agentic Action Knowledge Refinement | Synworld: 用于改进制剂行动知识的虚拟情景合成 | [2504.03561v2](http://arxiv.org/abs/2504.03561v2)
- [19](#article-19) | 05-28 | From Strangers to Assistants: Fast Desire Alignment for Embodied   Agent-User Adaptation | Von Fremdlingen zu Assistenten: Schnelles Wunsch-Ausrichtung für eingedickte Agent-User-Anpassung | 从陌生人到助理:对装装配剂用户适应的快速理想调整 | [2505.22503v1](http://arxiv.org/abs/2505.22503v1)
- [20](#article-20) | 05-28 | OptiMindTune: A Multi-Agent Framework for Intelligent Hyperparameter   Optimization | OptiMindTune: Multi-Agenten-Framework für intelligente Hyperparameter-Optimierung | OptiMindTunne: 智能超参数优化的多机构框架 | [2505.19205v2](http://arxiv.org/abs/2505.19205v2)
- [21](#article-21) | 05-28 | The Complexity of Pure Strategy Relevant Equilibria in Concurrent Games | Die Komplexität der reinen Strategie Relevante Equilibria in Parallelspielen | 同时运动会中纯粹战略相关平衡的复杂性 | [2505.07501v2](http://arxiv.org/abs/2505.07501v2)
- [22](#article-22) | 05-28 | Voice CMS: updating the knowledge base of a digital assistant through   conversation | Voice CMS: Aktualisierung der Wissensbasis eines digitalen Assistenten durch Konversation | 语音CMS:通过对话更新数字助理的知识库 | [2505.22303v1](http://arxiv.org/abs/2505.22303v1)
- [23](#article-23) | 05-28 | Leveraging Dual Process Theory in Language Agent Framework for Real-time   Simultaneous Human-AI Collaboration | Leveraging Dual Process Theory in Language Agent Framework for Real-time Simultaneous Human-AI Collaboration | 利用语言代理框架中的双重进程理论促进实时同时人类-AI合作 | [2502.11882v5](http://arxiv.org/abs/2502.11882v5)
- [24](#article-24) | 05-28 | Efficient Leave-one-out Approximation in LLM Multi-agent Debate Based on   Introspection | Effiziente Ein-Aus-Annäherung in der LLM-Multiagenten-Debatte auf der Grundlage von Introspektion | 以内审为基础的多机构辩论 | [2505.22192v1](http://arxiv.org/abs/2505.22192v1)
- [25](#article-25) | 05-28 | Online Fair Division for Personalized $2$-Value Instances | Online Fair Division für Personalisierte $2$-Value Instances | 个人个人价值2美元-价值实例在线网上交易会司 | [2505.22174v1](http://arxiv.org/abs/2505.22174v1)
- [26](#article-26) | 05-28 | Sentiment Simulation using Generative AI Agents | Sentiment-Simulation mit generativen KI-Agenten | 使用 " 产生AI " 制剂模拟情感 | [2505.22125v1](http://arxiv.org/abs/2505.22125v1)
- [27](#article-27) | 05-28 | Benchmarking LLMs' Swarm intelligence | Benchmarking der Swarm-Intelligenz der LLM | 基准确定LLLMs的Swarm情报 | [2505.04364v3](http://arxiv.org/abs/2505.04364v3)
- [28](#article-28) | 05-28 | AudioGenie: A Training-Free Multi-Agent Framework for Diverse   Multimodality-to-Multiaudio Generation | AudioGenie: Ein trainingsfreies Multi-Agent-Framework für die vielfältige Multimodalität-zu-Multiaudio-Generierung | AudioGenie:多元化多式联运到多民族一代的无培训多机会多机会框架 | [2505.22053v1](http://arxiv.org/abs/2505.22053v1)
- [29](#article-29) | 05-28 | Reward-Independent Messaging for Decentralized Multi-Agent Reinforcement   Learning | Reward-independent Messaging für dezentralisiertes Mehr-Agenten-Verstärkungs-Lernen | 权力下放多机构加强学习分权式多机构加强学习的回报独立通信 | [2505.21985v1](http://arxiv.org/abs/2505.21985v1)
- [30](#article-30) | 05-28 | Preference-CFR$\:$ Beyond Nash Equilibrium for Better Game Strategies | Präferenz-CFR$\:$ Jenseits von Nash Equilibrium für bessere Spielstrategien | 普特-CFR$ =: Nash 后平衡促进更好游戏战略的美元 | [2411.01217v2](http://arxiv.org/abs/2411.01217v2)
- [31](#article-31) | 05-28 | Properties of zero-determinant strategies in multichannel games | Eigenschaften von Zero-Determinant-Strategien in Multichannel-Spielen | 多频道游戏零决定策略属性 | [2505.21952v1](http://arxiv.org/abs/2505.21952v1)
- [32](#article-32) | 05-28 | Co-Saving: Resource Aware Multi-Agent Collaboration for Software   Development | Co-Saving: Ressourcenschonende Multi-Agenten-Kollaboration für Software-Entwicklung | 共同节省:为开发软件进行有意识的资源、多机构协作 | [2505.21898v1](http://arxiv.org/abs/2505.21898v1)
- [33](#article-33) | 05-28 | Incorporating LLMs for Large-Scale Urban Complex Mobility Simulation | Einschließlich LLMs für großräumige Urban Complex Mobility Simulation | 大型城市综合流动模拟项目LLMs | [2505.21880v1](http://arxiv.org/abs/2505.21880v1)
- [34](#article-34) | 05-27 | Optimal Output Feedback Learning Control for Discrete-Time Linear   Quadratic Regulation | Optimale Output-Feedback-Lernsteuerung für diskrete Zeit lineare quadratische Regulierung | 用于分立时线性二次曲线调控的最佳输出反馈学习控制 | [2503.06226v3](http://arxiv.org/abs/2503.06226v3)
- [35](#article-35) | 05-27 | Empowering Scientific Workflows with Federated Agents | Stärkung wissenschaftlicher Workflows mit Federated Agents | 赋予联邦药剂部门科学工作流程权能 | [2505.05428v2](http://arxiv.org/abs/2505.05428v2)
- [36](#article-36) | 05-27 | AI-Supported Platform for System Monitoring and Decision-Making in   Nuclear Waste Management with Large Language Models | AI-unterstützte Plattform für Systemüberwachung und Entscheidungsfindung in der Entsorgung nuklearer Abfälle mit großen Sprachmodellen | AI-支持的具有大语言模式的核废物管理系统监测和决策平台 | [2505.21741v1](http://arxiv.org/abs/2505.21741v1)
- [37](#article-37) | 05-27 | Communication- and Computation-Efficient Distributed Submodular   Optimization in Robot Mesh Networks | Kommunikation- und Computation-Effizient verteilte Submodulare Optimierung in Robot Mesh-Netzwerken | 机器人网网中的通信和计算-有效分布式子模块优化 | [2407.10382v3](http://arxiv.org/abs/2407.10382v3)
- [38](#article-38) | 05-27 | Paper2Poster: Towards Multimodal Poster Automation from Scientific   Papers | Paper2Poster: Auf dem Weg zur multimodalen Plakatautomatisierung aus wissenschaftlichen Papieren | Paper2Poster:从科学论文中走向多式海报自动化 | [2505.21497v1](http://arxiv.org/abs/2505.21497v1)
- [39](#article-39) | 05-27 | Agentic Medical Knowledge Graphs Enhance Medical Question Answering:   Bridging the Gap Between LLMs and Evolving Medical Knowledge | Agentisches medizinisches Wissen Grafiken verbessern medizinische Frageantworten: Die Lücke zwischen LLMs und sich entwickelndem medizinischem Wissen überbrücken | 药用知识图加强医疗问题的回答:缩小LLMM与不断发展的医学知识之间的差距 | [2502.13010v2](http://arxiv.org/abs/2502.13010v2)
- [40](#article-40) | 05-27 | Learning Individual Behavior in Agent-Based Models with Graph Diffusion   Networks | Individuelles Verhalten in agentenbasierten Modellen mit Graph Diffusionsnetzwerken lernen | 具有图表传播网络的基于代理模型的学习个人行为 | [2505.21426v1](http://arxiv.org/abs/2505.21426v1)
- [41](#article-41) | 05-27 | Autonomous Multi-Modal LLM Agents for Treatment Planning in Focused   Ultrasound Ablation Surgery | Autonome Multi-Modal LLM-Agenten für die Behandlungsplanung in fokussierter Ultraschallablationschirurgie | 重点超声速超声振动外科手术治疗规划代理 | [2505.21418v1](http://arxiv.org/abs/2505.21418v1)
- [42](#article-42) | 05-27 | Sequential Resource Trading Using Comparison-Based Gradient Estimation | Sequentieller Ressourcenhandel mit Vergleichsbasis-Gradientenschätzung | 使用基于比较的逐步梯度估计法进行按顺序进行的资源贸易 | [2408.11186v3](http://arxiv.org/abs/2408.11186v3)
- [43](#article-43) | 05-27 | PeerGuard: Defending Multi-Agent Systems Against Backdoor Attacks   Through Mutual Reasoning | PeerGuard: Verteidigen von Multi-Agenten-Systemen gegen Hintertürangriffe durch gegenseitige Vernunft | 同伴保护:捍卫多机构系统,防止通过相互理由进行后门攻击 | [2505.11642v2](http://arxiv.org/abs/2505.11642v2)
- [44](#article-44) | 05-27 | Large Language Models Miss the Multi-Agent Mark | Große Sprachmodelle vermissen das Multi-Agent Mark | 大语言模型 | [2505.21298v1](http://arxiv.org/abs/2505.21298v1)
- [45](#article-45) | 05-27 | Breaking the Performance Ceiling in Complex Reinforcement Learning   requires Inference Strategies | Breaking the Performance Ceiling in komplexen Verstärkungs-Lernen erfordert Inferenz-Strategien | 综合加强学习中业绩上限的打破需要推断战略 | [2505.21236v1](http://arxiv.org/abs/2505.21236v1)
- [46](#article-46) | 05-27 | Voting or Consensus? Decision-Making in Multi-Agent Debate | Abstimmung oder Konsens? Entscheidungsfindung in Multi-Agent-Debatte | 表决还是协商一致?多机构辩论中的决策 | [2502.19130v2](http://arxiv.org/abs/2502.19130v2)
- [47](#article-47) | 05-27 | GGBond: Growing Graph-Based AI-Agent Society for Socially-Aware   Recommender Simulation | GGBond: Wachsende Graphen-basierte KI-Agenten-Gesellschaft für sozial-aware-Empfänger-Simulation | GGBond: 不断增长的基于图表的AI-Agent Society 社会软件建议模拟模拟软件 | [2505.21154v1](http://arxiv.org/abs/2505.21154v1)
- [48](#article-48) | 05-27 | Stopping Criteria for Value Iteration on Concurrent Stochastic   Reachability and Safety Games | Stoppen von Kriterien für die Wert-Iteration bei gleichzeitigen stochastischen Erreichbarkeits- und Sicherheitsspielen | 停止同时举行存储可达性和安全运动会的价值迭代标准 | [2505.21087v1](http://arxiv.org/abs/2505.21087v1)
- [49](#article-49) | 05-27 | Herd Behavior: Investigating Peer Influence in LLM-based Multi-Agent   Systems | Herdverhalten: Untersuchung des Peer-Einflusses in LLM-basierte Multi-Agent-Systeme | 牧民行为:调查基于LLM的多机构机构系统中的同侪影响 | [2505.21588v1](http://arxiv.org/abs/2505.21588v1)
- [50](#article-50) | 05-27 | Improving flocking behaviors in street networks with vision | Verbesserung des Beflockungsverhaltens in Straßennetzen mit Vision | 改善街头网络中有远见的群众行为 | [2505.21585v1](http://arxiv.org/abs/2505.21585v1)
- [51](#article-51) | 05-27 | Revisiting Multi-Agent World Modeling from a Diffusion-Inspired   Perspective | Multi-Agenten-Weltmodellierung aus einer diffusionsinspirierten Perspektive Revue passieren | 从传播启发的视角重新审视多股权世界建模 | [2505.20922v1](http://arxiv.org/abs/2505.20922v1)
- [52](#article-52) | 05-27 | Generalized Coordination of Partially Cooperative Urban Traffic | Generalisierte Koordinierung des teilweise kooperativen Stadtverkehrs | 部分合作城市交通协调 | [2505.20879v1](http://arxiv.org/abs/2505.20879v1)
- [53](#article-53) | 05-27 | MedSentry: Understanding and Mitigating Safety Risks in Medical LLM   Multi-Agent Systems | MedSentry: Sicherheitsrisiken in medizinischen LLM-Multiagentensystemen verstehen und mindern | MedSentry:了解和减轻医疗LLM多机构系统中的安全风险 | [2505.20824v1](http://arxiv.org/abs/2505.20824v1)
- [54](#article-54) | 05-27 | Many Heads Are Better Than One: Improved Scientific Idea Generation by A   LLM-Based Multi-Agent System | Viele Köpfe sind besser als eins: Verbesserte wissenschaftliche Idee-Generation durch ein LLM-basiertes Multi-Agent-System | 许多领导人比一个领导人好得多:由以LLM为基础的多种机构系统改进科学思想的一代 | [2410.09403v4](http://arxiv.org/abs/2410.09403v4)
- [55](#article-55) | 05-27 | ReMA: Learning to Meta-think for LLMs with Multi-Agent Reinforcement   Learning | ReMA: Meta-Denken lernen für LLMs mit Multi-Agenten-Verstärkungs-Lernen | ReMA:学习多机构强化学习的LLMLM的元思维 | [2503.09501v3](http://arxiv.org/abs/2503.09501v3)
- [56](#article-56) | 05-27 | JaxRobotarium: Training and Deploying Multi-Robot Policies in 10 Minutes | JaxRobotarium: Schulung und Einsatz von Multi-Roboter-Politik in 10 Minuten | JaxRobotior:10分钟内培训和部署多机器人政策 | [2505.06771v2](http://arxiv.org/abs/2505.06771v2)
- [57](#article-57) | 05-26 | xChemAgents: Agentic AI for Explainable Quantum Chemistry | xChemAgenten: Agentische KI für erklärbare Quantenchemie | xchemAgents: 可解释量子化学的AAA剂 | [2505.20574v1](http://arxiv.org/abs/2505.20574v1)
- [58](#article-58) | 05-26 | Streamlining Resilient Kubernetes Autoscaling with Multi-Agent Systems   via an Automated Online Design Framework | Straffung des Resilients Kubernetes Autoscaling mit Multi-Agent Systemen über ein automatisiertes Online-Design-Framework | 通过自动在线设计框架与多机构系统自动调整 | [2505.21559v1](http://arxiv.org/abs/2505.21559v1)
- [59](#article-59) | 05-26 | Reconceptualizing Smart Microscopy: From Data Collection to Knowledge   Creation by Multi-Agent Integration | Intelligente Mikroskopie neu konzipieren: Von der Datenerhebung zur Wissenserstellung durch Multi-Agent-Integration | 重新概念化智能微镜:从数据收集到通过多机构整合创造知识 | [2505.20466v1](http://arxiv.org/abs/2505.20466v1)
- [60](#article-60) | 05-26 | Sable: a Performant, Efficient and Scalable Sequence Model for MARL | Sable: ein leistungsfähiges, effizientes und skalierbares Sequenzmodell für MARL | 电缆:MARL的性能、高效和可缩放序列模型 | [2410.01706v5](http://arxiv.org/abs/2410.01706v5)
- [61](#article-61) | 05-26 | Federated Domain Generalization with Data-free On-server Matching   Gradient | Föderierte Domain-Verallgemeinerung mit datenfreiem On-Server-Zustimmungs-Gradient | 具有无数据观测站上与渐变匹配的无数据观测器的联邦通用域 | [2501.14653v2](http://arxiv.org/abs/2501.14653v2)
- [62](#article-62) | 05-26 | Semantic-Aware Resource Management for C-V2X Platooning via Multi-Agent   Reinforcement Learning | Semantic-Aware Ressourcenmanagement für C-V2X Platooning über Multi-Agent Verstärkungslernen | 通过多机构强化学习进行 C-V2X 等离子处理的语义软件资源管理 | [2411.04672v2](http://arxiv.org/abs/2411.04672v2)
- [63](#article-63) | 05-26 | Multi-Agent Reinforcement Learning in Cybersecurity: From Fundamentals   to Applications | Multi-Agenten-Verstärkung Lernen in Cybersicherheit: Von Grundlagen zu Anwendungen | 网络安全多机构强化多机构网络安全学习:从基础到应用 | [2505.19837v1](http://arxiv.org/abs/2505.19837v1)
- [64](#article-64) | 05-26 | Fast and Robust Flocking of Protesters on Street Networks | Schnelles und robustes Auspeitschen von Protestierenden auf Straßennetzen | 街头网络上抗争者快速和强力封锁 | [2406.01101v3](http://arxiv.org/abs/2406.01101v3)
- [65](#article-65) | 05-26 | Adaptive Episode Length Adjustment for Multi-agent Reinforcement   Learning | Adaptive Anpassung der Episodenlänge für das Multi-Agenten-Verstärkungs-Lernen | 多试剂强化学习的适应性分单元长度调整 | [2505.19637v1](http://arxiv.org/abs/2505.19637v1)
- [66](#article-66) | 05-26 | Multi-Agent Collaboration via Evolving Orchestration | Multi-Agenten-Zusammenarbeit über Evolving Orchestration | 通过不断演变的管弦化多机构协作 | [2505.19591v1](http://arxiv.org/abs/2505.19591v1)
- [67](#article-67) | 05-26 | LLM-Agent-Controller: A Universal Multi-Agent Large Language Model   System as a Control Engineer | LLM-Agent-Controller: Ein universelles Multi-Agent-Großsprachmodellsystem als Steuerungsingenieur | LLM-代理主计长:作为控制工程师的通用多代理大型语文示范系统 | [2505.19567v1](http://arxiv.org/abs/2505.19567v1)
- [68](#article-68) | 05-26 | DoctorRAG: Medical RAG Fusing Knowledge with Patient Analogy through   Textual Gradients | DoctorRAG: Medizinische RAG Durch Textabstufungen Wissen mit Patient Analogie fusionieren | 医生RAG:通过文字梯度将医学RAG知识与病人分析知识与病人分析相融合 | [2505.19538v1](http://arxiv.org/abs/2505.19538v1)
- [69](#article-69) | 05-26 | VLMLight: Traffic Signal Control via Vision-Language Meta-Control and   Dual-Branch Reasoning | VLMLight: Verkehrssignalsteuerung über Vision-Language Meta-Control und Dual-Branch-Reasoning | VLMLight:通过视觉语言、超控制和双层理由解释控制交通信号控制 | [2505.19486v1](http://arxiv.org/abs/2505.19486v1)
- [70](#article-70) | 05-26 | Win Fast or Lose Slow: Balancing Speed and Accuracy in Latency-Sensitive   Decisions of LLMs | Gewinnen Sie schnell oder verlieren Sie langsam: Ausgleichende Geschwindigkeit und Genauigkeit in Latenz-Sensitive Entscheidungen von LLMs | 慢赢或慢输:LLMs的延缓敏感决定中平衡速度和准确性 | [2505.19481v1](http://arxiv.org/abs/2505.19481v1)
- [71](#article-71) | 05-25 | Making Teams and Influencing Agents: Efficiently Coordinating Decision   Trees for Interpretable Multi-Agent Reinforcement Learning | Teambildung und Beeinflussung von Agenten: Entscheidungsbäume effizient koordinieren für interpretierbares Mehr-Agenten-Verstärkungs-Lernen | 建立团队和对代理人产生影响的代理:高效协调可解释的多机构强化学习决策树 | [2505.19316v1](http://arxiv.org/abs/2505.19316v1)
- [72](#article-72) | 05-25 | Agentic Information Theory: Ergodicity and Intrinsic Semantics of   Information Processes | Agentische Informationstheorie: Ergodikität und Intrinsische Semantik von Informationsprozessen | 代理信息理论:信息过程的分化和内在的语义 | [2505.19275v1](http://arxiv.org/abs/2505.19275v1)
- [73](#article-73) | 05-25 | GUARDIAN: Safeguarding LLM Multi-Agent Collaborations with Temporal   Graph Modeling | GUARDIAN: LLM-Multiagent-Kollaborationen mit zeitlicher Graphenmodellierung sichern | GUARDIAN: 保护LLM 多机构协作与时间图建模 | [2505.19234v1](http://arxiv.org/abs/2505.19234v1)
- [74](#article-74) | 05-25 | Where Paths Collide: A Comprehensive Survey of Classic and   Learning-Based Multi-Agent Pathfinding | Where Paths Collide: Eine umfassende Untersuchung der klassischen und lernbasierten multi-agenten Pathfinding | 路径相撞之处:对经典和以学习为基础的多方代理调查的全面调查 | [2505.19219v1](http://arxiv.org/abs/2505.19219v1)
- [75](#article-75) | 05-25 | Collaborative Agentic AI Needs Interoperability Across Ecosystems | Kollaborative Agentische KI braucht Interoperabilität über Ökosysteme hinweg | AI 需要跨生态系统的互操作性 | [2505.21550v1](http://arxiv.org/abs/2505.21550v1)
- [76](#article-76) | 05-25 | Interacting Large Language Model Agents. Interpretable Models and Social   Learning | Interagieren von Large Language Model Agents. Interpretierbare Modelle und soziales Lernen | 跨大语言示范工具、可解释模型和社会学习 | [2411.01271v2](http://arxiv.org/abs/2411.01271v2)
- [77](#article-77) | 05-25 | Adversarial Bandit over Bandits: Hierarchical Bandits for Online   Configuration Management | Adversarial Bandit über Bandits: Hierarchische Bandits für Online-Konfigurationsmanagement | 反强盗强盗: 用于在线配置管理的等级强盗 | [2505.19061v1](http://arxiv.org/abs/2505.19061v1)
- [78](#article-78) | 05-25 | Adaptive Inference through Bayesian and Inverse Bayesian Inference with   Symmetry-Bias in Nonstationary Environments | Adaptive Schlussfolgerung durch Bayesische und Inverse Bayesische Schlussfolgerung mit Symmetrie-Bias in nichtstationären Umgebungen | 在非静止环境中,通过贝耶斯和反贝耶斯和反贝耶斯的同对称-比亚推理,进行适应性推理 | [2505.12796v3](http://arxiv.org/abs/2505.12796v3)
- [79](#article-79) | 05-25 | SANNet: A Semantic-Aware Agentic AI Networking Framework for Multi-Agent   Cross-Layer Coordination | SANNet: Ein Semantic-Aware Agentic AI Networking Framework für die multi-agente Cross-Layer-Koordination | SANNet: 多代理人跨行业协调的语义学-敏感物义学AI联网框架 | [2505.18946v1](http://arxiv.org/abs/2505.18946v1)
- [80](#article-80) | 05-24 | Distributed Set-membership Filtering Frameworks For Multi-agent Systems   With Absolute and Relative Measurements | Distributed Set-Membership Filtering Frameworks für Multi-Agent-Systeme mit absoluten und relativen Messungen | 具有绝对和相对计量的多试剂系统分布式成员筛选框架 | [2305.15797v2](http://arxiv.org/abs/2305.15797v2)
- [81](#article-81) | 05-24 | Coordinated guidance and control for multiple parafoil system landing | Koordinierte Führung und Steuerung für die Landung mehrerer Parafoil-Systeme | 协调制导和管制多个抛油系统着陆的协调制导和控制 | [2505.18691v1](http://arxiv.org/abs/2505.18691v1)
- [82](#article-82) | 05-24 | Augmenting the action space with conventions to improve multi-agent   cooperation in Hanabi | Erweiterung des Aktionsraums mit Konventionen zur Verbesserung der Multi-Agenten-Kooperation in Hanabi | 与公约扩大行动空间,以改进哈纳比多剂合作 | [2412.06333v3](http://arxiv.org/abs/2412.06333v3)
- [83](#article-83) | 05-24 | DDO: Dual-Decision Optimization via Multi-Agent Collaboration for   LLM-Based Medical Consultation | DDO: Dual-Decision-Optimierung durch Multi-Agent-Kollaboration für LLM-basierte medizinische Beratung | DDO:通过多方机构协作,优化基于LLM的医疗咨询的双重决定 | [2505.18630v1](http://arxiv.org/abs/2505.18630v1)
- [84](#article-84) | 05-24 | An Identity Based Agent Model for Value Alignment | Ein identitätsbasiertes Agentenmodell für die Wertausrichtung | 基于身份的保值调整代理模型 | [2401.12159v4](http://arxiv.org/abs/2401.12159v4)
- [85](#article-85) | 05-24 | MisoDICE: Multi-Agent Imitation from Unlabeled Mixed-Quality   Demonstrations | MisoDICE: Multi-Agent-Imitation aus nicht gekennzeichneten Mixed-Quality-Demonstrationen | MisoDICE:从未贴标签的混合质量示范中多机构吸收 | [2505.18595v1](http://arxiv.org/abs/2505.18595v1)
- [86](#article-86) | 05-24 | MASTER: Multi-Agent Security Through Exploration of Roles and   Topological Structures -- A Comprehensive Framework | MASTER: Multi-Agent Sicherheit durch Erforschung von Rollen und topologischen Strukturen -- Ein umfassender Rahmen | 通过探索作用和地形结构实现多机构安全 -- -- 综合框架 | [2505.18572v1](http://arxiv.org/abs/2505.18572v1)
- [87](#article-87) | 05-24 | MRGAgents: A Multi-Agent Framework for Improved Medical Report   Generation with Med-LVLMs | MRGAgents: Multi-Agenten-Rahmen für verbesserte medizinische Report-Generation mit Med-LVLMs | MRGGGGss: 采用医疗低水平医疗报告制改进医疗报告制的多机构框架 | [2505.18530v1](http://arxiv.org/abs/2505.18530v1)
- [88](#article-88) | 05-24 | Group Trip Planning Query Problem with Multimodal Journey | Gruppenreiseplanungs-Abfrage-Problem mit multimodaler Reise | 具有多模式旅程的问询问题 | [2502.03144v2](http://arxiv.org/abs/2502.03144v2)
- [89](#article-89) | 05-24 | TextArena | TextArena | TextArenna 文本 | [2504.11442v2](http://arxiv.org/abs/2504.11442v2)
- [90](#article-90) | 05-24 | EdgeAgentX: A Novel Framework for Agentic AI at the Edge in Military   Communication Networks | EdgeAgentX: Ein neuartiges Framework für Agentische KI am Rand in militärischen Kommunikationsnetzwerken | EdgeAgengengenderX:军事通信网络边缘地带AAA剂性AI新框架 | [2505.18457v1](http://arxiv.org/abs/2505.18457v1)
- [91](#article-91) | 05-24 | Finite-Time Global Optimality Convergence in Deep Neural Actor-Critic   Methods for Decentralized Multi-Agent Reinforcement Learning | Finite-Time Global Optimality Convergence in Deep Neural Actor-Critic Methoden für dezentralisiertes Mehr-Agenten-Verstärkungs-Lernen | 分散式多机构强化学习的深神经立体-集中式多机构强化学习方法中全球最佳程度趋同 | [2505.18433v1](http://arxiv.org/abs/2505.18433v1)

## Article 0
### Title@2025-05-29: ROTATE: Regret-driven Open-ended Training for Ad Hoc Teamwork
**Title**: ROTATE: Regret-driven Open-ended Training for Ad Hoc Teamwork | ROTATE: Bedauern-getriebenes Open-End-Training für Ad-Hoc-Teamwork | 对特设团队工作不限成员名额培训的遗憾驱动的不限名额培训 [2505.23686v1](http://arxiv.org/abs/2505.23686v1)

**Authors**: Caroline Wang, Arrasy Rahman, Jiaxun Cui, Yoonchang Sung, Peter Stone

Developing AI agents capable of collaborating with previously unseen partners is a fundamental generalization challenge in multi-agent learning, known as Ad Hoc Teamwork (AHT). Existing AHT approaches typically adopt a two-stage pipeline, where first, a fixed population of teammates is generated with the idea that they should be representative of the teammates that will be seen at deployment time, and second, an AHT agent is trained to collaborate well with agents in the population. To date, the research community has focused on designing separate algorithms for each stage. This separation has led to algorithms that generate teammate pools with limited coverage of possible behaviors, and that ignore whether the generated teammates are easy to learn from for the AHT agent. Furthermore, algorithms for training AHT agents typically treat the set of training teammates as static, thus attempting to generalize to previously unseen partner agents without assuming any control over the distribution of training teammates. In this paper, we present a unified framework for AHT by reformulating the problem as an open-ended learning process between an ad hoc agent and an adversarial teammate generator. We introduce ROTATE, a regret-driven, open-ended training algorithm that alternates between improving the AHT agent and generating teammates that probe its deficiencies. Extensive experiments across diverse AHT environments demonstrate that ROTATE significantly outperforms baselines at generalizing to an unseen set of evaluation teammates, thus establishing a new standard for robust and generalizable teamwork.

---

## Article 1
### Title@2025-05-29: Collaborative Last-Mile Delivery: A Multi-Platform Vehicle Routing   Problem With En-route Charging
**Title**: Collaborative Last-Mile Delivery: A Multi-Platform Vehicle Routing   Problem With En-route Charging | Collaborative Last-Mile Lieferung: Ein Multi-Platform Fahrzeug Routing Problem mit en-route Laden | 合作性最后一式交付:多平台车辆运行问题与连路充电 [2505.23584v1](http://arxiv.org/abs/2505.23584v1)

**Authors**: Sumbal Malik, Majid Khonji, Khaled Elbassioni, Jorge Dias

The rapid growth of e-commerce and the increasing demand for timely, cost-effective last-mile delivery have increased interest in collaborative logistics. This research introduces a novel collaborative synchronized multi-platform vehicle routing problem with drones and robots (VRP-DR), where a fleet of $\mathcal{M}$ trucks, $\mathcal{N}$ drones and $\mathcal{K}$ robots, cooperatively delivers parcels. Trucks serve as mobile platforms, enabling the launching, retrieving, and en-route charging of drones and robots, thereby addressing critical limitations such as restricted payload capacities, limited range, and battery constraints. The VRP-DR incorporates five realistic features: (1) multi-visit service per trip, (2) multi-trip operations, (3) flexible docking, allowing returns to the same or different trucks (4) cyclic and acyclic operations, enabling return to the same or different nodes; and (5) en-route charging, enabling drones and robots to recharge while being transported on the truck, maximizing operational efficiency by utilizing idle transit time. The VRP-DR is formulated as a mixed-integer linear program (MILP) to minimize both operational costs and makespan. To overcome the computational challenges of solving large-scale instances, a scalable heuristic algorithm, FINDER (Flexible INtegrated Delivery with Energy Recharge), is developed, to provide efficient, near-optimal solutions. Numerical experiments across various instance sizes evaluate the performance of the MILP and heuristic approaches in terms of solution quality and computation time. The results demonstrate significant time savings of the combined delivery mode over the truck-only mode and substantial cost reductions from enabling multi-visits. The study also provides insights into the effects of en-route charging, docking flexibility, drone count, speed, and payload capacity on system performance.

---

## Article 2
### Title@2025-05-29: MegaAgent: A Large-Scale Autonomous LLM-based Multi-Agent System Without   Predefined SOPs
**Title**: MegaAgent: A Large-Scale Autonomous LLM-based Multi-Agent System Without   Predefined SOPs | MegaAgent: Ein autonomes LLM-basiertes Multi-Agent-System ohne vordefinierte SOPs | 大型机构:一个以大型自治LLM为基础的没有预先界定的SOP的多机构系统 [2408.09955v3](http://arxiv.org/abs/2408.09955v3)

**Authors**: Qian Wang, Tianyu Wang, Zhenheng Tang, Qinbin Li, Nuo Chen, Jingsheng Liang, Bingsheng He

LLM-based multi-agent systems (MAS) have shown promise in tackling complex tasks. However, existing solutions often suffer from limited agent coordination and heavy reliance on predefined Standard Operating Procedures (SOPs), which demand extensive human input. To address these limitations, we propose MegaAgent, a large-scale autonomous LLM-based multi-agent system. MegaAgent generates agents based on task complexity and enables dynamic task decomposition, parallel execution, efficient communication, and comprehensive system monitoring of agents. In evaluations, MegaAgent demonstrates exceptional performance, successfully developing a Gobang game within 800 seconds and scaling up to 590 agents in a national policy simulation to generate multi-domain policies. It significantly outperforms existing systems, such as MetaGPT, in both task completion efficiency and scalability. By eliminating the need for predefined SOPs, MegaAgent demonstrates exceptional scalability and autonomy, setting a foundation for advancing true autonomy in MAS. Our code is available at https://github.com/Xtra-Computing/MegaAgent .

---

## Article 3
### Title@2025-05-29: Agentic Knowledgeable Self-awareness
**Title**: Agentic Knowledgeable Self-awareness | Agentisch sachkundiges Selbstbewußtsein | A. 动态知识自觉意识 [2504.03553v2](http://arxiv.org/abs/2504.03553v2)

**Authors**: Shuofei Qiao, Zhisong Qiu, Baochang Ren, Xiaobin Wang, Xiangyuan Ru, Ningyu Zhang, Xiang Chen, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen

Large Language Models (LLMs) have achieved considerable performance across various agentic planning tasks. However, traditional agent planning approaches adopt a "flood irrigation" methodology that indiscriminately injects gold trajectories, external feedback, and domain knowledge into agent models. This practice overlooks the fundamental human cognitive principle of situational self-awareness during decision-making-the ability to dynamically assess situational demands and strategically employ resources during decision-making. We propose agentic knowledgeable self-awareness to address this gap, a novel paradigm enabling LLM-based agents to autonomously regulate knowledge utilization. Specifically, we propose KnowSelf, a data-centric approach that applies agents with knowledgeable self-awareness like humans. Concretely, we devise a heuristic situation judgement criterion to mark special tokens on the agent's self-explored trajectories for collecting training data. Through a two-stage training process, the agent model can switch between different situations by generating specific special tokens, achieving optimal planning effects with minimal costs. Our experiments demonstrate that KnowSelf can outperform various strong baselines on different tasks and models with minimal use of external knowledge. Code is available at https://github.com/zjunlp/KnowSelf.

---

## Article 4
### Title@2025-05-29: The challenge of hidden gifts in multi-agent reinforcement learning
**Title**: The challenge of hidden gifts in multi-agent reinforcement learning | Die Herausforderung der versteckten Gaben in Multi-Agenten-Verstärkung Lernen | 多试剂强化学习中隐藏礼品的挑战 [2505.20579v2](http://arxiv.org/abs/2505.20579v2)

**Authors**: Dane Malenfant, Blake A. Richards

Sometimes we benefit from actions that others have taken even when we are unaware that they took those actions. For example, if your neighbor chooses not to take a parking spot in front of your house when you are not there, you can benefit, even without being aware that they took this action. These "hidden gifts" represent an interesting challenge for multi-agent reinforcement learning (MARL), since assigning credit when the beneficial actions of others are hidden is non-trivial. Here, we study the impact of hidden gifts with a very simple MARL task. In this task, agents in a grid-world environment have individual doors to unlock in order to obtain individual rewards. As well, if all the agents unlock their door the group receives a larger collective reward. However, there is only one key for all of the doors, such that the collective reward can only be obtained when the agents drop the key for others after they use it. Notably, there is nothing to indicate to an agent that the other agents have dropped the key, thus the act of dropping the key for others is a "hidden gift". We show that several different state-of-the-art RL algorithms, including MARL algorithms, fail to learn how to obtain the collective reward in this simple task. Interestingly, we find that independent model-free policy gradient agents can solve the task when we provide them with information about their own action history, but MARL agents still cannot solve the task with action history. Finally, we derive a correction term for these independent agents, inspired by learning aware approaches, which reduces the variance in learning and helps them to converge to collective success more reliably. These results show that credit assignment in multi-agent settings can be particularly challenging in the presence of "hidden gifts", and demonstrate that learning awareness in independent agents can benefit these settings.

---

## Article 5
### Title@2025-05-29: Understanding the Information Propagation Effects of Communication   Topologies in LLM-based Multi-Agent Systems
**Title**: Understanding the Information Propagation Effects of Communication   Topologies in LLM-based Multi-Agent Systems | Verständnis der Informationsverbreitungseffekte von Kommunikationstopologien in LLM-basierten Multi-Agent-Systemen | 了解基于LLOM的多机构机构系统中的通信地形对信息传播的影响 [2505.23352v1](http://arxiv.org/abs/2505.23352v1)

**Authors**: Xu Shen, Yixin Liu, Yiwei Dai, Yili Wang, Rui Miao, Yue Tan, Shirui Pan, Xin Wang

The communication topology in large language model-based multi-agent systems fundamentally governs inter-agent collaboration patterns, critically shaping both the efficiency and effectiveness of collective decision-making. While recent studies for communication topology automated design tend to construct sparse structures for efficiency, they often overlook why and when sparse and dense topologies help or hinder collaboration. In this paper, we present a causal framework to analyze how agent outputs, whether correct or erroneous, propagate under topologies with varying sparsity. Our empirical studies reveal that moderately sparse topologies, which effectively suppress error propagation while preserving beneficial information diffusion, typically achieve optimal task performance. Guided by this insight, we propose a novel topology design approach, EIB-leanrner, that balances error suppression and beneficial information propagation by fusing connectivity patterns from both dense and sparse graphs. Extensive experiments show the superior effectiveness, communication cost, and robustness of EIB-leanrner.

---

## Article 6
### Title@2025-05-29: Emergent social conventions and collective bias in LLM populations
**Title**: Emergent social conventions and collective bias in LLM populations | Emergente soziale Konventionen und kollektive Voreingenommenheit in LLM-Populationen | 新出现的社会习俗和LLM人口的集体偏见 [2410.08948v2](http://arxiv.org/abs/2410.08948v2)

**Authors**: Ariel Flint Ashery, Luca Maria Aiello, Andrea Baronchelli

Social conventions are the backbone of social coordination, shaping how individuals form a group. As growing populations of artificial intelligence (AI) agents communicate through natural language, a fundamental question is whether they can bootstrap the foundations of a society. Here, we present experimental results that demonstrate the spontaneous emergence of universally adopted social conventions in decentralized populations of large language model (LLM) agents. We then show how strong collective biases can emerge during this process, even when agents exhibit no bias individually. Last, we examine how committed minority groups of adversarial LLM agents can drive social change by imposing alternative social conventions on the larger population. Our results show that AI systems can autonomously develop social conventions without explicit programming and have implications for designing AI systems that align, and remain aligned, with human values and societal goals.

---

## Article 7
### Title@2025-05-29: Language Agents with Reinforcement Learning for Strategic Play in the   Werewolf Game
**Title**: Language Agents with Reinforcement Learning for Strategic Play in the   Werewolf Game | Sprachagenten mit Verstärkung Lernen für strategisches Spiel im Werwolf Spiel | 在狼人游戏中进行战略游戏强化学习的语文代理 [2310.18940v4](http://arxiv.org/abs/2310.18940v4)

**Authors**: Zelai Xu, Chao Yu, Fei Fang, Yu Wang, Yi Wu

Agents built with large language models (LLMs) have shown great potential across a wide range of domains. However, in complex decision-making tasks, pure LLM-based agents tend to exhibit intrinsic bias in their choice of actions, which is inherited from the model's training data and results in suboptimal performance. To develop strategic language agents, i.e., agents that generate flexible language actions and possess strong decision-making abilities, we propose a novel framework that powers LLM-based agents with reinforcement learning (RL). We consider Werewolf, a popular social deduction game, as a challenging testbed that emphasizes versatile communication and strategic gameplay. To mitigate the intrinsic bias in language actions, our agents use an LLM to perform deductive reasoning and generate a diverse set of action candidates. Then an RL policy trained to optimize the decision-making ability chooses an action from the candidates to play in the game. Extensive experiments show that our agents overcome the intrinsic bias and outperform existing LLM-based agents in the Werewolf game. We also conduct human-agent experiments and find that our agents achieve human-level performance and demonstrate strong strategic play.

---

## Article 8
### Title@2025-05-29: Cross-Task Experiential Learning on LLM-based Multi-Agent Collaboration
**Title**: Cross-Task Experiential Learning on LLM-based Multi-Agent Collaboration | Erfahrungsübergreifendes Lernen auf LLM-basierter Multi-Agent-Kollaboration | 关于基于LLM的多机构合作的跨任务跨任务经验学习 [2505.23187v1](http://arxiv.org/abs/2505.23187v1)

**Authors**: Yilong Li, Chen Qian, Yu Xia, Ruijie Shi, Yufan Dang, Zihao Xie, Ziming You, Weize Chen, Cheng Yang, Weichuan Liu, Ye Tian, Xuantang Xiong, Lei Han, Zhiyuan Liu, Maosong Sun

Large Language Model-based multi-agent systems (MAS) have shown remarkable progress in solving complex tasks through collaborative reasoning and inter-agent critique. However, existing approaches typically treat each task in isolation, resulting in redundant computations and limited generalization across structurally similar tasks. To address this, we introduce multi-agent cross-task experiential learning (MAEL), a novel framework that endows LLM-driven agents with explicit cross-task learning and experience accumulation. We model the task-solving workflow on a graph-structured multi-agent collaboration network, where agents propagate information and coordinate via explicit connectivity. During the experiential learning phase, we quantify the quality for each step in the task-solving workflow and store the resulting rewards along with the corresponding inputs and outputs into each agent's individual experience pool. During inference, agents retrieve high-reward, task-relevant experiences as few-shot examples to enhance the effectiveness of each reasoning step, thereby enabling more accurate and efficient multi-agent collaboration. Experimental results on diverse datasets demonstrate that MAEL empowers agents to learn from prior task experiences effectively-achieving faster convergence and producing higher-quality solutions on current tasks.

---

## Article 9
### Title@2025-05-29: Topological Structure Learning Should Be A Research Priority for   LLM-Based Multi-Agent Systems
**Title**: Topological Structure Learning Should Be A Research Priority for   LLM-Based Multi-Agent Systems | Topologisches Strukturlernen sollte eine Forschungspriorität für LLM-basierte Multi-Agent-Systeme sein | 地形结构学习应成为以LLM为基础的多种机构系统的研究重点 [2505.22467v2](http://arxiv.org/abs/2505.22467v2)

**Authors**: Jiaxi Yang, Mengqi Zhang, Yiqiao Jin, Hao Chen, Qingsong Wen, Lu Lin, Yi He, Weijie Xu, James Evans, Jindong Wang

Large Language Model-based Multi-Agent Systems (MASs) have emerged as a powerful paradigm for tackling complex tasks through collaborative intelligence. Nevertheless, the question of how agents should be structurally organized for optimal cooperation remains largely unexplored. In this position paper, we aim to gently redirect the focus of the MAS research community toward this critical dimension: develop topology-aware MASs for specific tasks. Specifically, the system consists of three core components - agents, communication links, and communication patterns - that collectively shape its coordination performance and efficiency. To this end, we introduce a systematic, three-stage framework: agent selection, structure profiling, and topology synthesis. Each stage would trigger new research opportunities in areas such as language models, reinforcement learning, graph learning, and generative modeling; together, they could unleash the full potential of MASs in complicated real-world applications. Then, we discuss the potential challenges and opportunities in the evaluation of multiple systems. We hope our perspective and framework can offer critical new insights in the era of agentic AI.

---

## Article 10
### Title@2025-05-29: MedRAX: Medical Reasoning Agent for Chest X-ray
**Title**: MedRAX: Medical Reasoning Agent for Chest X-ray | MedRAX: Medizinischer Reasoning Agent für Bruströntgen | MedraX: 胸前X光医疗理疗代理 [2502.02673v2](http://arxiv.org/abs/2502.02673v2)

**Authors**: Adibvafa Fallahpour, Jun Ma, Alif Munim, Hongwei Lyu, Bo Wang

Chest X-rays (CXRs) play an integral role in driving critical decisions in disease management and patient care. While recent innovations have led to specialized models for various CXR interpretation tasks, these solutions often operate in isolation, limiting their practical utility in clinical practice. We present MedRAX, the first versatile AI agent that seamlessly integrates state-of-the-art CXR analysis tools and multimodal large language models into a unified framework. MedRAX dynamically leverages these models to address complex medical queries without requiring additional training. To rigorously evaluate its capabilities, we introduce ChestAgentBench, a comprehensive benchmark containing 2,500 complex medical queries across 7 diverse categories. Our experiments demonstrate that MedRAX achieves state-of-the-art performance compared to both open-source and proprietary models, representing a significant step toward the practical deployment of automated CXR interpretation systems. Data and code have been publicly available at https://github.com/bowang-lab/MedRAX

---

## Article 11
### Title@2025-05-29: Learning Recommender Mechanisms for Bayesian Stochastic Games
**Title**: Learning Recommender Mechanisms for Bayesian Stochastic Games | Lern-Empfänger-Mechanismen für Bayesian Stochastic Games | 贝耶斯沙沙运动会学习建议机制 [2505.22979v1](http://arxiv.org/abs/2505.22979v1)

**Authors**: Bengisu Guresti, Chongjie Zhang, Yevgeniy Vorobeychik

An important challenge in non-cooperative game theory is coordinating on a single (approximate) equilibrium from many possibilities - a challenge that becomes even more complex when players hold private information. Recommender mechanisms tackle this problem by recommending strategies to players based on their reported type profiles. A key consideration in such mechanisms is to ensure that players are incentivized to participate, report their private information truthfully, and follow the recommendations. While previous work has focused on designing recommender mechanisms for one-shot and extensive-form games, these approaches cannot be effectively applied to stochastic games, particularly if we constrain recommendations to be Markov stationary policies. To bridge this gap, we introduce a novel bi-level reinforcement learning approach for automatically designing recommender mechanisms in Bayesian stochastic games. Our method produces a mechanism represented by a parametric function (such as a neural network), and is therefore highly efficient at execution time. Experimental results on two repeated and two stochastic games demonstrate that our approach achieves social welfare levels competitive with cooperative multi-agent reinforcement learning baselines, while also providing significantly improved incentive properties.

---

## Article 12
### Title@2025-05-29: MermaidFlow: Redefining Agentic Workflow Generation via   Safety-Constrained Evolutionary Programming
**Title**: MermaidFlow: Redefining Agentic Workflow Generation via   Safety-Constrained Evolutionary Programming | MermaidFlow: Neudefinition der agentischen Workflow-Generierung durch sicherheitsbeschränkte evolutionäre Programmierung | 美人鱼:通过受安全限制的进化方案拟订,重新确定干燥性工作流的产生 [2505.22967v1](http://arxiv.org/abs/2505.22967v1)

**Authors**: Chengqi Zheng, Jianda Chen, Yueming Lyu, Wen Zheng Terence Ng, Haopeng Zhang, Yew-Soon Ong, Ivor Tsang, Haiyan Yin

Despite the promise of autonomous agentic reasoning, existing workflow generation methods frequently produce fragile, unexecutable plans due to unconstrained LLM-driven construction. We introduce MermaidFlow, a framework that redefines the agentic search space through safety-constrained graph evolution. At its core, MermaidFlow represent workflows as a verifiable intermediate representation using Mermaid, a structured and human-interpretable graph language. We formulate domain-aware evolutionary operators, i.e., crossover, mutation, insertion, and deletion, to preserve semantic correctness while promoting structural diversity, enabling efficient exploration of a high-quality, statically verifiable workflow space. Without modifying task settings or evaluation protocols, MermaidFlow achieves consistent improvements in success rates and faster convergence to executable plans on the agent reasoning benchmark. The experimental results demonstrate that safety-constrained graph evolution offers a scalable, modular foundation for robust and interpretable agentic reasoning systems.

---

## Article 13
### Title@2025-05-28: A Large Language Model-Enabled Control Architecture for Dynamic Resource   Capability Exploration in Multi-Agent Manufacturing Systems
**Title**: A Large Language Model-Enabled Control Architecture for Dynamic Resource   Capability Exploration in Multi-Agent Manufacturing Systems | Eine großsprachige modellfähige Steuerungsarchitektur für dynamische Ressourcenkapazitäts-Exploration in Multi-Agent-Produktionssystemen | 多机构制造系统动态资源能力探索大语言模型化控制结构 [2505.22814v1](http://arxiv.org/abs/2505.22814v1)

**Authors**: Jonghan Lim, Ilya Kovalenko

Manufacturing environments are becoming more complex and unpredictable due to factors such as demand variations and shorter product lifespans. This complexity requires real-time decision-making and adaptation to disruptions. Traditional control approaches highlight the need for advanced control strategies capable of overcoming unforeseen challenges, as they demonstrate limitations in responsiveness within dynamic industrial settings. Multi-agent systems address these challenges through decentralization of decision-making, enabling systems to respond dynamically to operational changes. However, current multi-agent systems encounter challenges related to real-time adaptation, context-aware decision-making, and the dynamic exploration of resource capabilities. Large language models provide the possibility to overcome these limitations through context-aware decision-making capabilities. This paper introduces a large language model-enabled control architecture for multi-agent manufacturing systems to dynamically explore resource capabilities in response to real-time disruptions. A simulation-based case study demonstrates that the proposed architecture improves system resilience and flexibility. The case study findings show improved throughput and efficient resource utilization compared to existing approaches.

---

## Article 14
### Title@2025-05-28: Dynamic Task Adaptation for Multi-Robot Manufacturing Systems with Large   Language Models
**Title**: Dynamic Task Adaptation for Multi-Robot Manufacturing Systems with Large   Language Models | Dynamische Aufgabenanpassung für Multi-Roboter-Produktionssysteme mit großen Sprachmodellen | 具有大语言模型的多机器人制造系统动态任务适应 [2505.22804v1](http://arxiv.org/abs/2505.22804v1)

**Authors**: Jonghan Lim, Ilya Kovalenko

Recent manufacturing systems are increasingly adopting multi-robot collaboration to handle complex and dynamic environments. While multi-agent architectures support decentralized coordination among robot agents, they often face challenges in enabling real-time adaptability for unexpected disruptions without predefined rules. Recent advances in large language models offer new opportunities for context-aware decision-making to enable adaptive responses to unexpected changes. This paper presents an initial exploratory implementation of a large language model-enabled control framework for dynamic task reassignment in multi-robot manufacturing systems. A central controller agent leverages the large language model's ability to interpret structured robot configuration data and generate valid reassignments in response to robot failures. Experiments in a real-world setup demonstrate high task success rates in recovering from failures, highlighting the potential of this approach to improve adaptability in multi-robot manufacturing systems.

---

## Article 15
### Title@2025-05-28: Enhancing Lifelong Multi-Agent Path-finding by Using Artificial   Potential Fields
**Title**: Enhancing Lifelong Multi-Agent Path-finding by Using Artificial   Potential Fields | Verbesserung der lebensbegleitenden multi-agenten Path-Finding durch den Einsatz künstlicher Potenzialfelder | 利用人造潜在潜力领域加强终身多机构探索 [2505.22753v1](http://arxiv.org/abs/2505.22753v1)

**Authors**: Arseniy Pertzovsky, Roni Stern, Ariel Felner, Roie Zivan

We explore the use of Artificial Potential Fields (APFs) to solve Multi-Agent Path Finding (MAPF) and Lifelong MAPF (LMAPF) problems. In MAPF, a team of agents must move to their goal locations without collisions, whereas in LMAPF, new goals are generated upon arrival. We propose methods for incorporating APFs in a range of MAPF algorithms, including Prioritized Planning, MAPF-LNS2, and Priority Inheritance with Backtracking (PIBT). Experimental results show that using APF is not beneficial for MAPF but yields up to a 7-fold increase in overall system throughput for LMAPF.

---

## Article 16
### Title@2025-05-28: A Novel Zero-Trust Identity Framework for Agentic AI: Decentralized   Authentication and Fine-Grained Access Control
**Title**: A Novel Zero-Trust Identity Framework for Agentic AI: Decentralized   Authentication and Fine-Grained Access Control | Ein neuartiges Null-Vertrauens-Identitäts-Framework für Agentische KI: Dezentrale Authentisierung und feinkörnige Zugriffskontrolle | AI:分散认证和精密访问控制 [2505.19301v2](http://arxiv.org/abs/2505.19301v2)

**Authors**: Ken Huang, Vineeth Sai Narajala, John Yeoh, Jason Ross, Ramesh Raskar, Youssef Harkati, Jerry Huang, Idan Habler, Chris Hughes

Traditional Identity and Access Management (IAM) systems, primarily designed for human users or static machine identities via protocols such as OAuth, OpenID Connect (OIDC), and SAML, prove fundamentally inadequate for the dynamic, interdependent, and often ephemeral nature of AI agents operating at scale within Multi Agent Systems (MAS), a computational system composed of multiple interacting intelligent agents that work collectively.   This paper posits the imperative for a novel Agentic AI IAM framework: We deconstruct the limitations of existing protocols when applied to MAS, illustrating with concrete examples why their coarse-grained controls, single-entity focus, and lack of context-awareness falter. We then propose a comprehensive framework built upon rich, verifiable Agent Identities (IDs), leveraging Decentralized Identifiers (DIDs) and Verifiable Credentials (VCs), that encapsulate an agents capabilities, provenance, behavioral scope, and security posture.   Our framework includes an Agent Naming Service (ANS) for secure and capability-aware discovery, dynamic fine-grained access control mechanisms, and critically, a unified global session management and policy enforcement layer for real-time control and consistent revocation across heterogeneous agent communication protocols. We also explore how Zero-Knowledge Proofs (ZKPs) enable privacy-preserving attribute disclosure and verifiable policy compliance.   We outline the architecture, operational lifecycle, innovative contributions, and security considerations of this new IAM paradigm, aiming to establish the foundational trust, accountability, and security necessary for the burgeoning field of agentic AI and the complex ecosystems they will inhabit.

---

## Article 17
### Title@2025-05-28: HDDLGym: A Tool for Studying Multi-Agent Hierarchical Problems Defined   in HDDL with OpenAI Gym
**Title**: HDDLGym: A Tool for Studying Multi-Agent Hierarchical Problems Defined   in HDDL with OpenAI Gym | HDDLGym: Ein Tool zum Studieren multi-agenter Hierarchischer Probleme, definiert in HDDL mit OpenAI Gym | HDDLGym: 与 OpenAI Gym 一起研究在HDDL 中界定的多代理等级问题的工具 [2505.22597v1](http://arxiv.org/abs/2505.22597v1)

**Authors**: Ngoc La, Ruaridh Mon-Williams, Julie A. Shah

In recent years, reinforcement learning (RL) methods have been widely tested using tools like OpenAI Gym, though many tasks in these environments could also benefit from hierarchical planning. However, there is a lack of a tool that enables seamless integration of hierarchical planning with RL. Hierarchical Domain Definition Language (HDDL), used in classical planning, introduces a structured approach well-suited for model-based RL to address this gap. To bridge this integration, we introduce HDDLGym, a Python-based tool that automatically generates OpenAI Gym environments from HDDL domains and problems. HDDLGym serves as a link between RL and hierarchical planning, supporting multi-agent scenarios and enabling collaborative planning among agents. This paper provides an overview of HDDLGym's design and implementation, highlighting the challenges and design choices involved in integrating HDDL with the Gym interface, and applying RL policies to support hierarchical planning. We also provide detailed instructions and demonstrations for using the HDDLGym framework, including how to work with existing HDDL domains and problems from International Planning Competitions, exemplified by the Transport domain. Additionally, we offer guidance on creating new HDDL domains for multi-agent scenarios and demonstrate the practical use of HDDLGym in the Overcooked domain. By leveraging the advantages of HDDL and Gym, HDDLGym aims to be a valuable tool for studying RL in hierarchical planning, particularly in multi-agent contexts.

---

## Article 18
### Title@2025-05-28: SynWorld: Virtual Scenario Synthesis for Agentic Action Knowledge   Refinement
**Title**: SynWorld: Virtual Scenario Synthesis for Agentic Action Knowledge   Refinement | SynWorld: Virtual Scenario Synthesis for Agentic Action Knowledge Refinement | Synworld: 用于改进制剂行动知识的虚拟情景合成 [2504.03561v2](http://arxiv.org/abs/2504.03561v2)

**Authors**: Runnan Fang, Xiaobin Wang, Yuan Liang, Shuofei Qiao, Jialong Wu, Zekun Xi, Ningyu Zhang, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen

In the interaction between agents and their environments, agents expand their capabilities by planning and executing actions. However, LLM-based agents face substantial challenges when deployed in novel environments or required to navigate unconventional action spaces. To empower agents to autonomously explore environments, optimize workflows, and enhance their understanding of actions, we propose SynWorld, a framework that allows agents to synthesize possible scenarios with multi-step action invocation within the action space and perform Monte Carlo Tree Search (MCTS) exploration to effectively refine their action knowledge in the current environment. Our experiments demonstrate that SynWorld is an effective and general approach to learning action knowledge in new environments. Code is available at https://github.com/zjunlp/SynWorld.

---

## Article 19
### Title@2025-05-28: From Strangers to Assistants: Fast Desire Alignment for Embodied   Agent-User Adaptation
**Title**: From Strangers to Assistants: Fast Desire Alignment for Embodied   Agent-User Adaptation | Von Fremdlingen zu Assistenten: Schnelles Wunsch-Ausrichtung für eingedickte Agent-User-Anpassung | 从陌生人到助理:对装装配剂用户适应的快速理想调整 [2505.22503v1](http://arxiv.org/abs/2505.22503v1)

**Authors**: Yuanfei Wang, Xinju Huang, Fangwei Zhong, Yaodong Yang, Yizhou Wang, Yuanpei Chen, Hao Dong

While embodied agents have made significant progress in performing complex physical tasks, real-world applications demand more than pure task execution. The agents must collaborate with unfamiliar agents and human users, whose goals are often vague and implicit. In such settings, interpreting ambiguous instructions and uncovering underlying desires is essential for effective assistance. Therefore, fast and accurate desire alignment becomes a critical capability for embodied agents. In this work, we first develop a home assistance simulation environment HA-Desire that integrates an LLM-driven human user agent exhibiting realistic value-driven goal selection and communication. The ego agent must interact with this proxy user to infer and adapt to the user's latent desires. To achieve this, we present a novel framework FAMER for fast desire alignment, which introduces a desire-based mental reasoning mechanism to identify user intent and filter desire-irrelevant actions. We further design a reflection-based communication module that reduces redundant inquiries, and incorporate goal-relevant information extraction with memory persistence to improve information reuse and reduce unnecessary exploration. Extensive experiments demonstrate that our framework significantly enhances both task execution and communication efficiency, enabling embodied agents to quickly adapt to user-specific desires in complex embodied environments.

---

## Article 20
### Title@2025-05-28: OptiMindTune: A Multi-Agent Framework for Intelligent Hyperparameter   Optimization
**Title**: OptiMindTune: A Multi-Agent Framework for Intelligent Hyperparameter   Optimization | OptiMindTune: Multi-Agenten-Framework für intelligente Hyperparameter-Optimierung | OptiMindTunne: 智能超参数优化的多机构框架 [2505.19205v2](http://arxiv.org/abs/2505.19205v2)

**Authors**: Meher Bhaskar Madiraju, Meher Sai Preetam Madiraju

Hyperparameter optimization (HPO) is a critical yet challenging aspect of machine learning model development, significantly impacting model performance and generalization. Traditional HPO methods often struggle with high dimensionality, complex interdependencies, and computational expense. This paper introduces OptiMindTune, a novel multi-agent framework designed to intelligently and efficiently optimize hyperparameters. OptiMindTune leverages the collaborative intelligence of three specialized AI agents -- a Recommender Agent, an Evaluator Agent, and a Decision Agent -- each powered by Google's Gemini models. These agents address distinct facets of the HPO problem, from model selection and hyperparameter suggestion to robust evaluation and strategic decision-making. By fostering dynamic interactions and knowledge sharing, OptiMindTune aims to converge to optimal hyperparameter configurations more rapidly and robustly than existing single-agent or monolithic approaches. Our framework integrates principles from advanced large language models, and adaptive search to achieve scalable and intelligent AutoML. We posit that this multi-agent paradigm offers a promising avenue for tackling the increasing complexity of modern machine learning model tuning.

---

## Article 21
### Title@2025-05-28: The Complexity of Pure Strategy Relevant Equilibria in Concurrent Games
**Title**: The Complexity of Pure Strategy Relevant Equilibria in Concurrent Games | Die Komplexität der reinen Strategie Relevante Equilibria in Parallelspielen | 同时运动会中纯粹战略相关平衡的复杂性 [2505.07501v2](http://arxiv.org/abs/2505.07501v2)

**Authors**: Purandar Bhaduri

We study rational synthesis problems for concurrent games with $\omega$-regular objectives. Our model of rationality considers only pure strategy Nash equilibria that satisfy either a social welfare or Pareto optimality condition with respect to an $\omega$-regular objective for each agent. This extends earlier work on equilibria in concurrent games, without consideration about their quality. Our results show that the existence of Nash equilibria satisfying social welfare conditions can be computed as efficiently as the constrained Nash equilibrium existence problem. On the other hand, the existence of Nash equilibria satisfying the Pareto optimality condition possibly involves a higher upper bound, except in the case of B\"uchi and Muller games, for which all three problems are in the classes P and PSPACE-complete, respectively.

---

## Article 22
### Title@2025-05-28: Voice CMS: updating the knowledge base of a digital assistant through   conversation
**Title**: Voice CMS: updating the knowledge base of a digital assistant through   conversation | Voice CMS: Aktualisierung der Wissensbasis eines digitalen Assistenten durch Konversation | 语音CMS:通过对话更新数字助理的知识库 [2505.22303v1](http://arxiv.org/abs/2505.22303v1)

**Authors**: Grzegorz Wolny, Michał Szczerbak

In this study, we propose a solution based on a multi-agent LLM architecture and a voice user interface (VUI) designed to update the knowledge base of a digital assistant. Its usability is evaluated in comparison to a more traditional graphical content management system (CMS), with a focus on understanding the relationship between user preferences and the complexity of the information being provided. The findings demonstrate that, while the overall usability of the VUI is rated lower than the graphical interface, it is already preferred by users for less complex tasks. Furthermore, the quality of content entered through the VUI is comparable to that achieved with the graphical interface, even for highly complex tasks. Obtained qualitative results suggest that a hybrid interface combining the strengths of both approaches could address the key challenges identified during the experiment, such as reducing cognitive load through graphical feedback while maintaining the intuitive nature of voice-based interactions. This work highlights the potential of conversational interfaces as a viable and effective method for knowledge management in specific business contexts.

---

## Article 23
### Title@2025-05-28: Leveraging Dual Process Theory in Language Agent Framework for Real-time   Simultaneous Human-AI Collaboration
**Title**: Leveraging Dual Process Theory in Language Agent Framework for Real-time   Simultaneous Human-AI Collaboration | Leveraging Dual Process Theory in Language Agent Framework for Real-time Simultaneous Human-AI Collaboration | 利用语言代理框架中的双重进程理论促进实时同时人类-AI合作 [2502.11882v5](http://arxiv.org/abs/2502.11882v5)

**Authors**: Shao Zhang, Xihuai Wang, Wenhao Zhang, Chaoran Li, Junru Song, Tingyu Li, Lin Qiu, Xuezhi Cao, Xunliang Cai, Wen Yao, Weinan Zhang, Xinbing Wang, Ying Wen

Agents built on large language models (LLMs) have excelled in turn-by-turn human-AI collaboration but struggle with simultaneous tasks requiring real-time interaction. Latency issues and the challenge of inferring variable human strategies hinder their ability to make autonomous decisions without explicit instructions. Through experiments with current independent System 1 and System 2 methods, we validate the necessity of using Dual Process Theory (DPT) in real-time tasks. We propose DPT-Agent, a novel language agent framework that integrates System 1 and System 2 for efficient real-time simultaneous human-AI collaboration. DPT-Agent's System 1 uses a Finite-state Machine (FSM) and code-as-policy for fast, intuitive, and controllable decision-making. DPT-Agent's System 2 integrates Theory of Mind (ToM) and asynchronous reflection to infer human intentions and perform reasoning-based autonomous decisions. We demonstrate the effectiveness of DPT-Agent through further experiments with rule-based agents and human collaborators, showing significant improvements over mainstream LLM-based frameworks. DPT-Agent can effectively help LLMs convert correct slow thinking and reasoning into executable actions, thereby improving performance. To the best of our knowledge, DPT-Agent is the first language agent framework that achieves successful real-time simultaneous human-AI collaboration autonomously. Code of DPT-Agent can be found in https://github.com/sjtu-marl/DPT-Agent.

---

## Article 24
### Title@2025-05-28: Efficient Leave-one-out Approximation in LLM Multi-agent Debate Based on   Introspection
**Title**: Efficient Leave-one-out Approximation in LLM Multi-agent Debate Based on   Introspection | Effiziente Ein-Aus-Annäherung in der LLM-Multiagenten-Debatte auf der Grundlage von Introspektion | 以内审为基础的多机构辩论 [2505.22192v1](http://arxiv.org/abs/2505.22192v1)

**Authors**: Yue Cui, Liuyi Yao, Zitao Li, Yaliang Li, Bolin Ding, Xiaofang Zhou

Multi-agent systems based on large language models (LLMs) advance automatic task completion in various fields, where debate is a common cooperation form for agents to solve complicated problems with reasoning and cross-review to solidify answers. Assessing the individual contributions of agents within these debates is crucial for system refinement and outcome reliability. Traditional leave-one-out (LOO) method offers a clear framework for evaluating each agent's role but face challenges in LLM-based systems due to high computational costs and associated financial implications. This paper presents introspective-leave-one-out (IntrospecLOO), a simple yet effective prompting for approximation of LOO in LLM-powered multi-agent debates. IntrospecLOO introduces an additional querying round after standard debates, prompting agents to update their answers while ignoring responses from a designated agent. This strategy effectively isolates and gauges each participant's influence at a reduced query complexity compared to the original LOO approaches. Validation through experiments on three benchmark datasets confirms the effectiveness of IntrospecLOO.

---

## Article 25
### Title@2025-05-28: Online Fair Division for Personalized $2$-Value Instances
**Title**: Online Fair Division for Personalized $2$-Value Instances | Online Fair Division für Personalisierte $2$-Value Instances | 个人个人价值2美元-价值实例在线网上交易会司 [2505.22174v1](http://arxiv.org/abs/2505.22174v1)

**Authors**: Georgios Amanatidis, Alexandros Lolos, Evangelos Markakis, Victor Turmel

We study an online fair division setting, where goods arrive one at a time and there is a fixed set of $n$ agents, each of whom has an additive valuation function over the goods. Once a good appears, the value each agent has for it is revealed and it must be allocated immediately and irrevocably to one of the agents. It is known that without any assumptions about the values being severely restricted or coming from a distribution, very strong impossibility results hold in this setting. To bypass the latter, we turn our attention to instances where the valuation functions are restricted. In particular, we study personalized $2$-value instances, where there are only two possible values each agent may have for each good, possibly different across agents, and we show how to obtain worst case guarantees with respect to well-known fairness notions, such as maximin share fairness and envy-freeness up to one (or two) good(s). We suggest a deterministic algorithm that maintains a $1/(2n-1)$-MMS allocation at every time step and show that this is the best possible any deterministic algorithm can achieve if one cares about every single time step; nevertheless, eventually the allocation constructed by our algorithm becomes a $1/4$-MMS allocation. To achieve this, the algorithm implicitly maintains a fragile system of priority levels for all agents. Further, we show that, by allowing some limited access to future information, it is possible to have stronger results with less involved approaches. By knowing the values of goods for $n-1$ time steps into the future, we design a matching-based algorithm that achieves an EF$1$ allocation every $n$ time steps, while always maintaining an EF$2$ allocation. Finally, we show that our results allow us to get the first nontrivial guarantees for additive instances in which the ratio of the maximum over the minimum value an agent has for a good is bounded.

---

## Article 26
### Title@2025-05-28: Sentiment Simulation using Generative AI Agents
**Title**: Sentiment Simulation using Generative AI Agents | Sentiment-Simulation mit generativen KI-Agenten | 使用 " 产生AI " 制剂模拟情感 [2505.22125v1](http://arxiv.org/abs/2505.22125v1)

**Authors**: Melrose Tia, Jezreel Sophia Lanuzo, Lei Rigi Baltazar, Marie Joy Lopez-Relente, Diwa Malaya Quiñones, Jason Albia

Traditional sentiment analysis relies on surface-level linguistic patterns and retrospective data, limiting its ability to capture the psychological and contextual drivers of human sentiment. These limitations constrain its effectiveness in applications that require predictive insight, such as policy testing, narrative framing, and behavioral forecasting. We present a robust framework for sentiment simulation using generative AI agents embedded with psychologically rich profiles. Agents are instantiated from a nationally representative survey of 2,485 Filipino respondents, combining sociodemographic information with validated constructs of personality traits, values, beliefs, and socio-political attitudes. The framework includes three stages: (1) agent embodiment via categorical or contextualized encodings, (2) exposure to real-world political and economic scenarios, and (3) generation of sentiment ratings accompanied by explanatory rationales. Using Quadratic Weighted Accuracy (QWA), we evaluated alignment between agent-generated and human responses. Contextualized encoding achieved 92% alignment in replicating original survey responses. In sentiment simulation tasks, agents reached 81%--86% accuracy against ground truth sentiment, with contextualized profile encodings significantly outperforming categorical (p < 0.0001, Cohen's d = 0.70). Simulation results remained consistent across repeated trials (+/-0.2--0.5% SD) and resilient to variation in scenario framing (p = 0.9676, Cohen's d = 0.02). Our findings establish a scalable framework for sentiment modeling through psychographically grounded AI agents. This work signals a paradigm shift in sentiment analysis from retrospective classification to prospective and dynamic simulation grounded in psychology of sentiment formation.

---

## Article 27
### Title@2025-05-28: Benchmarking LLMs' Swarm intelligence
**Title**: Benchmarking LLMs' Swarm intelligence | Benchmarking der Swarm-Intelligenz der LLM | 基准确定LLLMs的Swarm情报 [2505.04364v3](http://arxiv.org/abs/2505.04364v3)

**Authors**: Kai Ruan, Mowen Huang, Ji-Rong Wen, Hao Sun

Large Language Models (LLMs) show potential for complex reasoning, yet their capacity for emergent coordination in Multi-Agent Systems (MAS) when operating under strict swarm-like constraints-limited local perception and communication-remains largely unexplored. Existing benchmarks often do not fully capture the unique challenges of decentralized coordination when agents operate with incomplete spatio-temporal information. To bridge this gap, we introduce SwarmBench, a novel benchmark designed to systematically evaluate the swarm intelligence capabilities of LLMs acting as decentralized agents. SwarmBench features five foundational MAS coordination tasks (Pursuit, Synchronization, Foraging, Flocking, Transport) within a configurable 2D grid environment, forcing agents to rely solely on local sensory input ($k\times k$ view) and local communication. We propose metrics for coordination effectiveness and analyze emergent group dynamics. Zero-shot evaluations of leading LLMs (e.g., deepseek-v3, o4-mini) reveal significant task-dependent performance variations. While some rudimentary coordination is observed, our results indicate that current LLMs significantly struggle with robust long-range planning and adaptive strategy formation under the uncertainty inherent in these decentralized scenarios. Assessing LLMs under such swarm-like constraints is crucial for understanding their utility in future decentralized intelligent systems. We release SwarmBench as an open, extensible toolkit-built on a customizable physical system-providing environments, prompts, evaluation scripts, and comprehensive datasets. This aims to foster reproducible research into LLM-based MAS coordination and the theoretical underpinnings of emergent collective behavior under severe informational decentralization. Our code repository is available at https://github.com/x66ccff/swarmbench.

---

## Article 28
### Title@2025-05-28: AudioGenie: A Training-Free Multi-Agent Framework for Diverse   Multimodality-to-Multiaudio Generation
**Title**: AudioGenie: A Training-Free Multi-Agent Framework for Diverse   Multimodality-to-Multiaudio Generation | AudioGenie: Ein trainingsfreies Multi-Agent-Framework für die vielfältige Multimodalität-zu-Multiaudio-Generierung | AudioGenie:多元化多式联运到多民族一代的无培训多机会多机会框架 [2505.22053v1](http://arxiv.org/abs/2505.22053v1)

**Authors**: Yan Rong, Jinting Wang, Shan Yang, Guangzhi Lei, Li Liu

Multimodality-to-Multiaudio (MM2MA) generation faces significant challenges in synthesizing diverse and contextually aligned audio types (e.g., sound effects, speech, music, and songs) from multimodal inputs (e.g., video, text, images), owing to the scarcity of high-quality paired datasets and the lack of robust multi-task learning frameworks. Recently, multi-agent system shows great potential in tackling the above issues. However, directly applying it to MM2MA task presents three critical challenges: (1) inadequate fine-grained understanding of multimodal inputs (especially for video), (2) the inability of single models to handle diverse audio events, and (3) the absence of self-correction mechanisms for reliable outputs. To this end, we propose AudioGenie, a novel training-free multi-agent system featuring a dual-layer architecture with a generation team and a supervisor team. For the generation team, a fine-grained task decomposition and an adaptive Mixture-of-Experts (MoE) collaborative entity are designed for dynamic model selection, and a trial-and-error iterative refinement module is designed for self-correction. The supervisor team ensures temporal-spatial consistency and verifies outputs through feedback loops. Moreover, we build MA-Bench, the first benchmark for MM2MA tasks, comprising 198 annotated videos with multi-type audios. Experiments demonstrate that our AudioGenie outperforms state-of-the-art (SOTA) methods across 9 metrics in 8 tasks. User study further validate the effectiveness of the proposed method in terms of quality, accuracy, alignment, and aesthetic. The anonymous project website with samples can be found at https://audiogenie.github.io/.

---

## Article 29
### Title@2025-05-28: Reward-Independent Messaging for Decentralized Multi-Agent Reinforcement   Learning
**Title**: Reward-Independent Messaging for Decentralized Multi-Agent Reinforcement   Learning | Reward-independent Messaging für dezentralisiertes Mehr-Agenten-Verstärkungs-Lernen | 权力下放多机构加强学习分权式多机构加强学习的回报独立通信 [2505.21985v1](http://arxiv.org/abs/2505.21985v1)

**Authors**: Naoto Yoshida, Tadahiro Taniguchi

In multi-agent reinforcement learning (MARL), effective communication improves agent performance, particularly under partial observability. We propose MARL-CPC, a framework that enables communication among fully decentralized, independent agents without parameter sharing. MARL-CPC incorporates a message learning model based on collective predictive coding (CPC) from emergent communication research. Unlike conventional methods that treat messages as part of the action space and assume cooperation, MARL-CPC links messages to state inference, supporting communication in non-cooperative, reward-independent settings. We introduce two algorithms -Bandit-CPC and IPPO-CPC- and evaluate them in non-cooperative MARL tasks. Benchmarks show that both outperform standard message-as-action approaches, establishing effective communication even when messages offer no direct benefit to the sender. These results highlight MARL-CPC's potential for enabling coordination in complex, decentralized environments.

---

## Article 30
### Title@2025-05-28: Preference-CFR$\:$ Beyond Nash Equilibrium for Better Game Strategies
**Title**: Preference-CFR$\:$ Beyond Nash Equilibrium for Better Game Strategies | Präferenz-CFR$\:$ Jenseits von Nash Equilibrium für bessere Spielstrategien | 普特-CFR$ =: Nash 后平衡促进更好游戏战略的美元 [2411.01217v2](http://arxiv.org/abs/2411.01217v2)

**Authors**: Qi Ju, Thomas Tellier, Meng Sun, Zhemei Fang, Yunfeng Luo

Artificial intelligence (AI) has surpassed top human players in a variety of games. In imperfect information games, these achievements have primarily been driven by Counterfactual Regret Minimization (CFR) and its variants for computing Nash equilibrium. However, most existing research has focused on maximizing payoff, while largely neglecting the importance of strategic diversity and the need for varied play styles, thereby limiting AI's adaptability to different user preferences.   To address this gap, we propose Preference-CFR (Pref-CFR), a novel method that incorporates two key parameters: preference degree and vulnerability degree. These parameters enable the AI to adjust its strategic distribution within an acceptable performance loss threshold, thereby enhancing its adaptability to a wider range of strategic demands. In our experiments with Texas Hold'em, Pref-CFR successfully trained Aggressive and Loose Passive styles that not only match original CFR-based strategies in performance but also display clearly distinct behavioral patterns. Notably, for certain hand scenarios, Pref-CFR produces strategies that diverge significantly from both conventional expert heuristics and original CFR outputs, potentially offering novel insights for professional players.

---

## Article 31
### Title@2025-05-28: Properties of zero-determinant strategies in multichannel games
**Title**: Properties of zero-determinant strategies in multichannel games | Eigenschaften von Zero-Determinant-Strategien in Multichannel-Spielen | 多频道游戏零决定策略属性 [2505.21952v1](http://arxiv.org/abs/2505.21952v1)

**Authors**: Masahiko Ueda

Controlling payoffs in repeated games is one of the important topics in control theory of multi-agent systems. Recently proposed zero-determinant strategies enable players to unilaterally enforce linear relations between payoffs. Furthermore, based on the mathematics of zero-determinant strategies, regional payoff control, in which payoffs are enforced into some feasible regions, has been discovered in social dilemma situations. More recently, theory of payoff control was extended to multichannel games, where players parallelly interact with each other in multiple channels. However, properties of zero-determinant strategies specific to multichannel games are still not clear. In this paper, we elucidate properties of zero-determinant strategies in multichannel games. First, we relate the existence condition of zero-determinant strategies in multichannel games to that of zero-determinant strategies in each channel. We then show that the existence of zero-determinant strategies in multichannel games requires the existence of zero-determinant strategies in some channels. This result implies that the existence of zero-determinant strategies in multichannel games is tightly restricted by structure of games played in each channel.

---

## Article 32
### Title@2025-05-28: Co-Saving: Resource Aware Multi-Agent Collaboration for Software   Development
**Title**: Co-Saving: Resource Aware Multi-Agent Collaboration for Software   Development | Co-Saving: Ressourcenschonende Multi-Agenten-Kollaboration für Software-Entwicklung | 共同节省:为开发软件进行有意识的资源、多机构协作 [2505.21898v1](http://arxiv.org/abs/2505.21898v1)

**Authors**: Rennai Qiu, Chen Qian, Ran Li, Yufan Dang, Weize Chen, Cheng Yang, Yingli Zhang, Ye Tian, Xuantang Xiong, Lei Han, Zhiyuan Liu, Maosong Sun

Recent advancements in Large Language Models (LLMs) and autonomous agents have demonstrated remarkable capabilities across various domains. However, standalone agents frequently encounter limitations when handling complex tasks that demand extensive interactions and substantial computational resources. Although Multi-Agent Systems (MAS) alleviate some of these limitations through collaborative mechanisms like task decomposition, iterative communication, and role specialization, they typically remain resource-unaware, incurring significant inefficiencies due to high token consumption and excessive execution time. To address these limitations, we propose a resource-aware multi-agent system -- Co-Saving (meaning that multiple agents collaboratively engage in resource-saving activities), which leverages experiential knowledge to enhance operational efficiency and solution quality. Our key innovation is the introduction of "shortcuts" -- instructional transitions learned from historically successful trajectories -- which allows to bypass redundant reasoning agents and expedite the collective problem-solving process. Experiments for software development tasks demonstrate significant advantages over existing methods. Specifically, compared to the state-of-the-art MAS ChatDev, our method achieves an average reduction of 50.85% in token usage, and improves the overall code quality by 10.06%.

---

## Article 33
### Title@2025-05-28: Incorporating LLMs for Large-Scale Urban Complex Mobility Simulation
**Title**: Incorporating LLMs for Large-Scale Urban Complex Mobility Simulation | Einschließlich LLMs für großräumige Urban Complex Mobility Simulation | 大型城市综合流动模拟项目LLMs [2505.21880v1](http://arxiv.org/abs/2505.21880v1)

**Authors**: Yu-Lun Song, Chung-En Tsern, Che-Cheng Wu, Yu-Ming Chang, Syuan-Bo Huang, Wei-Chu Chen, Michael Chia-Liang Lin, Yu-Ta Lin

This study presents an innovative approach to urban mobility simulation by integrating a Large Language Model (LLM) with Agent-Based Modeling (ABM). Unlike traditional rule-based ABM, the proposed framework leverages LLM to enhance agent diversity and realism by generating synthetic population profiles, allocating routine and occasional locations, and simulating personalized routes. Using real-world data, the simulation models individual behaviors and large-scale mobility patterns in Taipei City. Key insights, such as route heat maps and mode-specific indicators, provide urban planners with actionable information for policy-making. Future work focuses on establishing robust validation frameworks to ensure accuracy and reliability in urban planning applications.

---

## Article 34
### Title@2025-05-27: Optimal Output Feedback Learning Control for Discrete-Time Linear   Quadratic Regulation
**Title**: Optimal Output Feedback Learning Control for Discrete-Time Linear   Quadratic Regulation | Optimale Output-Feedback-Lernsteuerung für diskrete Zeit lineare quadratische Regulierung | 用于分立时线性二次曲线调控的最佳输出反馈学习控制 [2503.06226v3](http://arxiv.org/abs/2503.06226v3)

**Authors**: Kedi Xie, Martin Guay, Shimin Wang, Fang Deng, Maobin Lu

This paper studies the linear quadratic regulation (LQR) problem of unknown discrete-time systems via dynamic output feedback learning control. In contrast to the state feedback, the optimality of the dynamic output feedback control for solving the LQR problem requires an implicit condition on the convergence of the state observer. Moreover, due to unknown system matrices and the existence of observer error, it is difficult to analyze the convergence and stability of most existing output feedback learning-based control methods. To tackle these issues, we propose a generalized dynamic output feedback learning control approach with guaranteed convergence, stability, and optimality performance for solving the LQR problem of unknown discrete-time linear systems. In particular, a dynamic output feedback controller is designed to be equivalent to a state feedback controller. This equivalence relationship is an inherent property without requiring convergence of the estimated state by the state observer, which plays a key role in establishing the off-policy learning control approaches. By value iteration and policy iteration schemes, the adaptive dynamic programming based learning control approaches are developed to estimate the optimal feedback control gain. In addition, a model-free stability criterion is provided by finding a nonsingular parameterization matrix, which contributes to establishing a switched iteration scheme. Furthermore, the convergence, stability, and optimality analyses of the proposed output feedback learning control approaches are given. Finally, the theoretical results are validated by two numerical examples.

---

## Article 35
### Title@2025-05-27: Empowering Scientific Workflows with Federated Agents
**Title**: Empowering Scientific Workflows with Federated Agents | Stärkung wissenschaftlicher Workflows mit Federated Agents | 赋予联邦药剂部门科学工作流程权能 [2505.05428v2](http://arxiv.org/abs/2505.05428v2)

**Authors**: J. Gregory Pauloski, Yadu Babuji, Ryan Chard, Mansi Sakarvadia, Kyle Chard, Ian Foster

Agentic systems, in which diverse agents cooperate to tackle challenging problems, are exploding in popularity in the AI community. However, the agentic frameworks used to build these systems have not previously enabled use with research cyberinfrastructure. Here we introduce Academy, a modular and extensible middleware designed to deploy autonomous agents across the federated research ecosystem, including HPC systems, experimental facilities, and data repositories. To meet the demands of scientific computing, Academy supports asynchronous execution, heterogeneous resources, high-throughput data flows, and dynamic resource availability. It provides abstractions for expressing stateful agents, managing inter-agent coordination, and integrating computation with experimental control. We present microbenchmark results that demonstrate high performance and scalability in HPC environments. To demonstrate the breadth of applications that can be supported by agentic workflow designs, we also present case studies in materials discovery, decentralized learning, and information extraction in which agents are deployed across diverse HPC systems.

---

## Article 36
### Title@2025-05-27: AI-Supported Platform for System Monitoring and Decision-Making in   Nuclear Waste Management with Large Language Models
**Title**: AI-Supported Platform for System Monitoring and Decision-Making in   Nuclear Waste Management with Large Language Models | AI-unterstützte Plattform für Systemüberwachung und Entscheidungsfindung in der Entsorgung nuklearer Abfälle mit großen Sprachmodellen | AI-支持的具有大语言模式的核废物管理系统监测和决策平台 [2505.21741v1](http://arxiv.org/abs/2505.21741v1)

**Authors**: Dongjune Chang, Sola Kim, Young Soo Park

Nuclear waste management requires rigorous regulatory compliance assessment, demanding advanced decision-support systems capable of addressing complex legal, environmental, and safety considerations. This paper presents a multi-agent Retrieval-Augmented Generation (RAG) system that integrates large language models (LLMs) with document retrieval mechanisms to enhance decision accuracy through structured agent collaboration. Through a structured 10-round discussion model, agents collaborate to assess regulatory compliance and safety requirements while maintaining document-grounded responses. Implemented on consumer-grade hardware, the system leverages Llama 3.2 and mxbai-embed-large-v1 embeddings for efficient retrieval and semantic representation. A case study of a proposed temporary nuclear waste storage site near Winslow, Arizona, demonstrates the framework's effectiveness. Results show the Regulatory Agent achieves consistently higher relevance scores in maintaining alignment with legal frameworks, while the Safety Agent effectively manages complex risk assessments requiring multifaceted analysis. The system demonstrates progressive improvement in agreement rates between agents across discussion rounds while semantic drift decreases, indicating enhanced decision-making consistency and response coherence. The system ensures regulatory decisions remain factually grounded, dynamically adapting to evolving regulatory frameworks through real-time document retrieval. By balancing automated assessment with human oversight, this framework offers a scalable and transparent approach to regulatory governance. These findings underscore the potential of AI-driven, multi-agent systems in advancing evidence-based, accountable, and adaptive decision-making for high-stakes environmental management scenarios.

---

## Article 37
### Title@2025-05-27: Communication- and Computation-Efficient Distributed Submodular   Optimization in Robot Mesh Networks
**Title**: Communication- and Computation-Efficient Distributed Submodular   Optimization in Robot Mesh Networks | Kommunikation- und Computation-Effizient verteilte Submodulare Optimierung in Robot Mesh-Netzwerken | 机器人网网中的通信和计算-有效分布式子模块优化 [2407.10382v3](http://arxiv.org/abs/2407.10382v3)

**Authors**: Zirui Xu, Sandilya Sai Garimella, Vasileios Tzoumas

We provide a communication- and computation-efficient method for distributed submodular optimization in robot mesh networks. Submodularity is a property of diminishing returns that arises in active information gathering such as mapping, surveillance, and target tracking. Our method, Resource-Aware distributed Greedy (RAG), introduces a new distributed optimization paradigm that enables scalable and near-optimal action coordination. To this end, RAG requires each robot to make decisions based only on information received from and about their neighbors. In contrast, the current paradigms allow the relay of information about all robots across the network. As a result, RAG's decision-time scales linearly with the network size, while state-of-the-art near-optimal submodular optimization algorithms scale cubically. We also characterize how the designed mesh-network topology affects RAG's approximation performance. Our analysis implies that sparser networks favor scalability without proportionally compromising approximation performance: while RAG's decision time scales linearly with network size, the gain in approximation performance scales sublinearly. We demonstrate RAG's performance in simulated scenarios of area detection with up to 45 robots, simulating realistic robot-to-robot (r2r) communication speeds such as the 0.25 Mbps speed of the Digi XBee 3 Zigbee 3.0. In the simulations, RAG enables real-time planning, up to three orders of magnitude faster than competitive near-optimal algorithms, while also achieving superior mean coverage performance. To enable the simulations, we extend the high-fidelity and photo-realistic simulator AirSim by integrating a scalable collaborative autonomy pipeline to tens of robots and simulating r2r communication delays. Our code is available at https://github.com/UM-iRaL/Resource-Aware-Coordination-AirSim.

---

## Article 38
### Title@2025-05-27: Paper2Poster: Towards Multimodal Poster Automation from Scientific   Papers
**Title**: Paper2Poster: Towards Multimodal Poster Automation from Scientific   Papers | Paper2Poster: Auf dem Weg zur multimodalen Plakatautomatisierung aus wissenschaftlichen Papieren | Paper2Poster:从科学论文中走向多式海报自动化 [2505.21497v1](http://arxiv.org/abs/2505.21497v1)

**Authors**: Wei Pang, Kevin Qinghong Lin, Xiangru Jian, Xi He, Philip Torr

Academic poster generation is a crucial yet challenging task in scientific communication, requiring the compression of long-context interleaved documents into a single, visually coherent page. To address this challenge, we introduce the first benchmark and metric suite for poster generation, which pairs recent conference papers with author-designed posters and evaluates outputs on (i)Visual Quality-semantic alignment with human posters, (ii)Textual Coherence-language fluency, (iii)Holistic Assessment-six fine-grained aesthetic and informational criteria scored by a VLM-as-judge, and notably (iv)PaperQuiz-the poster's ability to convey core paper content as measured by VLMs answering generated quizzes. Building on this benchmark, we propose PosterAgent, a top-down, visual-in-the-loop multi-agent pipeline: the (a)Parser distills the paper into a structured asset library; the (b)Planner aligns text-visual pairs into a binary-tree layout that preserves reading order and spatial balance; and the (c)Painter-Commenter loop refines each panel by executing rendering code and using VLM feedback to eliminate overflow and ensure alignment. In our comprehensive evaluation, we find that GPT-4o outputs-though visually appealing at first glance-often exhibit noisy text and poor PaperQuiz scores, and we find that reader engagement is the primary aesthetic bottleneck, as human-designed posters rely largely on visual semantics to convey meaning. Our fully open-source variants (e.g. based on the Qwen-2.5 series) outperform existing 4o-driven multi-agent systems across nearly all metrics, while using 87% fewer tokens. It transforms a 22-page paper into a finalized yet editable .pptx poster - all for just $0.005. These findings chart clear directions for the next generation of fully automated poster-generation models. The code and datasets are available at https://github.com/Paper2Poster/Paper2Poster.

---

## Article 39
### Title@2025-05-27: Agentic Medical Knowledge Graphs Enhance Medical Question Answering:   Bridging the Gap Between LLMs and Evolving Medical Knowledge
**Title**: Agentic Medical Knowledge Graphs Enhance Medical Question Answering:   Bridging the Gap Between LLMs and Evolving Medical Knowledge | Agentisches medizinisches Wissen Grafiken verbessern medizinische Frageantworten: Die Lücke zwischen LLMs und sich entwickelndem medizinischem Wissen überbrücken | 药用知识图加强医疗问题的回答:缩小LLMM与不断发展的医学知识之间的差距 [2502.13010v2](http://arxiv.org/abs/2502.13010v2)

**Authors**: Mohammad Reza Rezaei, Reza Saadati Fard, Rahul G. Krishnan, Milad Lankarany

Large Language Models (LLMs) have significantly advanced medical question-answering by leveraging extensive clinical data and medical literature. However, the rapid evolution of medical knowledge and the labor-intensive process of manually updating domain-specific resources pose challenges to the reliability of these systems. To address this, we introduce Agentic Medical Graph-RAG (AMG-RAG), a comprehensive framework that automates the construction and continuous updating of medical knowledge graphs, integrates reasoning, and retrieves current external evidence, such as PubMed and WikiSearch. By dynamically linking new findings and complex medical concepts, AMG-RAG not only improves accuracy but also enhances interpretability in medical queries.   Evaluations on the MEDQA and MEDMCQA benchmarks demonstrate the effectiveness of AMG-RAG, achieving an F1 score of 74.1 percent on MEDQA and an accuracy of 66.34 percent on MEDMCQA, outperforming both comparable models and those 10 to 100 times larger. Notably, these improvements are achieved without increasing computational overhead, highlighting the critical role of automated knowledge graph generation and external evidence retrieval in delivering up-to-date, trustworthy medical insights.

---

## Article 40
### Title@2025-05-27: Learning Individual Behavior in Agent-Based Models with Graph Diffusion   Networks
**Title**: Learning Individual Behavior in Agent-Based Models with Graph Diffusion   Networks | Individuelles Verhalten in agentenbasierten Modellen mit Graph Diffusionsnetzwerken lernen | 具有图表传播网络的基于代理模型的学习个人行为 [2505.21426v1](http://arxiv.org/abs/2505.21426v1)

**Authors**: Francesco Cozzi, Marco Pangallo, Alan Perotti, André Panisson, Corrado Monti

Agent-Based Models (ABMs) are powerful tools for studying emergent properties in complex systems. In ABMs, agent behaviors are governed by local interactions and stochastic rules. However, these rules are, in general, non-differentiable, limiting the use of gradient-based methods for optimization, and thus integration with real-world data. We propose a novel framework to learn a differentiable surrogate of any ABM by observing its generated data. Our method combines diffusion models to capture behavioral stochasticity and graph neural networks to model agent interactions. Distinct from prior surrogate approaches, our method introduces a fundamental shift: rather than approximating system-level outputs, it models individual agent behavior directly, preserving the decentralized, bottom-up dynamics that define ABMs. We validate our approach on two ABMs (Schelling's segregation model and a Predator-Prey ecosystem) showing that it replicates individual-level patterns and accurately forecasts emergent dynamics beyond training. Our results demonstrate the potential of combining diffusion models and graph learning for data-driven ABM simulation.

---

## Article 41
### Title@2025-05-27: Autonomous Multi-Modal LLM Agents for Treatment Planning in Focused   Ultrasound Ablation Surgery
**Title**: Autonomous Multi-Modal LLM Agents for Treatment Planning in Focused   Ultrasound Ablation Surgery | Autonome Multi-Modal LLM-Agenten für die Behandlungsplanung in fokussierter Ultraschallablationschirurgie | 重点超声速超声振动外科手术治疗规划代理 [2505.21418v1](http://arxiv.org/abs/2505.21418v1)

**Authors**: Lina Zhao, Jiaxing Bai, Zihao Bian, Qingyue Chen, Yafang Li, Guangbo Li, Min He, Huaiyuan Yao, Zongjiu Zhang

Focused Ultrasound Ablation Surgery (FUAS) has emerged as a promising non-invasive therapeutic modality, valued for its safety and precision. Nevertheless, its clinical implementation entails intricate tasks such as multimodal image interpretation, personalized dose planning, and real-time intraoperative decision-making processes that demand intelligent assistance to improve efficiency and reliability. We introduce FUAS-Agents, an autonomous agent system that leverages the multimodal understanding and tool-using capabilities of large language models (LLMs). By integrating patient profiles and MRI data, FUAS-Agents orchestrates a suite of specialized medical AI tools, including segmentation, treatment dose prediction, and clinical guideline retrieval, to generate personalized treatment plans comprising MRI image, dose parameters, and therapeutic strategies. We evaluate the system in a uterine fibroid treatment scenario. Human assessment by four senior FUAS experts indicates that 82.5%, 82.5%, 87.5%, and 97.5% of the generated plans were rated 4 or above (on a 5-point scale) in terms of completeness, accuracy, fluency, and clinical compliance, respectively. These results demonstrate the potential of LLM-driven agents in enhancing decision-making across complex clinical workflows, and exemplify a translational paradigm that combines general-purpose models with specialized expert systems to solve practical challenges in vertical healthcare domains.

---

## Article 42
### Title@2025-05-27: Sequential Resource Trading Using Comparison-Based Gradient Estimation
**Title**: Sequential Resource Trading Using Comparison-Based Gradient Estimation | Sequentieller Ressourcenhandel mit Vergleichsbasis-Gradientenschätzung | 使用基于比较的逐步梯度估计法进行按顺序进行的资源贸易 [2408.11186v3](http://arxiv.org/abs/2408.11186v3)

**Authors**: Surya Murthy, Mustafa O. Karabag, Ufuk Topcu

Autonomous agents interact with other autonomous agents and humans of unknown preferences to share resources in their environment. We explore sequential trading for resource allocation in a setting where two greedily rational agents sequentially trade resources from a finite set of categories. Each agent has a utility function that depends on the amount of resources it possesses in each category. The offering agent makes trade offers to improve its utility without knowing the responding agent's utility function, and the responding agent only accepts offers that improve its utility. To facilitate cooperation between an autonomous agent and another autonomous agent or a human, we present an algorithm for the offering agent to estimate the responding agent's gradient (preferences) and make offers based on previous acceptance or rejection responses. The algorithm's goal is to reach a Pareto-optimal resource allocation state while ensuring that the utilities of both agents improve after every accepted trade. The algorithm estimates the responding agent's gradient by leveraging the rejected offers and the greedy rationality assumption, to prune the space of potential gradients. We show that, after the algorithm makes a finite number of rejected offers, the algorithm either finds a mutually beneficial trade or certifies that the current state is epsilon-weakly Pareto optimal. We compare the proposed algorithm against various baselines in continuous and discrete trading scenarios and show that it improves the societal benefit with fewer offers. Additionally, we validate these findings in a user study with human participants, where the algorithm achieves high performance in scenarios with high resource conflict due to aligned agent goals.

---

## Article 43
### Title@2025-05-27: PeerGuard: Defending Multi-Agent Systems Against Backdoor Attacks   Through Mutual Reasoning
**Title**: PeerGuard: Defending Multi-Agent Systems Against Backdoor Attacks   Through Mutual Reasoning | PeerGuard: Verteidigen von Multi-Agenten-Systemen gegen Hintertürangriffe durch gegenseitige Vernunft | 同伴保护:捍卫多机构系统,防止通过相互理由进行后门攻击 [2505.11642v2](http://arxiv.org/abs/2505.11642v2)

**Authors**: Falong Fan, Xi Li

Multi-agent systems leverage advanced AI models as autonomous agents that interact, cooperate, or compete to complete complex tasks across applications such as robotics and traffic management. Despite their growing importance, safety in multi-agent systems remains largely underexplored, with most research focusing on single AI models rather than interacting agents. This work investigates backdoor vulnerabilities in multi-agent systems and proposes a defense mechanism based on agent interactions. By leveraging reasoning abilities, each agent evaluates responses from others to detect illogical reasoning processes, which indicate poisoned agents. Experiments on LLM-based multi-agent systems, including ChatGPT series and Llama 3, demonstrate the effectiveness of the proposed method, achieving high accuracy in identifying poisoned agents while minimizing false positives on clean agents. We believe this work provides insights into multi-agent system safety and contributes to the development of robust, trustworthy AI interactions.

---

## Article 44
### Title@2025-05-27: Large Language Models Miss the Multi-Agent Mark
**Title**: Large Language Models Miss the Multi-Agent Mark | Große Sprachmodelle vermissen das Multi-Agent Mark | 大语言模型 [2505.21298v1](http://arxiv.org/abs/2505.21298v1)

**Authors**: Emanuele La Malfa, Gabriele La Malfa, Samuele Marro, Jie M. Zhang, Elizabeth Black, Micheal Luck, Philip Torr, Michael Wooldridge

Recent interest in Multi-Agent Systems of Large Language Models (MAS LLMs) has led to an increase in frameworks leveraging multiple LLMs to tackle complex tasks. However, much of this literature appropriates the terminology of MAS without engaging with its foundational principles. In this position paper, we highlight critical discrepancies between MAS theory and current MAS LLMs implementations, focusing on four key areas: the social aspect of agency, environment design, coordination and communication protocols, and measuring emergent behaviours. Our position is that many MAS LLMs lack multi-agent characteristics such as autonomy, social interaction, and structured environments, and often rely on oversimplified, LLM-centric architectures. The field may slow down and lose traction by revisiting problems the MAS literature has already addressed. Therefore, we systematically analyse this issue and outline associated research opportunities; we advocate for better integrating established MAS concepts and more precise terminology to avoid mischaracterisation and missed opportunities.

---

## Article 45
### Title@2025-05-27: Breaking the Performance Ceiling in Complex Reinforcement Learning   requires Inference Strategies
**Title**: Breaking the Performance Ceiling in Complex Reinforcement Learning   requires Inference Strategies | Breaking the Performance Ceiling in komplexen Verstärkungs-Lernen erfordert Inferenz-Strategien | 综合加强学习中业绩上限的打破需要推断战略 [2505.21236v1](http://arxiv.org/abs/2505.21236v1)

**Authors**: Felix Chalumeau, Daniel Rajaonarivonivelomanantsoa, Ruan de Kock, Claude Formanek, Sasha Abramowitz, Oumayma Mahjoub, Wiem Khlifi, Simon Du Toit, Louay Ben Nessir, Refiloe Shabe, Arnol Fokam, Siddarth Singh, Ulrich Mbou Sob, Arnu Pretorius

Reinforcement learning (RL) systems have countless applications, from energy-grid management to protein design. However, such real-world scenarios are often extremely difficult, combinatorial in nature, and require complex coordination between multiple agents. This level of complexity can cause even state-of-the-art RL systems, trained until convergence, to hit a performance ceiling which they are unable to break out of with zero-shot inference. Meanwhile, many digital or simulation-based applications allow for an inference phase that utilises a specific time and compute budget to explore multiple attempts before outputting a final solution. In this work, we show that such an inference phase employed at execution time, and the choice of a corresponding inference strategy, are key to breaking the performance ceiling observed in complex multi-agent RL problems. Our main result is striking: we can obtain up to a 126% and, on average, a 45% improvement over the previous state-of-the-art across 17 tasks, using only a couple seconds of extra wall-clock time during execution. We also demonstrate promising compute scaling properties, supported by over 60k experiments, making it the largest study on inference strategies for complex RL to date. Our experimental data and code are available at https://sites.google.com/view/inf-marl.

---

## Article 46
### Title@2025-05-27: Voting or Consensus? Decision-Making in Multi-Agent Debate
**Title**: Voting or Consensus? Decision-Making in Multi-Agent Debate | Abstimmung oder Konsens? Entscheidungsfindung in Multi-Agent-Debatte | 表决还是协商一致?多机构辩论中的决策 [2502.19130v2](http://arxiv.org/abs/2502.19130v2)

**Authors**: Lars Benedikt Kaesberg, Jonas Becker, Jan Philip Wahle, Terry Ruas, Bela Gipp

Much of the success of multi-agent debates depends on carefully choosing the right parameters. The decision-making protocol stands out as it can highly impact final model answers, depending on how decisions are reached. Systematic comparison of decision protocols is difficult because many studies alter multiple discussion parameters beyond the protocol. So far, it has been largely unknown how decision-making influences different tasks. This work systematically evaluates the impact of seven decision protocols (e.g., majority voting, unanimity consensus). We change only one variable at a time - the decision protocol - to analyze how different methods affect the collaboration between agents and measure differences in knowledge and reasoning tasks. Our results show that voting protocols improve performance by 13.2% in reasoning tasks and consensus protocols by 2.8% in knowledge tasks compared to other decision protocols. Increasing the number of agents improves performance, while more discussion rounds before voting reduce it. To improve decision-making by increasing answer diversity, we propose two new methods, All-Agents Drafting (AAD) and Collective Improvement (CI). Our methods improve task performance by up to 3.3% with AAD and up to 7.4% with CI. This work demonstrates the importance of decision-making in multi-agent debates beyond scaling.

---

## Article 47
### Title@2025-05-27: GGBond: Growing Graph-Based AI-Agent Society for Socially-Aware   Recommender Simulation
**Title**: GGBond: Growing Graph-Based AI-Agent Society for Socially-Aware   Recommender Simulation | GGBond: Wachsende Graphen-basierte KI-Agenten-Gesellschaft für sozial-aware-Empfänger-Simulation | GGBond: 不断增长的基于图表的AI-Agent Society 社会软件建议模拟模拟软件 [2505.21154v1](http://arxiv.org/abs/2505.21154v1)

**Authors**: Hailin Zhong, Hanlin Wang, Yujun Ye, Meiyi Zhang, Shengxin Zhu

Current personalized recommender systems predominantly rely on static offline data for algorithm design and evaluation, significantly limiting their ability to capture long-term user preference evolution and social influence dynamics in real-world scenarios. To address this fundamental challenge, we propose a high-fidelity social simulation platform integrating human-like cognitive agents and dynamic social interactions to realistically simulate user behavior evolution under recommendation interventions. Specifically, the system comprises a population of Sim-User Agents, each equipped with a five-layer cognitive architecture that encapsulates key psychological mechanisms, including episodic memory, affective state transitions, adaptive preference learning, and dynamic trust-risk assessments. In particular, we innovatively introduce the Intimacy--Curiosity--Reciprocity--Risk (ICR2) motivational engine grounded in psychological and sociological theories, enabling more realistic user decision-making processes. Furthermore, we construct a multilayer heterogeneous social graph (GGBond Graph) supporting dynamic relational evolution, effectively modeling users' evolving social ties and trust dynamics based on interest similarity, personality alignment, and structural homophily. During system operation, agents autonomously respond to recommendations generated by typical recommender algorithms (e.g., Matrix Factorization, MultVAE, LightGCN), deciding whether to consume, rate, and share content while dynamically updating their internal states and social connections, thereby forming a stable, multi-round feedback loop. This innovative design transcends the limitations of traditional static datasets, providing a controlled, observable environment for evaluating long-term recommender effects.

---

## Article 48
### Title@2025-05-27: Stopping Criteria for Value Iteration on Concurrent Stochastic   Reachability and Safety Games
**Title**: Stopping Criteria for Value Iteration on Concurrent Stochastic   Reachability and Safety Games | Stoppen von Kriterien für die Wert-Iteration bei gleichzeitigen stochastischen Erreichbarkeits- und Sicherheitsspielen | 停止同时举行存储可达性和安全运动会的价值迭代标准 [2505.21087v1](http://arxiv.org/abs/2505.21087v1)

**Authors**: Marta Grobelna, Jan Křetínský, Maximilian Weininger

We consider two-player zero-sum concurrent stochastic games (CSGs) played on graphs with reachability and safety objectives. These include degenerate classes such as Markov decision processes or turn-based stochastic games, which can be solved by linear or quadratic programming; however, in practice, value iteration (VI) outperforms the other approaches and is the most implemented method. Similarly, for CSGs, this practical performance makes VI an attractive alternative to the standard theoretical solution via the existential theory of reals.   VI starts with an under-approximation of the sought values for each state and iteratively updates them, traditionally terminating once two consecutive approximations are $\epsilon$-close. However, this stopping criterion lacks guarantees on the precision of the approximation, which is the goal of this work. We provide bounded (a.k.a. interval) VI for CSGs: it complements standard VI with a converging sequence of over-approximations and terminates once the over- and under-approximations are $\epsilon$-close.

---

## Article 49
### Title@2025-05-27: Herd Behavior: Investigating Peer Influence in LLM-based Multi-Agent   Systems
**Title**: Herd Behavior: Investigating Peer Influence in LLM-based Multi-Agent   Systems | Herdverhalten: Untersuchung des Peer-Einflusses in LLM-basierte Multi-Agent-Systeme | 牧民行为:调查基于LLM的多机构机构系统中的同侪影响 [2505.21588v1](http://arxiv.org/abs/2505.21588v1)

**Authors**: Young-Min Cho, Sharath Chandra Guntuku, Lyle Ungar

Recent advancements in Large Language Models (LLMs) have enabled the emergence of multi-agent systems where LLMs interact, collaborate, and make decisions in shared environments. While individual model behavior has been extensively studied, the dynamics of peer influence in such systems remain underexplored. In this paper, we investigate herd behavior, the tendency of agents to align their outputs with those of their peers, within LLM-based multi-agent interactions. We present a series of controlled experiments that reveal how herd behaviors are shaped by multiple factors. First, we show that the gap between self-confidence and perceived confidence in peers significantly impacts an agent's likelihood to conform. Second, we find that the format in which peer information is presented plays a critical role in modulating the strength of herd behavior. Finally, we demonstrate that the degree of herd behavior can be systematically controlled, and that appropriately calibrated herd tendencies can enhance collaborative outcomes. These findings offer new insights into the social dynamics of LLM-based systems and open pathways for designing more effective and adaptive multi-agent collaboration frameworks.

---

## Article 50
### Title@2025-05-27: Improving flocking behaviors in street networks with vision
**Title**: Improving flocking behaviors in street networks with vision | Verbesserung des Beflockungsverhaltens in Straßennetzen mit Vision | 改善街头网络中有远见的群众行为 [2505.21585v1](http://arxiv.org/abs/2505.21585v1)

**Authors**: Guillaume Moinard, Matthieu Latapy

We improve a flocking model on street networks introduced in a previous paper. We expand the field of vision of walkers, making the model more realistic. Under such conditions, we obtain groups of walkers whose gathering times and robustness to break ups are better than previous results. We explain such improvements because the alignment rule with vision guaranties walkers do not split into divergent directions at intersections anymore, and because the attraction rule with vision gathers distant groups. This paves the way to a better understanding of events where walkers have collective decentralized goals, like protests.

---

## Article 51
### Title@2025-05-27: Revisiting Multi-Agent World Modeling from a Diffusion-Inspired   Perspective
**Title**: Revisiting Multi-Agent World Modeling from a Diffusion-Inspired   Perspective | Multi-Agenten-Weltmodellierung aus einer diffusionsinspirierten Perspektive Revue passieren | 从传播启发的视角重新审视多股权世界建模 [2505.20922v1](http://arxiv.org/abs/2505.20922v1)

**Authors**: Yang Zhang, Xinran Li, Jianing Ye, Delin Qu, Shuang Qiu, Chongjie Zhang, Xiu Li, Chenjia Bai

World models have recently attracted growing interest in Multi-Agent Reinforcement Learning (MARL) due to their ability to improve sample efficiency for policy learning. However, accurately modeling environments in MARL is challenging due to the exponentially large joint action space and highly uncertain dynamics inherent in multi-agent systems. To address this, we reduce modeling complexity by shifting from jointly modeling the entire state-action transition dynamics to focusing on the state space alone at each timestep through sequential agent modeling. Specifically, our approach enables the model to progressively resolve uncertainty while capturing the structured dependencies among agents, providing a more accurate representation of how agents influence the state. Interestingly, this sequential revelation of agents' actions in a multi-agent system aligns with the reverse process in diffusion models--a class of powerful generative models known for their expressiveness and training stability compared to autoregressive or latent variable models. Leveraging this insight, we develop a flexible and robust world model for MARL using diffusion models. Our method, Diffusion-Inspired Multi-Agent world model (DIMA), achieves state-of-the-art performance across multiple multi-agent control benchmarks, significantly outperforming prior world models in terms of final return and sample efficiency, including MAMuJoCo and Bi-DexHands. DIMA establishes a new paradigm for constructing multi-agent world models, advancing the frontier of MARL research.

---

## Article 52
### Title@2025-05-27: Generalized Coordination of Partially Cooperative Urban Traffic
**Title**: Generalized Coordination of Partially Cooperative Urban Traffic | Generalisierte Koordinierung des teilweise kooperativen Stadtverkehrs | 部分合作城市交通协调 [2505.20879v1](http://arxiv.org/abs/2505.20879v1)

**Authors**: Max Bastian Mertens, Michael Buchholz

Vehicle-to-anything connectivity, especially for autonomous vehicles, promises to increase passenger comfort and safety of road traffic, for example, by sharing perception and driving intention. Cooperative maneuver planning uses connectivity to enhance traffic efficiency, which has, so far, been mainly considered for automated intersection management. In this article, we present a novel cooperative maneuver planning approach that is generalized to various situations found in urban traffic. Our framework handles challenging mixed traffic, that is, traffic comprising both cooperative connected vehicles and other vehicles at any distribution. Our solution is based on an optimization approach accompanied by an efficient heuristic method for high-load scenarios. We extensively evaluate the proposed planer in a distinctly realistic simulation framework and show significant efficiency gains already at a cooperation rate of 40%. Traffic throughput increases, while the average waiting time and the number of stopped vehicles are reduced, without impacting traffic safety.

---

## Article 53
### Title@2025-05-27: MedSentry: Understanding and Mitigating Safety Risks in Medical LLM   Multi-Agent Systems
**Title**: MedSentry: Understanding and Mitigating Safety Risks in Medical LLM   Multi-Agent Systems | MedSentry: Sicherheitsrisiken in medizinischen LLM-Multiagentensystemen verstehen und mindern | MedSentry:了解和减轻医疗LLM多机构系统中的安全风险 [2505.20824v1](http://arxiv.org/abs/2505.20824v1)

**Authors**: Kai Chen, Taihang Zhen, Hewei Wang, Kailai Liu, Xinfeng Li, Jing Huo, Tianpei Yang, Jinfeng Xu, Wei Dong, Yang Gao

As large language models (LLMs) are increasingly deployed in healthcare, ensuring their safety, particularly within collaborative multi-agent configurations, is paramount. In this paper we introduce MedSentry, a benchmark comprising 5 000 adversarial medical prompts spanning 25 threat categories with 100 subthemes. Coupled with this dataset, we develop an end-to-end attack-defense evaluation pipeline to systematically analyze how four representative multi-agent topologies (Layers, SharedPool, Centralized, and Decentralized) withstand attacks from 'dark-personality' agents. Our findings reveal critical differences in how these architectures handle information contamination and maintain robust decision-making, exposing their underlying vulnerability mechanisms. For instance, SharedPool's open information sharing makes it highly susceptible, whereas Decentralized architectures exhibit greater resilience thanks to inherent redundancy and isolation. To mitigate these risks, we propose a personality-scale detection and correction mechanism that identifies and rehabilitates malicious agents, restoring system safety to near-baseline levels. MedSentry thus furnishes both a rigorous evaluation framework and practical defense strategies that guide the design of safer LLM-based multi-agent systems in medical domains.

---

## Article 54
### Title@2025-05-27: Many Heads Are Better Than One: Improved Scientific Idea Generation by A   LLM-Based Multi-Agent System
**Title**: Many Heads Are Better Than One: Improved Scientific Idea Generation by A   LLM-Based Multi-Agent System | Viele Köpfe sind besser als eins: Verbesserte wissenschaftliche Idee-Generation durch ein LLM-basiertes Multi-Agent-System | 许多领导人比一个领导人好得多:由以LLM为基础的多种机构系统改进科学思想的一代 [2410.09403v4](http://arxiv.org/abs/2410.09403v4)

**Authors**: Haoyang Su, Renqi Chen, Shixiang Tang, Zhenfei Yin, Xinzhe Zheng, Jinzhe Li, Biqing Qi, Qi Wu, Hui Li, Wanli Ouyang, Philip Torr, Bowen Zhou, Nanqing Dong

The rapid advancement of scientific progress requires innovative tools that can accelerate knowledge discovery. Although recent AI methods, particularly large language models (LLMs), have shown promise in tasks such as hypothesis generation and experimental design, they fall short of replicating the collaborative nature of real-world scientific practices, where diverse experts work together in teams to tackle complex problems. To address the limitations, we propose an LLM-based multi-agent system, i.e., Virtual Scientists (VirSci), designed to mimic the teamwork inherent in scientific research. VirSci organizes a team of agents to collaboratively generate, evaluate, and refine research ideas. Through comprehensive experiments, we demonstrate that this multi-agent approach outperforms the state-of-the-art method in producing novel scientific ideas. We further investigate the collaboration mechanisms that contribute to its tendency to produce ideas with higher novelty, offering valuable insights to guide future research and illuminating pathways toward building a robust system for autonomous scientific discovery. The code is available at https://github.com/open-sciencelab/Virtual-Scientists.

---

## Article 55
### Title@2025-05-27: ReMA: Learning to Meta-think for LLMs with Multi-Agent Reinforcement   Learning
**Title**: ReMA: Learning to Meta-think for LLMs with Multi-Agent Reinforcement   Learning | ReMA: Meta-Denken lernen für LLMs mit Multi-Agenten-Verstärkungs-Lernen | ReMA:学习多机构强化学习的LLMLM的元思维 [2503.09501v3](http://arxiv.org/abs/2503.09501v3)

**Authors**: Ziyu Wan, Yunxiang Li, Xiaoyu Wen, Yan Song, Hanjing Wang, Linyi Yang, Mark Schmidt, Jun Wang, Weinan Zhang, Shuyue Hu, Ying Wen

Recent research on Reasoning of Large Language Models (LLMs) has sought to further enhance their performance by integrating meta-thinking -- enabling models to monitor, evaluate, and control their reasoning processes for more adaptive and effective problem-solving. However, current single-agent work lacks a specialized design for acquiring meta-thinking, resulting in low efficacy. To address this challenge, we introduce Reinforced Meta-thinking Agents (ReMA), a novel framework that leverages Multi-Agent Reinforcement Learning (MARL) to elicit meta-thinking behaviors, encouraging LLMs to think about thinking. ReMA decouples the reasoning process into two hierarchical agents: a high-level meta-thinking agent responsible for generating strategic oversight and plans, and a low-level reasoning agent for detailed executions. Through iterative reinforcement learning with aligned objectives, these agents explore and learn collaboration, leading to improved generalization and robustness. Empirical results from single-turn experiments demonstrate that ReMA outperforms single-agent RL baselines on complex reasoning tasks, including competitive-level mathematical benchmarks and LLM-as-a-Judge benchmarks. Additionally, we further extend ReMA to multi-turn interaction settings, leveraging turn-level ratio and parameter sharing to improve efficiency. Comprehensive ablation studies further illustrate the evolving dynamics of each distinct agent, providing valuable insights into how the meta-thinking reasoning process enhances the reasoning capabilities of LLMs. Our code can be found in https://github.com/ziyuwan/ReMA-public

---

## Article 56
### Title@2025-05-27: JaxRobotarium: Training and Deploying Multi-Robot Policies in 10 Minutes
**Title**: JaxRobotarium: Training and Deploying Multi-Robot Policies in 10 Minutes | JaxRobotarium: Schulung und Einsatz von Multi-Roboter-Politik in 10 Minuten | JaxRobotior:10分钟内培训和部署多机器人政策 [2505.06771v2](http://arxiv.org/abs/2505.06771v2)

**Authors**: Shalin Anand Jain, Jiazhen Liu, Siva Kailas, Harish Ravichandar

Multi-agent reinforcement learning (MARL) has emerged as a promising solution for learning complex and scalable coordination behaviors in multi-robot systems. However, established MARL platforms (e.g., SMAC and MPE) lack robotics relevance and hardware deployment, leaving multi-robot learning researchers to develop bespoke environments and hardware testbeds dedicated to the development and evaluation of their individual contributions. The Multi-Agent RL Benchmark and Learning Environment for the Robotarium (MARBLER) is an exciting recent step in providing a standardized robotics-relevant platform for MARL, by bridging the Robotarium testbed with existing MARL software infrastructure. However, MARBLER lacks support for parallelization and GPU/TPU execution, making the platform prohibitively slow compared to modern MARL environments and hindering adoption. We contribute JaxRobotarium, a Jax-powered end-to-end simulation, learning, deployment, and benchmarking platform for the Robotarium. JaxRobotarium enables rapid training and deployment of multi-robot RL (MRRL) policies with realistic robot dynamics and safety constraints, supporting parallelization and hardware acceleration. Our generalizable learning interface integrates easily with SOTA MARL libraries (e.g., JaxMARL). In addition, JaxRobotarium includes eight standardized coordination scenarios, including four novel scenarios that bring established MARL benchmark tasks (e.g., RWARE and Level-Based Foraging) to a robotics setting. We demonstrate that JaxRobotarium retains high simulation fidelity while achieving dramatic speedups over baseline (20x in training and 150x in simulation), and provides an open-access sim-to-real evaluation pipeline through the Robotarium testbed, accelerating and democratizing access to multi-robot learning research and evaluation. Our code is available at https://github.com/GT-STAR-Lab/JaxRobotarium.

---

## Article 57
### Title@2025-05-26: xChemAgents: Agentic AI for Explainable Quantum Chemistry
**Title**: xChemAgents: Agentic AI for Explainable Quantum Chemistry | xChemAgenten: Agentische KI für erklärbare Quantenchemie | xchemAgents: 可解释量子化学的AAA剂 [2505.20574v1](http://arxiv.org/abs/2505.20574v1)

**Authors**: Can Polat, Mehmet Tuncel, Hasan Kurban, Erchin Serpedin, Mustafa Kurban

Recent progress in multimodal graph neural networks has demonstrated that augmenting atomic XYZ geometries with textual chemical descriptors can enhance predictive accuracy across a range of electronic and thermodynamic properties. However, naively appending large sets of heterogeneous descriptors often degrades performance on tasks sensitive to molecular shape or symmetry, and undermines interpretability. xChemAgents proposes a cooperative agent framework that injects physics-aware reasoning into multimodal property prediction. xChemAgents comprises two language-model-based agents: a Selector, which adaptively identifies a sparse, weighted subset of descriptors relevant to each target, and provides a natural language rationale; and a Validator, which enforces physical constraints such as unit consistency and scaling laws through iterative dialogue. On standard benchmark datasets, xChemAgents achieves up to a 22\% reduction in mean absolute error over strong baselines, while producing faithful, human-interpretable explanations. Experiment results highlight the potential of cooperative, self-verifying agents to enhance both accuracy and transparency in foundation-model-driven materials science. The implementation and accompanying dataset are available anonymously at https://github.com/KurbanIntelligenceLab/xChemAgents.

---

## Article 58
### Title@2025-05-26: Streamlining Resilient Kubernetes Autoscaling with Multi-Agent Systems   via an Automated Online Design Framework
**Title**: Streamlining Resilient Kubernetes Autoscaling with Multi-Agent Systems   via an Automated Online Design Framework | Straffung des Resilients Kubernetes Autoscaling mit Multi-Agent Systemen über ein automatisiertes Online-Design-Framework | 通过自动在线设计框架与多机构系统自动调整 [2505.21559v1](http://arxiv.org/abs/2505.21559v1)

**Authors**: Julien Soulé, Jean-Paul Jamont, Michel Occello, Louis-Marie Traonouez, Paul Théron

In cloud-native systems, Kubernetes clusters with interdependent services often face challenges to their operational resilience due to poor workload management issues such as resource blocking, bottlenecks, or continuous pod crashes. These vulnerabilities are further amplified in adversarial scenarios, such as Distributed Denial-of-Service attacks (DDoS). Conventional Horizontal Pod Autoscaling (HPA) approaches struggle to address such dynamic conditions, while reinforcement learning-based methods, though more adaptable, typically optimize single goals like latency or resource usage, neglecting broader failure scenarios. We propose decomposing the overarching goal of maintaining operational resilience into failure-specific sub-goals delegated to collaborative agents, collectively forming an HPA Multi-Agent System (MAS). We introduce an automated, four-phase online framework for HPA MAS design: 1) modeling a digital twin built from cluster traces; 2) training agents in simulation using roles and missions tailored to failure contexts; 3) analyzing agent behaviors for explainability; and 4) transferring learned policies to the real cluster. Experimental results demonstrate that the generated HPA MASs outperform three state-of-the-art HPA systems in sustaining operational resilience under various adversarial conditions in a proposed complex cluster.

---

## Article 59
### Title@2025-05-26: Reconceptualizing Smart Microscopy: From Data Collection to Knowledge   Creation by Multi-Agent Integration
**Title**: Reconceptualizing Smart Microscopy: From Data Collection to Knowledge   Creation by Multi-Agent Integration | Intelligente Mikroskopie neu konzipieren: Von der Datenerhebung zur Wissenserstellung durch Multi-Agent-Integration | 重新概念化智能微镜:从数据收集到通过多机构整合创造知识 [2505.20466v1](http://arxiv.org/abs/2505.20466v1)

**Authors**: P. S. Kesavan, Pontus Nordenfelt

Smart microscopy represents a paradigm shift in biological imaging, moving from passive observation tools to active collaborators in scientific inquiry. Enabled by advances in automation, computational power, and artificial intelligence, these systems are now capable of adaptive decision-making and real-time experimental control. Here, we introduce a theoretical framework that reconceptualizes smart microscopy as a partner in scientific investigation. Central to our framework is the concept of the 'epistemic-empirical divide' in cellular investigation-the gap between what is observable (empirical domain) and what must be understood (epistemic domain). We propose six core design principles: epistemic-empirical awareness, hierarchical context integration, an evolution from detection to perception, adaptive measurement frameworks, narrative synthesis capabilities, and cross-contextual reasoning. Together, these principles guide a multi-agent architecture designed to align empirical observation with the goals of scientific understanding. Our framework provides a roadmap for building microscopy systems that go beyond automation to actively support hypothesis generation, insight discovery, and theory development, redefining the role of scientific instruments in the process of knowledge creation.

---

## Article 60
### Title@2025-05-26: Sable: a Performant, Efficient and Scalable Sequence Model for MARL
**Title**: Sable: a Performant, Efficient and Scalable Sequence Model for MARL | Sable: ein leistungsfähiges, effizientes und skalierbares Sequenzmodell für MARL | 电缆:MARL的性能、高效和可缩放序列模型 [2410.01706v5](http://arxiv.org/abs/2410.01706v5)

**Authors**: Omayma Mahjoub, Sasha Abramowitz, Ruan de Kock, Wiem Khlifi, Simon du Toit, Jemma Daniel, Louay Ben Nessir, Louise Beyers, Claude Formanek, Liam Clark, Arnu Pretorius

As multi-agent reinforcement learning (MARL) progresses towards solving larger and more complex problems, it becomes increasingly important that algorithms exhibit the key properties of (1) strong performance, (2) memory efficiency, and (3) scalability. In this work, we introduce Sable, a performant, memory-efficient, and scalable sequence modeling approach to MARL. Sable works by adapting the retention mechanism in Retentive Networks (Sun et al., 2023) to achieve computationally efficient processing of multi-agent observations with long context memory for temporal reasoning. Through extensive evaluations across six diverse environments, we demonstrate how Sable is able to significantly outperform existing state-of-the-art methods in a large number of diverse tasks (34 out of 45 tested). Furthermore, Sable maintains performance as we scale the number of agents, handling environments with more than a thousand agents while exhibiting a linear increase in memory usage. Finally, we conduct ablation studies to isolate the source of Sable's performance gains and confirm its efficient computational memory usage.

---

## Article 61
### Title@2025-05-26: Federated Domain Generalization with Data-free On-server Matching   Gradient
**Title**: Federated Domain Generalization with Data-free On-server Matching   Gradient | Föderierte Domain-Verallgemeinerung mit datenfreiem On-Server-Zustimmungs-Gradient | 具有无数据观测站上与渐变匹配的无数据观测器的联邦通用域 [2501.14653v2](http://arxiv.org/abs/2501.14653v2)

**Authors**: Trong-Binh Nguyen, Minh-Duong Nguyen, Jinsun Park, Quoc-Viet Pham, Won Joo Hwang

Domain Generalization (DG) aims to learn from multiple known source domains a model that can generalize well to unknown target domains. One of the key approaches in DG is training an encoder which generates domain-invariant representations. However, this approach is not applicable in Federated Domain Generalization (FDG), where data from various domains are distributed across different clients. In this paper, we introduce a novel approach, dubbed Federated Learning via On-server Matching Gradient (FedOMG), which can \emph{efficiently leverage domain information from distributed domains}. Specifically, we utilize the local gradients as information about the distributed models to find an invariant gradient direction across all domains through gradient inner product maximization. The advantages are two-fold: 1) FedOMG can aggregate the characteristics of distributed models on the centralized server without incurring any additional communication cost, and 2) FedOMG is orthogonal to many existing FL/FDG methods, allowing for additional performance improvements by being seamlessly integrated with them. Extensive experimental evaluations on various settings to demonstrate the robustness of FedOMG compared to other FL/FDG baselines. Our method outperforms recent SOTA baselines on four FL benchmark datasets (MNIST, EMNIST, CIFAR-10, and CIFAR-100), and three FDG benchmark datasets (PACS, VLCS, and OfficeHome).

---

## Article 62
### Title@2025-05-26: Semantic-Aware Resource Management for C-V2X Platooning via Multi-Agent   Reinforcement Learning
**Title**: Semantic-Aware Resource Management for C-V2X Platooning via Multi-Agent   Reinforcement Learning | Semantic-Aware Ressourcenmanagement für C-V2X Platooning über Multi-Agent Verstärkungslernen | 通过多机构强化学习进行 C-V2X 等离子处理的语义软件资源管理 [2411.04672v2](http://arxiv.org/abs/2411.04672v2)

**Authors**: Wenjun Zhang, Qiong Wu, Pingyi Fan, Kezhi Wang, Nan Cheng, Wen Chen, Khaled B. Letaief

Semantic communication transmits the extracted features of information rather than raw data, significantly reducing redundancy, which is crucial for addressing spectrum and energy challenges in 6G networks. In this paper, we introduce semantic communication into a cellular vehicle-to-everything (C-V2X)- based autonomous vehicle platoon system for the first time, aiming to achieve efficient management of communication resources in a dynamic environment. Firstly, we construct a mathematical model for semantic communication in platoon systems, in which the DeepSC model and MU-DeepSC model are used to semantically encode and decode unimodal and multi-modal data, respectively. Then, we propose the quality of experience (QoE) metric based on semantic similarity and semantic rate. Meanwhile, we consider the success rate of semantic information transmission (SRS) metric to ensure the fairness of channel resource allocation. Next, the optimization problem is posed with the aim of maximizing the QoE in vehicle-to-vehicle (V2V) links while improving SRS. To solve this mixed integer nonlinear programming problem (MINLP) and adapt to time-varying channel conditions, the paper proposes a distributed semantic-aware multi-modal resource allocation (SAMRA) algorithm based on multi-agent reinforcement learning (MARL), referred to as SAMRAMARL. The algorithm can dynamically allocate channels and power and determine semantic symbol length based on the contextual importance of the transmitted information, ensuring efficient resource utilization. Finally, extensive simulations have demonstrated that SAMRAMARL outperforms existing methods, achieving significant gains in QoE, SRS, and communication delay in C-V2X platooning scenarios.

---

## Article 63
### Title@2025-05-26: Multi-Agent Reinforcement Learning in Cybersecurity: From Fundamentals   to Applications
**Title**: Multi-Agent Reinforcement Learning in Cybersecurity: From Fundamentals   to Applications | Multi-Agenten-Verstärkung Lernen in Cybersicherheit: Von Grundlagen zu Anwendungen | 网络安全多机构强化多机构网络安全学习:从基础到应用 [2505.19837v1](http://arxiv.org/abs/2505.19837v1)

**Authors**: Christoph R. Landolt, Christoph Würsch, Roland Meier, Alain Mermoud, Julian Jang-Jaccard

Multi-Agent Reinforcement Learning (MARL) has shown great potential as an adaptive solution for addressing modern cybersecurity challenges. MARL enables decentralized, adaptive, and collaborative defense strategies and provides an automated mechanism to combat dynamic, coordinated, and sophisticated threats. This survey investigates the current state of research in MARL applications for automated cyber defense (ACD), focusing on intruder detection and lateral movement containment. Additionally, it examines the role of Autonomous Intelligent Cyber-defense Agents (AICA) and Cyber Gyms in training and validating MARL agents. Finally, the paper outlines existing challenges, such as scalability and adversarial robustness, and proposes future research directions. This also discusses how MARL integrates in AICA to provide adaptive, scalable, and dynamic solutions to counter the increasingly sophisticated landscape of cyber threats. It highlights the transformative potential of MARL in areas like intrusion detection and lateral movement containment, and underscores the value of Cyber Gyms for training and validation of AICA.

---

## Article 64
### Title@2025-05-26: Fast and Robust Flocking of Protesters on Street Networks
**Title**: Fast and Robust Flocking of Protesters on Street Networks | Schnelles und robustes Auspeitschen von Protestierenden auf Straßennetzen | 街头网络上抗争者快速和强力封锁 [2406.01101v3](http://arxiv.org/abs/2406.01101v3)

**Authors**: Guillaume Moinard, Matthieu Latapy

We propose a simple model of protesters scattered throughout a city who want to gather into large and mobile groups. This model relies on random walkers on a street network that follow tactics built from a set of basic rules. Our goal is to identify the most important rules for fast and robust flocking of walkers. We explore a wide set of tactics and show the central importance of a specific rule based on alignment. Other rules alone perform poorly, but our experiments show that combining alignment with them enhances flocking, and that obtained groups are then remarkably robust.

---

## Article 65
### Title@2025-05-26: Adaptive Episode Length Adjustment for Multi-agent Reinforcement   Learning
**Title**: Adaptive Episode Length Adjustment for Multi-agent Reinforcement   Learning | Adaptive Anpassung der Episodenlänge für das Multi-Agenten-Verstärkungs-Lernen | 多试剂强化学习的适应性分单元长度调整 [2505.19637v1](http://arxiv.org/abs/2505.19637v1)

**Authors**: Byunghyun Yoo, Younghwan Shin, Hyunwoo Kim, Euisok Chung, Jeongmin Yang

In standard reinforcement learning, an episode is defined as a sequence of interactions between agents and the environment, which terminates upon reaching a terminal state or a pre-defined episode length. Setting a shorter episode length enables the generation of multiple episodes with the same number of data samples, thereby facilitating an exploration of diverse states. While shorter episodes may limit the collection of long-term interactions, they may offer significant advantages when properly managed. For example, trajectory truncation in single-agent reinforcement learning has shown how the benefits of shorter episodes can be leveraged despite the trade-off of reduced long-term interaction experiences. However, this approach remains underexplored in MARL. This paper proposes a novel MARL approach, Adaptive Episode Length Adjustment (AELA), where the episode length is initially limited and gradually increased based on an entropy-based assessment of learning progress. By starting with shorter episodes, agents can focus on learning effective strategies for initial states and minimize time spent in dead-end states. The use of entropy as an assessment metric prevents premature convergence to suboptimal policies and ensures balanced training over varying episode lengths. We validate our approach using the StarCraft Multi-agent Challenge (SMAC) and a modified predator-prey environment, demonstrating significant improvements in both convergence speed and overall performance compared to existing methods. To the best of our knowledge, this is the first study to adaptively adjust episode length in MARL based on learning progress.

---

## Article 66
### Title@2025-05-26: Multi-Agent Collaboration via Evolving Orchestration
**Title**: Multi-Agent Collaboration via Evolving Orchestration | Multi-Agenten-Zusammenarbeit über Evolving Orchestration | 通过不断演变的管弦化多机构协作 [2505.19591v1](http://arxiv.org/abs/2505.19591v1)

**Authors**: Yufan Dang, Chen Qian, Xueheng Luo, Jingru Fan, Zihao Xie, Ruijie Shi, Weize Chen, Cheng Yang, Xiaoyin Che, Ye Tian, Xuantang Xiong, Lei Han, Zhiyuan Liu, Maosong Sun

Large language models (LLMs) have achieved remarkable results across diverse downstream tasks, but their monolithic nature restricts scalability and efficiency in complex problem-solving. While recent research explores multi-agent collaboration among LLMs, most approaches rely on static organizational structures that struggle to adapt as task complexity and agent numbers grow, resulting in coordination overhead and inefficiencies. To this end, we propose a puppeteer-style paradigm for LLM-based multi-agent collaboration, where a centralized orchestrator ("puppeteer") dynamically directs agents ("puppets") in response to evolving task states. This orchestrator is trained via reinforcement learning to adaptively sequence and prioritize agents, enabling flexible and evolvable collective reasoning. Experiments on closed- and open-domain scenarios show that this method achieves superior performance with reduced computational costs. Analyses further reveal that the key improvements consistently stem from the emergence of more compact, cyclic reasoning structures under the orchestrator's evolution.

---

## Article 67
### Title@2025-05-26: LLM-Agent-Controller: A Universal Multi-Agent Large Language Model   System as a Control Engineer
**Title**: LLM-Agent-Controller: A Universal Multi-Agent Large Language Model   System as a Control Engineer | LLM-Agent-Controller: Ein universelles Multi-Agent-Großsprachmodellsystem als Steuerungsingenieur | LLM-代理主计长:作为控制工程师的通用多代理大型语文示范系统 [2505.19567v1](http://arxiv.org/abs/2505.19567v1)

**Authors**: Rasoul Zahedifar, Sayyed Ali Mirghasemi, Mahdieh Soleymani Baghshah, Alireza Taheri

This study presents the LLM-Agent-Controller, a multi-agent large language model (LLM) system developed to address a wide range of problems in control engineering (Control Theory). The system integrates a central controller agent with multiple specialized auxiliary agents, responsible for tasks such as controller design, model representation, control analysis, time-domain response, and simulation. A supervisor oversees high-level decision-making and workflow coordination, enhancing the system's reliability and efficiency. The LLM-Agent-Controller incorporates advanced capabilities, including Retrieval-Augmented Generation (RAG), Chain-of-Thought reasoning, self-criticism and correction, efficient memory handling, and user-friendly natural language communication. It is designed to function without requiring users to have prior knowledge of Control Theory, enabling them to input problems in plain language and receive complete, real-time solutions. To evaluate the system, we propose new performance metrics assessing both individual agents and the system as a whole. We test five categories of Control Theory problems and benchmark performance across three advanced LLMs. Additionally, we conduct a comprehensive qualitative conversational analysis covering all key services. Results show that the LLM-Agent-Controller successfully solved 83% of general tasks, with individual agents achieving an average success rate of 87%. Performance improved with more advanced LLMs. This research demonstrates the potential of multi-agent LLM architectures to solve complex, domain-specific problems. By integrating specialized agents, supervisory control, and advanced reasoning, the LLM-Agent-Controller offers a scalable, robust, and accessible solution framework that can be extended to various technical domains.

---

## Article 68
### Title@2025-05-26: DoctorRAG: Medical RAG Fusing Knowledge with Patient Analogy through   Textual Gradients
**Title**: DoctorRAG: Medical RAG Fusing Knowledge with Patient Analogy through   Textual Gradients | DoctorRAG: Medizinische RAG Durch Textabstufungen Wissen mit Patient Analogie fusionieren | 医生RAG:通过文字梯度将医学RAG知识与病人分析知识与病人分析相融合 [2505.19538v1](http://arxiv.org/abs/2505.19538v1)

**Authors**: Yuxing Lu, Gecheng Fu, Wei Wu, Xukai Zhao, Sin Yee Goi, Jinzhuo Wang

Existing medical RAG systems mainly leverage knowledge from medical knowledge bases, neglecting the crucial role of experiential knowledge derived from similar patient cases -- a key component of human clinical reasoning. To bridge this gap, we propose DoctorRAG, a RAG framework that emulates doctor-like reasoning by integrating both explicit clinical knowledge and implicit case-based experience. DoctorRAG enhances retrieval precision by first allocating conceptual tags for queries and knowledge sources, together with a hybrid retrieval mechanism from both relevant knowledge and patient. In addition, a Med-TextGrad module using multi-agent textual gradients is integrated to ensure that the final output adheres to the retrieved knowledge and patient query. Comprehensive experiments on multilingual, multitask datasets demonstrate that DoctorRAG significantly outperforms strong baseline RAG models and gains improvements from iterative refinements. Our approach generates more accurate, relevant, and comprehensive responses, taking a step towards more doctor-like medical reasoning systems.

---

## Article 69
### Title@2025-05-26: VLMLight: Traffic Signal Control via Vision-Language Meta-Control and   Dual-Branch Reasoning
**Title**: VLMLight: Traffic Signal Control via Vision-Language Meta-Control and   Dual-Branch Reasoning | VLMLight: Verkehrssignalsteuerung über Vision-Language Meta-Control und Dual-Branch-Reasoning | VLMLight:通过视觉语言、超控制和双层理由解释控制交通信号控制 [2505.19486v1](http://arxiv.org/abs/2505.19486v1)

**Authors**: Maonan Wang, Yirong Chen, Aoyu Pang, Yuxin Cai, Chung Shue Chen, Yuheng Kan, Man-On Pun

Traffic signal control (TSC) is a core challenge in urban mobility, where real-time decisions must balance efficiency and safety. Existing methods - ranging from rule-based heuristics to reinforcement learning (RL) - often struggle to generalize to complex, dynamic, and safety-critical scenarios. We introduce VLMLight, a novel TSC framework that integrates vision-language meta-control with dual-branch reasoning. At the core of VLMLight is the first image-based traffic simulator that enables multi-view visual perception at intersections, allowing policies to reason over rich cues such as vehicle type, motion, and spatial density. A large language model (LLM) serves as a safety-prioritized meta-controller, selecting between a fast RL policy for routine traffic and a structured reasoning branch for critical cases. In the latter, multiple LLM agents collaborate to assess traffic phases, prioritize emergency vehicles, and verify rule compliance. Experiments show that VLMLight reduces waiting times for emergency vehicles by up to 65% over RL-only systems, while preserving real-time performance in standard conditions with less than 1% degradation. VLMLight offers a scalable, interpretable, and safety-aware solution for next-generation traffic signal control.

---

## Article 70
### Title@2025-05-26: Win Fast or Lose Slow: Balancing Speed and Accuracy in Latency-Sensitive   Decisions of LLMs
**Title**: Win Fast or Lose Slow: Balancing Speed and Accuracy in Latency-Sensitive   Decisions of LLMs | Gewinnen Sie schnell oder verlieren Sie langsam: Ausgleichende Geschwindigkeit und Genauigkeit in Latenz-Sensitive Entscheidungen von LLMs | 慢赢或慢输:LLMs的延缓敏感决定中平衡速度和准确性 [2505.19481v1](http://arxiv.org/abs/2505.19481v1)

**Authors**: Hao Kang, Qingru Zhang, Han Cai, Weiyuan Xu, Tushar Krishna, Yilun Du, Tsachy Weissman

Large language models (LLMs) have shown remarkable performance across diverse reasoning and generation tasks, and are increasingly deployed as agents in dynamic environments such as code generation and recommendation systems. However, many real-world applications, such as high-frequency trading and real-time competitive gaming, require decisions under strict latency constraints, where faster responses directly translate into higher rewards. Despite the importance of this latency quality trade off, it remains underexplored in the context of LLM based agents. In this work, we present the first systematic study of this trade off in real time decision making tasks. To support our investigation, we introduce two new benchmarks: HFTBench, a high frequency trading simulation, and StreetFighter, a competitive gaming platform. Our analysis reveals that optimal latency quality balance varies by task, and that sacrificing quality for lower latency can significantly enhance downstream performance. To address this, we propose FPX, an adaptive framework that dynamically selects model size and quantization level based on real time demands. Our method achieves the best performance on both benchmarks, improving win rate by up to 80% in Street Fighter and boosting daily yield by up to 26.52% in trading, underscoring the need for latency aware evaluation and deployment strategies for LLM based agents. These results demonstrate the critical importance of latency aware evaluation and deployment strategies for real world LLM based agents. Our benchmarks are available at Latency Sensitive Benchmarks.

---

## Article 71
### Title@2025-05-25: Making Teams and Influencing Agents: Efficiently Coordinating Decision   Trees for Interpretable Multi-Agent Reinforcement Learning
**Title**: Making Teams and Influencing Agents: Efficiently Coordinating Decision   Trees for Interpretable Multi-Agent Reinforcement Learning | Teambildung und Beeinflussung von Agenten: Entscheidungsbäume effizient koordinieren für interpretierbares Mehr-Agenten-Verstärkungs-Lernen | 建立团队和对代理人产生影响的代理:高效协调可解释的多机构强化学习决策树 [2505.19316v1](http://arxiv.org/abs/2505.19316v1)

**Authors**: Rex Chen, Stephanie Milani, Zhicheng Zhang, Norman Sadeh, Fei Fang

Poor interpretability hinders the practical applicability of multi-agent reinforcement learning (MARL) policies. Deploying interpretable surrogates of uninterpretable policies enhances the safety and verifiability of MARL for real-world applications. However, if these surrogates are to interact directly with the environment within human supervisory frameworks, they must be both performant and computationally efficient. Prior work on interpretable MARL has either sacrificed performance for computational efficiency or computational efficiency for performance. To address this issue, we propose HYDRAVIPER, a decision tree-based interpretable MARL algorithm. HYDRAVIPER coordinates training between agents based on expected team performance, and adaptively allocates budgets for environment interaction to improve computational efficiency. Experiments on standard benchmark environments for multi-agent coordination and traffic signal control show that HYDRAVIPER matches the performance of state-of-the-art methods using a fraction of the runtime, and that it maintains a Pareto frontier of performance for different interaction budgets.

---

## Article 72
### Title@2025-05-25: Agentic Information Theory: Ergodicity and Intrinsic Semantics of   Information Processes
**Title**: Agentic Information Theory: Ergodicity and Intrinsic Semantics of   Information Processes | Agentische Informationstheorie: Ergodikität und Intrinsische Semantik von Informationsprozessen | 代理信息理论:信息过程的分化和内在的语义 [2505.19275v1](http://arxiv.org/abs/2505.19275v1)

**Authors**: James P. Crutchfield, Alexandra Jurgens

We develop information theory for the temporal behavior of memoryful agents moving through complex -- structured, stochastic -- environments. We introduce information processes -- stochastic processes produced by cognitive agents in real-time as they interact with and interpret incoming stimuli. We provide basic results on the ergodicity and semantics of the resulting time series of Shannon information measures that monitor an agent's adapting view of uncertainty and structural correlation in its environment.

---

## Article 73
### Title@2025-05-25: GUARDIAN: Safeguarding LLM Multi-Agent Collaborations with Temporal   Graph Modeling
**Title**: GUARDIAN: Safeguarding LLM Multi-Agent Collaborations with Temporal   Graph Modeling | GUARDIAN: LLM-Multiagent-Kollaborationen mit zeitlicher Graphenmodellierung sichern | GUARDIAN: 保护LLM 多机构协作与时间图建模 [2505.19234v1](http://arxiv.org/abs/2505.19234v1)

**Authors**: Jialong Zhou, Lichao Wang, Xiao Yang

The emergence of large language models (LLMs) enables the development of intelligent agents capable of engaging in complex and multi-turn dialogues. However, multi-agent collaboration face critical safety challenges, such as hallucination amplification and error injection and propagation. This paper presents GUARDIAN, a unified method for detecting and mitigating multiple safety concerns in GUARDing Intelligent Agent collaboratioNs. By modeling the multi-agent collaboration process as a discrete-time temporal attributed graph, GUARDIAN explicitly captures the propagation dynamics of hallucinations and errors. The unsupervised encoder-decoder architecture incorporating an incremental training paradigm, learns to reconstruct node attributes and graph structures from latent embeddings, enabling the identification of anomalous nodes and edges with unparalleled precision. Moreover, we introduce a graph abstraction mechanism based on the Information Bottleneck Theory, which compresses temporal interaction graphs while preserving essential patterns. Extensive experiments demonstrate GUARDIAN's effectiveness in safeguarding LLM multi-agent collaborations against diverse safety vulnerabilities, achieving state-of-the-art accuracy with efficient resource utilization.

---

## Article 74
### Title@2025-05-25: Where Paths Collide: A Comprehensive Survey of Classic and   Learning-Based Multi-Agent Pathfinding
**Title**: Where Paths Collide: A Comprehensive Survey of Classic and   Learning-Based Multi-Agent Pathfinding | Where Paths Collide: Eine umfassende Untersuchung der klassischen und lernbasierten multi-agenten Pathfinding | 路径相撞之处:对经典和以学习为基础的多方代理调查的全面调查 [2505.19219v1](http://arxiv.org/abs/2505.19219v1)

**Authors**: Shiyue Wang, Haozheng Xu, Yuhan Zhang, Jingran Lin, Changhong Lu, Xiangfeng Wang, Wenhao Li

Multi-Agent Path Finding (MAPF) is a fundamental problem in artificial intelligence and robotics, requiring the computation of collision-free paths for multiple agents navigating from their start locations to designated goals. As autonomous systems become increasingly prevalent in warehouses, urban transportation, and other complex environments, MAPF has evolved from a theoretical challenge to a critical enabler of real-world multi-robot coordination. This comprehensive survey bridges the long-standing divide between classical algorithmic approaches and emerging learning-based methods in MAPF research. We present a unified framework that encompasses search-based methods (including Conflict-Based Search, Priority-Based Search, and Large Neighborhood Search), compilation-based approaches (SAT, SMT, CSP, ASP, and MIP formulations), and data-driven techniques (reinforcement learning, supervised learning, and hybrid strategies). Through systematic analysis of experimental practices across 200+ papers, we uncover significant disparities in evaluation methodologies, with classical methods typically tested on larger-scale instances (up to 200 by 200 grids with 1000+ agents) compared to learning-based approaches (predominantly 10-100 agents). We provide a comprehensive taxonomy of evaluation metrics, environment types, and baseline selections, highlighting the need for standardized benchmarking protocols. Finally, we outline promising future directions including mixed-motive MAPF with game-theoretic considerations, language-grounded planning with large language models, and neural solver architectures that combine the rigor of classical methods with the flexibility of deep learning. This survey serves as both a comprehensive reference for researchers and a practical guide for deploying MAPF solutions in increasingly complex real-world applications.

---

## Article 75
### Title@2025-05-25: Collaborative Agentic AI Needs Interoperability Across Ecosystems
**Title**: Collaborative Agentic AI Needs Interoperability Across Ecosystems | Kollaborative Agentische KI braucht Interoperabilität über Ökosysteme hinweg | AI 需要跨生态系统的互操作性 [2505.21550v1](http://arxiv.org/abs/2505.21550v1)

**Authors**: Rishi Sharma, Martijn de Vos, Pradyumna Chari, Ramesh Raskar, Anne-Marie Kermarrec

Collaborative agentic AI is projected to transform entire industries by enabling AI-powered agents to autonomously perceive, plan, and act within digital environments. Yet, current solutions in this field are all built in isolation, and we are rapidly heading toward a landscape of fragmented, incompatible ecosystems. In this position paper, we argue that interoperability, achieved by the adoption of minimal standards, is essential to ensure open, secure, web-scale, and widely-adopted agentic ecosystems. To this end, we devise a minimal architectural foundation for collaborative agentic AI, named Web of Agents, which is composed of four components: agent-to-agent messaging, interaction interoperability, state management, and agent discovery. Web of Agents adopts existing standards and reuses existing infrastructure where possible. With Web of Agents, we take the first but critical step toward interoperable agentic systems and offer a pragmatic path forward before ecosystem fragmentation becomes the norm.

---

## Article 76
### Title@2025-05-25: Interacting Large Language Model Agents. Interpretable Models and Social   Learning
**Title**: Interacting Large Language Model Agents. Interpretable Models and Social   Learning | Interagieren von Large Language Model Agents. Interpretierbare Modelle und soziales Lernen | 跨大语言示范工具、可解释模型和社会学习 [2411.01271v2](http://arxiv.org/abs/2411.01271v2)

**Authors**: Adit Jain, Vikram Krishnamurthy

This paper discusses the theory and algorithms for interacting large language model agents (LLMAs) using methods from statistical signal processing and microeconomics. While both fields are mature, their application to decision-making involving interacting LLMAs remains unexplored. Motivated by Bayesian sentiment analysis on online platforms, we construct interpretable models and algorithms that enable LLMAs to interact and perform Bayesian inference. Because interacting LLMAs learn from both prior decisions and external inputs, they can exhibit bias and herding behavior. Thus, developing interpretable models and stochastic control algorithms is essential to understand and mitigate these behaviors. This paper has three main results. First, we show using Bayesian revealed preferences from microeconomics that an individual LLMA satisfies the necessary and sufficient conditions for rationally inattentive (bounded rationality) Bayesian utility maximization and, given an observation, the LLMA chooses an action that maximizes a regularized utility. Second, we utilize Bayesian social learning to construct interpretable models for LLMAs that interact sequentially with each other and the environment while performing Bayesian inference. Our proposed models capture the herding behavior exhibited by interacting LLMAs. Third, we propose a stochastic control framework to delay herding and improve state estimation accuracy under 2 settings: (a) centrally controlled LLMAs (b) autonomous LLMAs with incentives. We demonstrate the effectiveness of our methods on real datasets for hate speech classification and product quality assessment, using open-source models like LLaMA and closed-source models like ChatGPT. The main takeaway of this paper, based on empirical analysis and mathematical formalism, is that LLMAs act as rationally bounded Bayesian agents that exhibit social learning when interacting.

---

## Article 77
### Title@2025-05-25: Adversarial Bandit over Bandits: Hierarchical Bandits for Online   Configuration Management
**Title**: Adversarial Bandit over Bandits: Hierarchical Bandits for Online   Configuration Management | Adversarial Bandit über Bandits: Hierarchische Bandits für Online-Konfigurationsmanagement | 反强盗强盗: 用于在线配置管理的等级强盗 [2505.19061v1](http://arxiv.org/abs/2505.19061v1)

**Authors**: Chen Avin, Zvi Lotker, Shie Mannor, Gil Shabat, Hanan Shteingart, Roey Yadgar

Motivated by dynamic parameter optimization in finite, but large action (configurations) spaces, this work studies the nonstochastic multi-armed bandit (MAB) problem in metric action spaces with oblivious Lipschitz adversaries. We propose ABoB, a hierarchical Adversarial Bandit over Bandits algorithm that can use state-of-the-art existing "flat" algorithms, but additionally clusters similar configurations to exploit local structures and adapt to changing environments. We prove that in the worst-case scenario, such clustering approach cannot hurt too much and ABoB guarantees a standard worst-case regret bound of $O\left(k^{\frac{1}{2}}T^{\frac{1}{2}}\right)$, where $T$ is the number of rounds and $k$ is the number of arms, matching the traditional flat approach. However, under favorable conditions related to the algorithm properties, clusters properties, and certain Lipschitz conditions, the regret bound can be improved to $O\left(k^{\frac{1}{4}}T^{\frac{1}{2}}\right)$. Simulations and experiments on a real storage system demonstrate that ABoB, using standard algorithms like EXP3 and Tsallis-INF, achieves lower regret and faster convergence than the flat method, up to 50% improvement in known previous setups, nonstochastic and stochastic, as well as in our settings.

---

## Article 78
### Title@2025-05-25: Adaptive Inference through Bayesian and Inverse Bayesian Inference with   Symmetry-Bias in Nonstationary Environments
**Title**: Adaptive Inference through Bayesian and Inverse Bayesian Inference with   Symmetry-Bias in Nonstationary Environments | Adaptive Schlussfolgerung durch Bayesische und Inverse Bayesische Schlussfolgerung mit Symmetrie-Bias in nichtstationären Umgebungen | 在非静止环境中,通过贝耶斯和反贝耶斯和反贝耶斯的同对称-比亚推理,进行适应性推理 [2505.12796v3](http://arxiv.org/abs/2505.12796v3)

**Authors**: Shuji Shinohara, Daiki Morita, Hayato Hirai, Ryosuke Kuribayashi, Nobuhito Manome, Toru Moriyama, Yoshihiro Nakajima, Yukio-Pegio Gunji, Ung-il Chung

This study introduces a novel inference framework, designated as Bayesian and inverse Bayesian (BIB) inference, which concurrently performs both conventional and inverse Bayesian updates by integrating symmetry bias into Bayesian inference. The effectiveness of the model was evaluated through a sequential estimation task involving observations sampled from a Gaussian distribution with a stochastically time-varying mean. Conventional Bayesian inference entails a fundamental trade-off between adaptability to abrupt environmental shifts and estimation accuracy during stable intervals. The BIB framework addresses this limitation by dynamically modulating the learning rate through inverse Bayesian updates, thereby enhancing adaptive flexibility. The BIB model generated spontaneous bursts in the learning rate during sudden environmental transitions, transiently entering a high-sensitivity state to accommodate incoming data. This intermittent burst-relaxation pattern functions as a dynamic mechanism that balances adaptability and accuracy. Further analysis of burst interval distributions demonstrated that the BIB model consistently produced power-law distributions under diverse conditions. Such robust scaling behavior, absent in conventional Bayesian inference, appears to emerge from a self-regulatory mechanism driven by inverse Bayesian updates. These results present a novel computational perspective on scale-free phenomena in natural systems and offer implications for designing adaptive inference systems in nonstationary environments.

---

## Article 79
### Title@2025-05-25: SANNet: A Semantic-Aware Agentic AI Networking Framework for Multi-Agent   Cross-Layer Coordination
**Title**: SANNet: A Semantic-Aware Agentic AI Networking Framework for Multi-Agent   Cross-Layer Coordination | SANNet: Ein Semantic-Aware Agentic AI Networking Framework für die multi-agente Cross-Layer-Koordination | SANNet: 多代理人跨行业协调的语义学-敏感物义学AI联网框架 [2505.18946v1](http://arxiv.org/abs/2505.18946v1)

**Authors**: Yong Xiao, Haoran Zhou, Xubo Li, Yayu Gao, Guangming Shi, Ping Zhang

Agentic AI networking (AgentNet) is a novel AI-native networking paradigm that relies on a large number of specialized AI agents to collaborate and coordinate for autonomous decision-making, dynamic environmental adaptation, and complex goal achievement. It has the potential to facilitate real-time network management alongside capabilities for self-configuration, self-optimization, and self-adaptation across diverse and complex networking environments, laying the foundation for fully autonomous networking systems in the future. Despite its promise, AgentNet is still in the early stage of development, and there still lacks an effective networking framework to support automatic goal discovery and multi-agent self-orchestration and task assignment. This paper proposes SANNet, a novel semantic-aware agentic AI networking architecture that can infer the semantic goal of the user and automatically assign agents associated with different layers of a mobile system to fulfill the inferred goal. Motivated by the fact that one of the major challenges in AgentNet is that different agents may have different and even conflicting objectives when collaborating for certain goals, we introduce a dynamic weighting-based conflict-resolving mechanism to address this issue. We prove that SANNet can provide theoretical guarantee in both conflict-resolving and model generalization performance for multi-agent collaboration in dynamic environment. We develop a hardware prototype of SANNet based on the open RAN and 5GS core platform. Our experimental results show that SANNet can significantly improve the performance of multi-agent networking systems, even when agents with conflicting objectives are selected to collaborate for the same goal.

---

## Article 80
### Title@2025-05-24: Distributed Set-membership Filtering Frameworks For Multi-agent Systems   With Absolute and Relative Measurements
**Title**: Distributed Set-membership Filtering Frameworks For Multi-agent Systems   With Absolute and Relative Measurements | Distributed Set-Membership Filtering Frameworks für Multi-Agent-Systeme mit absoluten und relativen Messungen | 具有绝对和相对计量的多试剂系统分布式成员筛选框架 [2305.15797v2](http://arxiv.org/abs/2305.15797v2)

**Authors**: Yu Ding, Yirui Cong, Xiangke Wang

In this paper, we focus on the distributed set-membership filtering (SMFing) problem for a multi-agent system with absolute (taken from agents themselves) and relative (taken from neighbors) measurements. In the literature, the relative measurements are difficult to deal with, and the SMFs highly rely on specific set descriptions. As a result, establishing the general distributed SMFing framework having relative measurements is still an open problem. To solve this problem, first, we provide the set description based on uncertain variables determined by the relative measurements between two agents as the foundation. Surprisingly, the accurate description requires only a single calculation step rather than multiple iterations, which can effectively reduce computational complexity. Based on the derived set description, called the uncertain range, we propose two distributed SMFing frameworks: one calculates the joint uncertain range of the agent itself and its neighbors, while the other only computes the marginal uncertain range of each local system. Furthermore, we compare the performance of our proposed two distributed SMFing frameworks and the benchmark -- centralized SMFing framework. A rigorous set analysis reveals that the distributed SMF can be essentially considered as the process of computing the marginal uncertain range to outer bound the projection of the uncertain range obtained by the centralized SMF in the corresponding subspace. Simulation results corroborate the effectiveness of our proposed distributed frameworks and verify our theoretical analysis.

---

## Article 81
### Title@2025-05-24: Coordinated guidance and control for multiple parafoil system landing
**Title**: Coordinated guidance and control for multiple parafoil system landing | Koordinierte Führung und Steuerung für die Landung mehrerer Parafoil-Systeme | 协调制导和管制多个抛油系统着陆的协调制导和控制 [2505.18691v1](http://arxiv.org/abs/2505.18691v1)

**Authors**: Zhenyu Wei, Zhijiang Shao, Lorenz T. Biegler

Multiple parafoil landing is an enabling technology for massive supply delivery missions. However, it is still an open question to design a collision-free, computation-efficient guidance and control method for unpowered parafoils. To address this issue, this paper proposes a coordinated guidance and control method for multiple parafoil landing. First, the multiple parafoil landing process is formulated as a trajectory optimization problem. Then, the landing point allocation algorithm is designed to assign the landing point to each parafoil. In order to guarantee flight safety, the collision-free trajectory replanning algorithm is designed. On this basis, the nonlinear model predictive control algorithm is adapted to leverage the nonlinear dynamics model for trajectory tracking. Finally, the parafoil kinematic model is utilized to reduce the computational burden of trajectory calculation, and kinematic model is updated by the moving horizon correction algorithm to improve the trajectory accuracy. Simulation results demonstrate the effectiveness and computational efficiency of the proposed coordinated guidance and control method for the multiple parafoil landing.

---

## Article 82
### Title@2025-05-24: Augmenting the action space with conventions to improve multi-agent   cooperation in Hanabi
**Title**: Augmenting the action space with conventions to improve multi-agent   cooperation in Hanabi | Erweiterung des Aktionsraums mit Konventionen zur Verbesserung der Multi-Agenten-Kooperation in Hanabi | 与公约扩大行动空间,以改进哈纳比多剂合作 [2412.06333v3](http://arxiv.org/abs/2412.06333v3)

**Authors**: F. Bredell, H. A. Engelbrecht, J. C. Schoeman

The card game Hanabi is considered a strong medium for the testing and development of multi-agent reinforcement learning (MARL) algorithms, due to its cooperative nature, partial observability, limited communication and remarkable complexity. Previous research efforts have explored the capabilities of MARL algorithms within Hanabi, focusing largely on advanced architecture design and algorithmic manipulations to achieve state-of-the-art performance for various number of cooperators. However, this often leads to complex solution strategies with high computational cost and requiring large amounts of training data. For humans to solve the Hanabi game effectively, they require the use of conventions, which often allows for a means to implicitly convey ideas or knowledge based on a predefined, and mutually agreed upon, set of "rules" or principles. Multi-agent problems containing partial observability, especially when limited communication is present, can benefit greatly from the use of implicit knowledge sharing. In this paper, we propose a novel approach to augmenting an agent's action space using conventions, which act as a sequence of special cooperative actions that span over and include multiple time steps and multiple agents, requiring agents to actively opt in for it to reach fruition. These conventions are based on existing human conventions, and result in a significant improvement on the performance of existing techniques for self-play and cross-play for various number of cooperators within Hanabi.

---

## Article 83
### Title@2025-05-24: DDO: Dual-Decision Optimization via Multi-Agent Collaboration for   LLM-Based Medical Consultation
**Title**: DDO: Dual-Decision Optimization via Multi-Agent Collaboration for   LLM-Based Medical Consultation | DDO: Dual-Decision-Optimierung durch Multi-Agent-Kollaboration für LLM-basierte medizinische Beratung | DDO:通过多方机构协作,优化基于LLM的医疗咨询的双重决定 [2505.18630v1](http://arxiv.org/abs/2505.18630v1)

**Authors**: Zhihao Jia, Mingyi Jia, Junwen Duan, Jianxin Wang

Large Language Models (LLMs) demonstrate strong generalization and reasoning abilities, making them well-suited for complex decision-making tasks such as medical consultation (MC). However, existing LLM-based methods often fail to capture the dual nature of MC, which entails two distinct sub-tasks: symptom inquiry, a sequential decision-making process, and disease diagnosis, a classification problem. This mismatch often results in ineffective symptom inquiry and unreliable disease diagnosis. To address this, we propose \textbf{DDO}, a novel LLM-based framework that performs \textbf{D}ual-\textbf{D}ecision \textbf{O}ptimization by decoupling and independently optimizing the the two sub-tasks through a collaborative multi-agent workflow. Experiments on three real-world MC datasets show that DDO consistently outperforms existing LLM-based approaches and achieves competitive performance with state-of-the-art generation-based methods, demonstrating its effectiveness in the MC task.

---

## Article 84
### Title@2025-05-24: An Identity Based Agent Model for Value Alignment
**Title**: An Identity Based Agent Model for Value Alignment | Ein identitätsbasiertes Agentenmodell für die Wertausrichtung | 基于身份的保值调整代理模型 [2401.12159v4](http://arxiv.org/abs/2401.12159v4)

**Authors**: Karthik Sama, Janvi Chhabra, Arpitha Srivatsha Malavalli, Jayati Deshmukh, Srinath Srinivasa

Social identities play an important role in the dynamics of human societies, and it can be argued that some sense of identification with a larger cause or idea plays a critical role in making humans act responsibly. Often social activists strive to get populations to identify with some cause or notion -- like green energy, diversity, etc. in order to bring about desired social changes. We explore the problem of designing computational models for social identities in the context of autonomous AI agents. For this, we propose an agent model that enables agents to identify with certain notions and show how this affects collective outcomes. We also contrast between associations of identity with rational preferences. The proposed model is simulated in an application context of urban mobility, where we show how changes in social identity affect mobility patterns and collective outcomes.

---

## Article 85
### Title@2025-05-24: MisoDICE: Multi-Agent Imitation from Unlabeled Mixed-Quality   Demonstrations
**Title**: MisoDICE: Multi-Agent Imitation from Unlabeled Mixed-Quality   Demonstrations | MisoDICE: Multi-Agent-Imitation aus nicht gekennzeichneten Mixed-Quality-Demonstrationen | MisoDICE:从未贴标签的混合质量示范中多机构吸收 [2505.18595v1](http://arxiv.org/abs/2505.18595v1)

**Authors**: The Viet Bui, Tien Mai, Hong Thanh Nguyen

We study offline imitation learning (IL) in cooperative multi-agent settings, where demonstrations have unlabeled mixed quality - containing both expert and suboptimal trajectories. Our proposed solution is structured in two stages: trajectory labeling and multi-agent imitation learning, designed jointly to enable effective learning from heterogeneous, unlabeled data. In the first stage, we combine advances in large language models and preference-based reinforcement learning to construct a progressive labeling pipeline that distinguishes expert-quality trajectories. In the second stage, we introduce MisoDICE, a novel multi-agent IL algorithm that leverages these labels to learn robust policies while addressing the computational complexity of large joint state-action spaces. By extending the popular single-agent DICE framework to multi-agent settings with a new value decomposition and mixing architecture, our method yields a convex policy optimization objective and ensures consistency between global and local policies. We evaluate MisoDICE on multiple standard multi-agent RL benchmarks and demonstrate superior performance, especially when expert data is scarce.

---

## Article 86
### Title@2025-05-24: MASTER: Multi-Agent Security Through Exploration of Roles and   Topological Structures -- A Comprehensive Framework
**Title**: MASTER: Multi-Agent Security Through Exploration of Roles and   Topological Structures -- A Comprehensive Framework | MASTER: Multi-Agent Sicherheit durch Erforschung von Rollen und topologischen Strukturen -- Ein umfassender Rahmen | 通过探索作用和地形结构实现多机构安全 -- -- 综合框架 [2505.18572v1](http://arxiv.org/abs/2505.18572v1)

**Authors**: Yifan Zhu, Chao Zhang, Xin Shi, Xueqiao Zhang, Yi Yang, Yawei Luo

Large Language Models (LLMs)-based Multi-Agent Systems (MAS) exhibit remarkable problem-solving and task planning capabilities across diverse domains due to their specialized agentic roles and collaborative interactions. However, this also amplifies the severity of security risks under MAS attacks. To address this, we introduce MASTER, a novel security research framework for MAS, focusing on diverse Role configurations and Topological structures across various scenarios. MASTER offers an automated construction process for different MAS setups and an information-flow-based interaction paradigm. To tackle MAS security challenges in varied scenarios, we design a scenario-adaptive, extensible attack strategy utilizing role and topological information, which dynamically allocates targeted, domain-specific attack tasks for collaborative agent execution. Our experiments demonstrate that such an attack, leveraging role and topological information, exhibits significant destructive potential across most models. Additionally, we propose corresponding defense strategies, substantially enhancing MAS resilience across diverse scenarios. We anticipate that our framework and findings will provide valuable insights for future research into MAS security challenges.

---

## Article 87
### Title@2025-05-24: MRGAgents: A Multi-Agent Framework for Improved Medical Report   Generation with Med-LVLMs
**Title**: MRGAgents: A Multi-Agent Framework for Improved Medical Report   Generation with Med-LVLMs | MRGAgents: Multi-Agenten-Rahmen für verbesserte medizinische Report-Generation mit Med-LVLMs | MRGGGGss: 采用医疗低水平医疗报告制改进医疗报告制的多机构框架 [2505.18530v1](http://arxiv.org/abs/2505.18530v1)

**Authors**: Pengyu Wang, Shuchang Ye, Usman Naseem, Jinman Kim

Medical Large Vision-Language Models (Med-LVLMs) have been widely adopted for medical report generation. Despite Med-LVLMs producing state-of-the-art performance, they exhibit a bias toward predicting all findings as normal, leading to reports that overlook critical abnormalities. Furthermore, these models often fail to provide comprehensive descriptions of radiologically relevant regions necessary for accurate diagnosis. To address these challenges, we proposeMedical Report Generation Agents (MRGAgents), a novel multi-agent framework that fine-tunes specialized agents for different disease categories. By curating subsets of the IU X-ray and MIMIC-CXR datasets to train disease-specific agents, MRGAgents generates reports that more effectively balance normal and abnormal findings while ensuring a comprehensive description of clinically relevant regions. Our experiments demonstrate that MRGAgents outperformed the state-of-the-art, improving both report comprehensiveness and diagnostic utility.

---

## Article 88
### Title@2025-05-24: Group Trip Planning Query Problem with Multimodal Journey
**Title**: Group Trip Planning Query Problem with Multimodal Journey | Gruppenreiseplanungs-Abfrage-Problem mit multimodaler Reise | 具有多模式旅程的问询问题 [2502.03144v2](http://arxiv.org/abs/2502.03144v2)

**Authors**: Dildar Ali, Suman Banerjee, Yamuna Prasad

In Group Trip Planning (GTP) Query Problem, we are given a city road network where a number of Points of Interest (PoI) have been marked with their respective categories (e.g., Cafeteria, Park, Movie Theater, etc.). A group of agents want to visit one PoI from every category from their respective starting location and once finished, they want to reach their respective destinations. This problem asks which PoI from every category should be chosen so that the aggregated travel cost of the group is minimized. This problem has been studied extensively in the last decade, and several solution approaches have been proposed. However, to the best of our knowledge, none of the existing studies have considered the different modalities of the journey, which makes the problem more practical. To bridge this gap, we introduce and study the GTP Query Problem with Multimodal Journey in this paper. Along with the other inputs of the GTP Query Problem, we are also given the different modalities of the journey that are available and their respective cost. Now, the problem is not only to select the PoIs from respective categories but also to select the modality of the journey. For this problem, we have proposed an efficient solution approach, which has been analyzed to understand their time and space requirements. A large number of experiments have been conducted using real-life datasets and the results have been reported. From the results, we observe that the PoIs and modality of journey recommended by the proposed solution approach lead to much less time and cost than the baseline methods.

---

## Article 89
### Title@2025-05-24: TextArena
**Title**: TextArena | TextArena | TextArenna 文本 [2504.11442v2](http://arxiv.org/abs/2504.11442v2)

**Authors**: Leon Guertler, Bobby Cheng, Simon Yu, Bo Liu, Leshem Choshen, Cheston Tan

TextArena is an open-source collection of competitive text-based games for training and evaluation of agentic behavior in Large Language Models (LLMs). It spans 57+ unique environments (including single-player, two-player, and multi-player setups) and allows for easy evaluation of model capabilities via an online-play system (against humans and other submitted models) with real-time TrueSkill scores. Traditional benchmarks rarely assess dynamic social skills such as negotiation, theory of mind, and deception, creating a gap that TextArena addresses. Designed with research, community and extensibility in mind, TextArena emphasizes ease of adding new games, adapting the framework, testing models, playing against the models, and training models. Detailed documentation of environments, games, leaderboard, and examples are available on https://github.com/LeonGuertler/TextArena and https://www.textarena.ai/.

---

## Article 90
### Title@2025-05-24: EdgeAgentX: A Novel Framework for Agentic AI at the Edge in Military   Communication Networks
**Title**: EdgeAgentX: A Novel Framework for Agentic AI at the Edge in Military   Communication Networks | EdgeAgentX: Ein neuartiges Framework für Agentische KI am Rand in militärischen Kommunikationsnetzwerken | EdgeAgengengenderX:军事通信网络边缘地带AAA剂性AI新框架 [2505.18457v1](http://arxiv.org/abs/2505.18457v1)

**Authors**: Abir Ray

This paper introduces EdgeAgentX, a novel framework integrating federated learning (FL), multi-agent reinforcement learning (MARL), and adversarial defense mechanisms, tailored for military communication networks. EdgeAgentX significantly improves autonomous decision-making, reduces latency, enhances throughput, and robustly withstands adversarial disruptions, as evidenced by comprehensive simulations.

---

## Article 91
### Title@2025-05-24: Finite-Time Global Optimality Convergence in Deep Neural Actor-Critic   Methods for Decentralized Multi-Agent Reinforcement Learning
**Title**: Finite-Time Global Optimality Convergence in Deep Neural Actor-Critic   Methods for Decentralized Multi-Agent Reinforcement Learning | Finite-Time Global Optimality Convergence in Deep Neural Actor-Critic Methoden für dezentralisiertes Mehr-Agenten-Verstärkungs-Lernen | 分散式多机构强化学习的深神经立体-集中式多机构强化学习方法中全球最佳程度趋同 [2505.18433v1](http://arxiv.org/abs/2505.18433v1)

**Authors**: Zhiyao Zhang, Myeung Suk Oh, FNU Hairi, Ziyue Luo, Alvaro Velasquez, Jia Liu

Actor-critic methods for decentralized multi-agent reinforcement learning (MARL) facilitate collaborative optimal decision making without centralized coordination, thus enabling a wide range of applications in practice. To date, however, most theoretical convergence studies for existing actor-critic decentralized MARL methods are limited to the guarantee of a stationary solution under the linear function approximation. This leaves a significant gap between the highly successful use of deep neural actor-critic for decentralized MARL in practice and the current theoretical understanding. To bridge this gap, in this paper, we make the first attempt to develop a deep neural actor-critic method for decentralized MARL, where both the actor and critic components are inherently non-linear. We show that our proposed method enjoys a global optimality guarantee with a finite-time convergence rate of O(1/T), where T is the total iteration times. This marks the first global convergence result for deep neural actor-critic methods in the MARL literature. We also conduct extensive numerical experiments, which verify our theoretical results.

---

